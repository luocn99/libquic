diff --git a/src/AUTHORS b/src/AUTHORS
deleted file mode 100644
index 058b926..0000000
--- a/src/AUTHORS
+++ /dev/null
@@ -1,771 +0,0 @@
-# Names should be added to this file with this pattern:
-#
-# For individuals:
-#   Name <email address>
-#
-# For organizations:
-#   Organization <fnmatch pattern>
-#
-# See python fnmatch module documentation for more information.
-
-Aaron Jacobs <samusaaron3@gmail.com>
-Aaron Leventhal <aaronlevbugs@gmail.com>
-Aaron Randolph <aaron.randolph@gmail.com>
-Abhijeet Kandalkar <abhijeet.k@samsung.com>
-Abhishek Agarwal <abhishek.a21@samsung.com>
-Abhishek Singh <abhi.rathore@samsung.com>
-Adam Bonner <abonner-chromium@solscope.com>
-Adam Roben <adam@github.com>
-Adam Treat <adam.treat@samsung.com>
-Addanki Gandhi Kishor <kishor.ag@samsung.com>
-Adenilson Cavalcanti <a.cavalcanti@samsung.com>
-Aditya Bhargava <heuristicist@gmail.com>
-Adrian Belgun <adrian.belgun@intel.com>
-Abhishek Kanike <abhishek.ka@samsung.com>
-Ahmet Emir Ercin <ahmetemiremir@gmail.com>
-Ajay Berwal <ajay.berwal@samsung.com>
-Ajay Berwal <a.berwal@samsung.com>
-Ajith Kumar V <ajith.v@samsung.com>
-Aku Kotkavuo <a.kotkavuo@partner.samsung.com>
-Alex Gabriel <minilogo@gmail.com>
-Alex Gartrell <agartrell@cmu.edu>
-Alex Henrie <alexhenrie24@gmail.com>
-Alex Scheele <alexscheele@gmail.com>
-Alexander Shalamov <alexander.shalamov@intel.com>
-Alexander Sulfrian <alexander@sulfrian.net>
-Alexandre Abreu <wiss1976@gmail.com>
-Alexandru Chiculita <achicu@adobe.com>
-Alexey Korepanov <alexkorep@gmail.com>
-Alexis Brenon <brenon.alexis@gmail.com>
-Alexis Menard <alexis.menard@intel.com>
-Alfredo Hernandez <ahernandez.miralles@gmail.com>
-Ali Vathi <ali.akbar@gmail.com>
-Allan Sandfeld Jensen <allan.jensen@theqtcompany.com>
-Ambarish Rapte <ambarish.r@samsung.com>
-Amit Sarkar <amit.srkr@samsung.com>
-Amogh Bihani <amogh.bihani@samsung.com>
-Amos Lim <amoseui@gmail.com>
-Amruth Raj <amruthraj@motorola.com>
-Amruth Raj <ckqr36@motorola.com>
-Anand Ratn <anand.ratn@samsung.com>
-Anastasios Cassiotis <tom.cassiotis@gmail.com>
-Ancil George <ancilgeorge@samsung.com>
-Andra Paraschiv <andra.paraschiv@intel.com>
-Andrei Parvu <andrei.prv@gmail.com>
-Andrei Parvu <parvu@adobe.com>
-Andrew Brampton <me@bramp.net>
-Andrew Hung <andrhung@amazon.com>
-Andrew Tulloch <andrew@tullo.ch>
-Anish Patankar <anish.p@samsung.com>
-Ankit Kumar <ankit2.kumar@samsung.com>
-Ankur Verma <ankur1.verma@samsung.com>
-Anne Kao <annekao94@gmail.com>
-Anssi Hannula <anssi.hannula@iki.fi>
-Anton Obzhirov <a.obzhirov@samsung.com>
-Antonin Hildebrand <antonin.hildebrand@gmail.com>
-Antonio Gomes <a1.gomes@sisa.samsung.com>
-Anuj Kumar Sharma <anujk.sharma@samsung.com>
-Arjun Karthik <arjunkar@amazon.com>
-Armin Burgmeier <aburgmeier@bloomberg.net>
-Arnaud Renevier <a.renevier@samsung.com>
-Arpita Bahuguna <a.bah@samsung.com>
-Arthur Lussos <developer0420@gmail.com>
-Arun Kulkarni <kulkarni.a@samsung.com>
-Arun Kumar <arun87.kumar@samsung.com>
-Arun Mankuzhi <arun.m@samsung.com>
-Arunoday Sarkar <a.sarkar.arun@gmail.com>
-Arunprasad Rajkumar <ararunprasad@gmail.com>
-Arunprasad Rajkumar <arurajku@cisco.com>
-Ashlin Joseph <ashlin.j@samsung.com>
-Attila Dusnoki <dati91@gmail.com>
-Avinaash Doreswamy <avi.nitk@samsung.com>
-Balazs Kelemen <b.kelemen@samsung.com>
-Baul Eun <baul.eun@samsung.com>
-Behara Mani Shyam Patro <behara.ms@samsung.com>
-Bem Jones-Bey <bemajaniman@gmail.com>
-Bem Jones-Bey <bjonesbe@adobe.com>
-Ben Fiola <benfiola@gmail.com>
-Ben Karel <eschew@gmail.com>
-Ben Noordhuis <ben@strongloop.com>
-Benjamin Dupont <bedupont@cisco.com>
-Benjamin Jemlich <pcgod99@gmail.com>
-Bernard Cafarelli <voyageur@gentoo.org>
-Bhanukrushana Rout <b.rout@samsung.com>
-Bobby Powers <bobbypowers@gmail.com>
-Branden Archer <bma4@zips.uakron.edu>
-Brendan Kirby <brendan.kirby@imgtec.com>
-Brendan Long <self@brendanlong.com>
-Brian G. Merrell <bgmerrell@gmail.com>
-Brian Konzman, SJ <b.g.konzman@gmail.com>
-Brian Luft <brian@electroly.com>
-Brian Merrell, Novell Inc. <bgmerrell@gmail.com>
-Brian Yip <itsbriany@gmail.com>
-Bruno Calvignac <bruno@flock.com>
-Bruno de Oliveira Abinader <brunoabinader@gmail.com>
-Bruno Roy <brusi_roy@hotmail.com>
-Bryan Donlan <bdonlan@gmail.com>
-Byoungkwon Ko <gogag2@gmail.com>
-Byungwoo Lee <bw80.lee@samsung.com>
-Caio Marcelo de Oliveira Filho <caio.de.oliveira.filho@intel.com>
-Caitlin Potter <caitpotter88@gmail.com>
-Calvin Mei <calvimei@amazon.com>
-Cameron Gutman <aicommander@gmail.com>
-Catalin Badea <badea@adobe.com>
-Cem Kocagil <cem.kocagil@gmail.com>
-Chakshu Ahuja <chakshu.a@samsung.com>
-Chamal De Silva <chamalsl@yahoo.com>
-Chandra Shekar Vallala <brk376@motorola.com>
-Chang Shu <c.shu@samsung.com>
-ChangSeok Oh <shivamidow@gmail.com>
-Changbin Shao <changbin.shao@intel.com>
-Changjun Yang <changjun.yang@intel.com>
-Changwan Hong <cwhong893@gmail.com>
-Changyeon Kim <cyzero.kim@samsung.com>
-Chansik Yun <chansik.yun@gmail.com>
-Chaobin Zhang <zhchbin@gmail.com>
-Chris Greene <cwgreene@amazon.com>
-Chris Harrelson <chrishtr@gmail.com>
-Chris Nardi <hichris123@gmail.com>
-Chris Tserng <tserng@amazon.com>
-Chris Vasselli <clindsay@gmail.com>
-Chris Szurgot <szurgotc@amazon.com>
-Christophe Dumez <ch.dumez@samsung.com>
-Christopher Dale <chrelad@gmail.com>
-Clemens Fruhwirth <clemens@endorphin.org>
-Clement Scheelfeldt Skau <clementskau@gmail.com>
-Clinton Staley <clintstaley@chromium.org>
-Clinton Staley <clintstaley@gmail.com>
-Craig Schlenter <craig.schlenter@gmail.com>
-Daegyu Lee <na7jun8gi@gmail.com>
-Dai Chunyang <chunyang.dai@intel.com>
-Daiwei Li <daiweili@suitabletech.com>
-Damien Marié <damien@dam.io>
-Dan McCombs <overridex@gmail.com>
-Daniel Bomar <dbdaniel42@gmail.com>
-Daniel Carvalho Liedke <dliedke@gmail.com>
-Daniel Imms <daniimms@amazon.com>
-Daniel Johnson <danielj41@gmail.com>
-Daniel Lockyer <thisisdaniellockyer@gmail.com>
-Daniel Nishi <dhnishi@gmail.com>
-Daniel Platz <daplatz@googlemail.com>
-Daniel Shaulov <dshaulov@ptc.com>
-Daniel Trebbien <dtrebbien@gmail.com>
-Daniel Waxweiler <daniel.waxweiler@gmail.com>
-Darshini KN <kn.darshini@samsung.com>
-David Benjamin <davidben@mit.edu>
-David Erceg <erceg.david@gmail.com>
-David Fox <david@davidjfox.com>
-David Futcher <david.mike.futcher@gmail.com>
-David Leen <davileen@amazon.com>
-David McAllister <mcdavid@amazon.com>
-David Spellman <dspell@amazon.com>
-Dax Kelson <dkelson@gurulabs.com>
-Debashish Samantaray <d.samantaray@samsung.com>
-Deepak Dilip Borade <deepak.db@samsung.com>
-Deepak Mittal <deepak.m1@samsung.com>
-Deepak Singla <deepak.s@samsung.com>
-Deokjin Kim <deokjin81.kim@samsung.com>
-Derek Halman <d.halman@gmail.com>
-Devlin Cronin <rdevlin.cronin@gmail.com>
-Diego Ferreiro Val <elfogris@gmail.com>
-Dillon Sellars <dill.sellars@gmail.com>
-Divya Bansal <divya.bansal@samsung.com>
-Dominic Jodoin <dominic.jodoin@gmail.com>
-Dominik Röttsches <dominik.rottsches@intel.com>
-Don Woodward <woodward@adobe.com>
-Dongie Agnir <dongie.agnir@gmail.com>
-Dongjun Kim <djmix.kim@samsung.com>
-Dongseong Hwang <dongseong.hwang@intel.com>
-Dongwoo Joshua Im <dw.im@samsung.com>
-Dongyu Lin <l2d4y3@gmail.com>
-Douglas F. Turner <doug.turner@gmail.com>
-Dustin Doloff <doloffd@amazon.com>
-Ebrahim Byagowi <ebraminio@gmail.com>
-Eduardo Lima (Etrunko) <eblima@gmail.com>
-Eduardo Lima (Etrunko) <eduardo.lima@intel.com>
-Edward Baker <edward.baker@intel.com>
-Edward Crossman <tedoc2000@gmail.com>
-Eero Häkkinen <eero.hakkinen@intel.com>
-Eero Häkkinen <e.hakkinen@samsung.com>
-Egor Starkov <egor.starkov@samsung.com>
-Ehsan Akhgari <ehsan.akhgari@gmail.com>
-Elan Ruusamäe <elan.ruusamae@gmail.com>
-Eric Ahn <byungwook.ahn@gmail.com>
-Eric Rescorla <ekr@rtfm.com>
-Erik Hill <erikghill@gmail.com>
-Erik Sjölund <erik.sjolund@gmail.com>
-Eriq Augustine <eriq.augustine@gmail.com>
-Etienne Laurin <etienne@atnnn.com>
-Evan Peterson <evan.peterson.ep@gmail.com>
-Evan Wallace <evan.exe@gmail.com>
-Evangelos Foutras <evangelos@foutrelis.com>
-Evgeniy Dushistov <dushistov@gmail.com>
-Evgeny Agafonchikov <evgeny.agafonchikov@akvelon.com>
-Fabien Tassin <fta@sofaraway.org>
-Felix H. Dahlke <fhd@ubercode.de>
-Fernando Jiménez Moreno <ferjmoreno@gmail.com>
-Finbar Crago <finbar.crago@gmail.com>
-François Beaufort <beaufort.francois@gmail.com>
-Francois Kritzinger <francoisk777@gmail.com>
-Francois Rauch <leopardb@gmail.com>
-Frédéric Jacob <frederic.jacob.78@gmail.com>
-Frédéric Wang <fred.wang@free.fr>
-Gaetano Mendola <mendola@gmail.com>
-Gajendra N <gajendra.n@samsung.com>
-Gajendra Singh <wxjg68@motorola.com>
-Gao Chun <chun.gao@intel.com>
-Gao Chun <gaochun.dev@gmail.com>
-George Liaskos <geo.liaskos@gmail.com>
-Georgy Buranov <gburanov@gmail.com>
-Gergely Nagy <ngg@ngg.hu>
-Gideon Pyzer <gjpyzer@gmail.com>
-Gitanshu Mehndiratta <g.mehndiratt@samsung.com>
-Giuseppe Iuculano <giuseppe@iuculano.it>
-Glenn Adams <glenn@chromium.org>
-Gnanasekar Somanathan <gnanasekar.s@samsung.com>
-Gordana Cmiljanovic <gordana.cmiljanovic@imgtec.com>
-Goutham Jagannatha <wrm364@motorola.com>
-Graham Yoakum <gyoakum@skobalt.com>
-Gregory Davis <gpdavis.chromium@gmail.com>
-Grzegorz Czajkowski <g.czajkowski@samsung.com>
-Guangzhen Li <guangzhen.li@intel.com>
-Gurpreet Kaur <k.gurpreet@samsung.com>
-Gustav Tiger <gustav.tiger@sonymobile.com>
-Gyuyoung Kim <gyuyoung.kim@navercorp.com>
-Gzob Qq <gzobqq@gmail.com>
-Habib Virji <habib.virji@samsung.com>
-Haitao Feng <haitao.feng@intel.com>
-Halley Zhao <halley.zhao@intel.com>
-Halton Huo <halton.huo@intel.com>
-Hans Hillen <hans.hillen@gmail.com>
-Haojian Wu <hokein.wu@gmail.com>
-Hari Singh <hari.singh1@samsung.com>
-Harpreet Singh Khurana <harpreet.sk@samsung.com>
-Harshikesh Kumar <harshikeshnobug@gmail.com>
-Hautio Kari <khautio@gmail.com>
-Heejin R. Chung <heejin.r.chung@samsung.com>
-Heeyoun Lee <heeyoun.lee@samsung.com>
-Himanshu Joshi <h.joshi@samsung.com>
-Holger Kraus <kraush@amazon.com>
-Hong Zheng <hong.zheng@intel.com>
-Hongbo Min <hongbo.min@intel.com>
-Horia Olaru <horia.olaru@gmail.com>
-Horia Olaru <olaru@adobe.com>
-Hosung You <hosung.you@samsung.com>
-Huapeng Li <huapengl@amazon.com>
-Huayong Xu <huayong.xu@samsung.com>
-Hugo Holgersson <hugo.holgersson@sonymobile.com>
-Hwanseung Lee <hs1217.lee@gmail.com>
-Hwanseung Lee <hs1217.lee@samsung.com>
-Hyunjune Kim <hyunjune.kim@samsung.com>
-Hyunki Baik <hyunki.baik@samsung.com>
-Hyungwook Lee <withlhw@gmail.com>
-Hyungwook Lee <hyungwook.lee@navercorp.com>
-Ian Cullinan <cullinan@amazon.com>
-Ian Scott <ian.scott@arteris.com>
-Ibrar Ahmed <ibrar.ahmad@gmail.com>
-Ilia K <ki.stfu@gmail.com>
-Ilya Konstantinov <ilya.konstantinov@gmail.com>
-Ion Rosca <rosca@adobe.com>
-Isaac Reilly <reillyi@amazon.com>
-Ivan Sham <ivansham@amazon.com>
-J. Ryan Stinnett <jryans@chromium.org>
-Jacob Mandelson <jacob@mandelson.org>
-Jaehun Lim <ljaehun.lim@samsung.com>
-Jaekyeom Kim <btapiz@gmail.com>
-Jaemin Seo <jaemin86.seo@samsung.com>
-Jaeseok Yoon <yjaeseok@gmail.com>
-Jaime Soriano Pastor <jsorianopastor@gmail.com>
-Jake Helfert <jake@helfert.us>
-Jakob Weigert <jakob.j.w@googlemail.com>
-Jakub Machacek <xtreit@gmail.com>
-James Choi <jchoi42@pha.jhu.edu>
-James Vega <vega.james@gmail.com>
-James Wei <james.wei@intel.com>
-James Willcox <jwillcox@litl.com>
-Jan Sauer <jan@jansauer.de>
-Janwar Dinata <j.dinata@gmail.com>
-Jared Shumway <jaredshumway94@gmail.com>
-Jared Sohn <jared.sohn@gmail.com>
-Jared Wein <weinjared@gmail.com>
-Jari Karppanen <jkarp@amazon.com>
-Jay Oster <jay@kodewerx.org>
-Jay Soffian <jaysoffian@gmail.com>
-Jeado Ko <haibane84@gmail.com>
-Jeongeun Kim <je_julie.kim@samsung.com>
-Jeongmin Kim <kimwjdalsl@gmail.com>
-Jeremy Noring <jnoring@hirevue.com>
-Jeremy Spiegel <jeremysspiegel@gmail.com>
-Jesper Storm Bache <jsbache@gmail.com>
-Jesse Miller <jesse@jmiller.biz>
-Jesus Sanchez-Palencia <jesus.sanchez-palencia.fernandez.fil@intel.com>
-Jiadong Zhu <jiadong.zhu@linaro.org>
-Jiajia Qin <jiajia.qin@intel.com>
-Jiawei Shao <jiawei.shao@intel.com>
-Jie Chen <jie.a.chen@intel.com>
-Jihoon Chung <jihoon@gmail.com>
-Jihoon Chung <j.c@navercorp.com>
-Jihun Brent Kim <devgrapher@gmail.com>
-Jin Yang <jin.a.yang@intel.com>
-Jincheol Jo <jincheol.jo@navercorp.com>
-Jingwei Liu <kingweiliu@gmail.com>
-Jingyi Wei <wjywbs@gmail.com>
-Jinho Bang <jinho.bang@samsung.com>
-Jinkyu Seong <jinkyu.seong@lge.com>
-Jinwoo Song <jinwoo7.song@samsung.com>
-Jitendra Kumar Sahoo <jitendra.ks@samsung.com>
-Joachim Bauch <mail@joachim-bauch.de>
-Joachim Bauch <jbauch@webrtc.org>
-Joe Knoll <joe.knoll@workday.com>
-Joe Thomas <mhx348@motorola.com>
-Joel Stanley <joel@jms.id.au>
-Johannes Rudolph <johannes.rudolph@googlemail.com>
-John Yani <vanuan@gmail.com>
-John Yoo <nearbyh13@gmail.com>
-Johnson Lin <johnson.lin@intel.com>
-Jonathan Frazer <listedegarde@gmail.com>
-Jonathan Garbee <jonathan@garbee.me>
-Jonathan Hacker <jhacker@arcanefour.com>
-Jongsoo Lee <leejongsoo@gmail.com>
-Joone Hur <joone.hur@intel.com>
-Jorge Villatoro <jorge@tomatocannon.com>
-Joseph Gentle <josephg@gmail.com>
-Josh Triplett <josh@joshtriplett.org>
-Josh Triplett <josh.triplett@intel.com>
-Joshua Lock <joshua.lock@intel.com>
-Joshua Roesslein <jroesslein@gmail.com>
-Josué Ratelle <jorat1346@gmail.com>
-Juhui Lee <juhui24.lee@samsung.com>
-Julien Brianceau <jbriance@cisco.com>
-Julien Isorce <j.isorce@samsung.com>
-Julien Racle <jracle@logitech.com>
-Jun Fang <jun_fang@foxitsoftware.com>
-Jun Jiang <jun.a.jiang@intel.com>
-Junchao Han <junchao.han@intel.com>
-JungJik Lee <jungjik.lee@samsung.com>
-Jungkee Song <jungkee.song@samsung.com>
-Junmin Zhu <junmin.zhu@intel.com>
-Kai Jiang <jiangkai@gmail.com>
-Kal Conley <kcconley@gmail.com>
-Kalyan Kondapally <kalyan.kondapally@intel.com>
-Kamil Jiwa <kamil.jiwa@gmail.com>
-Kamil Rytarowski <krytarowski@gmail.com>
-Kangil Han <kangil.han@samsung.com>
-Kangyuan Shu <kangyuan.shu@intel.com>
-Kartikey Bhatt <kartikey@amazon.com>
-Kaspar Brand <googlecontrib@velox.ch>
-Kaustubh Atrawalkar <kaustubh.ra@gmail.com>
-Kaustubh Atrawalkar <kaustubh.a@samsung.com>
-Keene Pan <keenepan@linpus.com>
-Keith Chen <keitchen@amazon.com>
-Kenneth Rohde Christiansen <kenneth.r.christiansen@intel.com>
-Kenneth Zhou <knthzh@gmail.com>
-Keonho Kim <keonho07.kim@samsung.com>
-Ketan Goyal <ketan.goyal@samsung.com>
-Kevin Lee Helpingstine <sig11@reprehensible.net>
-Kevin M. McCormick <mckev@amazon.com>
-Khasim Syed Mohammed <khasim.mohammed@linaro.org>
-Kihong Kwon <kihong.kwon@samsung.com>
-Kim Christensen <kimworking@gmail.com>
-Kingshuk Jana <kingshuk.j@samsung.com>
-Kirill Bobyrev <kirillbobyrev@gmail.com>
-Kirk Shoop <kirk.shoop@microsoft.com>
-Klemen Forstnerič <klemen.forstneric@gmail.com>
-Krishna Chaitanya <krish.botta@samsung.com>
-Kristof Kosztyo <kkosztyo.u-szeged@partner.samsung.com>
-Krzysztof Czech <k.czech@samsung.com>
-Krzysztof Wolanski <k.wolanski@samsung.com>
-Kunal Thakar <kunalt@gmail.com>
-Kushal Pisavadia <kushi.p@gmail.com>
-Kwangho Shin <k_h.shin@samsung.com>
-Kyle Nahrgang <kpn24@drexel.edu>
-Kyounga Ra <kyounga.ra@gmail.com>
-Kyungtae Kim <ktf.kim@samsung.com>
-Kyung Yeol Kim <chitacan@gmail.com>
-Laszlo Gombos <l.gombos@samsung.com>
-Laszlo Radanyi <bekkra@gmail.com>
-Lauren Yeun Kim <lauren.yeun.kim@gmail.com>
-Lauri Oherd <lauri.oherd@gmail.com>
-Lavar Askew <open.hyperion@gmail.com>
-Legend Lee <guanxian.li@intel.com>
-Leith Bade <leith@leithalweapon.geek.nz>
-Leo Wolf <jclw@ymail.com>
-Leon Han <leon.han@intel.com>
-Leung Wing Chung <lwchkg@gmail.com>
-Li Yin <li.yin@intel.com>
-Lidwine Genevet <lgenevet@cisco.com>
-Lionel Landwerlin <lionel.g.landwerlin@intel.com>
-Lorenzo Stoakes <lstoakes@gmail.com>
-Lu Guanqun <guanqun.lu@gmail.com>
-Lucie Brozkova <lucinka.brozkova@gmail.com>
-Luiz Von Dentz <luiz.von.dentz@intel.com>
-Luke Inman-Semerau <luke.semerau@gmail.com>
-Luke Zarko <lukezarko@gmail.com>
-Luoxi Pan <l.panpax@gmail.com>
-Maarten Lankhorst <m.b.lankhorst@gmail.com>
-Magnus Danielsson <fuzzac@gmail.com>
-Mahesh Kulkarni <mahesh.kk@samsung.com>
-Mahesh Machavolu <mahesh.ma@samsung.com>
-Maksim Sisov <maksim.sisov@intel.com>
-Malcolm Wang <malcolm.2.wang@gmail.com>
-Manish Chhajer <chhajer.m@samsung.com>
-Manojkumar Bhosale <manojkumar.bhosale@imgtec.com>
-Manuel Braun <thembrown@gmail.com>
-Mao Yujie <maojie0924@gmail.com>
-Mao Yujie <yujie.mao@intel.com>
-Marco Rodrigues <gothicx@gmail.com>
-Mario Pistrich <m.pistrich@gmail.com>
-Mario Sanchez Prada <mario.prada@samsung.com>
-Mariusz Mlynski <marius.mlynski@gmail.com>
-Mark Hahnenberg <mhahnenb@andrew.cmu.edu>
-Mark Seaborn <mrs@mythic-beasts.com>
-Martijn Croonen <martijn@martijnc.be>
-Martin Bednorz <m.s.bednorz@gmail.com>
-Martina Kollarova <martina.kollarova@intel.com>
-Masahiro Yado <yado.masa@gmail.com>
-Masaru Nishida <msr.i386@gmail.com>
-Matej Knopp <matej.knopp@gmail.com>
-Matheus Bratfisch <matheusbrat@gmail.com>
-Mathias Bynens <mathias@qiwi.be>
-Mathieu Meisser <mmeisser@logitech.com>
-Matt Arpidone <mma.public@gmail.com>
-Matt Strum <mstrum@amazon.com>
-Matt Zeunert <matt@mostlystatic.com>
-Matthew Bauer <mjbauer95@gmail.com>
-Matthew Demarest <demarem@amazon.com>
-Matthew Robertson <matthewrobertson03@gmail.com>
-Matthew Turk <matthewturk@gmail.com>
-Matthew Willis <appamatto@gmail.com>
-Matthias Reitinger <reimarvin@gmail.com>
-Max Perepelitsyn <pph34r@gmail.com>
-Max Vujovic <mvujovic@adobe.com>
-Mayur Kankanwadi <mayurk.vk@samsung.com>
-Md Sami Uddin <md.sami@samsung.com>
-Michael Cirone <mikecirone@gmail.com>
-Michael Gilbert <floppymaster@gmail.com>
-Michael Lopez <lopes92290@gmail.com>
-Michael Morrison <codebythepound@gmail.com>
-Michael Schechter <mike.schechter@gmail.com>
-Michaël Zasso <mic.besace@gmail.com>
-Michael Zugelder <michael@zugelder.org>
-Mihai Maerean <mmaerean@adobe.com>
-Mihai Tica <mihai.o.tica@gmail.com>
-Mihai Tica <mitica@adobe.com>
-Mike Tilburg <mtilburg@adobe.com>
-Mikhail Pozdnyakov <mikhail.pozdnyakov@intel.com>
-Milko Leporis <milko.leporis@imgtec.com>
-Milton Chiang <milton.chiang@mediatek.com>
-Mingmin Xie <melvinxie@gmail.com>
-Minsoo Max Koo <msu.koo@samsung.com>
-Miran Karic <miran.karic@imgtec.com>
-Mirela Budaes <mbudaes@gmail.com>
-Mirela Budaes <mbudaes@adobe.com>
-Mitchell Rosen <mitchellwrosen@chromium.org>
-Miyoung Shin <myid.shin@samsung.com>
-Mohamed I. Hammad <ibraaaa@gmail.com>
-Mohamed Mansour <m0.interactive@gmail.com>
-Mohammed Wajahat Ali Siddiqui <wajahat.s@samsung.com>
-Mohan Reddy <mohan.reddy@samsung.com>
-Mohit Bhalla <bhallam@amazon.com>
-Mrunal Kapade <mrunal.kapade@intel.com>
-Myles C. Maxfield <mymax@amazon.com>
-Nagarjuna Atluri <nagarjuna.a@samsung.com>
-Naiem Shaik <naiem.shaik@gmail.com>
-Naoki Takano <takano.naoki@gmail.com>
-Naveen Bobbili <naveenbobbili@motorola.com>
-Naveen Bobbili <qghc36@motorola.com>
-Naveen Kumar S G <naveensg@samsung.com>
-Nayan Kumar K <qtc746@motorola.com>
-Nedeljko Babic <nedeljko.babic@imgtec.com>
-Nikhil Bansal <n.bansal@samsung.com>
-Nikita Ofitserov <himikof@gmail.com>
-Nils Schneider <nils@nilsschneider.net>
-Nils Schneider <nils.schneider@gmail.com>
-Ningxin Hu <ningxin.hu@intel.com>
-Nitish Mehrotra <nitish.m@samsung.com>
-Noj Vek <nojvek@gmail.com>
-Nolan Cao <nolan.robin.cao@gmail.com>
-Omar Sandoval <osandov@osandov.com>
-Pan Deng <pan.deng@intel.com>
-Parag Radke <nrqv63@motorola.com>
-Paritosh Kumar <paritosh.in@samsung.com>
-Patrasciuc Sorin Cristian <cristian.patrasciuc@gmail.com>
-Patrick Kettner <patrickkettner@gmail.com>
-Patrick Riordan <patrickriordan177@gmail.com>
-Patrik Ackland <patrikackland@gmail.com>
-Paul Adolph <padolph@netflix.com>
-Paul Kehrer <paul.l.kehrer@gmail.com>
-Paul Lind <paul.lind@imgtec.com>
-Paul Nettleship <pnettleship@gmail.com>
-Paul Robinson <paulrobinson85@googlemail.com>
-Paul Roskell <blurrech@gmail.com>
-Paul Sapunaru <paul.sapunaru@intel.com>
-Paul Wicks <pwicks86@gmail.com>
-Pavan Kumar Emani <pavan.e@samsung.com>
-Pavel Ivanov <paivanof@gmail.com>
-Paweł Hajdan jr <phajdan.jr@gmail.com>
-Pawel Forysiuk <p.forysiuk@samsung.com>
-Peng Jiang <leiyi.jp@gmail.com>
-Peng Xinchao <pxinchao@gmail.com>
-Petar Jovanovic <petarj@mips.com>
-Peter Beverloo <peter@chromium.org>
-Peter Bright <drpizza@quiscalusmexicanus.org>
-Peter Brophy <pbrophy@adobe.com>
-Peter Collingbourne <peter@pcc.me.uk>
-Peter Gal <pgal.u-szeged@partner.samsung.com>
-Peter Molnar <pmolnar.u-szeged@partner.samsung.com>
-Philipp Hancke <fippo@andyet.net>
-Philippe Beauchamp <philippe.beauchamp@gmail.com>
-Philippe Beaudoin <philippe.beaudoin@gmail.com>
-Pierre-Antoine LaFayette <pierre.lafayette@gmail.com>
-Po-Chun Chang <pochang0403@gmail.com>
-Pramod Begur Srinath <pramod.bs@samsung.com>
-Pranay Kumar <pranay.kumar@samsung.com>
-Prashant Hiremath <prashhir@cisco.com>
-Prashant Nevase <prashant.n@samsung.com>
-Prashant Patil <prashant.patil@imgtec.com>
-Praveen Akkiraju <praveen.anp@samsung.com>
-Pritam Nikam <pritam.nikam@samsung.com>
-Puttaraju R <puttaraju.r@samsung.com>
-Qiankun Miao <qiankun.miao@intel.com>
-Qing Zhang <qing.zhang@intel.com>
-Qi Yang <qi1988.yang@samsung.com>
-Radu Stavila <stavila@adobe.com>
-Radu Velea <radu.velea@intel.com>
-Rafael Antognolli <rafael.antognolli@intel.com>
-Raghavendra Ghatage <r.ghatage@samsung.com>
-Rahul Gupta <rahul.g@samsung.com>
-Raman Tenneti <raman.tenneti@gmail.com>
-Ramkumar Gokarnesan <ramkumar.gokarnesan@gmail.com>
-Ramkumar Ramachandra <artagnon@gmail.com>
-Ramya Vadlamudi <ramya.v@samsung.com>
-Randy Posynick <randy.posynick@gmail.com>
-Raphael Kubo da Costa <raphael.kubo.da.costa@intel.com>
-Raveendra Karu <r.karu@samsung.com>
-Ravi Phaneendra Kasibhatla <r.kasibhatla@samsung.com>
-Ravi Phaneendra Kasibhatla <ravi.kasibhatla@motorola.com>
-Renata Hodovan <rhodovan.u-szeged@partner.samsung.com>
-Rene Bolldorf <rb@radix.io>
-Rene Ladan <r.c.ladan@gmail.com>
-Rijubrata Bhaumik <rijubrata.bhaumik@intel.com>
-Riku Voipio <riku.voipio@linaro.org>
-Rob Buis <rob.buis@samsung.com>
-Rob Wu <rob@robwu.nl>
-Robert Bear Travis <bear.travis@gmail.com>
-Robert Bear Travis <betravis@adobe.com>
-Robert Bradford <robert.bradford@intel.com>
-Robert Goldberg <goldberg@adobe.com>
-Robert Hogan <robhogan@gmail.com>
-Robert Nagy <robert.nagy@gmail.com>
-Robert Sesek <rsesek@bluestatic.org>
-Roland Takacs <rtakacs.u-szeged@partner.samsung.com>
-Rosen Dash <nqk836@motorola.com>
-Rosen Dash <rosen.dash@gmail.com>
-ruben <chromium@hybridsource.org>
-Ruben Terrazas <rubentopo@gmail.com>
-Rufus Hamade <rufus.hamade@imgtec.com>
-Ruiyi Luo <luoruiyi2008@gmail.com>
-Ryan Ackley <ryanackley@gmail.com>
-Ryan Norton <rnorton10@gmail.com>
-Ryan Sleevi <ryan-chromium-dev@sleevi.com>
-Ryan Yoakum <ryoakum@skobalt.com>
-Ryuan Choi <ryuan.choi@samsung.com>
-Saikrishna Arcot <saiarcot895@gmail.com>
-Salvatore Iovene <salvatore.iovene@intel.com>
-Sam Larison <qufighter@gmail.com>
-Sam McDonald <sam@sammcd.com>
-Sanghyun Park <sh919.park@samsung.com>
-Sanghyup Lee <sh53.lee@samsung.com>
-Sangwoo Ko <sangwoo108@gmail.com>
-Sanjoy Pal <ncj674@motorola.com>
-Sanjoy Pal <sanjoy.pal@samsung.com>
-Sanne Wouda <sanne.wouda@gmail.com>
-Santosh Mahto <samahto@cisco.com>
-Sarath Singapati <s.singapati@gmail.com>
-Sarath Singapati <s.singapati@samsung.com>
-Saravanan KR <sramajay@cisco.com>
-Sathish Kuppuswamy <sathish.kuppuswamy@intel.com>
-Satoshi Matsuzaki <satoshi.matsuzaki@gmail.com>
-Sayan Nayak <sayan.nayak@samsung.com>
-Scott Blomquist <sblom@microsoft.com>
-Scott D Phillips <scott.d.phillips@intel.com>
-Sean Bryant <sean@cyberwang.net>
-Seo Sanghyeon <sanxiyn@gmail.com>
-Seokju Kwon <seokju.kwon@gmail.com>
-SeongTae Jeong <ferendevelop.gl@gmail.com>
-Sergey Putilin <p.sergey@samsung.com>
-Sergey Shekyan <shekyan@gmail.com>
-Sergio Carlos Morales Angeles <carloschilazo@gmail.com>
-Sergiy Byelozyorov <rryk.ua@gmail.com>
-Seshadri Mahalingam <seshadri.mahalingam@gmail.com>
-Sevan Janiyan <venture37@geeklan.co.uk>
-Shahriar Rostami <shahriar.rostami@gmail.com>
-ShankarGanesh K <blr.bmlab@gmail.com>
-Shanmuga Pandi M <shanmuga.m@samsung.com>
-Shail Singhal <shail.s@samsung.com>
-Shaobo Yan <shaobo.yan@intel.com>
-Shashi Kumar <sk.kumar@samsung.com>
-Sherry Mou <wenjinm@amazon.com>
-Shez Baig <sbaig1@bloomberg.net>
-Shiliu Wang <aofdwsl@gmail.com>
-Shiliu Wang <shiliu.wang@intel.com>
-Shilpa Shri <shilpa.shri@samsung.com>
-Shivakumar JM <shiva.jm@samsung.com>
-Shouqun Liu <liushouqun@xiaomi.com>
-Shouqun Liu <shouqun.liu@intel.com>
-Shreeram Kushwaha <shreeram.k@samsung.com>
-Shreyas Gopal <shreyas.g@samsung.com>
-Shreyas VA <v.a.shreyas@gmail.com>
-Siba Samal <siba.samal@samsung.com>
-Simon Arlott <simon.arlott@gmail.com>
-Siva Kumar Gunturi <siva.gunturi@samsung.com>
-Sohan Jyoti Ghosh <sohan.jyoti@samsung.com>
-Song YeWen <ffmpeg@gmail.com>
-Sooho Park <sooho1000@gmail.com>
-Soren Dreijer <dreijerbit@gmail.com>
-Srirama Chandra Sekhar Mogali <srirama.m@samsung.com>
-Stephen Searles <stephen.searles@gmail.com>
-Steven Pennington <spenn@engr.uvic.ca>
-Steven Roussey <sroussey@gmail.com>
-Subrahmanya Praveen Munukutla <sataya.m@samsung.com>
-Suchit Agrawal <a.suchit@samsung.com>
-Sudarsana Babu Nagineni <sudarsana.nagineni@intel.com>
-Sudarshan Parthasarathy <sudarshan.p@samsung.com>
-Sujith S S <sujiths.s@samsung.com>
-Sungguk Lim <limasdf@gmail.com>
-Sungmann Cho <sungmann.cho@gmail.com>
-Sungmann Cho <sungmann.cho@navercorp.com>
-Sunitha Srivatsa <srivats@amazon.com>
-Suyash Sengar <suyash.s@samsung.com>
-Sunil Ratnu <sunil.ratnu@samsung.com>
-Suvanjan Mukherjee <suvanjanmukherjee@gmail.com>
-Swati Jaiswal <swa.jaiswal@samsung.com>
-Sylvain Zimmer <sylvinus@gmail.com>
-Szymon Piechowicz <szymonpiechowicz@o2.pl>
-Taehoon Lee <taylor.hoon@gmail.com>
-Takeshi Kurosawa <taken.spc@gmail.com>
-Tanay Chowdhury <tanay.c@samsung.com>
-Tapu Kumar Ghose <ghose.tapu@gmail.com>
-Taylor Price <trprice@gmail.com>
-Ted Kim <neot0000@gmail.com>
-Ted Vessenes <tedvessenes@gmail.com>
-Teodora Novkovic <teodora.petrovic@gmail.com>
-Thiago Farina <thiago.farina@gmail.com>
-Thiago Marcos P. Santos <thiago.santos@intel.com>
-Thomas Butter <tbutter@gmail.com>
-Thomas Conti <tomc@amazon.com>
-Tiago Vignatti <tiago.vignatti@intel.com>
-Tim Ansell <mithro@mithis.com>
-Tim Niederhausen <tim@rnc-ag.de>
-Timo Reimann <ttr314@googlemail.com>
-Tom Harwood <tfh@skip.org>
-Torsten Kurbad <google@tk-webart.de>
-Tomas Popela <tomas.popela@gmail.com>
-Trevor Perrin <unsafe@trevp.net>
-U. Artie Eoff <ullysses.a.eoff@intel.com>
-Umar Hansa <umar.hansa@gmail.com>
-Upendra Gowda <upendrag.gowda@gmail.com>
-Vaibhav Agrawal <vaibhav1.a@samsung.com>
-Valentin Ilie <valentin.ilie@intel.com>
-Vamshikrishna Yellenki <vamshi@motorola.com>
-Vani Hegde <vani.hegde@samsung.com>
-Vartul Katiyar <vartul.k@samsung.com>
-Vedran Šajatović <vedran.sajatovic@gmail.com>
-Vernon Tang <vt@foilhead.net>
-Viatcheslav Ostapenko <sl.ostapenko@samsung.com>
-Victor Costan <costan@gmail.com>
-Viet-Trung Luu <viettrungluu@gmail.com>
-Vinay Anantharaman <vinaya@adobe.com>
-Vipul Bhasin <vipul.bhasin@gmail.com>
-Visa Putkinen <v.putkinen@partner.samsung.com>
-Vivek Galatage <vivek.vg@samsung.com>
-Volker Sorge <volker.sorge@gmail.com>
-Waihung Fu <fufranci@amazon.com>
-Wesley Lancel <wesleylancel@gmail.com>
-Wesley Wigham <t-weswig@microsoft.com>
-Wesley Wigham <wwigham@gmail.com>
-Will Hirsch <chromium@willhirsch.co.uk>
-Will Shackleton <w.shackleton@gmail.com>
-William Xie <william.xie@chromium.com>
-William Xie <william.xie@intel.com>
-Xiang Long <xiang.long@intel.com>
-Xiangze Zhang <xiangze.zhang@intel.com>
-Xiaolei Yu <dreifachstein@gmail.com>
-Xinchao He <hexinchao@gmail.com>
-Xing Zhang <xzhang@adobe.com>
-Xinghua Cao <xinghua.cao@intel.com>
-Xu Samuel <samuel.xu@intel.com>
-Xu Xing <xing.xu@intel.com>
-Xuefei Ren <xrenishere@gmail.com>
-Xun Sun <xun.sun@intel.com>
-Yael Aharon <yael.aharon@intel.com>
-Yair Yogev <progame@chromium.org>
-Yang Gu <yang.gu@intel.com>
-Yarin Kaul <yarin.kaul@gmail.com>
-Ye Liu <cbakgly@gmail.com>
-Yi Shen <yi.shen@samsung.com>
-Yi Sun <ratsunny@gmail.com>
-Yoav Weiss <yoav@yoav.ws>
-Yoav Zilberberg <yoav.zilberberg@gmail.com>
-Yong Shin <sy3620@gmail.com>
-Yongsheng Zhu <yongsheng.zhu@intel.com>
-Yoshinori Sano <yoshinori.sano@gmail.com>
-Youngho Seo <hazivoo@gmail.com>
-YoungKi Hong <simon.hong81@gmail.com>
-Youngmin Yoo <youngmin.yoo@samsung.com>
-Youngsoo Choi <kenshin.choi@samsung.com>
-Youngsun Suh <zard17@gmail.com>
-Yumikiyo Osanai <yumios.art@gmail.com>
-Yunchao He <yunchao.he@intel.com>
-Yuri Gorobets <yuri.gorobets@gmail.com>
-Zeno Albisser <zeno.albisser@digia.com>
-Zhaoze Zhou <zhaoze.zhou@partner.samsung.com>
-Zheng Chuang <zhengchuangscu@gmail.com>
-Zhenyu Liang <zhenyu.liang@intel.com>
-Zhenyu Shan <zhenyu.shan@intel.com>
-Zhuoyu Qian <zhuoyu.qian@samsung.com>
-Ziran Sun <ziran.sun@samsung.com>
-Zoltan Herczeg <zherczeg.u-szeged@partner.samsung.com>
-Zoltan Kuscsik <zoltan.kuscsik@linaro.org>
-Zsolt Borbely <zsborbely.u-szeged@partner.samsung.com>
-Yongha Lee <yongha78.lee@samsung.com>
-方觉 (Fang Jue) <fangjue23303@gmail.com>
-Yupei Wang <perryuwang@tencent.com>
-Peng Hu <penghu@tencent.com>
-WenSheng He <wensheng.he@samsung.com>
-Raghu Ram Nagaraj <r.nagaraj@samsung.com>
-Chanho Park <parkch98@gmail.com>
-Payal Pandey <payal.pandey@samsung.com>
-Kenneth Strickland <ken.strickland@gmail.com>
-Olli Raula (Old name Olli Syrjälä) <olli.raula@intel.com>
-Vishal Bhatnagar <vishal.b@samsung.com>
-Yunsik Jang <yunsik.jang@lge.com>
-Siddharth Bagai <b.siddharth@samsung.com>
-Andrei Borza <andrei.borza@gmail.com>
-anatoly techtonik <techtonik@gmail.com>
-Aleksandar Stojiljkovic <aleksandar.stojiljkovic@intel.com>
-Marc des Garets <marc.desgarets@googlemail.com>
-Siddharth Shankar <funkysidd@gmail.com>
-Eden Wang <nedenwang@tencent.com>
-Cathie Chen <cathiechen@tencent.com>
-Kyle Plumadore <kyle.plumadore@amd.com>
-Sunchang Li <johnstonli@tencent.com>
-
-BlackBerry Limited <*@blackberry.com>
-Code Aurora Forum <*@codeaurora.org>
-Comodo CA Limited
-Endless Mobile, Inc. <*@endlessm.com>
-Google Inc. <*@google.com>
-Hewlett-Packard Development Company, L.P. <*@hp.com>
-Igalia S.L. <*@igalia.com>
-NVIDIA Corporation <*@nvidia.com>
-Opera Software ASA <*@opera.com>
-Spotify AB <*@spotify.com>
-TeamSpeak Systems GmbH <*@teamspeak.com>
-The Chromium Authors <*@chromium.org>
-The MathWorks, Inc. <binod.pant@mathworks.com>
-Torchmobile Inc.
-Venture 3 Systems LLC <*@venture3systems.com>
-Yandex LLC <*@yandex-team.ru>
-ARM Holdings <*@arm.com>
-Macadamian <*@macadamian.com>
diff --git a/src/base/allocator/allocator_shim.cc b/src/base/allocator/allocator_shim.cc
index 95480ea..a9fc095 100644
--- a/src/base/allocator/allocator_shim.cc
+++ b/src/base/allocator/allocator_shim.cc
@@ -39,18 +39,6 @@ bool g_call_new_handler_on_malloc_failure = false;
 subtle::Atomic32 g_new_handler_lock = 0;
 #endif
 
-// In theory this should be just base::ThreadChecker. But we can't afford
-// the luxury of a LazyInstance<ThreadChecker> here as it would cause a new().
-bool CalledOnValidThread() {
-  using subtle::Atomic32;
-  const Atomic32 kInvalidTID = static_cast<Atomic32>(kInvalidThreadId);
-  static Atomic32 g_tid = kInvalidTID;
-  Atomic32 cur_tid = static_cast<Atomic32>(PlatformThread::CurrentId());
-  Atomic32 prev_tid =
-      subtle::NoBarrier_CompareAndSwap(&g_tid, kInvalidTID, cur_tid);
-  return prev_tid == kInvalidTID || prev_tid == cur_tid;
-}
-
 inline size_t GetCachedPageSize() {
   static size_t pagesize = 0;
   if (!pagesize)
@@ -112,25 +100,35 @@ void* UncheckedAlloc(size_t size) {
 }
 
 void InsertAllocatorDispatch(AllocatorDispatch* dispatch) {
-  // Ensure this is always called on the same thread.
-  DCHECK(CalledOnValidThread());
-
-  dispatch->next = GetChainHead();
-
-  // This function does not guarantee to be thread-safe w.r.t. concurrent
-  // insertions, but still has to guarantee that all the threads always
-  // see a consistent chain, hence the MemoryBarrier() below.
-  // InsertAllocatorDispatch() is NOT a fastpath, as opposite to malloc(), so
-  // we don't really want this to be a release-store with a corresponding
-  // acquire-load during malloc().
-  subtle::MemoryBarrier();
+  // Loop in case of (an unlikely) race on setting the list head.
+  size_t kMaxRetries = 7;
+  for (size_t i = 0; i < kMaxRetries; ++i) {
+    const AllocatorDispatch* chain_head = GetChainHead();
+    dispatch->next = chain_head;
+
+    // This function guarantees to be thread-safe w.r.t. concurrent
+    // insertions. It also has to guarantee that all the threads always
+    // see a consistent chain, hence the MemoryBarrier() below.
+    // InsertAllocatorDispatch() is NOT a fastpath, as opposite to malloc(), so
+    // we don't really want this to be a release-store with a corresponding
+    // acquire-load during malloc().
+    subtle::MemoryBarrier();
+    subtle::AtomicWord old_value =
+        reinterpret_cast<subtle::AtomicWord>(chain_head);
+    // Set the chain head to the new dispatch atomically. If we lose the race,
+    // the comparison will fail, and the new head of chain will be returned.
+    if (subtle::NoBarrier_CompareAndSwap(
+            &g_chain_head, old_value,
+            reinterpret_cast<subtle::AtomicWord>(dispatch)) == old_value) {
+      // Success.
+      return;
+    }
+  }
 
-  subtle::NoBarrier_Store(&g_chain_head,
-                          reinterpret_cast<subtle::AtomicWord>(dispatch));
+  CHECK(false);  // Too many retries, this shouldn't happen.
 }
 
 void RemoveAllocatorDispatchForTesting(AllocatorDispatch* dispatch) {
-  DCHECK(CalledOnValidThread());
   DCHECK_EQ(GetChainHead(), dispatch);
   subtle::NoBarrier_Store(&g_chain_head,
                           reinterpret_cast<subtle::AtomicWord>(dispatch->next));
diff --git a/src/base/allocator/allocator_shim.h b/src/base/allocator/allocator_shim.h
index aca13d2..8fd060f 100644
--- a/src/base/allocator/allocator_shim.h
+++ b/src/base/allocator/allocator_shim.h
@@ -86,10 +86,10 @@ BASE_EXPORT void SetCallNewHandlerOnMallocFailure(bool value);
 // regardless of SetCallNewHandlerOnMallocFailure().
 BASE_EXPORT void* UncheckedAlloc(size_t size);
 
-// Inserts |dispatch| in front of the allocator chain. This method is NOT
+// Inserts |dispatch| in front of the allocator chain. This method is
 // thread-safe w.r.t concurrent invocations of InsertAllocatorDispatch().
-// The callers have the responsibility of linearizing the changes to the chain
-// (or more likely call these always on the same thread).
+// The callers have responsibility for inserting a single dispatch no more
+// than once.
 BASE_EXPORT void InsertAllocatorDispatch(AllocatorDispatch* dispatch);
 
 // Test-only. Rationale: (1) lack of use cases; (2) dealing safely with a
diff --git a/src/base/allocator/allocator_shim_override_glibc_weak_symbols.h b/src/base/allocator/allocator_shim_override_glibc_weak_symbols.h
index dda49aa..7949399 100644
--- a/src/base/allocator/allocator_shim_override_glibc_weak_symbols.h
+++ b/src/base/allocator/allocator_shim_override_glibc_weak_symbols.h
@@ -105,5 +105,6 @@ SHIM_ALWAYS_EXPORT int __posix_memalign(void** r, size_t a, size_t s)
 
 // Safety check.
 #if !defined(__GLIBC__)
-#error The current platform does not seem to use Glibc.
+#error The target platform does not seem to use Glibc. Disable the allocator \
+shim by setting use_experimental_allocator_shim=false in GN args.
 #endif
diff --git a/src/base/android/build_info.h b/src/base/android/build_info.h
index 16e7e9c..cce74f4 100644
--- a/src/base/android/build_info.h
+++ b/src/base/android/build_info.h
@@ -26,7 +26,8 @@ enum SdkVersion {
   SDK_VERSION_KITKAT_WEAR = 20,
   SDK_VERSION_LOLLIPOP = 21,
   SDK_VERSION_LOLLIPOP_MR1 = 22,
-  SDK_VERSION_MARSHMALLOW = 23
+  SDK_VERSION_MARSHMALLOW = 23,
+  SDK_VERSION_NOUGAT = 24
 };
 
 // BuildInfo is a singleton class that stores android build and device
diff --git a/src/base/android/java_message_handler_factory.h b/src/base/android/java_message_handler_factory.h
index ea1bd79..801617d 100644
--- a/src/base/android/java_message_handler_factory.h
+++ b/src/base/android/java_message_handler_factory.h
@@ -11,6 +11,7 @@
 namespace base {
 
 class MessagePumpForUI;
+class WaitableEvent;
 
 namespace android {
 
diff --git a/src/base/android/jni_android.cc b/src/base/android/jni_android.cc
index c342218..02e264c 100644
--- a/src/base/android/jni_android.cc
+++ b/src/base/android/jni_android.cc
@@ -11,8 +11,10 @@
 #include "base/android/build_info.h"
 #include "base/android/jni_string.h"
 #include "base/android/jni_utils.h"
+#include "base/debug/debugging_flags.h"
 #include "base/lazy_instance.h"
 #include "base/logging.h"
+#include "base/threading/thread_local.h"
 
 namespace {
 using base::android::GetClass;
@@ -26,6 +28,11 @@ base::LazyInstance<base::android::ScopedJavaGlobalRef<jobject> >::Leaky
     g_class_loader = LAZY_INSTANCE_INITIALIZER;
 jmethodID g_class_loader_load_class_method_id = 0;
 
+#if BUILDFLAG(ENABLE_PROFILING) && HAVE_TRACE_STACK_FRAME_POINTERS
+base::LazyInstance<base::ThreadLocalPointer<void>>::Leaky
+    g_stack_frame_pointer = LAZY_INSTANCE_INITIALIZER;
+#endif
+
 }  // namespace
 
 namespace base {
@@ -282,6 +289,22 @@ std::string GetJavaExceptionInfo(JNIEnv* env, jthrowable java_throwable) {
   return ConvertJavaStringToUTF8(exception_string);
 }
 
+#if BUILDFLAG(ENABLE_PROFILING) && HAVE_TRACE_STACK_FRAME_POINTERS
+
+JNIStackFrameSaver::JNIStackFrameSaver(void* current_fp) {
+  previous_fp_ = g_stack_frame_pointer.Pointer()->Get();
+  g_stack_frame_pointer.Pointer()->Set(current_fp);
+}
+
+JNIStackFrameSaver::~JNIStackFrameSaver() {
+  g_stack_frame_pointer.Pointer()->Set(previous_fp_);
+}
+
+void* JNIStackFrameSaver::SavedFrame() {
+  return g_stack_frame_pointer.Pointer()->Get();
+}
+
+#endif  // ENABLE_PROFILING && HAVE_TRACE_STACK_FRAME_POINTERS
 
 }  // namespace android
 }  // namespace base
diff --git a/src/base/android/jni_android.h b/src/base/android/jni_android.h
index 909e3da..9674653 100644
--- a/src/base/android/jni_android.h
+++ b/src/base/android/jni_android.h
@@ -14,6 +14,39 @@
 #include "base/atomicops.h"
 #include "base/base_export.h"
 #include "base/compiler_specific.h"
+#include "base/debug/stack_trace.h"
+#include "base/macros.h"
+
+#if HAVE_TRACE_STACK_FRAME_POINTERS
+
+// When profiling is enabled (enable_profiling=true) this macro is added to
+// all generated JNI stubs so that it becomes the last thing that runs before
+// control goes into Java.
+//
+// This macro saves stack frame pointer of the current function. Saved value
+// used later by JNI_LINK_SAVED_FRAME_POINTER.
+#define JNI_SAVE_FRAME_POINTER \
+  base::android::JNIStackFrameSaver jni_frame_saver(__builtin_frame_address(0))
+
+// When profiling is enabled (enable_profiling=true) this macro is added to
+// all generated JNI callbacks so that it becomes the first thing that runs
+// after control returns from Java.
+//
+// This macro links stack frame of the current function to the stack frame
+// saved by JNI_SAVE_FRAME_POINTER, allowing frame-based unwinding
+// (used by the heap profiler) to produce complete traces.
+#define JNI_LINK_SAVED_FRAME_POINTER                    \
+  base::debug::ScopedStackFrameLinker jni_frame_linker( \
+      __builtin_frame_address(0),                       \
+      base::android::JNIStackFrameSaver::SavedFrame())
+
+#else
+
+// Frame-based stack unwinding is not supported, do nothing.
+#define JNI_SAVE_FRAME_POINTER
+#define JNI_LINK_SAVED_FRAME_POINTER
+
+#endif  // HAVE_TRACE_STACK_FRAME_POINTERS
 
 namespace base {
 namespace android {
@@ -122,6 +155,24 @@ BASE_EXPORT void CheckException(JNIEnv* env);
 BASE_EXPORT std::string GetJavaExceptionInfo(JNIEnv* env,
                                              jthrowable java_throwable);
 
+#if HAVE_TRACE_STACK_FRAME_POINTERS
+
+// Saves caller's PC and stack frame in a thread-local variable.
+// Implemented only when profiling is enabled (enable_profiling=true).
+class BASE_EXPORT JNIStackFrameSaver {
+ public:
+  JNIStackFrameSaver(void* current_fp);
+  ~JNIStackFrameSaver();
+  static void* SavedFrame();
+
+ private:
+  void* previous_fp_;
+
+  DISALLOW_COPY_AND_ASSIGN(JNIStackFrameSaver);
+};
+
+#endif  // HAVE_TRACE_STACK_FRAME_POINTERS
+
 }  // namespace android
 }  // namespace base
 
diff --git a/src/base/android/scoped_java_ref.h b/src/base/android/scoped_java_ref.h
index c844c8d..6d728e9 100644
--- a/src/base/android/scoped_java_ref.h
+++ b/src/base/android/scoped_java_ref.h
@@ -44,13 +44,16 @@ template<typename T> class JavaRef;
 template<>
 class BASE_EXPORT JavaRef<jobject> {
  public:
+  // Initializes a null reference. Don't add anything else here; it's inlined.
+  JavaRef() : obj_(nullptr) {}
+
   // Allow nullptr to be converted to JavaRef. This avoids having to declare an
-  // empty ScopedJavaLocalRef just to pass null to a function with a JavaRef
-  // parameter, and makes C++ "nullptr" and Java "null" equivalent.
+  // empty JavaRef just to pass null to a function, and makes C++ "nullptr" and
+  // Java "null" equivalent.
   JavaRef(std::nullptr_t) : JavaRef() {}
 
-  // Public to allow destruction of temporary JavaRef objects created by the
-  // nullptr conversion. Don't add anything else here; it's inlined.
+  // Public to allow destruction of null JavaRef objects.
+  // Don't add anything else here; it's inlined.
   ~JavaRef() {}
 
   jobject obj() const { return obj_; }
@@ -58,9 +61,6 @@ class BASE_EXPORT JavaRef<jobject> {
   bool is_null() const { return obj_ == nullptr; }
 
  protected:
-  // Initializes a null reference. Don't add anything else here; it's inlined.
-  JavaRef() : obj_(nullptr) {}
-
   // Takes ownership of the |obj| reference passed; requires it to be a local
   // reference type.
 #if DCHECK_IS_ON()
@@ -93,14 +93,13 @@ class BASE_EXPORT JavaRef<jobject> {
 template<typename T>
 class JavaRef : public JavaRef<jobject> {
  public:
+  JavaRef() {}
   JavaRef(std::nullptr_t) : JavaRef<jobject>(nullptr) {}
   ~JavaRef() {}
 
   T obj() const { return static_cast<T>(JavaRef<jobject>::obj()); }
 
  protected:
-  JavaRef() {}
-
   JavaRef(JNIEnv* env, T obj) : JavaRef<jobject>(env, obj) {}
 
  private:
@@ -161,13 +160,14 @@ class ScopedJavaLocalRef : public JavaRef<T> {
     this->swap(other);
   }
 
-  template <typename U>
-  explicit ScopedJavaLocalRef(const U& other) : env_(nullptr) {
+  explicit ScopedJavaLocalRef(const JavaRef<T>& other) : env_(nullptr) {
     this->Reset(other);
   }
 
   // Assumes that |obj| is a local reference to a Java object and takes
   // ownership  of this local reference.
+  // TODO(torne): this shouldn't be used outside of JNI helper functions but
+  // there are currently some cases where there aren't helpers for things.
   ScopedJavaLocalRef(JNIEnv* env, T obj) : JavaRef<T>(env, obj), env_(env) {}
 
   ~ScopedJavaLocalRef() {
@@ -189,27 +189,23 @@ class ScopedJavaLocalRef : public JavaRef<T> {
     this->ResetLocalRef(env_);
   }
 
-  template<typename U>
-  void Reset(const ScopedJavaLocalRef<U>& other) {
+  void Reset(const ScopedJavaLocalRef<T>& other) {
     // We can copy over env_ here as |other| instance must be from the same
     // thread as |this| local ref. (See class comment for multi-threading
     // limitations, and alternatives).
     this->Reset(other.env_, other.obj());
   }
 
-  template<typename U>
-  void Reset(const U& other) {
+  void Reset(const JavaRef<T>& other) {
     // If |env_| was not yet set (is still null) it will be attached to the
     // current thread in SetNewLocalRef().
     this->Reset(env_, other.obj());
   }
 
-  template<typename U>
-  void Reset(JNIEnv* env, U obj) {
-    static_assert(std::is_convertible<U, T>::value,
-                  "U must be convertible to T");
-    env_ = this->SetNewLocalRef(env, obj);
-  }
+  // Creates a new local reference to the Java object, unlike the constructor
+  // with the same parameters that takes ownership of the existing reference.
+  // TODO(torne): these should match as this is confusing.
+  void Reset(JNIEnv* env, T obj) { env_ = this->SetNewLocalRef(env, obj); }
 
   // Releases the local reference to the caller. The caller *must* delete the
   // local reference when it is done with it. Note that calling a Java method
@@ -249,10 +245,7 @@ class ScopedJavaGlobalRef : public JavaRef<T> {
 
   ScopedJavaGlobalRef(JNIEnv* env, T obj) { this->Reset(env, obj); }
 
-  template<typename U>
-  explicit ScopedJavaGlobalRef(const U& other) {
-    this->Reset(other);
-  }
+  explicit ScopedJavaGlobalRef(const JavaRef<T>& other) { this->Reset(other); }
 
   ~ScopedJavaGlobalRef() {
     this->Reset();
@@ -270,22 +263,13 @@ class ScopedJavaGlobalRef : public JavaRef<T> {
     this->ResetGlobalRef();
   }
 
-  template<typename U>
-  void Reset(const U& other) {
-    this->Reset(nullptr, other.obj());
-  }
+  void Reset(const JavaRef<T>& other) { this->Reset(nullptr, other.obj()); }
 
-  template<typename U>
-  void Reset(JNIEnv* env, const JavaParamRef<U>& other) {
+  void Reset(JNIEnv* env, const JavaParamRef<T>& other) {
     this->Reset(env, other.obj());
   }
 
-  template<typename U>
-  void Reset(JNIEnv* env, U obj) {
-    static_assert(std::is_convertible<U, T>::value,
-                  "U must be convertible to T");
-    this->SetNewGlobalRef(env, obj);
-  }
+  void Reset(JNIEnv* env, T obj) { this->SetNewGlobalRef(env, obj); }
 
   // Releases the global reference to the caller. The caller *must* delete the
   // global reference when it is done with it. Note that calling a Java method
diff --git a/src/base/atomic_ref_count.h b/src/base/atomic_ref_count.h
index 2ab7242..93c1f0d 100644
--- a/src/base/atomic_ref_count.h
+++ b/src/base/atomic_ref_count.h
@@ -12,7 +12,7 @@
 
 namespace base {
 
-typedef subtle::Atomic32 AtomicRefCount;
+typedef subtle::AtomicWord AtomicRefCount;
 
 // Increment a reference count by "increment", which must exceed 0.
 inline void AtomicRefCountIncN(volatile AtomicRefCount *ptr,
diff --git a/src/base/base_paths_posix.cc b/src/base/base_paths_posix.cc
index a60e112..baba3cd 100644
--- a/src/base/base_paths_posix.cc
+++ b/src/base/base_paths_posix.cc
@@ -36,8 +36,8 @@ namespace base {
 bool PathProviderPosix(int key, FilePath* result) {
   FilePath path;
   switch (key) {
-    case base::FILE_EXE:
-    case base::FILE_MODULE: {  // TODO(evanm): is this correct?
+    case FILE_EXE:
+    case FILE_MODULE: {  // TODO(evanm): is this correct?
 #if defined(OS_LINUX)
       FilePath bin_dir;
       if (!ReadSymbolicLink(FilePath(kProcSelfExe), &bin_dir)) {
@@ -77,24 +77,23 @@ bool PathProviderPosix(int key, FilePath* result) {
       return true;
 #endif
     }
-    case base::DIR_SOURCE_ROOT: {
+    case DIR_SOURCE_ROOT: {
       // Allow passing this in the environment, for more flexibility in build
       // tree configurations (sub-project builds, gyp --output_dir, etc.)
-      std::unique_ptr<base::Environment> env(base::Environment::Create());
+      std::unique_ptr<Environment> env(Environment::Create());
       std::string cr_source_root;
       if (env->GetVar("CR_SOURCE_ROOT", &cr_source_root)) {
         path = FilePath(cr_source_root);
-        if (base::PathExists(path)) {
+        if (PathExists(path)) {
           *result = path;
           return true;
-        } else {
-          DLOG(WARNING) << "CR_SOURCE_ROOT is set, but it appears to not "
-                        << "point to a directory.";
         }
+        DLOG(WARNING) << "CR_SOURCE_ROOT is set, but it appears to not "
+                      << "point to a directory.";
       }
       // On POSIX, unit tests execute two levels deep from the source root.
       // For example:  out/{Debug|Release}/net_unittest
-      if (PathService::Get(base::DIR_EXE, &path)) {
+      if (PathService::Get(DIR_EXE, &path)) {
         *result = path.DirName().DirName();
         return true;
       }
@@ -103,13 +102,13 @@ bool PathProviderPosix(int key, FilePath* result) {
                   << "Try running from your chromium/src directory.";
       return false;
     }
-    case base::DIR_USER_DESKTOP:
-      *result = base::nix::GetXDGUserDirectory("DESKTOP", "Desktop");
+    case DIR_USER_DESKTOP:
+      *result = nix::GetXDGUserDirectory("DESKTOP", "Desktop");
       return true;
-    case base::DIR_CACHE: {
-      std::unique_ptr<base::Environment> env(base::Environment::Create());
-      FilePath cache_dir(base::nix::GetXDGDirectory(env.get(), "XDG_CACHE_HOME",
-                                                    ".cache"));
+    case DIR_CACHE: {
+      std::unique_ptr<Environment> env(Environment::Create());
+      FilePath cache_dir(
+          nix::GetXDGDirectory(env.get(), "XDG_CACHE_HOME", ".cache"));
       *result = cache_dir;
       return true;
     }
diff --git a/src/base/bind.h b/src/base/bind.h
index ec707a0..ce71797 100644
--- a/src/base/bind.h
+++ b/src/base/bind.h
@@ -23,7 +23,6 @@
 // terms and concepts.
 
 namespace base {
-namespace internal {
 
 // Bind as OnceCallback.
 template <typename Functor, typename... Args>
@@ -69,16 +68,14 @@ BindRepeating(Functor&& functor, Args&&... args) {
       std::forward<Args>(args)...));
 }
 
-}  // namespace internal
-
 // Unannotated Bind.
 // TODO(tzik): Deprecate this and migrate to OnceCallback and
 // RepeatingCallback, once they get ready.
 template <typename Functor, typename... Args>
 inline Callback<MakeUnboundRunType<Functor, Args...>>
 Bind(Functor&& functor, Args&&... args) {
-  return internal::BindRepeating(std::forward<Functor>(functor),
-                                 std::forward<Args>(args)...);
+  return BindRepeating(std::forward<Functor>(functor),
+                       std::forward<Args>(args)...);
 }
 
 }  // namespace base
diff --git a/src/base/bind_helpers.h b/src/base/bind_helpers.h
index c7c7be8..1e65225 100644
--- a/src/base/bind_helpers.h
+++ b/src/base/bind_helpers.h
@@ -179,6 +179,9 @@ struct BindUnwrapTraits;
 
 namespace internal {
 
+template <typename Functor, typename SFINAE = void>
+struct FunctorTraits;
+
 template <typename T>
 class UnretainedWrapper {
  public:
@@ -521,6 +524,48 @@ struct BindUnwrapTraits<internal::PassedWrapper<T>> {
   }
 };
 
+// CallbackCancellationTraits allows customization of Callback's cancellation
+// semantics. By default, callbacks are not cancellable. A specialization should
+// set is_cancellable = true and implement an IsCancelled() that returns if the
+// callback should be cancelled.
+template <typename Functor, typename BoundArgsTuple, typename SFINAE = void>
+struct CallbackCancellationTraits {
+  static constexpr bool is_cancellable = false;
+};
+
+// Specialization for method bound to weak pointer receiver.
+template <typename Functor, typename... BoundArgs>
+struct CallbackCancellationTraits<
+    Functor,
+    std::tuple<BoundArgs...>,
+    typename std::enable_if<
+        internal::IsWeakMethod<internal::FunctorTraits<Functor>::is_method,
+                               BoundArgs...>::value>::type> {
+  static constexpr bool is_cancellable = true;
+
+  template <typename Receiver, typename... Args>
+  static bool IsCancelled(const Functor&,
+                          const Receiver& receiver,
+                          const Args&...) {
+    return !receiver;
+  }
+};
+
+// Specialization for a nested bind.
+template <typename Signature,
+          typename... BoundArgs,
+          internal::CopyMode copy_mode,
+          internal::RepeatMode repeat_mode>
+struct CallbackCancellationTraits<Callback<Signature, copy_mode, repeat_mode>,
+                                  std::tuple<BoundArgs...>> {
+  static constexpr bool is_cancellable = true;
+
+  template <typename Functor>
+  static bool IsCancelled(const Functor& functor, const BoundArgs&...) {
+    return functor.IsCancelled();
+  }
+};
+
 }  // namespace base
 
 #endif  // BASE_BIND_HELPERS_H_
diff --git a/src/base/bind_internal.h b/src/base/bind_internal.h
index 5845a4d..8988bdc 100644
--- a/src/base/bind_internal.h
+++ b/src/base/bind_internal.h
@@ -130,7 +130,7 @@ struct ForceVoidReturn<R(Args...)> {
 // FunctorTraits<>
 //
 // See description at top of file.
-template <typename Functor, typename SFINAE = void>
+template <typename Functor, typename SFINAE>
 struct FunctorTraits;
 
 // For a callable type that is convertible to the corresponding function type.
@@ -387,39 +387,41 @@ IsNull(const Functor&) {
   return false;
 }
 
-template <typename Functor, typename... BoundArgs>
-struct BindState;
+// Used by ApplyCancellationTraits below.
+template <typename Functor, typename BoundArgsTuple, size_t... indices>
+bool ApplyCancellationTraitsImpl(const Functor& functor,
+                                 const BoundArgsTuple& bound_args,
+                                 IndexSequence<indices...>) {
+  return CallbackCancellationTraits<Functor, BoundArgsTuple>::IsCancelled(
+      functor, base::get<indices>(bound_args)...);
+}
 
-template <typename BindStateType, typename SFINAE = void>
-struct CancellationChecker {
-  static constexpr bool is_cancellable = false;
-  static bool Run(const BindStateBase*) {
-    return false;
-  }
+// Relays |base| to corresponding CallbackCancellationTraits<>::Run(). Returns
+// true if the callback |base| represents is canceled.
+template <typename BindStateType>
+bool ApplyCancellationTraits(const BindStateBase* base) {
+  const BindStateType* storage = static_cast<const BindStateType*>(base);
+  static constexpr size_t num_bound_args =
+      std::tuple_size<decltype(storage->bound_args_)>::value;
+  return ApplyCancellationTraitsImpl(storage->functor_, storage->bound_args_,
+                                     MakeIndexSequence<num_bound_args>());
 };
 
+// Template helpers to detect using Bind() on a base::Callback without any
+// additional arguments. In that case, the original base::Callback object should
+// just be directly used.
 template <typename Functor, typename... BoundArgs>
-struct CancellationChecker<
-    BindState<Functor, BoundArgs...>,
-    typename std::enable_if<IsWeakMethod<FunctorTraits<Functor>::is_method,
-                                         BoundArgs...>::value>::type> {
-  static constexpr bool is_cancellable = true;
-  static bool Run(const BindStateBase* base) {
-    using BindStateType = BindState<Functor, BoundArgs...>;
-    const BindStateType* bind_state = static_cast<const BindStateType*>(base);
-    return !base::get<0>(bind_state->bound_args_);
-  }
+struct BindingCallbackWithNoArgs {
+  static constexpr bool value = false;
 };
 
-template <typename Signature, typename... BoundArgs>
-struct CancellationChecker<BindState<Callback<Signature>, BoundArgs...>> {
-  static constexpr bool is_cancellable = true;
-  static bool Run(const BindStateBase* base) {
-    using Functor = Callback<Signature>;
-    using BindStateType = BindState<Functor, BoundArgs...>;
-    const BindStateType* bind_state = static_cast<const BindStateType*>(base);
-    return bind_state->functor_.IsCancelled();
-  }
+template <typename Signature,
+          typename... BoundArgs,
+          CopyMode copy_mode,
+          RepeatMode repeat_mode>
+struct BindingCallbackWithNoArgs<Callback<Signature, copy_mode, repeat_mode>,
+                                 BoundArgs...> {
+  static constexpr bool value = sizeof...(BoundArgs) == 0;
 };
 
 // BindState<>
@@ -428,18 +430,26 @@ struct CancellationChecker<BindState<Callback<Signature>, BoundArgs...>> {
 template <typename Functor, typename... BoundArgs>
 struct BindState final : BindStateBase {
   using IsCancellable = std::integral_constant<
-      bool, CancellationChecker<BindState>::is_cancellable>;
+      bool,
+      CallbackCancellationTraits<Functor,
+                                 std::tuple<BoundArgs...>>::is_cancellable>;
 
   template <typename ForwardFunctor, typename... ForwardBoundArgs>
   explicit BindState(BindStateBase::InvokeFuncStorage invoke_func,
                      ForwardFunctor&& functor,
                      ForwardBoundArgs&&... bound_args)
-      // IsCancellable is std::false_type if the CancellationChecker<>::Run
-      // returns always false. Otherwise, it's std::true_type.
+      // IsCancellable is std::false_type if
+      // CallbackCancellationTraits<>::IsCancelled returns always false.
+      // Otherwise, it's std::true_type.
       : BindState(IsCancellable{},
                   invoke_func,
                   std::forward<ForwardFunctor>(functor),
-                  std::forward<ForwardBoundArgs>(bound_args)...) {}
+                  std::forward<ForwardBoundArgs>(bound_args)...) {
+    static_assert(!BindingCallbackWithNoArgs<Functor, BoundArgs...>::value,
+                  "Attempting to bind a base::Callback with no additional "
+                  "arguments: save a heap allocation and use the original "
+                  "base::Callback object");
+  }
 
   Functor functor_;
   std::tuple<BoundArgs...> bound_args_;
@@ -450,8 +460,9 @@ struct BindState final : BindStateBase {
                      BindStateBase::InvokeFuncStorage invoke_func,
                      ForwardFunctor&& functor,
                      ForwardBoundArgs&&... bound_args)
-      : BindStateBase(invoke_func, &Destroy,
-                      &CancellationChecker<BindState>::Run),
+      : BindStateBase(invoke_func,
+                      &Destroy,
+                      &ApplyCancellationTraits<BindState>),
         functor_(std::forward<ForwardFunctor>(functor)),
         bound_args_(std::forward<ForwardBoundArgs>(bound_args)...) {
     DCHECK(!IsNull(functor_));
@@ -470,8 +481,8 @@ struct BindState final : BindStateBase {
 
   ~BindState() {}
 
-  static void Destroy(BindStateBase* self) {
-    delete static_cast<BindState*>(self);
+  static void Destroy(const BindStateBase* self) {
+    delete static_cast<const BindState*>(self);
   }
 };
 
diff --git a/src/base/bits.h b/src/base/bits.h
index a3a59d1..d101cb7 100644
--- a/src/base/bits.h
+++ b/src/base/bits.h
@@ -1,4 +1,4 @@
-// Copyright (c) 2009 The Chromium Authors. All rights reserved.
+// Copyright (c) 2013 The Chromium Authors. All rights reserved.
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
@@ -10,8 +10,13 @@
 #include <stddef.h>
 #include <stdint.h>
 
+#include "base/compiler_specific.h"
 #include "base/logging.h"
 
+#if defined(COMPILER_MSVC)
+#include <intrin.h>
+#endif
+
 namespace base {
 namespace bits {
 
@@ -49,6 +54,58 @@ inline size_t Align(size_t size, size_t alignment) {
   return (size + alignment - 1) & ~(alignment - 1);
 }
 
+// These functions count the number of leading zeros in a binary value, starting
+// with the most significant bit. C does not have an operator to do this, but
+// fortunately the various compilers have built-ins that map to fast underlying
+// processor instructions.
+#if defined(COMPILER_MSVC)
+
+ALWAYS_INLINE uint32_t CountLeadingZeroBits32(uint32_t x) {
+  unsigned long index;
+  return LIKELY(_BitScanReverse(&index, x)) ? (31 - index) : 32;
+}
+
+#if defined(ARCH_CPU_64_BITS)
+
+// MSVC only supplies _BitScanForward64 when building for a 64-bit target.
+ALWAYS_INLINE uint64_t CountLeadingZeroBits64(uint64_t x) {
+  unsigned long index;
+  return LIKELY(_BitScanReverse64(&index, x)) ? (63 - index) : 64;
+}
+
+#endif
+
+#elif defined(COMPILER_GCC)
+
+// This is very annoying. __builtin_clz has undefined behaviour for an input of
+// 0, even though there's clearly a return value that makes sense, and even
+// though some processor clz instructions have defined behaviour for 0. We could
+// drop to raw __asm__ to do better, but we'll avoid doing that unless we see
+// proof that we need to.
+ALWAYS_INLINE uint32_t CountLeadingZeroBits32(uint32_t x) {
+  return LIKELY(x) ? __builtin_clz(x) : 32;
+}
+
+ALWAYS_INLINE uint64_t CountLeadingZeroBits64(uint64_t x) {
+  return LIKELY(x) ? __builtin_clzll(x) : 64;
+}
+
+#endif
+
+#if defined(ARCH_CPU_64_BITS)
+
+ALWAYS_INLINE size_t CountLeadingZeroBitsSizeT(size_t x) {
+  return CountLeadingZeroBits64(x);
+}
+
+#else
+
+ALWAYS_INLINE size_t CountLeadingZeroBitsSizeT(size_t x) {
+  return CountLeadingZeroBits32(x);
+}
+
+#endif
+
 }  // namespace bits
 }  // namespace base
 
diff --git a/src/base/callback.h b/src/base/callback.h
index c6b8ca3..344acfe 100644
--- a/src/base/callback.h
+++ b/src/base/callback.h
@@ -21,6 +21,12 @@ namespace base {
 
 namespace internal {
 
+template <typename CallbackType>
+struct IsOnceCallback : std::false_type {};
+
+template <typename Signature>
+struct IsOnceCallback<OnceCallback<Signature>> : std::true_type {};
+
 // RunMixin provides different variants of `Run()` function to `Callback<>`
 // based on the type of callback.
 template <typename CallbackType>
@@ -28,14 +34,29 @@ class RunMixin;
 
 // Specialization for OnceCallback.
 template <typename R, typename... Args>
-class RunMixin<Callback<R(Args...), CopyMode::MoveOnly, RepeatMode::Once>> {
+class RunMixin<OnceCallback<R(Args...)>> {
  private:
-  using CallbackType =
-      Callback<R(Args...), CopyMode::MoveOnly, RepeatMode::Once>;
+  using CallbackType = OnceCallback<R(Args...)>;
 
  public:
   using PolymorphicInvoke = R(*)(internal::BindStateBase*, Args&&...);
 
+  R Run(Args... args) & {
+    // Note: even though this static_assert will trivially always fail, it
+    // cannot be simply replaced with static_assert(false, ...) because:
+    // - Per [dcl.dcl]/p4, a program is ill-formed if the constant-expression
+    //   argument does not evaluate to true.
+    // - Per [temp.res]/p8, if no valid specialization can be generated for a
+    //   template definition, and that template is not instantiated, the
+    //   template definition is ill-formed, no diagnostic required.
+    // These two clauses, taken together, would allow a conforming C++ compiler
+    // to immediately reject static_assert(false, ...), even inside an
+    // uninstantiated template.
+    static_assert(!IsOnceCallback<CallbackType>::value,
+                  "OnceCallback::Run() may only be invoked on an rvalue, i.e. "
+                  "std::move(callback).Run().");
+  }
+
   R Run(Args... args) && {
     // Move the callback instance into a local variable before the invocation,
     // that ensures the internal state is cleared after the invocation.
@@ -49,10 +70,10 @@ class RunMixin<Callback<R(Args...), CopyMode::MoveOnly, RepeatMode::Once>> {
 };
 
 // Specialization for RepeatingCallback.
-template <typename R, typename... Args, CopyMode copy_mode>
-class RunMixin<Callback<R(Args...), copy_mode, RepeatMode::Repeating>> {
+template <typename R, typename... Args>
+class RunMixin<RepeatingCallback<R(Args...)>> {
  private:
-  using CallbackType = Callback<R(Args...), copy_mode, RepeatMode::Repeating>;
+  using CallbackType = RepeatingCallback<R(Args...)>;
 
  public:
   using PolymorphicInvoke = R(*)(internal::BindStateBase*, Args&&...);
@@ -69,10 +90,8 @@ template <typename From, typename To>
 struct IsCallbackConvertible : std::false_type {};
 
 template <typename Signature>
-struct IsCallbackConvertible<
-  Callback<Signature, CopyMode::Copyable, RepeatMode::Repeating>,
-  Callback<Signature, CopyMode::MoveOnly, RepeatMode::Once>> : std::true_type {
-};
+struct IsCallbackConvertible<RepeatingCallback<Signature>,
+                             OnceCallback<Signature>> : std::true_type {};
 
 }  // namespace internal
 
diff --git a/src/base/callback_forward.h b/src/base/callback_forward.h
index ce4c3e7..13eed0e 100644
--- a/src/base/callback_forward.h
+++ b/src/base/callback_forward.h
@@ -32,8 +32,6 @@ class Callback;
 // will be used in a lot of APIs with delayed execution.
 using Closure = Callback<void()>;
 
-namespace internal {
-
 template <typename Signature>
 using OnceCallback = Callback<Signature,
                               internal::CopyMode::MoveOnly,
@@ -45,7 +43,6 @@ using RepeatingCallback = Callback<Signature,
 using OnceClosure = OnceCallback<void()>;
 using RepeatingClosure = RepeatingCallback<void()>;
 
-}  // namespace internal
 }  // namespace base
 
 #endif  // BASE_CALLBACK_FORWARD_H_
diff --git a/src/base/callback_internal.cc b/src/base/callback_internal.cc
index 5759a74..4afd567 100644
--- a/src/base/callback_internal.cc
+++ b/src/base/callback_internal.cc
@@ -18,23 +18,23 @@ bool ReturnFalse(const BindStateBase*) {
 }  // namespace
 
 BindStateBase::BindStateBase(InvokeFuncStorage polymorphic_invoke,
-                             void (*destructor)(BindStateBase*))
+                             void (*destructor)(const BindStateBase*))
     : BindStateBase(polymorphic_invoke, destructor, &ReturnFalse) {
 }
 
 BindStateBase::BindStateBase(InvokeFuncStorage polymorphic_invoke,
-                             void (*destructor)(BindStateBase*),
+                             void (*destructor)(const BindStateBase*),
                              bool (*is_cancelled)(const BindStateBase*))
     : polymorphic_invoke_(polymorphic_invoke),
       ref_count_(0),
       destructor_(destructor),
       is_cancelled_(is_cancelled) {}
 
-void BindStateBase::AddRef() {
+void BindStateBase::AddRef() const {
   AtomicRefCountInc(&ref_count_);
 }
 
-void BindStateBase::Release() {
+void BindStateBase::Release() const {
   if (!AtomicRefCountDec(&ref_count_))
     destructor_(this);
 }
diff --git a/src/base/callback_internal.h b/src/base/callback_internal.h
index afed81c..f7501f9 100644
--- a/src/base/callback_internal.h
+++ b/src/base/callback_internal.h
@@ -36,9 +36,9 @@ class BASE_EXPORT BindStateBase {
 
  protected:
   BindStateBase(InvokeFuncStorage polymorphic_invoke,
-                void (*destructor)(BindStateBase*));
+                void (*destructor)(const BindStateBase*));
   BindStateBase(InvokeFuncStorage polymorphic_invoke,
-                void (*destructor)(BindStateBase*),
+                void (*destructor)(const BindStateBase*),
                 bool (*is_cancelled)(const BindStateBase*));
   ~BindStateBase() = default;
 
@@ -51,8 +51,8 @@ class BASE_EXPORT BindStateBase {
     return is_cancelled_(this);
   }
 
-  void AddRef();
-  void Release();
+  void AddRef() const;
+  void Release() const;
 
   // In C++, it is safe to cast function pointers to function pointers of
   // another type. It is not okay to use void*. We create a InvokeFuncStorage
@@ -60,10 +60,10 @@ class BASE_EXPORT BindStateBase {
   // the original type on usage.
   InvokeFuncStorage polymorphic_invoke_;
 
-  AtomicRefCount ref_count_;
+  mutable AtomicRefCount ref_count_;
 
   // Pointer to a function that will properly destroy |this|.
-  void (*destructor_)(BindStateBase*);
+  void (*destructor_)(const BindStateBase*);
   bool (*is_cancelled_)(const BindStateBase*);
 
   DISALLOW_COPY_AND_ASSIGN(BindStateBase);
diff --git a/src/base/cancelable_callback.h b/src/base/cancelable_callback.h
index 0034fdd..13cbd0c 100644
--- a/src/base/cancelable_callback.h
+++ b/src/base/cancelable_callback.h
@@ -26,16 +26,18 @@
 // to the message loop, the intensive test runs, the message loop is run,
 // then the callback is cancelled.
 //
+// RunLoop run_loop;
+//
 // void TimeoutCallback(const std::string& timeout_message) {
 //   FAIL() << timeout_message;
-//   MessageLoop::current()->QuitWhenIdle();
+//   run_loop.QuitWhenIdle();
 // }
 //
 // CancelableClosure timeout(base::Bind(&TimeoutCallback, "Test timed out."));
-// MessageLoop::current()->PostDelayedTask(FROM_HERE, timeout.callback(),
-//                                         4000)  // 4 seconds to run.
+// ThreadTaskRunnerHandle::Get()->PostDelayedTask(FROM_HERE, timeout.callback(),
+//                                                TimeDelta::FromSeconds(4));
 // RunIntensiveTest();
-// MessageLoop::current()->Run();
+// run_loop.Run();
 // timeout.Cancel();  // Hopefully this is hit before the timeout callback runs.
 //
 
diff --git a/src/base/compiler_specific.h b/src/base/compiler_specific.h
index f064be8..0f4c058 100644
--- a/src/base/compiler_specific.h
+++ b/src/base/compiler_specific.h
@@ -100,6 +100,14 @@
 #define NOINLINE
 #endif
 
+#if COMPILER_GCC && defined(NDEBUG)
+#define ALWAYS_INLINE inline __attribute__((__always_inline__))
+#elif COMPILER_MSVC && defined(NDEBUG)
+#define ALWAYS_INLINE __forceinline
+#else
+#define ALWAYS_INLINE inline
+#endif
+
 // Specify memory alignment for structs, classes, etc.
 // Use like:
 //   class ALIGNAS(16) MyClass { ... }
@@ -149,6 +157,16 @@
 // If available, it would look like:
 //   __attribute__((format(wprintf, format_param, dots_param)))
 
+// Sanitizers annotations.
+#if defined(__has_attribute)
+#if __has_attribute(no_sanitize)
+#define NO_SANITIZE(what) __attribute__((no_sanitize(what)))
+#endif
+#endif
+#if !defined(NO_SANITIZE)
+#define NO_SANITIZE(what)
+#endif
+
 // MemorySanitizer annotations.
 #if defined(MEMORY_SANITIZER) && !defined(OS_NACL)
 #include <sanitizer/msan_interface.h>
@@ -171,7 +189,7 @@
 
 // DISABLE_CFI_PERF -- Disable Control Flow Integrity for perf reasons.
 #if !defined(DISABLE_CFI_PERF)
-#if defined(__clang__)
+#if defined(__clang__) && defined(OFFICIAL_BUILD)
 #define DISABLE_CFI_PERF __attribute__((no_sanitize("cfi")))
 #else
 #define DISABLE_CFI_PERF
@@ -196,6 +214,14 @@
 #endif  // defined(COMPILER_GCC)
 #endif  // !defined(UNLIKELY)
 
+#if !defined(LIKELY)
+#if defined(COMPILER_GCC)
+#define LIKELY(x) __builtin_expect(!!(x), 1)
+#else
+#define LIKELY(x) (x)
+#endif  // defined(COMPILER_GCC)
+#endif  // !defined(LIKELY)
+
 // Compiler feature-detection.
 // clang.llvm.org/docs/LanguageExtensions.html#has-feature-and-has-extension
 #if defined(__has_feature)
diff --git a/src/base/containers/mru_cache.h b/src/base/containers/mru_cache.h
index 6c1d626..4005489 100644
--- a/src/base/containers/mru_cache.h
+++ b/src/base/containers/mru_cache.h
@@ -209,10 +209,12 @@ class MRUCacheBase {
 
 // A container that does not do anything to free its data. Use this when storing
 // value types (as opposed to pointers) in the list.
-template <class KeyType, class PayloadType>
-class MRUCache : public MRUCacheBase<KeyType, PayloadType, std::less<KeyType>> {
+template <class KeyType,
+          class PayloadType,
+          class CompareType = std::less<KeyType>>
+class MRUCache : public MRUCacheBase<KeyType, PayloadType, CompareType> {
  private:
-  using ParentType = MRUCacheBase<KeyType, PayloadType, std::less<KeyType>>;
+  using ParentType = MRUCacheBase<KeyType, PayloadType, CompareType>;
 
  public:
   // See MRUCacheBase, noting the possibility of using NO_AUTO_EVICT.
diff --git a/src/base/containers/small_map.h b/src/base/containers/small_map.h
index ed96caf..2945d58 100644
--- a/src/base/containers/small_map.h
+++ b/src/base/containers/small_map.h
@@ -575,17 +575,13 @@ class SmallMap {
 
   // We want to call constructors and destructors manually, but we don't
   // want to allocate and deallocate the memory used for them separately.
-  // So, we use this crazy ManualConstructor class.
+  // So, we use this crazy ManualConstructor class. Since C++11 it's possible
+  // to use objects in unions like this, but the ManualDestructor syntax is
+  // a bit better and doesn't have limitations on object type.
   //
   // Since array_ and map_ are mutually exclusive, we'll put them in a
-  // union, too.  We add in a dummy_ value which quiets MSVC from otherwise
-  // giving an erroneous "union member has copy constructor" error message
-  // (C2621). This dummy member has to come before array_ to quiet the
-  // compiler.
-  //
-  // TODO(brettw) remove this and use C++11 unions when we require C++11.
+  // union.
   union {
-    ManualConstructor<value_type> dummy_;
     ManualConstructor<value_type> array_[kArraySize];
     ManualConstructor<NormalMap> map_;
   };
diff --git a/src/base/debug/activity_tracker.cc b/src/base/debug/activity_tracker.cc
index ba6ceb9..c9209f5 100644
--- a/src/base/debug/activity_tracker.cc
+++ b/src/base/debug/activity_tracker.cc
@@ -4,6 +4,8 @@
 
 #include "base/debug/activity_tracker.h"
 
+#include <algorithm>
+
 #include "base/debug/stack_trace.h"
 #include "base/files/file.h"
 #include "base/files/file_path.h"
@@ -35,6 +37,13 @@ const uint32_t kHeaderCookie = 0xC0029B24UL + 2;  // v2
 // The minimum depth a stack should support.
 const int kMinStackDepth = 2;
 
+// The amount of memory set aside for holding arbitrary user data (key/value
+// pairs) globally or associated with ActivityData entries.
+const size_t kUserDataSize = 1024;    // bytes
+const size_t kGlobalDataSize = 1024;  // bytes
+const size_t kMaxUserDataNameLength =
+    static_cast<size_t>(std::numeric_limits<uint8_t>::max());
+
 union ThreadRef {
   int64_t as_id;
 #if defined(OS_WIN)
@@ -50,6 +59,11 @@ union ThreadRef {
 #endif
 };
 
+// Determines the next aligned index.
+size_t RoundUpToAlignment(size_t index, size_t alignment) {
+  return (index + (alignment - 1)) & (0 - alignment);
+}
+
 }  // namespace
 
 
@@ -68,12 +82,100 @@ ActivityData ActivityData::ForThread(const PlatformThreadHandle& handle) {
   return ForThread(thread_ref.as_id);
 }
 
+ActivityTrackerMemoryAllocator::ActivityTrackerMemoryAllocator(
+    PersistentMemoryAllocator* allocator,
+    uint32_t object_type,
+    uint32_t object_free_type,
+    size_t object_size,
+    size_t cache_size,
+    bool make_iterable)
+    : allocator_(allocator),
+      object_type_(object_type),
+      object_free_type_(object_free_type),
+      object_size_(object_size),
+      cache_size_(cache_size),
+      make_iterable_(make_iterable),
+      iterator_(allocator),
+      cache_values_(new Reference[cache_size]),
+      cache_used_(0) {
+  DCHECK(allocator);
+}
+
+ActivityTrackerMemoryAllocator::~ActivityTrackerMemoryAllocator() {}
+
+ActivityTrackerMemoryAllocator::Reference
+ActivityTrackerMemoryAllocator::GetObjectReference() {
+  // First see if there is a cached value that can be returned. This is much
+  // faster than searching the memory system for free blocks.
+  while (cache_used_ > 0) {
+    Reference cached = cache_values_[--cache_used_];
+    // Change the type of the cached object to the proper type and return it.
+    // If the type-change fails that means another thread has taken this from
+    // under us (via the search below) so ignore it and keep trying.
+    if (allocator_->ChangeType(cached, object_type_, object_free_type_))
+      return cached;
+  }
+
+  // Fetch the next "free" object from persistent memory. Rather than restart
+  // the iterator at the head each time and likely waste time going again
+  // through objects that aren't relevant, the iterator continues from where
+  // it last left off and is only reset when the end is reached. If the
+  // returned reference matches |last|, then it has wrapped without finding
+  // anything.
+  const Reference last = iterator_.GetLast();
+  while (true) {
+    uint32_t type;
+    Reference found = iterator_.GetNext(&type);
+    if (found && type == object_free_type_) {
+      // Found a free object. Change it to the proper type and return it. If
+      // the type-change fails that means another thread has taken this from
+      // under us so ignore it and keep trying.
+      if (allocator_->ChangeType(found, object_type_, object_free_type_))
+        return found;
+    }
+    if (found == last) {
+      // Wrapped. No desired object was found.
+      break;
+    }
+    if (!found) {
+      // Reached end; start over at the beginning.
+      iterator_.Reset();
+    }
+  }
+
+  // No free block was found so instead allocate a new one.
+  Reference allocated = allocator_->Allocate(object_size_, object_type_);
+  if (allocated && make_iterable_)
+    allocator_->MakeIterable(allocated);
+  return allocated;
+}
+
+void ActivityTrackerMemoryAllocator::ReleaseObjectReference(Reference ref) {
+  // Zero the memory so that it is ready for immediate use if needed later.
+  char* mem_base = allocator_->GetAsArray<char>(
+      ref, object_type_, PersistentMemoryAllocator::kSizeAny);
+  DCHECK(mem_base);
+  memset(mem_base, 0, object_size_);
+
+  // Mark object as free.
+  bool success = allocator_->ChangeType(ref, object_free_type_, object_type_);
+  DCHECK(success);
+
+  // Add this reference to our "free" cache if there is space. If not, the type
+  // has still been changed to indicate that it is free so this (or another)
+  // thread can find it, albeit more slowly, using the iteration method above.
+  if (cache_used_ < cache_size_)
+    cache_values_[cache_used_++] = ref;
+}
+
 // static
 void Activity::FillFrom(Activity* activity,
+                        const void* program_counter,
                         const void* origin,
                         Type type,
                         const ActivityData& data) {
   activity->time_internal = base::TimeTicks::Now().ToInternalValue();
+  activity->calling_address = reinterpret_cast<uintptr_t>(program_counter);
   activity->origin_address = reinterpret_cast<uintptr_t>(origin);
   activity->activity_type = type;
   activity->data = data;
@@ -97,14 +199,125 @@ void Activity::FillFrom(Activity* activity,
 ActivitySnapshot::ActivitySnapshot() {}
 ActivitySnapshot::~ActivitySnapshot() {}
 
+ActivityUserData::ValueInfo::ValueInfo() {}
+ActivityUserData::ValueInfo::ValueInfo(ValueInfo&&) = default;
+ActivityUserData::ValueInfo::~ValueInfo() {}
+
+ActivityUserData::ActivityUserData(void* memory, size_t size)
+    : memory_(static_cast<char*>(memory)), available_(size) {}
+
+ActivityUserData::~ActivityUserData() {}
+
+void ActivityUserData::Set(StringPiece name,
+                           ValueType type,
+                           const void* memory,
+                           size_t size) {
+  DCHECK(thread_checker_.CalledOnValidThread());
+  DCHECK_GE(std::numeric_limits<uint8_t>::max(), name.length());
+  size = std::min(std::numeric_limits<uint16_t>::max() - (kMemoryAlignment - 1),
+                  size);
+
+  // It's possible that no user data is being stored.
+  if (!memory_)
+    return;
+
+  // The storage of a name is limited so use that limit during lookup.
+  if (name.length() > kMaxUserDataNameLength)
+    name.set(name.data(), kMaxUserDataNameLength);
+
+  ValueInfo* info;
+  auto existing = values_.find(name);
+  if (existing != values_.end()) {
+    info = &existing->second;
+  } else {
+    // The name size is limited to what can be held in a single byte but
+    // because there are not alignment constraints on strings, it's set tight
+    // against the header. Its extent (the reserved space, even if it's not
+    // all used) is calculated so that, when pressed against the header, the
+    // following field will be aligned properly.
+    size_t name_size = name.length();
+    size_t name_extent =
+        RoundUpToAlignment(sizeof(Header) + name_size, kMemoryAlignment) -
+        sizeof(Header);
+    size_t value_extent = RoundUpToAlignment(size, kMemoryAlignment);
+
+    // The "basic size" is the minimum size of the record. It's possible that
+    // lengthy values will get truncated but there must be at least some bytes
+    // available.
+    size_t basic_size = sizeof(Header) + name_extent + kMemoryAlignment;
+    if (basic_size > available_)
+      return;  // No space to store even the smallest value.
+
+    // The "full size" is the size for storing the entire value, truncated
+    // to the amount of available memory.
+    size_t full_size =
+        std::min(sizeof(Header) + name_extent + value_extent, available_);
+    size = std::min(full_size - sizeof(Header) - name_extent, size);
+
+    // Allocate a chunk of memory.
+    Header* header = reinterpret_cast<Header*>(memory_);
+    memory_ += full_size;
+    available_ -= full_size;
+
+    // Datafill the header and name records. Memory must be zeroed. The |type|
+    // is written last, atomically, to release all the other values.
+    DCHECK_EQ(END_OF_VALUES, header->type.load(std::memory_order_relaxed));
+    DCHECK_EQ(0, header->value_size.load(std::memory_order_relaxed));
+    header->name_size = static_cast<uint8_t>(name_size);
+    header->record_size = full_size;
+    char* name_memory = reinterpret_cast<char*>(header) + sizeof(Header);
+    void* value_memory =
+        reinterpret_cast<char*>(header) + sizeof(Header) + name_extent;
+    memcpy(name_memory, name.data(), name_size);
+    header->type.store(type, std::memory_order_release);
+
+    // Create an entry in |values_| so that this field can be found and changed
+    // later on without having to allocate new entries.
+    StringPiece persistent_name(name_memory, name_size);
+    auto inserted =
+        values_.insert(std::make_pair(persistent_name, ValueInfo()));
+    DCHECK(inserted.second);  // True if inserted, false if existed.
+    info = &inserted.first->second;
+    info->name = persistent_name;
+    info->memory = value_memory;
+    info->size_ptr = &header->value_size;
+    info->extent = full_size - sizeof(Header) - name_extent;
+    info->type = type;
+  }
+
+  // Copy the value data to storage. The |size| is written last, atomically, to
+  // release the copied data. Until then, a parallel reader will just ignore
+  // records with a zero size.
+  DCHECK_EQ(type, info->type);
+  size = std::min(size, info->extent);
+  info->size_ptr->store(0, std::memory_order_seq_cst);
+  memcpy(info->memory, memory, size);
+  info->size_ptr->store(size, std::memory_order_release);
+}
+
+void ActivityUserData::SetReference(StringPiece name,
+                                    ValueType type,
+                                    const void* memory,
+                                    size_t size) {
+  ReferenceRecord rec;
+  rec.address = reinterpret_cast<uintptr_t>(memory);
+  rec.size = size;
+  Set(name, type, &rec, sizeof(rec));
+}
 
 // This information is kept for every thread that is tracked. It is filled
 // the very first time the thread is seen. All fields must be of exact sizes
 // so there is no issue moving between 32 and 64-bit builds.
 struct ThreadActivityTracker::Header {
+  // Expected size for 32/64-bit check.
+  static constexpr size_t kExpectedInstanceSize = 80;
+
   // This unique number indicates a valid initialization of the memory.
   std::atomic<uint32_t> cookie;
-  uint32_t reserved;  // pad out to 64 bits
+
+  // The number of Activity slots (spaces that can hold an Activity) that
+  // immediately follow this structure in memory.
+  uint32_t stack_slots;
 
   // The process-id and thread-id (thread_ref.as_id) to which this data belongs.
   // These identifiers are not guaranteed to mean anything but are unique, in
@@ -126,9 +339,6 @@ struct ThreadActivityTracker::Header {
   int64_t start_time;
   int64_t start_ticks;
 
-  // The number of Activity slots in the data.
-  uint32_t stack_slots;
-
   // The current depth of the stack. This may be greater than the number of
   // slots. If the depth exceeds the number of slots, the newest entries
   // won't be recorded.
@@ -151,6 +361,39 @@ struct ThreadActivityTracker::Header {
   char thread_name[32];
 };
 
+ThreadActivityTracker::ScopedActivity::ScopedActivity(
+    ThreadActivityTracker* tracker,
+    const void* program_counter,
+    const void* origin,
+    Activity::Type type,
+    const ActivityData& data)
+    : tracker_(tracker) {
+  if (tracker_)
+    activity_id_ = tracker_->PushActivity(program_counter, origin, type, data);
+}
+
+ThreadActivityTracker::ScopedActivity::~ScopedActivity() {
+  if (tracker_)
+    tracker_->PopActivity(activity_id_);
+}
+
+void ThreadActivityTracker::ScopedActivity::ChangeTypeAndData(
+    Activity::Type type,
+    const ActivityData& data) {
+  if (tracker_)
+    tracker_->ChangeActivity(activity_id_, type, data);
+}
+
+ActivityUserData& ThreadActivityTracker::ScopedActivity::user_data() {
+  if (!user_data_) {
+    if (tracker_)
+      user_data_ = tracker_->GetUserData(activity_id_);
+    else
+      user_data_ = MakeUnique<ActivityUserData>(nullptr, 0);
+  }
+  return *user_data_;
+}
+
 ThreadActivityTracker::ThreadActivityTracker(void* base, size_t size)
     : header_(static_cast<Header*>(base)),
       stack_(reinterpret_cast<Activity*>(reinterpret_cast<char*>(base) +
@@ -228,9 +471,11 @@ ThreadActivityTracker::ThreadActivityTracker(void* base, size_t size)
 
 ThreadActivityTracker::~ThreadActivityTracker() {}
 
-void ThreadActivityTracker::PushActivity(const void* origin,
-                                         Activity::Type type,
-                                         const ActivityData& data) {
+ThreadActivityTracker::ActivityId ThreadActivityTracker::PushActivity(
+    const void* program_counter,
+    const void* origin,
+    Activity::Type type,
+    const ActivityData& data) {
   // A thread-checker creates a lock to check the thread-id which means
   // re-entry into this code if lock acquisitions are being tracked.
   DCHECK(type == Activity::ACT_LOCK_ACQUIRE ||
@@ -246,32 +491,34 @@ void ThreadActivityTracker::PushActivity(const void* origin,
     // Since no other threads modify the data, no compare/exchange is needed.
     // Since no other memory is being modified, a "relaxed" store is acceptable.
     header_->current_depth.store(depth + 1, std::memory_order_relaxed);
-    return;
+    return depth;
   }
 
   // Get a pointer to the next activity and load it. No atomicity is required
   // here because the memory is known only to this thread. It will be made
   // known to other threads once the depth is incremented.
-  Activity::FillFrom(&stack_[depth], origin, type, data);
+  Activity::FillFrom(&stack_[depth], program_counter, origin, type, data);
 
   // Save the incremented depth. Because this guards |activity| memory filled
   // above that may be read by another thread once the recorded depth changes,
   // a "release" store is required.
   header_->current_depth.store(depth + 1, std::memory_order_release);
+
+  // The current depth is used as the activity ID because it simply identifies
+  // an entry. Once an entry is pop'd, it's okay to reuse the ID.
+  return depth;
 }
 
-void ThreadActivityTracker::ChangeActivity(Activity::Type type,
+void ThreadActivityTracker::ChangeActivity(ActivityId id,
+                                           Activity::Type type,
                                            const ActivityData& data) {
   DCHECK(thread_checker_.CalledOnValidThread());
   DCHECK(type != Activity::ACT_NULL || &data != &kNullActivityData);
-
-  // Get the current depth of the stack and acquire the data held there.
-  uint32_t depth = header_->current_depth.load(std::memory_order_acquire);
-  DCHECK_LT(0U, depth);
+  DCHECK_LT(id, header_->current_depth.load(std::memory_order_acquire));
 
   // Update the information if it is being recorded (i.e. within slot limit).
-  if (depth <= stack_slots_) {
-    Activity* activity = &stack_[depth - 1];
+  if (id < stack_slots_) {
+    Activity* activity = &stack_[id];
 
     if (type != Activity::ACT_NULL) {
       DCHECK_EQ(activity->activity_type & Activity::ACT_CATEGORY_MASK,
@@ -284,21 +531,29 @@ void ThreadActivityTracker::ChangeActivity(Activity::Type type,
   }
 }
 
-void ThreadActivityTracker::PopActivity() {
+void ThreadActivityTracker::PopActivity(ActivityId id) {
   // Do an atomic decrement of the depth. No changes to stack entries guarded
   // by this variable are done here so a "relaxed" operation is acceptable.
-  // |depth| will receive the value BEFORE it was modified.
+  // |depth| will receive the value BEFORE it was modified which means the
+  // return value must also be decremented. The slot will be "free" after
+  // this call but since only a single thread can access this object, the
+  // data will remain valid until this method returns or calls outside.
   uint32_t depth =
-      header_->current_depth.fetch_sub(1, std::memory_order_relaxed);
+      header_->current_depth.fetch_sub(1, std::memory_order_relaxed) - 1;
 
   // Validate that everything is running correctly.
-  DCHECK_LT(0U, depth);
+  DCHECK_EQ(id, depth);
 
   // A thread-checker creates a lock to check the thread-id which means
   // re-entry into this code if lock acquisitions are being tracked.
-  DCHECK(stack_[depth - 1].activity_type == Activity::ACT_LOCK_ACQUIRE ||
+  DCHECK(stack_[depth].activity_type == Activity::ACT_LOCK_ACQUIRE ||
          thread_checker_.CalledOnValidThread());
 
+  // Check if there was any user-data memory. It isn't free'd until later
+  // because the call to release it can push something on the stack.
+  PersistentMemoryAllocator::Reference user_data = stack_[depth].user_data;
+  stack_[depth].user_data = 0;
+
   // The stack has shrunk meaning that some other thread trying to copy the
   // contents for reporting purposes could get bad data. That thread would
   // have written a non-zero value into |stack_unchanged|; clearing it here
@@ -306,6 +561,25 @@ void ThreadActivityTracker::PopActivity() {
   // happen after the atomic |depth| operation above so a "release" store
   // is required.
   header_->stack_unchanged.store(0, std::memory_order_release);
+
+  // Release resources located above. All stack processing is done so it's
+  // safe if some outside code does another push.
+  if (user_data)
+    GlobalActivityTracker::Get()->ReleaseUserDataMemory(&user_data);
+}
+
+std::unique_ptr<ActivityUserData> ThreadActivityTracker::GetUserData(
+    ActivityId id) {
+  // User-data is only stored for activities actually held in the stack.
+  if (id < stack_slots_) {
+    void* memory =
+        GlobalActivityTracker::Get()->GetUserDataMemory(&stack_[id].user_data);
+    if (memory)
+      return MakeUnique<ActivityUserData>(memory, kUserDataSize);
+  }
+
+  // Return a dummy object that will still accept (but ignore) Set() calls.
+  return MakeUnique<ActivityUserData>(nullptr, 0);
 }
 
 bool ThreadActivityTracker::IsValid() const {
@@ -501,66 +775,45 @@ void GlobalActivityTracker::CreateWithLocalMemory(size_t size,
 ThreadActivityTracker* GlobalActivityTracker::CreateTrackerForCurrentThread() {
   DCHECK(!this_thread_tracker_.Get());
 
-  PersistentMemoryAllocator::Reference mem_reference =
-      PersistentMemoryAllocator::kReferenceNull;
-  DCHECK(!mem_reference);  // invalid_value should be checkable with !
+  PersistentMemoryAllocator::Reference mem_reference;
 
-  while (true) {
-    // Get the first available memory from the top of the FIFO.
-    if (!available_memories_.pop(&mem_reference))
-      break;
-
-    // Turn the reference back into one of the activity-tracker type. This can
-    // fail if something else has already taken the block and changed its type.
-    if (allocator_->ChangeType(mem_reference, kTypeIdActivityTracker,
-                               kTypeIdActivityTrackerFree)) {
-      break;
-    }
+  {
+    base::AutoLock autolock(thread_tracker_allocator_lock_);
+    mem_reference = thread_tracker_allocator_.GetObjectReference();
   }
 
-  // Handle the case where no known available memories were found.
   if (!mem_reference) {
-    // Allocate a block of memory from the persistent segment.
-    mem_reference =
-        allocator_->Allocate(stack_memory_size_, kTypeIdActivityTracker);
-    if (mem_reference) {
-      // Success. Make the allocation iterable so it can be found later.
-      allocator_->MakeIterable(mem_reference);
-    } else {
-      // Failure. Look for any free blocks that weren't held in the cache
-      // of available memories and try to claim it. This can happen if the
-      // |available_memories_| stack isn't sufficiently large to hold all
-      // released memories or if multiple independent processes are sharing
-      // the memory segment.
-      PersistentMemoryAllocator::Iterator iter(allocator_.get());
-      while ((mem_reference = iter.GetNextOfType(kTypeIdActivityTrackerFree)) !=
-             0) {
-        if (allocator_->ChangeType(mem_reference, kTypeIdActivityTracker,
-                                   kTypeIdActivityTrackerFree)) {
-          break;
-        }
-        mem_reference = 0;
-      }
-      if (!mem_reference) {
-        // Dobule Failure. This shouldn't happen. But be graceful if it does,
-        // probably because the underlying allocator wasn't given enough memory
-        // to satisfy all possible requests.
-        NOTREACHED();
-        // Report the thread-count at which the allocator was full so that the
-        // failure can be seen and underlying memory resized appropriately.
-        UMA_HISTOGRAM_COUNTS_1000(
-            "ActivityTracker.ThreadTrackers.MemLimitTrackerCount",
-            thread_tracker_count_.load(std::memory_order_relaxed));
-        // Return null, just as if tracking wasn't enabled.
-        return nullptr;
-      }
-    }
+    // Failure. This shouldn't happen. But be graceful if it does, probably
+    // because the underlying allocator wasn't given enough memory to satisfy
+    // to all possible requests.
+    NOTREACHED();
+    // Report the thread-count at which the allocator was full so that the
+    // failure can be seen and underlying memory resized appropriately.
+    UMA_HISTOGRAM_COUNTS_1000(
+        "ActivityTracker.ThreadTrackers.MemLimitTrackerCount",
+        thread_tracker_count_.load(std::memory_order_relaxed));
+    // Return null, just as if tracking wasn't enabled.
+    return nullptr;
   }
 
   // Convert the memory block found above into an actual memory address.
+  // Doing the conversion as a Header object enacts the 32/64-bit size
+  // consistency checks which would not otherwise be done. Unfortunately,
+  // some older compilers and MSVC don't have standard-conforming definitions
+  // of std::atomic which cause it not to be plain-old-data. Don't check on
+  // those platforms assuming that the checks on other platforms will be
+  // sufficient.
+  // TODO(bcwhite): Review this after major compiler releases.
   DCHECK(mem_reference);
-  void* mem_base =
-      allocator_->GetAsObject<char>(mem_reference, kTypeIdActivityTracker);
+  void* mem_base;
+#if !defined(OS_WIN) && !defined(OS_ANDROID)
+  mem_base = allocator_->GetAsObject<ThreadActivityTracker::Header>(
+      mem_reference, kTypeIdActivityTracker);
+#else
+  mem_base = allocator_->GetAsArray<char>(mem_reference, kTypeIdActivityTracker,
+                                          PersistentMemoryAllocator::kSizeAny);
+#endif
+
   DCHECK(mem_base);
   DCHECK_LE(stack_memory_size_, allocator_->GetAllocSize(mem_reference));
 
@@ -584,6 +837,42 @@ void GlobalActivityTracker::ReleaseTrackerForCurrentThreadForTesting() {
     delete tracker;
 }
 
+void* GlobalActivityTracker::GetUserDataMemory(
+    PersistentMemoryAllocator::Reference* reference) {
+  if (!*reference) {
+    base::AutoLock autolock(user_data_allocator_lock_);
+    *reference = user_data_allocator_.GetObjectReference();
+    if (!*reference)
+      return nullptr;
+  }
+
+  void* memory = allocator_->GetAsArray<char>(
+      *reference, kTypeIdUserDataRecord, PersistentMemoryAllocator::kSizeAny);
+  DCHECK(memory);
+  return memory;
+}
+
+void GlobalActivityTracker::ReleaseUserDataMemory(
+    PersistentMemoryAllocator::Reference* reference) {
+  DCHECK(*reference);
+  base::AutoLock autolock(user_data_allocator_lock_);
+  user_data_allocator_.ReleaseObjectReference(*reference);
+  *reference = PersistentMemoryAllocator::kReferenceNull;
+}
+
+void GlobalActivityTracker::RecordLogMessage(StringPiece message) {
+  // Allocate at least one extra byte so the string is NUL terminated. All
+  // memory returned by the allocator is guaranteed to be zeroed.
+  PersistentMemoryAllocator::Reference ref =
+      allocator_->Allocate(message.size() + 1, kTypeIdGlobalLogMessage);
+  char* memory = allocator_->GetAsArray<char>(ref, kTypeIdGlobalLogMessage,
+                                              message.size() + 1);
+  if (memory) {
+    memcpy(memory, message.data(), message.size());
+    allocator_->MakeIterable(ref);
+  }
+}
+
 GlobalActivityTracker::GlobalActivityTracker(
     std::unique_ptr<PersistentMemoryAllocator> allocator,
     int stack_depth)
@@ -591,7 +880,24 @@ GlobalActivityTracker::GlobalActivityTracker(
       stack_memory_size_(ThreadActivityTracker::SizeForStackDepth(stack_depth)),
       this_thread_tracker_(&OnTLSDestroy),
       thread_tracker_count_(0),
-      available_memories_(kMaxThreadCount) {
+      thread_tracker_allocator_(allocator_.get(),
+                                kTypeIdActivityTracker,
+                                kTypeIdActivityTrackerFree,
+                                stack_memory_size_,
+                                kCachedThreadMemories,
+                                /*make_iterable=*/true),
+      user_data_allocator_(allocator_.get(),
+                           kTypeIdUserDataRecord,
+                           kTypeIdUserDataRecordFree,
+                           kUserDataSize,
+                           kCachedUserDataMemories,
+                           /*make_iterable=*/false),
+      user_data_(
+          allocator_->GetAsArray<char>(
+              allocator_->Allocate(kGlobalDataSize, kTypeIdGlobalDataRecord),
+              kTypeIdGlobalDataRecord,
+              PersistentMemoryAllocator::kSizeAny),
+          kGlobalDataSize) {
   // Ensure the passed memory is valid and empty (iterator finds nothing).
   uint32_t type;
   DCHECK(!PersistentMemoryAllocator::Iterator(allocator_.get()).GetNext(&type));
@@ -614,25 +920,13 @@ void GlobalActivityTracker::ReturnTrackerMemory(
   DCHECK(mem_reference);
   DCHECK(mem_base);
 
-  // Zero the memory so that it is ready for use if needed again later. It's
-  // better to clear the memory now, when a thread is exiting, than to do it
-  // when it is first needed by a thread doing actual work.
-  memset(mem_base, 0, stack_memory_size_);
-
   // Remove the destructed tracker from the set of known ones.
   DCHECK_LE(1, thread_tracker_count_.load(std::memory_order_relaxed));
   thread_tracker_count_.fetch_sub(1, std::memory_order_relaxed);
 
-  // The memory was within the persistent memory allocator. Change its type
-  // so it is effectively marked as "free".
-  allocator_->ChangeType(mem_reference, kTypeIdActivityTrackerFree,
-                         kTypeIdActivityTracker);
-
-  // Push this on the internal cache of available memory blocks so it can
-  // be found and reused quickly. If the push somehow exceeds the maximum
-  // size of the cache, it will fail but a fallback check in CreateTracker
-  // will find it by (slow) iteration.
-  available_memories_.push(mem_reference);
+  // Release this memory for re-use at a later time.
+  base::AutoLock autolock(thread_tracker_allocator_lock_);
+  thread_tracker_allocator_.ReleaseObjectReference(mem_reference);
 }
 
 // static
@@ -640,12 +934,13 @@ void GlobalActivityTracker::OnTLSDestroy(void* value) {
   delete reinterpret_cast<ManagedActivityTracker*>(value);
 }
 
-ScopedActivity::ScopedActivity(const tracked_objects::Location& location,
+ScopedActivity::ScopedActivity(const void* program_counter,
                                uint8_t action,
                                uint32_t id,
                                int32_t info)
     : GlobalActivityTracker::ScopedThreadActivity(
-          location.program_counter(),
+          program_counter,
+          nullptr,
           static_cast<Activity::Type>(Activity::ACT_GENERIC | action),
           ActivityData::ForGeneric(id, info),
           /*lock_allowed=*/true),
@@ -670,32 +965,41 @@ void ScopedActivity::ChangeActionAndInfo(uint8_t action, int32_t info) {
                     ActivityData::ForGeneric(id_, info));
 }
 
-ScopedTaskRunActivity::ScopedTaskRunActivity(const base::PendingTask& task)
+ScopedTaskRunActivity::ScopedTaskRunActivity(
+    const void* program_counter,
+    const base::PendingTask& task)
     : GlobalActivityTracker::ScopedThreadActivity(
+          program_counter,
           task.posted_from.program_counter(),
           Activity::ACT_TASK_RUN,
           ActivityData::ForTask(task.sequence_num),
           /*lock_allowed=*/true) {}
 
 ScopedLockAcquireActivity::ScopedLockAcquireActivity(
+    const void* program_counter,
     const base::internal::LockImpl* lock)
     : GlobalActivityTracker::ScopedThreadActivity(
+          program_counter,
           nullptr,
           Activity::ACT_LOCK_ACQUIRE,
           ActivityData::ForLock(lock),
           /*lock_allowed=*/false) {}
 
 ScopedEventWaitActivity::ScopedEventWaitActivity(
+    const void* program_counter,
     const base::WaitableEvent* event)
     : GlobalActivityTracker::ScopedThreadActivity(
+          program_counter,
           nullptr,
           Activity::ACT_EVENT_WAIT,
           ActivityData::ForEvent(event),
           /*lock_allowed=*/true) {}
 
 ScopedThreadJoinActivity::ScopedThreadJoinActivity(
+    const void* program_counter,
     const base::PlatformThreadHandle* thread)
     : GlobalActivityTracker::ScopedThreadActivity(
+          program_counter,
           nullptr,
           Activity::ACT_THREAD_JOIN,
           ActivityData::ForThread(*thread),
@@ -703,8 +1007,10 @@ ScopedThreadJoinActivity::ScopedThreadJoinActivity(
 
 #if !defined(OS_NACL) && !defined(OS_IOS)
 ScopedProcessWaitActivity::ScopedProcessWaitActivity(
+    const void* program_counter,
     const base::Process* process)
     : GlobalActivityTracker::ScopedThreadActivity(
+          program_counter,
           nullptr,
           Activity::ACT_PROCESS_WAIT,
           ActivityData::ForProcess(process->Pid()),
diff --git a/src/base/debug/activity_tracker.h b/src/base/debug/activity_tracker.h
index 2cf4850..1767ef4 100644
--- a/src/base/debug/activity_tracker.h
+++ b/src/base/debug/activity_tracker.h
@@ -16,11 +16,14 @@
 // PersistentMemoryAllocator which also uses std::atomic and is written
 // by the same author.
 #include <atomic>
+#include <map>
 #include <memory>
 #include <string>
 #include <vector>
 
 #include "base/base_export.h"
+#include "base/compiler_specific.h"
+#include "base/gtest_prod_util.h"
 #include "base/location.h"
 #include "base/metrics/persistent_memory_allocator.h"
 #include "base/threading/platform_thread.h"
@@ -33,7 +36,6 @@ struct PendingTask;
 
 class FilePath;
 class Lock;
-class MemoryMappedFile;
 class PlatformThreadHandle;
 class Process;
 class WaitableEvent;
@@ -125,6 +127,56 @@ union ActivityData {
 // A "null" activity-data that can be passed to indicate "do not change".
 extern const ActivityData kNullActivityData;
 
+
+// A helper class that is used for managing memory allocations within a
+// persistent memory allocator. Instances of this class are NOT thread-safe.
+// Use from a single thread or protect access with a lock.
+class ActivityTrackerMemoryAllocator {
+ public:
+  using Reference = PersistentMemoryAllocator::Reference;
+
+  // Creates a instance for allocating objects of a fixed |object_type|, a
+  // corresponding |object_free| type, and the |object_size|. An internal
+  // cache of the last |cache_size| released references will be kept for
+  // quick future fetches. If |make_iterable| then allocated objects will
+  // be marked "iterable" in the allocator.
+  ActivityTrackerMemoryAllocator(PersistentMemoryAllocator* allocator,
+                                 uint32_t object_type,
+                                 uint32_t object_free_type,
+                                 size_t object_size,
+                                 size_t cache_size,
+                                 bool make_iterable);
+  ~ActivityTrackerMemoryAllocator();
+
+  // Gets a reference to an object of the configured type. This can return
+  // a null reference if it was not possible to allocate the memory.
+  Reference GetObjectReference();
+
+  // Returns an object to the "free" pool.
+  void ReleaseObjectReference(Reference ref);
+
+  // The current "used size" of the internal cache, visible for testing.
+  size_t cache_used() const { return cache_used_; }
+
+ private:
+  PersistentMemoryAllocator* const allocator_;
+  const uint32_t object_type_;
+  const uint32_t object_free_type_;
+  const size_t object_size_;
+  const size_t cache_size_;
+  const bool make_iterable_;
+
+  // An iterator for going through persistent memory looking for free'd objects.
+  PersistentMemoryAllocator::Iterator iterator_;
+
+  // The cache of released object memories.
+  std::unique_ptr<Reference[]> cache_values_;
+  size_t cache_used_;
+
+  DISALLOW_COPY_AND_ASSIGN(ActivityTrackerMemoryAllocator);
+};
+
+
 // This structure is the full contents recorded for every activity pushed
 // onto the stack. The |activity_type| indicates what is actually stored in
 // the |data| field. All fields must be explicitly sized types to ensure no
@@ -176,6 +228,9 @@ struct Activity {
   // but when returned in a snapshot, it is "wall time".
   int64_t time_internal;
 
+  // The address that pushed the activity onto the stack as a raw number.
+  uint64_t calling_address;
+
   // The address that is the origin of the activity if it not obvious from
   // the call stack. This is useful for things like tasks that are posted
   // from a completely different thread though most activities will leave
@@ -189,6 +244,9 @@ struct Activity {
   // enabled.
   uint64_t call_stack[kActivityCallStackSize];
 
+  // Reference to arbitrary user data within the persistent memory segment.
+  uint32_t user_data;
+
   // The (enumerated) type of the activity. This defines what fields of the
   // |data| record are valid.
   uint8_t activity_type;
@@ -196,12 +254,13 @@ struct Activity {
   // Padding to ensure that the next member begins on a 64-bit boundary
   // even on 32-bit builds which ensures inter-operability between CPU
   // architectures. New fields can be taken from this space.
-  uint8_t padding[7];
+  uint8_t padding[3];
 
   // Information specific to the |activity_type|.
   ActivityData data;
 
   static void FillFrom(Activity* activity,
+                       const void* program_counter,
                        const void* origin,
                        Type type,
                        const ActivityData& data);
@@ -236,6 +295,114 @@ struct BASE_EXPORT ActivitySnapshot {
   uint32_t activity_stack_depth = 0;
 };
 
+// This class manages arbitrary user data that can be associated with activities
+// done by a thread by supporting key/value pairs of any type. This can provide
+// additional information during debugging. It is also used to store arbitrary
+// global data. All updates must be done from the same thread.
+class BASE_EXPORT ActivityUserData {
+  // List of known value type. REFERENCE types must immediately follow the non-
+  // external types.
+  enum ValueType : uint8_t {
+    END_OF_VALUES = 0,
+    RAW_VALUE,
+    RAW_VALUE_REFERENCE,
+    STRING_VALUE,
+    STRING_VALUE_REFERENCE,
+    CHAR_VALUE,
+    SIGNED_VALUE,
+    UNSIGNED_VALUE,
+  };
+
+ public:
+  ActivityUserData(void* memory, size_t size);
+  ~ActivityUserData();
+
+  // Writes a |value| (as part of a key/value pair) that will be included with
+  // the activity in any reports. The same |name| can be written multiple times
+  // with each successive call overwriting the previously stored |value|. For
+  // raw and string values, the maximum size of successive writes is limited by
+  // the first call. The length of "name" is limited to 255 characters.
+  //
+  // This information is stored on a "best effort" basis. It may be dropped if
+  // the memory buffer is full or the associated activity is beyond the maximum
+  // recording depth.
+  void Set(StringPiece name, const void* memory, size_t size) {
+    Set(name, RAW_VALUE, memory, size);
+  }
+  void SetString(StringPiece name, StringPiece value) {
+    Set(name, STRING_VALUE, value.data(), value.length());
+  }
+  void SetChar(StringPiece name, char value) {
+    Set(name, CHAR_VALUE, &value, sizeof(value));
+  }
+  void SetInt(StringPiece name, int64_t value) {
+    Set(name, SIGNED_VALUE, &value, sizeof(value));
+  }
+  void SetUint(StringPiece name, uint64_t value) {
+    Set(name, UNSIGNED_VALUE, &value, sizeof(value));
+  }
+
+  // These function as above but don't actually copy the data into the
+  // persistent memory. They store unaltered pointers along with a size. These
+  // can be used in conjuction with a memory dump to find certain large pieces
+  // of information.
+  void SetReference(StringPiece name, const void* memory, size_t size) {
+    SetReference(name, RAW_VALUE_REFERENCE, memory, size);
+  }
+  void SetStringReference(StringPiece name, StringPiece value) {
+    SetReference(name, STRING_VALUE_REFERENCE, value.data(), value.length());
+  }
+
+ private:
+  FRIEND_TEST_ALL_PREFIXES(ActivityTrackerTest, UserDataTest);
+
+  enum : size_t { kMemoryAlignment = sizeof(uint64_t) };
+
+  // A structure used to reference data held outside of persistent memory.
+  struct ReferenceRecord {
+    uint64_t address;
+    uint64_t size;
+  };
+
+  // Header to a key/value record held in persistent memory.
+  struct Header {
+    std::atomic<uint8_t> type;         // Encoded ValueType
+    uint8_t name_size;                 // Length of "name" key.
+    std::atomic<uint16_t> value_size;  // Actual size of of the stored value.
+    uint16_t record_size;              // Total storage of name, value, header.
+  };
+
+  // This record is used to hold known value is a map so that they can be
+  // found and overwritten later.
+  struct ValueInfo {
+    ValueInfo();
+    ValueInfo(ValueInfo&&);
+    ~ValueInfo();
+
+    StringPiece name;                 // The "key" of the record.
+    ValueType type;                   // The type of the value.
+    void* memory;                     // Where the "value" is held.
+    std::atomic<uint16_t>* size_ptr;  // Address of the actual size of value.
+    size_t extent;                    // The total storage of the value,
+  };                                  // typically rounded up for alignment.
+
+  void Set(StringPiece name, ValueType type, const void* memory, size_t size);
+  void SetReference(StringPiece name,
+                    ValueType type,
+                    const void* memory,
+                    size_t size);
+
+  // TODO(bcwhite): Add Get() methods for Analyzer to use.
+
+  std::map<StringPiece, ValueInfo> values_;
+
+  char* memory_;
+  size_t available_;
+
+  base::ThreadChecker thread_checker_;
+
+  DISALLOW_COPY_AND_ASSIGN(ActivityUserData);
+};
 
 // This class manages tracking a stack of activities for a single thread in
 // a persistent manner, implementing a bounded-size stack in a fixed-size
@@ -248,6 +415,13 @@ struct BASE_EXPORT ActivitySnapshot {
 // objects.
 class BASE_EXPORT ThreadActivityTracker {
  public:
+  // This structure contains all the common information about the thread so
+  // it doesn't have to be repeated in every entry on the stack. It is defined
+  // and used completely within the .cc file.
+  struct Header;
+
+  using ActivityId = uint32_t;
+
   // This is the base class for having the compiler manage an activity on the
   // tracker's stack. It does nothing but call methods on the passed |tracker|
   // if it is not null, making it safe (and cheap) to create these objects
@@ -255,29 +429,29 @@ class BASE_EXPORT ThreadActivityTracker {
   class BASE_EXPORT ScopedActivity {
    public:
     ScopedActivity(ThreadActivityTracker* tracker,
+                   const void* program_counter,
                    const void* origin,
                    Activity::Type type,
-                   const ActivityData& data)
-        : tracker_(tracker) {
-      if (tracker_)
-        tracker_->PushActivity(origin, type, data);
-    }
+                   const ActivityData& data);
+    ~ScopedActivity();
 
-    ~ScopedActivity() {
-      if (tracker_)
-        tracker_->PopActivity();
-    }
+    // Changes some basic metadata about the activity.
+    void ChangeTypeAndData(Activity::Type type, const ActivityData& data);
 
-    void ChangeTypeAndData(Activity::Type type, const ActivityData& data) {
-      if (tracker_)
-        tracker_->ChangeActivity(type, data);
-    }
+    // Returns an object for manipulating user data.
+    ActivityUserData& user_data();
 
    private:
     // The thread tracker to which this object reports. It can be null if
     // activity tracking is not (yet) enabled.
     ThreadActivityTracker* const tracker_;
 
+    // An identifier that indicates a specific activity on the stack.
+    ActivityId activity_id_;
+
+    // An object that manages additional user data, created only upon request.
+    std::unique_ptr<ActivityUserData> user_data_;
+
     DISALLOW_COPY_AND_ASSIGN(ScopedActivity);
   };
 
@@ -289,10 +463,23 @@ class BASE_EXPORT ThreadActivityTracker {
 
   // Indicates that an activity has started from a given |origin| address in
   // the code, though it can be null if the creator's address is not known.
-  // The |type| and |data| describe the activity.
-  void PushActivity(const void* origin,
-                    Activity::Type type,
-                    const ActivityData& data);
+  // The |type| and |data| describe the activity. |program_counter| should be
+  // the result of GetProgramCounter() where push is called. Returned is an
+  // ID that can be used to adjust the pushed activity.
+  ActivityId PushActivity(const void* program_counter,
+                          const void* origin,
+                          Activity::Type type,
+                          const ActivityData& data);
+
+  // An inlined version of the above that gets the program counter where it
+  // is called.
+  ALWAYS_INLINE
+  ActivityId PushActivity(const void* origin,
+                          Activity::Type type,
+                          const ActivityData& data) {
+    return PushActivity(::tracked_objects::GetProgramCounter(), origin, type,
+                        data);
+  }
 
   // Changes the activity |type| and |data| of the top-most entry on the stack.
   // This is useful if the information has changed and it is desireable to
@@ -301,10 +488,15 @@ class BASE_EXPORT ThreadActivityTracker {
   // unchanged. The type, if changed, must remain in the same category.
   // Changing both is not atomic so a snapshot operation could occur between
   // the update of |type| and |data| or between update of |data| fields.
-  void ChangeActivity(Activity::Type type, const ActivityData& data);
+  void ChangeActivity(ActivityId id,
+                      Activity::Type type,
+                      const ActivityData& data);
 
   // Indicates that an activity has completed.
-  void PopActivity();
+  void PopActivity(ActivityId id);
+
+  // Returns an object capable of storing arbitrary user data.
+  std::unique_ptr<ActivityUserData> GetUserData(ActivityId id);
 
   // Returns whether the current data is valid or not. It is not valid if
   // corruption has been detected in the header or other data structures.
@@ -323,11 +515,6 @@ class BASE_EXPORT ThreadActivityTracker {
  private:
   friend class ActivityTrackerTest;
 
-  // This structure contains all the common information about the thread so
-  // it doesn't have to be repeated in every entry on the stack. It is defined
-  // and used completely within the .cc file.
-  struct Header;
-
   Header* const header_;        // Pointer to the Header structure.
   Activity* const stack_;       // The stack of activities.
   const uint32_t stack_slots_;  // The total number of stack slots.
@@ -344,46 +531,6 @@ class BASE_EXPORT ThreadActivityTracker {
 // the thread trackers is taken from a PersistentMemoryAllocator which allows
 // for the data to be analyzed by a parallel process or even post-mortem.
 class BASE_EXPORT GlobalActivityTracker {
-  template <typename T>
-  class ThreadSafeStack {
-   public:
-    ThreadSafeStack(size_t size)
-        : size_(size), values_(new T[size]), used_(0) {}
-    ~ThreadSafeStack() {}
-
-    size_t size() { return size_; }
-    size_t used() {
-      base::AutoLock autolock(lock_);
-      return used_;
-    }
-
-    bool push(T value) {
-      base::AutoLock autolock(lock_);
-      if (used_ == size_)
-        return false;
-      values_[used_++] = value;
-      return true;
-    }
-
-    bool pop(T* out_value) {
-      base::AutoLock autolock(lock_);
-      if (used_ == 0)
-        return false;
-      *out_value = values_[--used_];
-      return true;
-    }
-
-   private:
-    const size_t size_;
-
-    std::unique_ptr<T[]> values_;
-    size_t used_;
-    base::Lock lock_;
-
-   private:
-    DISALLOW_COPY_AND_ASSIGN(ThreadSafeStack);
-  };
-
  public:
   // Type identifiers used when storing in persistent memory so they can be
   // identified during extraction; the first 4 bytes of the SHA1 of the name
@@ -392,8 +539,13 @@ class BASE_EXPORT GlobalActivityTracker {
   // will be safely ignored. These are public so that an external process
   // can recognize records of this type within an allocator.
   enum : uint32_t {
-    kTypeIdActivityTracker     = 0x5D7381AF + 1,  // SHA1(ActivityTracker) v1
-    kTypeIdActivityTrackerFree = 0x3F0272FB + 1,  // SHA1(ActivityTrackerFree)
+    kTypeIdActivityTracker = 0x5D7381AF + 3,   // SHA1(ActivityTracker) v3
+    kTypeIdUserDataRecord = 0x615EDDD7 + 1,    // SHA1(UserDataRecord) v1
+    kTypeIdGlobalDataRecord = 0xAFE61ABE + 1,  // SHA1(GlobalDataRecord) v1
+    kTypeIdGlobalLogMessage = 0x4CF434F9 + 1,  // SHA1(GlobalLogMessage) v1
+
+    kTypeIdActivityTrackerFree = ~kTypeIdActivityTracker,
+    kTypeIdUserDataRecordFree = ~kTypeIdUserDataRecord,
   };
 
   // This is a thin wrapper around the thread-tracker's ScopedActivity that
@@ -403,12 +555,14 @@ class BASE_EXPORT GlobalActivityTracker {
   class BASE_EXPORT ScopedThreadActivity
       : public ThreadActivityTracker::ScopedActivity {
    public:
-    ScopedThreadActivity(const void* origin,
+    ScopedThreadActivity(const void* program_counter,
+                         const void* origin,
                          Activity::Type type,
                          const ActivityData& data,
                          bool lock_allowed)
         : ThreadActivityTracker::ScopedActivity(
               GetOrCreateTracker(lock_allowed),
+              program_counter,
               origin,
               type,
               data) {}
@@ -492,6 +646,21 @@ class BASE_EXPORT GlobalActivityTracker {
   // Releases the activity-tracker for the current thread (for testing only).
   void ReleaseTrackerForCurrentThreadForTesting();
 
+  // Gets a reference to memory for holding user-defined activity data. If
+  // the reference is valid, it's memory will be returned. If not, then a
+  // new reference will be created (and stored) and that memory returned.
+  void* GetUserDataMemory(PersistentMemoryAllocator::Reference* reference);
+
+  // Releases memory for user-defined activity data.
+  void ReleaseUserDataMemory(PersistentMemoryAllocator::Reference* reference);
+
+  // Records a log message. The current implementation does NOT recycle these
+  // only store critical messages such as FATAL ones.
+  void RecordLogMessage(StringPiece message);
+
+  // Accesses the global data record for storing arbitrary key/value pairs.
+  ActivityUserData& user_data() { return user_data_; }
+
  private:
   friend class ActivityTrackerTest;
 
@@ -499,6 +668,8 @@ class BASE_EXPORT GlobalActivityTracker {
     // The maximum number of threads that can be tracked within a process. If
     // more than this number run concurrently, tracking of new ones may cease.
     kMaxThreadCount = 100,
+    kCachedThreadMemories = 10,
+    kCachedUserDataMemories = 10,
   };
 
   // A thin wrapper around the main thread-tracker that keeps additional
@@ -550,9 +721,17 @@ class BASE_EXPORT GlobalActivityTracker {
   // The number of thread trackers currently active.
   std::atomic<int> thread_tracker_count_;
 
-  // A cache of thread-tracker memories that have been previously freed and
-  // thus can be re-used instead of allocating new ones.
-  ThreadSafeStack<PersistentMemoryAllocator::Reference> available_memories_;
+  // A caching memory allocator for thread-tracker objects.
+  ActivityTrackerMemoryAllocator thread_tracker_allocator_;
+  base::Lock thread_tracker_allocator_lock_;
+
+  // A caching memory allocator for user data attached to activity data.
+  ActivityTrackerMemoryAllocator user_data_allocator_;
+  base::Lock user_data_allocator_lock_;
+
+  // An object for holding global arbitrary key value pairs. Values must always
+  // be written from the main UI thread.
+  ActivityUserData user_data_;
 
   // The active global activity tracker.
   static GlobalActivityTracker* g_tracker_;
@@ -577,17 +756,16 @@ class BASE_EXPORT ScopedActivity
   //   echo -n "MayNeverExit" | sha1sum   =>   e44873ccab21e2b71270da24aa1...
   //
   //   void MayNeverExit(int32_t foo) {
-  //     base::debug::ScopedActivity track_me(FROM_HERE, 0, 0xE44873CC, foo);
+  //     base::debug::ScopedActivity track_me(0, 0xE44873CC, foo);
   //     ...
   //   }
-  ScopedActivity(const tracked_objects::Location& location,
-                 uint8_t action,
-                 uint32_t id,
-                 int32_t info);
-
-  // Because this is inline, the FROM_HERE macro will resolve the current
-  // program-counter as the location in the calling code.
-  ScopedActivity() : ScopedActivity(FROM_HERE, 0, 0, 0) {}
+  ALWAYS_INLINE
+  ScopedActivity(uint8_t action, uint32_t id, int32_t info)
+      : ScopedActivity(::tracked_objects::GetProgramCounter(),
+                       action,
+                       id,
+                       info) {}
+  ScopedActivity() : ScopedActivity(0, 0, 0) {}
 
   // Changes the |action| and/or |info| of this activity on the stack. This
   // is useful for tracking progress through a function, updating the action
@@ -599,6 +777,12 @@ class BASE_EXPORT ScopedActivity
   void ChangeActionAndInfo(uint8_t action, int32_t info);
 
  private:
+  // Constructs the object using a passed-in program-counter.
+  ScopedActivity(const void* program_counter,
+                 uint8_t action,
+                 uint32_t id,
+                 int32_t info);
+
   // A copy of the ID code so it doesn't have to be passed by the caller when
   // changing the |info| field.
   uint32_t id_;
@@ -612,32 +796,56 @@ class BASE_EXPORT ScopedActivity
 class BASE_EXPORT ScopedTaskRunActivity
     : public GlobalActivityTracker::ScopedThreadActivity {
  public:
-  explicit ScopedTaskRunActivity(const base::PendingTask& task);
+  ALWAYS_INLINE
+  explicit ScopedTaskRunActivity(const base::PendingTask& task)
+      : ScopedTaskRunActivity(::tracked_objects::GetProgramCounter(),
+                              task) {}
+
  private:
+  ScopedTaskRunActivity(const void* program_counter,
+                        const base::PendingTask& task);
   DISALLOW_COPY_AND_ASSIGN(ScopedTaskRunActivity);
 };
 
 class BASE_EXPORT ScopedLockAcquireActivity
     : public GlobalActivityTracker::ScopedThreadActivity {
  public:
-  explicit ScopedLockAcquireActivity(const base::internal::LockImpl* lock);
+  ALWAYS_INLINE
+  explicit ScopedLockAcquireActivity(const base::internal::LockImpl* lock)
+      : ScopedLockAcquireActivity(::tracked_objects::GetProgramCounter(),
+                                  lock) {}
+
  private:
+  ScopedLockAcquireActivity(const void* program_counter,
+                            const base::internal::LockImpl* lock);
   DISALLOW_COPY_AND_ASSIGN(ScopedLockAcquireActivity);
 };
 
 class BASE_EXPORT ScopedEventWaitActivity
     : public GlobalActivityTracker::ScopedThreadActivity {
  public:
-  explicit ScopedEventWaitActivity(const base::WaitableEvent* event);
+  ALWAYS_INLINE
+  explicit ScopedEventWaitActivity(const base::WaitableEvent* event)
+      : ScopedEventWaitActivity(::tracked_objects::GetProgramCounter(),
+                                event) {}
+
  private:
+  ScopedEventWaitActivity(const void* program_counter,
+                          const base::WaitableEvent* event);
   DISALLOW_COPY_AND_ASSIGN(ScopedEventWaitActivity);
 };
 
 class BASE_EXPORT ScopedThreadJoinActivity
     : public GlobalActivityTracker::ScopedThreadActivity {
  public:
-  explicit ScopedThreadJoinActivity(const base::PlatformThreadHandle* thread);
+  ALWAYS_INLINE
+  explicit ScopedThreadJoinActivity(const base::PlatformThreadHandle* thread)
+      : ScopedThreadJoinActivity(::tracked_objects::GetProgramCounter(),
+                                 thread) {}
+
  private:
+  ScopedThreadJoinActivity(const void* program_counter,
+                           const base::PlatformThreadHandle* thread);
   DISALLOW_COPY_AND_ASSIGN(ScopedThreadJoinActivity);
 };
 
@@ -646,8 +854,14 @@ class BASE_EXPORT ScopedThreadJoinActivity
 class BASE_EXPORT ScopedProcessWaitActivity
     : public GlobalActivityTracker::ScopedThreadActivity {
  public:
-  explicit ScopedProcessWaitActivity(const base::Process* process);
+  ALWAYS_INLINE
+  explicit ScopedProcessWaitActivity(const base::Process* process)
+      : ScopedProcessWaitActivity(::tracked_objects::GetProgramCounter(),
+                                  process) {}
+
  private:
+  ScopedProcessWaitActivity(const void* program_counter,
+                            const base::Process* process);
   DISALLOW_COPY_AND_ASSIGN(ScopedProcessWaitActivity);
 };
 #endif
diff --git a/src/base/debug/stack_trace.cc b/src/base/debug/stack_trace.cc
index 59052aa..b8f880e 100644
--- a/src/base/debug/stack_trace.cc
+++ b/src/base/debug/stack_trace.cc
@@ -9,6 +9,7 @@
 #include <algorithm>
 #include <sstream>
 
+#include "base/logging.h"
 #include "base/macros.h"
 
 #if HAVE_TRACE_STACK_FRAME_POINTERS
@@ -176,6 +177,17 @@ uintptr_t ScanStackForNextFrame(uintptr_t fp, uintptr_t stack_end) {
   return 0;
 }
 
+// Links stack frame |fp| to |parent_fp|, so that during stack unwinding
+// TraceStackFramePointers() visits |parent_fp| after visiting |fp|.
+// Both frame pointers must come from __builtin_frame_address().
+// Returns previous stack frame |fp| was linked to.
+void* LinkStackFrames(void* fpp, void* parent_fp) {
+  uintptr_t fp = reinterpret_cast<uintptr_t>(fpp) - kStackFrameAdjustment;
+  void* prev_parent_fp = reinterpret_cast<void**>(fp)[0];
+  reinterpret_cast<void**>(fp)[0] = parent_fp;
+  return prev_parent_fp;
+}
+
 #endif  // HAVE_TRACE_STACK_FRAME_POINTERS
 
 }  // namespace
@@ -251,6 +263,17 @@ size_t TraceStackFramePointers(const void** out_trace,
   return depth;
 }
 
+ScopedStackFrameLinker::ScopedStackFrameLinker(void* fp, void* parent_fp)
+    : fp_(fp),
+      parent_fp_(parent_fp),
+      original_parent_fp_(LinkStackFrames(fp, parent_fp)) {}
+
+ScopedStackFrameLinker::~ScopedStackFrameLinker() {
+  void* previous_parent_fp = LinkStackFrames(fp_, original_parent_fp_);
+  CHECK_EQ(parent_fp_, previous_parent_fp)
+      << "Stack frame's parent pointer has changed!";
+}
+
 #endif  // HAVE_TRACE_STACK_FRAME_POINTERS
 
 }  // namespace debug
diff --git a/src/base/debug/stack_trace.h b/src/base/debug/stack_trace.h
index 23e7b51..d4918d6 100644
--- a/src/base/debug/stack_trace.h
+++ b/src/base/debug/stack_trace.h
@@ -11,6 +11,7 @@
 #include <string>
 
 #include "base/base_export.h"
+#include "base/macros.h"
 #include "build/build_config.h"
 
 #if defined(OS_POSIX)
@@ -113,6 +114,57 @@ class BASE_EXPORT StackTrace {
 BASE_EXPORT size_t TraceStackFramePointers(const void** out_trace,
                                            size_t max_depth,
                                            size_t skip_initial);
+
+// Links stack frame |fp| to |parent_fp|, so that during stack unwinding
+// TraceStackFramePointers() visits |parent_fp| after visiting |fp|.
+// Both frame pointers must come from __builtin_frame_address().
+// Destructor restores original linkage of |fp| to avoid corrupting caller's
+// frame register on return.
+//
+// This class can be used to repair broken stack frame chain in cases
+// when execution flow goes into code built without frame pointers:
+//
+// void DoWork() {
+//   Call_SomeLibrary();
+// }
+// static __thread void*  g_saved_fp;
+// void Call_SomeLibrary() {
+//   g_saved_fp = __builtin_frame_address(0);
+//   some_library_call(...); // indirectly calls SomeLibrary_Callback()
+// }
+// void SomeLibrary_Callback() {
+//   ScopedStackFrameLinker linker(__builtin_frame_address(0), g_saved_fp);
+//   ...
+//   TraceStackFramePointers(...);
+// }
+//
+// This produces the following trace:
+//
+// #0 SomeLibrary_Callback()
+// #1 <address of the code inside SomeLibrary that called #0>
+// #2 DoWork()
+// ...rest of the trace...
+//
+// SomeLibrary doesn't use frame pointers, so when SomeLibrary_Callback()
+// is called, stack frame register contains bogus value that becomes callback'
+// parent frame address. Without ScopedStackFrameLinker unwinding would've
+// stopped at that bogus frame address yielding just two first frames (#0, #1).
+// ScopedStackFrameLinker overwrites callback's parent frame address with
+// Call_SomeLibrary's frame, so unwinder produces full trace without even
+// noticing that stack frame chain was broken.
+class BASE_EXPORT ScopedStackFrameLinker {
+ public:
+  ScopedStackFrameLinker(void* fp, void* parent_fp);
+  ~ScopedStackFrameLinker();
+
+ private:
+  void* fp_;
+  void* parent_fp_;
+  void* original_parent_fp_;
+
+  DISALLOW_COPY_AND_ASSIGN(ScopedStackFrameLinker);
+};
+
 #endif  // HAVE_TRACE_STACK_FRAME_POINTERS
 
 namespace internal {
diff --git a/src/base/debug/task_annotator.cc b/src/base/debug/task_annotator.cc
index 2747d63..437d69a 100644
--- a/src/base/debug/task_annotator.cc
+++ b/src/base/debug/task_annotator.cc
@@ -28,34 +28,32 @@ void TaskAnnotator::DidQueueTask(const char* queue_function,
 }
 
 void TaskAnnotator::RunTask(const char* queue_function,
-                            const PendingTask& pending_task) {
-  ScopedTaskRunActivity task_activity(pending_task);
+                            PendingTask* pending_task) {
+  ScopedTaskRunActivity task_activity(*pending_task);
 
   tracked_objects::TaskStopwatch stopwatch;
   stopwatch.Start();
   tracked_objects::Duration queue_duration =
-      stopwatch.StartTime() - pending_task.EffectiveTimePosted();
+      stopwatch.StartTime() - pending_task->EffectiveTimePosted();
 
-  TRACE_EVENT_WITH_FLOW1(TRACE_DISABLED_BY_DEFAULT("toplevel.flow"),
-                          queue_function,
-                          TRACE_ID_MANGLE(GetTaskTraceID(pending_task)),
-                          TRACE_EVENT_FLAG_FLOW_IN,
-                          "queue_duration",
-                          queue_duration.InMilliseconds());
+  TRACE_EVENT_WITH_FLOW1(
+      TRACE_DISABLED_BY_DEFAULT("toplevel.flow"), queue_function,
+      TRACE_ID_MANGLE(GetTaskTraceID(*pending_task)), TRACE_EVENT_FLAG_FLOW_IN,
+      "queue_duration", queue_duration.InMilliseconds());
 
   // Before running the task, store the program counter where it was posted
   // and deliberately alias it to ensure it is on the stack if the task
   // crashes. Be careful not to assume that the variable itself will have the
   // expected value when displayed by the optimizer in an optimized build.
   // Look at a memory dump of the stack.
-  const void* program_counter = pending_task.posted_from.program_counter();
+  const void* program_counter = pending_task->posted_from.program_counter();
   debug::Alias(&program_counter);
 
-  pending_task.task.Run();
+  std::move(pending_task->task).Run();
 
   stopwatch.Stop();
-  tracked_objects::ThreadData::TallyRunOnNamedThreadIfTracking(
-      pending_task, stopwatch);
+  tracked_objects::ThreadData::TallyRunOnNamedThreadIfTracking(*pending_task,
+                                                               stopwatch);
 }
 
 uint64_t TaskAnnotator::GetTaskTraceID(const PendingTask& task) const {
diff --git a/src/base/debug/task_annotator.h b/src/base/debug/task_annotator.h
index 2687c5c..34115d8 100644
--- a/src/base/debug/task_annotator.h
+++ b/src/base/debug/task_annotator.h
@@ -28,7 +28,7 @@ class BASE_EXPORT TaskAnnotator {
 
   // Run a previously queued task. |queue_function| should match what was
   // passed into |DidQueueTask| for this task.
-  void RunTask(const char* queue_function, const PendingTask& pending_task);
+  void RunTask(const char* queue_function, PendingTask* pending_task);
 
  private:
   // Creates a process-wide unique ID to represent this task in trace events.
diff --git a/src/base/feature_list.h b/src/base/feature_list.h
index 698ecd5..daedd73 100644
--- a/src/base/feature_list.h
+++ b/src/base/feature_list.h
@@ -13,6 +13,7 @@
 #include "base/base_export.h"
 #include "base/gtest_prod_util.h"
 #include "base/macros.h"
+#include "base/metrics/persistent_memory_allocator.h"
 #include "base/strings/string_piece.h"
 #include "base/synchronization/lock.h"
 
@@ -92,6 +93,11 @@ class BASE_EXPORT FeatureList {
   void InitializeFromCommandLine(const std::string& enable_features,
                                  const std::string& disable_features);
 
+  // Initializes feature overrides through the field trial allocator, which
+  // we're using to store the feature names, their override state, and the name
+  // of the associated field trial.
+  void InitializeFromSharedMemory(PersistentMemoryAllocator* allocator);
+
   // Specifies whether a feature override enables or disables the feature.
   enum OverrideState {
     OVERRIDE_USE_DEFAULT,
@@ -124,6 +130,9 @@ class BASE_EXPORT FeatureList {
                                   OverrideState override_state,
                                   FieldTrial* field_trial);
 
+  // Loops through feature overrides and serializes them all into |allocator|.
+  void AddFeaturesToAllocator(PersistentMemoryAllocator* allocator);
+
   // Returns comma-separated lists of feature names (in the same format that is
   // accepted by InitializeFromCommandLine()) corresponding to features that
   // have been overridden - either through command-line or via FieldTrials. For
@@ -163,6 +172,8 @@ class BASE_EXPORT FeatureList {
 
   // Registers the given |instance| to be the singleton feature list for this
   // process. This should only be called once and |instance| must not be null.
+  // Note: If you are considering using this for the purposes of testing, take
+  // a look at using base/test/scoped_feature_list.h instead.
   static void SetInstance(std::unique_ptr<FeatureList> instance);
 
   // Clears the previously-registered singleton instance for tests and returns
@@ -178,6 +189,10 @@ class BASE_EXPORT FeatureList {
 
  private:
   FRIEND_TEST_ALL_PREFIXES(FeatureListTest, CheckFeatureIdentity);
+  FRIEND_TEST_ALL_PREFIXES(FeatureListTest,
+                           StoreAndRetrieveFeaturesFromSharedMemory);
+  FRIEND_TEST_ALL_PREFIXES(FeatureListTest,
+                           StoreAndRetrieveAssociatedFeaturesFromSharedMemory);
 
   struct OverrideEntry {
     // The overridden enable (on/off) state of the feature.
diff --git a/src/base/files/file_path.cc b/src/base/files/file_path.cc
index 0b06493..cff862a 100644
--- a/src/base/files/file_path.cc
+++ b/src/base/files/file_path.cc
@@ -560,6 +560,12 @@ FilePath FilePath::StripTrailingSeparators() const {
 }
 
 bool FilePath::ReferencesParent() const {
+  if (path_.find(kParentDirectory) == StringType::npos) {
+    // GetComponents is quite expensive, so avoid calling it in the majority
+    // of cases where there isn't a kParentDirectory anywhere in the path.
+    return false;
+  }
+
   std::vector<StringType> components;
   GetComponents(&components);
 
diff --git a/src/base/files/file_posix.cc b/src/base/files/file_posix.cc
index 3d2d54a..a0f2328 100644
--- a/src/base/files/file_posix.cc
+++ b/src/base/files/file_posix.cc
@@ -11,7 +11,7 @@
 #include <unistd.h>
 
 #include "base/logging.h"
-#include "base/metrics/sparse_histogram.h"
+#include "base/metrics/histogram_macros.h"
 #include "base/posix/eintr_wrapper.h"
 #include "base/strings/utf_string_conversions.h"
 #include "base/threading/thread_restrictions.h"
diff --git a/src/base/files/file_util.h b/src/base/files/file_util.h
index 420dcae..77a87e7 100644
--- a/src/base/files/file_util.h
+++ b/src/base/files/file_util.h
@@ -294,10 +294,6 @@ BASE_EXPORT bool DevicePathToDriveLetterPath(const FilePath& device_path,
 // be resolved with this function.
 BASE_EXPORT bool NormalizeToNativeFilePath(const FilePath& path,
                                            FilePath* nt_path);
-
-// Given an existing file in |path|, returns whether this file is on a network
-// drive or not. If |path| does not exist, this function returns false.
-BASE_EXPORT bool IsOnNetworkDrive(const base::FilePath& path);
 #endif
 
 // This function will return if the given file is a symlink or not.
@@ -365,6 +361,17 @@ BASE_EXPORT int GetUniquePathNumber(const FilePath& path,
 BASE_EXPORT bool SetNonBlocking(int fd);
 
 #if defined(OS_POSIX)
+// Creates a non-blocking, close-on-exec pipe.
+// This creates a non-blocking pipe that is not intended to be shared with any
+// child process. This will be done atomically if the operating system supports
+// it. Returns true if it was able to create the pipe, otherwise false.
+BASE_EXPORT bool CreateLocalNonBlockingPipe(int fds[2]);
+
+// Sets the given |fd| to close-on-exec mode.
+// Returns true if it was able to set it in the close-on-exec mode, otherwise
+// false.
+BASE_EXPORT bool SetCloseOnExec(int fd);
+
 // Test that |path| can only be changed by a given user and members of
 // a given set of groups.
 // Specifically, test that all parts of |path| under (and including) |base|:
diff --git a/src/base/files/file_util_posix.cc b/src/base/files/file_util_posix.cc
index 42de931..a8db259 100644
--- a/src/base/files/file_util_posix.cc
+++ b/src/base/files/file_util_posix.cc
@@ -351,6 +351,29 @@ bool CopyDirectory(const FilePath& from_path,
 }
 #endif  // !defined(OS_NACL_NONSFI)
 
+bool CreateLocalNonBlockingPipe(int fds[2]) {
+#if defined(OS_LINUX)
+  return pipe2(fds, O_CLOEXEC | O_NONBLOCK) == 0;
+#else
+  int raw_fds[2];
+  if (pipe(raw_fds) != 0)
+    return false;
+  ScopedFD fd_out(raw_fds[0]);
+  ScopedFD fd_in(raw_fds[1]);
+  if (!SetCloseOnExec(fd_out.get()))
+    return false;
+  if (!SetCloseOnExec(fd_in.get()))
+    return false;
+  if (!SetNonBlocking(fd_out.get()))
+    return false;
+  if (!SetNonBlocking(fd_in.get()))
+    return false;
+  fds[0] = fd_out.release();
+  fds[1] = fd_in.release();
+  return true;
+#endif
+}
+
 bool SetNonBlocking(int fd) {
   const int flags = fcntl(fd, F_GETFL);
   if (flags == -1)
@@ -362,6 +385,21 @@ bool SetNonBlocking(int fd) {
   return true;
 }
 
+bool SetCloseOnExec(int fd) {
+#if defined(OS_NACL_NONSFI)
+  const int flags = 0;
+#else
+  const int flags = fcntl(fd, F_GETFD);
+  if (flags == -1)
+    return false;
+  if (flags & FD_CLOEXEC)
+    return true;
+#endif  // defined(OS_NACL_NONSFI)
+  if (HANDLE_EINTR(fcntl(fd, F_SETFD, flags | FD_CLOEXEC)) == -1)
+    return false;
+  return true;
+}
+
 bool PathExists(const FilePath& path) {
   ThreadRestrictions::AssertIOAllowed();
 #if defined(OS_ANDROID)
diff --git a/src/base/json/json_parser.cc b/src/base/json/json_parser.cc
index b1f28b4..1850a1a 100644
--- a/src/base/json/json_parser.cc
+++ b/src/base/json/json_parser.cc
@@ -39,7 +39,7 @@ class DictionaryHiddenRootValue : public DictionaryValue {
   DictionaryHiddenRootValue(std::unique_ptr<std::string> json,
                             std::unique_ptr<Value> root)
       : json_(std::move(json)) {
-    DCHECK(root->IsType(Value::TYPE_DICTIONARY));
+    DCHECK(root->IsType(Value::Type::DICTIONARY));
     DictionaryValue::Swap(static_cast<DictionaryValue*>(root.get()));
   }
 
@@ -91,7 +91,7 @@ class ListHiddenRootValue : public ListValue {
   ListHiddenRootValue(std::unique_ptr<std::string> json,
                       std::unique_ptr<Value> root)
       : json_(std::move(json)) {
-    DCHECK(root->IsType(Value::TYPE_LIST));
+    DCHECK(root->IsType(Value::Type::LIST));
     ListValue::Swap(static_cast<ListValue*>(root.get()));
   }
 
@@ -140,7 +140,7 @@ class ListHiddenRootValue : public ListValue {
 class JSONStringValue : public Value {
  public:
   explicit JSONStringValue(StringPiece piece)
-      : Value(TYPE_STRING), string_piece_(piece) {}
+      : Value(Type::STRING), string_piece_(piece) {}
 
   // Overridden from Value:
   bool GetAsString(std::string* out_value) const override {
@@ -151,13 +151,11 @@ class JSONStringValue : public Value {
     *out_value = UTF8ToUTF16(string_piece_);
     return true;
   }
-  Value* DeepCopy() const override {
-    return new StringValue(string_piece_.as_string());
-  }
+  Value* DeepCopy() const override { return new StringValue(string_piece_); }
   bool Equals(const Value* other) const override {
     std::string other_string;
-    return other->IsType(TYPE_STRING) && other->GetAsString(&other_string) &&
-        StringPiece(other_string) == string_piece_;
+    return other->IsType(Type::STRING) && other->GetAsString(&other_string) &&
+           StringPiece(other_string) == string_piece_;
   }
 
  private:
@@ -190,6 +188,9 @@ class StackMarker {
 
 }  // namespace
 
+// This is U+FFFD.
+const char kUnicodeReplacementString[] = "\xEF\xBF\xBD";
+
 JSONParser::JSONParser(int options)
     : options_(options),
       start_pos_(nullptr),
@@ -254,15 +255,15 @@ std::unique_ptr<Value> JSONParser::Parse(StringPiece input) {
   // Dictionaries and lists can contain JSONStringValues, so wrap them in a
   // hidden root.
   if (!(options_ & JSON_DETACHABLE_CHILDREN)) {
-    if (root->IsType(Value::TYPE_DICTIONARY)) {
+    if (root->IsType(Value::Type::DICTIONARY)) {
       return MakeUnique<DictionaryHiddenRootValue>(std::move(input_copy),
                                                    std::move(root));
     }
-    if (root->IsType(Value::TYPE_LIST)) {
+    if (root->IsType(Value::Type::LIST)) {
       return MakeUnique<ListHiddenRootValue>(std::move(input_copy),
                                              std::move(root));
     }
-    if (root->IsType(Value::TYPE_STRING)) {
+    if (root->IsType(Value::Type::STRING)) {
       // A string type could be a JSONStringValue, but because there's no
       // corresponding HiddenRootValue, the memory will be lost. Deep copy to
       // preserve it.
@@ -628,11 +629,18 @@ bool JSONParser::ConsumeStringRaw(StringBuilder* out) {
   int32_t next_char = 0;
 
   while (CanConsume(1)) {
+    int start_index = index_;
     pos_ = start_pos_ + index_;  // CBU8_NEXT is postcrement.
     CBU8_NEXT(start_pos_, index_, length, next_char);
     if (next_char < 0 || !IsValidCharacter(next_char)) {
-      ReportError(JSONReader::JSON_UNSUPPORTED_ENCODING, 1);
-      return false;
+      if ((options_ & JSON_REPLACE_INVALID_CHARACTERS) == 0) {
+        ReportError(JSONReader::JSON_UNSUPPORTED_ENCODING, 1);
+        return false;
+      }
+      CBU8_NEXT(start_pos_, start_index, length, next_char);
+      string.Convert();
+      string.AppendString(kUnicodeReplacementString);
+      continue;
     }
 
     if (next_char == '"') {
diff --git a/src/base/json/json_parser.h b/src/base/json/json_parser.h
index 11a5111..1cebb8d 100644
--- a/src/base/json/json_parser.h
+++ b/src/base/json/json_parser.h
@@ -257,10 +257,14 @@ class BASE_EXPORT JSONParser {
   FRIEND_TEST_ALL_PREFIXES(JSONParserTest, ConsumeLiterals);
   FRIEND_TEST_ALL_PREFIXES(JSONParserTest, ConsumeNumbers);
   FRIEND_TEST_ALL_PREFIXES(JSONParserTest, ErrorMessages);
+  FRIEND_TEST_ALL_PREFIXES(JSONParserTest, ReplaceInvalidCharacters);
 
   DISALLOW_COPY_AND_ASSIGN(JSONParser);
 };
 
+// Used when decoding and an invalid utf-8 sequence is encountered.
+BASE_EXPORT extern const char kUnicodeReplacementString[];
+
 }  // namespace internal
 }  // namespace base
 
diff --git a/src/base/json/json_reader.h b/src/base/json/json_reader.h
index a954821..a39b37a 100644
--- a/src/base/json/json_reader.h
+++ b/src/base/json/json_reader.h
@@ -55,6 +55,11 @@ enum JSONParserOptions {
   // if the child is Remove()d from root, it would result in use-after-free
   // unless it is DeepCopy()ed or this option is used.
   JSON_DETACHABLE_CHILDREN = 1 << 1,
+
+  // If set the parser replaces invalid characters with the Unicode replacement
+  // character (U+FFFD). If not set, invalid characters trigger a hard error and
+  // parsing fails.
+  JSON_REPLACE_INVALID_CHARACTERS = 1 << 2,
 };
 
 class BASE_EXPORT JSONReader {
diff --git a/src/base/json/json_string_value_serializer.cc b/src/base/json/json_string_value_serializer.cc
index cd786db..2e46ab3 100644
--- a/src/base/json/json_string_value_serializer.cc
+++ b/src/base/json/json_string_value_serializer.cc
@@ -41,18 +41,15 @@ bool JSONStringValueSerializer::SerializeInternal(const Value& root,
 }
 
 JSONStringValueDeserializer::JSONStringValueDeserializer(
-    const base::StringPiece& json_string)
-    : json_string_(json_string),
-      allow_trailing_comma_(false) {
-}
+    const base::StringPiece& json_string,
+    int options)
+    : json_string_(json_string), options_(options) {}
 
 JSONStringValueDeserializer::~JSONStringValueDeserializer() {}
 
 std::unique_ptr<Value> JSONStringValueDeserializer::Deserialize(
     int* error_code,
     std::string* error_str) {
-  return base::JSONReader::ReadAndReturnError(
-      json_string_, allow_trailing_comma_ ? base::JSON_ALLOW_TRAILING_COMMAS
-                                          : base::JSON_PARSE_RFC,
-      error_code, error_str);
+  return base::JSONReader::ReadAndReturnError(json_string_, options_,
+                                              error_code, error_str);
 }
diff --git a/src/base/json/json_string_value_serializer.h b/src/base/json/json_string_value_serializer.h
index a97da23..55a53e2 100644
--- a/src/base/json/json_string_value_serializer.h
+++ b/src/base/json/json_string_value_serializer.h
@@ -47,8 +47,10 @@ class BASE_EXPORT JSONStringValueSerializer : public base::ValueSerializer {
 class BASE_EXPORT JSONStringValueDeserializer : public base::ValueDeserializer {
  public:
   // This retains a reference to the contents of |json_string|, so the data
-  // must outlive the JSONStringValueDeserializer.
-  explicit JSONStringValueDeserializer(const base::StringPiece& json_string);
+  // must outlive the JSONStringValueDeserializer. |options| is a bitmask of
+  // JSONParserOptions.
+  explicit JSONStringValueDeserializer(const base::StringPiece& json_string,
+                                       int options = 0);
 
   ~JSONStringValueDeserializer() override;
 
@@ -62,15 +64,10 @@ class BASE_EXPORT JSONStringValueDeserializer : public base::ValueDeserializer {
   std::unique_ptr<base::Value> Deserialize(int* error_code,
                                            std::string* error_message) override;
 
-  void set_allow_trailing_comma(bool new_value) {
-    allow_trailing_comma_ = new_value;
-  }
-
  private:
   // Data is owned by the caller of the constructor.
   base::StringPiece json_string_;
-  // If true, deserialization will allow trailing commas.
-  bool allow_trailing_comma_;
+  const int options_;
 
   DISALLOW_COPY_AND_ASSIGN(JSONStringValueDeserializer);
 };
diff --git a/src/base/json/json_writer.cc b/src/base/json/json_writer.cc
index 0b658ee..07b9d50 100644
--- a/src/base/json/json_writer.cc
+++ b/src/base/json/json_writer.cc
@@ -57,12 +57,12 @@ JSONWriter::JSONWriter(int options, std::string* json)
 
 bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
   switch (node.GetType()) {
-    case Value::TYPE_NULL: {
+    case Value::Type::NONE: {
       json_string_->append("null");
       return true;
     }
 
-    case Value::TYPE_BOOLEAN: {
+    case Value::Type::BOOLEAN: {
       bool value;
       bool result = node.GetAsBoolean(&value);
       DCHECK(result);
@@ -70,7 +70,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       return result;
     }
 
-    case Value::TYPE_INTEGER: {
+    case Value::Type::INTEGER: {
       int value;
       bool result = node.GetAsInteger(&value);
       DCHECK(result);
@@ -78,7 +78,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       return result;
     }
 
-    case Value::TYPE_DOUBLE: {
+    case Value::Type::DOUBLE: {
       double value;
       bool result = node.GetAsDouble(&value);
       DCHECK(result);
@@ -110,7 +110,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       return result;
     }
 
-    case Value::TYPE_STRING: {
+    case Value::Type::STRING: {
       std::string value;
       bool result = node.GetAsString(&value);
       DCHECK(result);
@@ -118,7 +118,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       return result;
     }
 
-    case Value::TYPE_LIST: {
+    case Value::Type::LIST: {
       json_string_->push_back('[');
       if (pretty_print_)
         json_string_->push_back(' ');
@@ -128,7 +128,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       bool result = node.GetAsList(&list);
       DCHECK(result);
       for (const auto& value : *list) {
-        if (omit_binary_values_ && value->GetType() == Value::TYPE_BINARY)
+        if (omit_binary_values_ && value->GetType() == Value::Type::BINARY)
           continue;
 
         if (first_value_has_been_output) {
@@ -149,7 +149,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       return result;
     }
 
-    case Value::TYPE_DICTIONARY: {
+    case Value::Type::DICTIONARY: {
       json_string_->push_back('{');
       if (pretty_print_)
         json_string_->append(kPrettyPrintLineEnding);
@@ -161,7 +161,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       for (DictionaryValue::Iterator itr(*dict); !itr.IsAtEnd();
            itr.Advance()) {
         if (omit_binary_values_ &&
-            itr.value().GetType() == Value::TYPE_BINARY) {
+            itr.value().GetType() == Value::Type::BINARY) {
           continue;
         }
 
@@ -194,7 +194,7 @@ bool JSONWriter::BuildJSONString(const Value& node, size_t depth) {
       return result;
     }
 
-    case Value::TYPE_BINARY:
+    case Value::Type::BINARY:
       // Successful only if we're allowed to omit it.
       DLOG_IF(ERROR, !omit_binary_values_) << "Cannot serialize binary value.";
       return omit_binary_values_;
diff --git a/src/base/lazy_instance.h b/src/base/lazy_instance.h
index 9218bf3..1183806 100644
--- a/src/base/lazy_instance.h
+++ b/src/base/lazy_instance.h
@@ -102,7 +102,7 @@ struct LeakyLazyInstanceTraits {
 };
 
 // Our AtomicWord doubles as a spinlock, where a value of
-// kBeingCreatedMarker means the spinlock is being held for creation.
+// kLazyInstanceStateCreating means the spinlock is being held for creation.
 static const subtle::AtomicWord kLazyInstanceStateCreating = 1;
 
 // Check if instance needs to be created. If so return true otherwise
diff --git a/src/base/logging.cc b/src/base/logging.cc
index 0771b47..7bd6d63 100644
--- a/src/base/logging.cc
+++ b/src/base/logging.cc
@@ -7,6 +7,7 @@
 #include <limits.h>
 #include <stdint.h>
 
+#include "base/debug/activity_tracker.h"
 #include "base/macros.h"
 #include "build/build_config.h"
 
@@ -722,6 +723,12 @@ LogMessage::~LogMessage() {
   }
 
   if (severity_ == LOG_FATAL) {
+    // Write the log message to the global activity tracker, if running.
+    base::debug::GlobalActivityTracker* tracker =
+        base::debug::GlobalActivityTracker::Get();
+    if (tracker)
+      tracker->RecordLogMessage(str_newline);
+
     // Ensure the first characters of the string are on the stack so they
     // are contained in minidumps for diagnostic purposes.
     char str_stack[1024];
@@ -765,13 +772,12 @@ void LogMessage::Init(const char* file, int line) {
   if (g_log_thread_id)
     stream_ << base::PlatformThread::CurrentId() << ':';
   if (g_log_timestamp) {
-    time_t t = time(nullptr);
-    struct tm local_time = {0};
-#ifdef _MSC_VER
-    localtime_s(&local_time, &t);
-#else
+#if defined(OS_POSIX)
+    timeval tv;
+    gettimeofday(&tv, nullptr);
+    time_t t = tv.tv_sec;
+    struct tm local_time;
     localtime_r(&t, &local_time);
-#endif
     struct tm* tm_time = &local_time;
     stream_ << std::setfill('0')
             << std::setw(2) << 1 + tm_time->tm_mon
@@ -780,7 +786,23 @@ void LogMessage::Init(const char* file, int line) {
             << std::setw(2) << tm_time->tm_hour
             << std::setw(2) << tm_time->tm_min
             << std::setw(2) << tm_time->tm_sec
+            << '.'
+            << std::setw(6) << tv.tv_usec
             << ':';
+#elif defined(OS_WIN)
+    SYSTEMTIME local_time;
+    GetLocalTime(&local_time);
+    stream_ << std::setfill('0')
+            << std::setw(2) << local_time.wMonth
+            << std::setw(2) << local_time.wDay
+            << '/'
+            << std::setw(2) << local_time.wHour
+            << std::setw(2) << local_time.wMinute
+            << std::setw(2) << local_time.wSecond
+            << '.'
+            << std::setw(3) << local_time.wMilliseconds
+            << ':';
+#endif
   }
   if (g_log_tickcount)
     stream_ << TickCount() << ':';
diff --git a/src/base/logging.h b/src/base/logging.h
index 3dde702..ce87a53 100644
--- a/src/base/logging.h
+++ b/src/base/logging.h
@@ -445,6 +445,25 @@ class CheckOpResult {
   std::string* message_;
 };
 
+// Crashes in the fastest, simplest possible way with no attempt at logging.
+#if defined(COMPILER_GCC) || defined(__clang__)
+#define IMMEDIATE_CRASH() __builtin_trap()
+#else
+#define IMMEDIATE_CRASH() ((void)(*(volatile char*)0 = 0))
+#endif
+
+// Specialization of IMMEDIATE_CRASH which will raise a custom exception on
+// Windows to signal this is OOM and not a normal assert.
+#if defined(OS_WIN)
+#define OOM_CRASH()                                                     \
+  do {                                                                  \
+    ::RaiseException(0xE0000008, EXCEPTION_NONCONTINUABLE, 0, nullptr); \
+    IMMEDIATE_CRASH();                                                  \
+  } while (0)
+#else
+#define OOM_CRASH() IMMEDIATE_CRASH()
+#endif
+
 // CHECK dies with a fatal error if condition is not true.  It is *not*
 // controlled by NDEBUG, so the check will be executed regardless of
 // compilation mode.
@@ -454,20 +473,14 @@ class CheckOpResult {
 
 #if defined(OFFICIAL_BUILD) && defined(NDEBUG)
 
-// Make all CHECK functions discard their log strings to reduce code
-// bloat, and improve performance, for official release builds.
-
-#if defined(COMPILER_GCC) || __clang__
-#define LOGGING_CRASH() __builtin_trap()
-#else
-#define LOGGING_CRASH() ((void)(*(volatile char*)0 = 0))
-#endif
-
+// Make all CHECK functions discard their log strings to reduce code bloat, and
+// improve performance, for official release builds.
+//
 // This is not calling BreakDebugger since this is called frequently, and
 // calling an out-of-line function instead of a noreturn inline macro prevents
 // compiler optimizations.
-#define CHECK(condition)                                                \
-  !(condition) ? LOGGING_CRASH() : EAT_STREAM_PARAMETERS
+#define CHECK(condition) \
+  !(condition) ? IMMEDIATE_CRASH() : EAT_STREAM_PARAMETERS
 
 #define PCHECK(condition) CHECK(condition)
 
@@ -527,12 +540,26 @@ class CheckOpResult {
 // it uses the definition for operator<<, with a few special cases below.
 template <typename T>
 inline typename std::enable_if<
-    base::internal::SupportsOstreamOperator<const T&>::value,
+    base::internal::SupportsOstreamOperator<const T&>::value &&
+        !std::is_function<typename std::remove_pointer<T>::type>::value,
     void>::type
 MakeCheckOpValueString(std::ostream* os, const T& v) {
   (*os) << v;
 }
 
+// Provide an overload for functions and function pointers. Function pointers
+// don't implicitly convert to void* but do implicitly convert to bool, so
+// without this function pointers are always printed as 1 or 0. (MSVC isn't
+// standards-conforming here and converts function pointers to regular
+// pointers, so this is a no-op for MSVC.)
+template <typename T>
+inline typename std::enable_if<
+    std::is_function<typename std::remove_pointer<T>::type>::value,
+    void>::type
+MakeCheckOpValueString(std::ostream* os, const T& v) {
+  (*os) << reinterpret_cast<const void*>(v);
+}
+
 // We need overloads for enums that don't support operator<<.
 // (i.e. scoped enums where no operator<< overload was declared).
 template <typename T>
@@ -589,11 +616,11 @@ std::string* MakeCheckOpString<std::string, std::string>(
   inline std::string* Check##name##Impl(const t1& v1, const t2& v2, \
                                         const char* names) { \
     if (v1 op v2) return NULL; \
-    else return MakeCheckOpString(v1, v2, names); \
+    else return ::logging::MakeCheckOpString(v1, v2, names);    \
   } \
   inline std::string* Check##name##Impl(int v1, int v2, const char* names) { \
     if (v1 op v2) return NULL; \
-    else return MakeCheckOpString(v1, v2, names); \
+    else return ::logging::MakeCheckOpString(v1, v2, names);    \
   }
 DEFINE_CHECK_OP_IMPL(EQ, ==)
 DEFINE_CHECK_OP_IMPL(NE, !=)
@@ -731,7 +758,7 @@ const LogSeverity LOG_DCHECK = LOG_INFO;
 // defined.
 //
 // You may append to the error message like so:
-//   DCHECK_NE(1, 2) << ": The world must be ending!";
+//   DCHECK_NE(1, 2) << "The world must be ending!";
 //
 // We are very careful to ensure that each argument is evaluated exactly
 // once, and that anything which is legal to pass as a function argument is
@@ -795,6 +822,9 @@ class BASE_EXPORT LogMessage {
 
   std::ostream& stream() { return stream_; }
 
+  LogSeverity severity() { return severity_; }
+  std::string str() { return stream_.str(); }
+
  private:
   void Init(const char* file, int line);
 
diff --git a/src/base/mac/bundle_locations.h b/src/base/mac/bundle_locations.h
index 276290b..5cc44ba 100644
--- a/src/base/mac/bundle_locations.h
+++ b/src/base/mac/bundle_locations.h
@@ -12,7 +12,6 @@
 #import <Foundation/Foundation.h>
 #else  // __OBJC__
 class NSBundle;
-class NSString;
 #endif  // __OBJC__
 
 namespace base {
diff --git a/src/base/mac/mac_util.h b/src/base/mac/mac_util.h
index d0173c0..67d1880 100644
--- a/src/base/mac/mac_util.h
+++ b/src/base/mac/mac_util.h
@@ -5,10 +5,11 @@
 #ifndef BASE_MAC_MAC_UTIL_H_
 #define BASE_MAC_MAC_UTIL_H_
 
-#include <Carbon/Carbon.h>
 #include <stdint.h>
 #include <string>
 
+#import <CoreGraphics/CoreGraphics.h>
+
 #include "base/base_export.h"
 
 namespace base {
@@ -30,9 +31,6 @@ enum FullScreenMode {
   kFullScreenModeNormal = 10,
 };
 
-BASE_EXPORT std::string PathFromFSRef(const FSRef& ref);
-BASE_EXPORT bool FSRefFromPath(const std::string& path, FSRef* ref);
-
 // Returns an sRGB color space.  The return value is a static value; do not
 // release it!
 BASE_EXPORT CGColorSpaceRef GetSRGBColorSpace();
@@ -65,11 +63,6 @@ BASE_EXPORT void ReleaseFullScreen(FullScreenMode mode);
 BASE_EXPORT void SwitchFullScreenModes(FullScreenMode from_mode,
                                        FullScreenMode to_mode);
 
-// Returns true if this process is in the foreground, meaning that it's the
-// frontmost process, the one whose menu bar is shown at the top of the main
-// display.
-BASE_EXPORT bool AmIForeground();
-
 // Excludes the file given by |file_path| from being backed up by Time Machine.
 BASE_EXPORT bool SetFileBackupExclusion(const FilePath& file_path);
 
diff --git a/src/base/mac/mac_util.mm b/src/base/mac/mac_util.mm
index d4b584d..9615f9d 100644
--- a/src/base/mac/mac_util.mm
+++ b/src/base/mac/mac_util.mm
@@ -122,19 +122,6 @@ bool IsHiddenLoginItem(LSSharedFileListItemRef item) {
 
 }  // namespace
 
-std::string PathFromFSRef(const FSRef& ref) {
-  ScopedCFTypeRef<CFURLRef> url(
-      CFURLCreateFromFSRef(kCFAllocatorDefault, &ref));
-  NSString *path_string = [(NSURL *)url.get() path];
-  return [path_string fileSystemRepresentation];
-}
-
-bool FSRefFromPath(const std::string& path, FSRef* ref) {
-  OSStatus status = FSPathMakeRef((const UInt8*)path.c_str(),
-                                  ref, nil);
-  return status == noErr;
-}
-
 CGColorSpaceRef GetGenericRGBColorSpace() {
   // Leaked. That's OK, it's scoped to the lifetime of the application.
   static CGColorSpaceRef g_color_space_generic_rgb(
@@ -218,26 +205,6 @@ void SwitchFullScreenModes(FullScreenMode from_mode, FullScreenMode to_mode) {
   SetUIMode();
 }
 
-bool AmIForeground() {
-  ProcessSerialNumber foreground_psn = { 0 };
-  OSErr err = GetFrontProcess(&foreground_psn);
-  if (err != noErr) {
-    OSSTATUS_DLOG(WARNING, err) << "GetFrontProcess";
-    return false;
-  }
-
-  ProcessSerialNumber my_psn = { 0, kCurrentProcess };
-
-  Boolean result = FALSE;
-  err = SameProcess(&foreground_psn, &my_psn, &result);
-  if (err != noErr) {
-    OSSTATUS_DLOG(WARNING, err) << "SameProcess";
-    return false;
-  }
-
-  return result;
-}
-
 bool SetFileBackupExclusion(const FilePath& file_path) {
   NSString* file_path_ns =
       [NSString stringWithUTF8String:file_path.value().c_str()];
@@ -329,11 +296,21 @@ bool WasLaunchedAsLoginOrResumeItem() {
   ProcessInfoRec info = {};
   info.processInfoLength = sizeof(info);
 
+// GetProcessInformation has been deprecated since macOS 10.9, but there is no
+// replacement that provides the information we need. See
+// https://crbug.com/650854.
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wdeprecated-declarations"
   if (GetProcessInformation(&psn, &info) == noErr) {
+#pragma clang diagnostic pop
     ProcessInfoRec parent_info = {};
     parent_info.processInfoLength = sizeof(parent_info);
-    if (GetProcessInformation(&info.processLauncher, &parent_info) == noErr)
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wdeprecated-declarations"
+    if (GetProcessInformation(&info.processLauncher, &parent_info) == noErr) {
+#pragma clang diagnostic pop
       return parent_info.processSignature == 'lgnw';
+    }
   }
   return false;
 }
diff --git a/src/base/mac/scoped_nsobject.h b/src/base/mac/scoped_nsobject.h
index cc54aa0..ecd8e78 100644
--- a/src/base/mac/scoped_nsobject.h
+++ b/src/base/mac/scoped_nsobject.h
@@ -102,7 +102,7 @@ class scoped_nsprotocol
       : ScopedTypeRef<NST, Traits>(that_as_subclass) {}
 
   scoped_nsprotocol(scoped_nsprotocol<NST>&& that)
-      : ScopedTypeRef<NST, Traits>(that) {}
+      : ScopedTypeRef<NST, Traits>(std::move(that)) {}
 
   scoped_nsprotocol& operator=(const scoped_nsprotocol<NST>& that) {
     ScopedTypeRef<NST, Traits>::operator=(that);
@@ -166,7 +166,7 @@ class scoped_nsobject : public scoped_nsprotocol<NST*> {
       : scoped_nsprotocol<NST*>(that_as_subclass) {}
 
   scoped_nsobject(scoped_nsobject<NST>&& that)
-      : scoped_nsprotocol<NST*>(that) {}
+      : scoped_nsprotocol<NST*>(std::move(that)) {}
 
   scoped_nsobject& operator=(const scoped_nsobject<NST>& that) {
     scoped_nsprotocol<NST*>::operator=(that);
@@ -214,7 +214,8 @@ class scoped_nsobject<id> : public scoped_nsprotocol<id> {
   explicit scoped_nsobject(const scoped_nsobject<NSR>& that_as_subclass)
       : scoped_nsprotocol<id>(that_as_subclass) {}
 
-  scoped_nsobject(scoped_nsobject<id>&& that) : scoped_nsprotocol<id>(that) {}
+  scoped_nsobject(scoped_nsobject<id>&& that)
+      : scoped_nsprotocol<id>(std::move(that)) {}
 
   scoped_nsobject& operator=(const scoped_nsobject<id>& that) {
     scoped_nsprotocol<id>::operator=(that);
diff --git a/src/base/mac/sdk_forward_declarations.h b/src/base/mac/sdk_forward_declarations.h
index 29e3521..9f60262 100644
--- a/src/base/mac/sdk_forward_declarations.h
+++ b/src/base/mac/sdk_forward_declarations.h
@@ -25,21 +25,6 @@
 // OSX SDK being compiled against.
 // ----------------------------------------------------------------------------
 
-#if !defined(MAC_OS_X_VERSION_10_12) || \
-    MAC_OS_X_VERSION_MAX_ALLOWED < MAC_OS_X_VERSION_10_12
-
-// The protocol was formalized by the 10.12 SDK, but it was informally used
-// before.
-@protocol CAAnimationDelegate
-- (void)animationDidStart:(CAAnimation*)animation;
-- (void)animationDidStop:(CAAnimation*)animation finished:(BOOL)finished;
-@end
-
-@protocol CALayerDelegate
-@end
-
-#endif  // MAC_OS_X_VERSION_10_12
-
 #if !defined(MAC_OS_X_VERSION_10_11) || \
     MAC_OS_X_VERSION_MAX_ALLOWED < MAC_OS_X_VERSION_10_11
 
@@ -67,19 +52,27 @@ typedef NSUInteger NSSpringLoadingHighlight;
 
 #endif  // MAC_OS_X_VERSION_10_11
 
+#if !defined(MAC_OS_X_VERSION_10_12) || \
+    MAC_OS_X_VERSION_MAX_ALLOWED < MAC_OS_X_VERSION_10_12
+
+// The protocol was formalized by the 10.12 SDK, but it was informally used
+// before.
+@protocol CAAnimationDelegate
+- (void)animationDidStart:(CAAnimation*)animation;
+- (void)animationDidStop:(CAAnimation*)animation finished:(BOOL)finished;
+@end
+
+@protocol CALayerDelegate
+@end
+
+#endif  // MAC_OS_X_VERSION_10_12
+
 // ----------------------------------------------------------------------------
 // Define NSStrings only available in newer versions of the OSX SDK to force
 // them to be statically linked.
 // ----------------------------------------------------------------------------
 
 extern "C" {
-#if !defined(MAC_OS_X_VERSION_10_9) || \
-    MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_9
-BASE_EXPORT extern NSString* const NSWindowDidChangeOcclusionStateNotification;
-BASE_EXPORT extern NSString* const CBAdvertisementDataOverflowServiceUUIDsKey;
-BASE_EXPORT extern NSString* const CBAdvertisementDataIsConnectable;
-#endif  // MAC_OS_X_VERSION_10_9
-
 #if !defined(MAC_OS_X_VERSION_10_10) || \
     MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_10
 BASE_EXPORT extern NSString* const NSUserActivityTypeBrowsingWeb;
@@ -95,116 +88,18 @@ BASE_EXPORT extern NSString* const NSAppearanceNameVibrantLight;
 // functions to suppress -Wpartial-availability warnings.
 // ----------------------------------------------------------------------------
 
-// Once Chrome no longer supports OSX 10.7, everything within this preprocessor
-// block can be removed.
-#if !defined(MAC_OS_X_VERSION_10_8) || \
-    MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_8
-
-@interface NSColor (MountainLionSDK)
-- (CGColorRef)CGColor;
-@end
-
-@interface NSUUID (MountainLionSDK)
-- (NSString*)UUIDString;
-@end
-
-@interface NSControl (MountainLionSDK)
-@property BOOL allowsExpansionToolTips;
-@end
-
-@interface NSNib (MountainLionSDK)
-- (BOOL)instantiateWithOwner:(id)owner
-             topLevelObjects:(NSArray**)topLevelObjects;
-@end
-
-#endif  // MAC_OS_X_VERSION_10_8
-
-// Once Chrome no longer supports OSX 10.8, everything within this preprocessor
-// block can be removed.
-#if !defined(MAC_OS_X_VERSION_10_9) || \
-    MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_9
-
-// NSProgress is public API in 10.9, but a version of it exists and is usable
-// in 10.8.
-@class NSProgress;
-@class NSAppearance;
-
-@interface NSProgress (MavericksSDK)
-
-- (instancetype)initWithParent:(NSProgress*)parentProgressOrNil
-                      userInfo:(NSDictionary*)userInfoOrNil;
-@property(copy) NSString* kind;
-
-@property int64_t totalUnitCount;
-@property int64_t completedUnitCount;
-
-@property(getter=isCancellable) BOOL cancellable;
-@property(getter=isPausable) BOOL pausable;
-@property(readonly, getter=isCancelled) BOOL cancelled;
-@property(readonly, getter=isPaused) BOOL paused;
-@property(copy) void (^cancellationHandler)(void);
-@property(copy) void (^pausingHandler)(void);
-- (void)cancel;
-- (void)pause;
-
-- (void)setUserInfoObject:(id)objectOrNil forKey:(NSString*)key;
-- (NSDictionary*)userInfo;
-
-@property(readonly, getter=isIndeterminate) BOOL indeterminate;
-@property(readonly) double fractionCompleted;
-
-- (void)publish;
-- (void)unpublish;
-
-@end
-
-@interface NSScreen (MavericksSDK)
-+ (BOOL)screensHaveSeparateSpaces;
-@end
-
-@interface NSView (MavericksSDK)
-- (void)setCanDrawSubviewsIntoLayer:(BOOL)flag;
-- (void)setAppearance:(NSAppearance*)appearance;
-- (NSAppearance*)effectiveAppearance;
-@end
-
-@interface NSWindow (MavericksSDK)
-- (NSWindowOcclusionState)occlusionState;
-@end
-
-@interface NSAppearance (MavericksSDK)
-+ (id<NSObject>)appearanceNamed:(NSString*)name;
-@end
-
-@interface CBPeripheral (MavericksSDK)
-@property(readonly, nonatomic) NSUUID* identifier;
-@end
-
-@interface NSVisualEffectView (MavericksSDK)
-- (void)setState:(NSVisualEffectState)state;
-@end
-
-@class NSVisualEffectView;
-
-@class NSUserActivity;
-
-#endif  // MAC_OS_X_VERSION_10_9
-
 // Once Chrome no longer supports OSX 10.9, everything within this preprocessor
 // block can be removed.
 #if !defined(MAC_OS_X_VERSION_10_10) || \
     MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_10
 
 @interface NSUserActivity (YosemiteSDK)
-
 @property(readonly, copy) NSString* activityType;
 @property(copy) NSDictionary* userInfo;
 @property(copy) NSURL* webpageURL;
-
 - (instancetype)initWithActivityType:(NSString*)activityType;
 - (void)becomeCurrent;
 - (void)invalidate;
-
 @end
 
 @interface CBUUID (YosemiteSDK)
@@ -223,6 +118,16 @@ BASE_EXPORT extern NSString* const NSAppearanceNameVibrantLight;
 @property(readonly) NSOperatingSystemVersion operatingSystemVersion;
 @end
 
+@interface NSLayoutConstraint (YosemiteSDK)
+@property(getter=isActive) BOOL active;
+@end
+
+@interface NSVisualEffectView (YosemiteSDK)
+- (void)setState:(NSVisualEffectState)state;
+@end
+
+@class NSVisualEffectView;
+
 #endif  // MAC_OS_X_VERSION_10_10
 
 // Once Chrome no longer supports OSX 10.10.2, everything within this
@@ -240,6 +145,26 @@ BASE_EXPORT extern NSString* const NSAppearanceNameVibrantLight;
 
 #endif  // MAC_OS_X_VERSION_10_10
 
+// Once Chrome no longer supports OSX 10.10, everything within this
+// preprocessor block can be removed.
+#if !defined(MAC_OS_X_VERSION_10_11) || \
+    MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_11
+
+@class NSLayoutXAxisAnchor;
+@class NSLayoutYAxisAnchor;
+
+@interface NSView (ElCapitanSDK)
+@property(readonly, strong) NSLayoutXAxisAnchor* leftAnchor;
+@property(readonly, strong) NSLayoutXAxisAnchor* rightAnchor;
+@property(readonly, strong) NSLayoutYAxisAnchor* bottomAnchor;
+@end
+
+@interface NSWindow (ElCapitanSDK)
+- (void)performWindowDragWithEvent:(NSEvent*)event;
+@end
+
+#endif  // MAC_OS_X_VERSION_10_11
+
 // Once Chrome no longer supports OSX 10.11, everything within this
 // preprocessor block can be removed.
 #if !defined(MAC_OS_X_VERSION_10_12) || \
@@ -251,6 +176,20 @@ BASE_EXPORT extern NSString* const NSAppearanceNameVibrantLight;
 
 #endif  // MAC_OS_X_VERSION_10_12
 
+// Once Chrome no longer supports OSX 10.12.0, everything within this
+// preprocessor block can be removed.
+#if !defined(MAC_OS_X_VERSION_10_12_1) || \
+    MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_12_1
+
+@interface NSButton (SierraPointOneSDK)
+@property(copy) NSColor* bezelColor;
++ (instancetype)buttonWithTitle:(NSString*)title
+                         target:(id)target
+                         action:(SEL)action;
+@end
+
+#endif  // MAC_OS_X_VERSION_10_12_1
+
 // ----------------------------------------------------------------------------
 // The symbol for kCWSSIDDidChangeNotification is available in the
 // CoreWLAN.framework for OSX versions 10.6 through 10.10. The symbol is not
diff --git a/src/base/mac/sdk_forward_declarations.mm b/src/base/mac/sdk_forward_declarations.mm
index 4e1d7ec..61f6b52 100644
--- a/src/base/mac/sdk_forward_declarations.mm
+++ b/src/base/mac/sdk_forward_declarations.mm
@@ -4,39 +4,6 @@
 
 #include "base/mac/sdk_forward_declarations.h"
 
-#if !defined(MAC_OS_X_VERSION_10_7) || \
-    MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_7
-NSString* const NSWindowWillEnterFullScreenNotification =
-    @"NSWindowWillEnterFullScreenNotification";
-
-NSString* const NSWindowWillExitFullScreenNotification =
-    @"NSWindowWillExitFullScreenNotification";
-
-NSString* const NSWindowDidEnterFullScreenNotification =
-    @"NSWindowDidEnterFullScreenNotification";
-
-NSString* const NSWindowDidExitFullScreenNotification =
-    @"NSWindowDidExitFullScreenNotification";
-
-NSString* const NSWindowDidChangeBackingPropertiesNotification =
-    @"NSWindowDidChangeBackingPropertiesNotification";
-
-NSString* const CBAdvertisementDataServiceDataKey = @"kCBAdvDataServiceData";
-
-NSString* const CBAdvertisementDataServiceUUIDsKey = @"kCBAdvDataServiceUUIDs";
-#endif  // MAC_OS_X_VERSION_10_7
-
-#if !defined(MAC_OS_X_VERSION_10_9) || \
-    MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_9
-NSString* const NSWindowDidChangeOcclusionStateNotification =
-    @"NSWindowDidChangeOcclusionStateNotification";
-
-NSString* const CBAdvertisementDataOverflowServiceUUIDsKey =
-    @"kCBAdvDataOverflowServiceUUIDs";
-
-NSString* const CBAdvertisementDataIsConnectable = @"kCBAdvDataIsConnectable";
-#endif  // MAC_OS_X_VERSION_10_9
-
 #if !defined(MAC_OS_X_VERSION_10_10) || \
     MAC_OS_X_VERSION_MIN_REQUIRED < MAC_OS_X_VERSION_10_10
 NSString* const NSUserActivityTypeBrowsingWeb =
diff --git a/src/base/memory/ref_counted.cc b/src/base/memory/ref_counted.cc
index f5924d0..cd6181b 100644
--- a/src/base/memory/ref_counted.cc
+++ b/src/base/memory/ref_counted.cc
@@ -15,32 +15,32 @@ bool RefCountedThreadSafeBase::HasOneRef() const {
 }
 
 RefCountedThreadSafeBase::RefCountedThreadSafeBase() : ref_count_(0) {
-#ifndef NDEBUG
+#if DCHECK_IS_ON()
   in_dtor_ = false;
 #endif
 }
 
 RefCountedThreadSafeBase::~RefCountedThreadSafeBase() {
-#ifndef NDEBUG
+#if DCHECK_IS_ON()
   DCHECK(in_dtor_) << "RefCountedThreadSafe object deleted without "
                       "calling Release()";
 #endif
 }
 
 void RefCountedThreadSafeBase::AddRef() const {
-#ifndef NDEBUG
+#if DCHECK_IS_ON()
   DCHECK(!in_dtor_);
 #endif
   AtomicRefCountInc(&ref_count_);
 }
 
 bool RefCountedThreadSafeBase::Release() const {
-#ifndef NDEBUG
+#if DCHECK_IS_ON()
   DCHECK(!in_dtor_);
   DCHECK(!AtomicRefCountIsZero(&ref_count_));
 #endif
   if (!AtomicRefCountDec(&ref_count_)) {
-#ifndef NDEBUG
+#if DCHECK_IS_ON()
     in_dtor_ = true;
 #endif
     return true;
diff --git a/src/base/memory/ref_counted.h b/src/base/memory/ref_counted.h
index 05fc4c4..784a178 100644
--- a/src/base/memory/ref_counted.h
+++ b/src/base/memory/ref_counted.h
@@ -14,10 +14,8 @@
 #include "base/atomic_ref_count.h"
 #include "base/base_export.h"
 #include "base/compiler_specific.h"
-#include "base/macros.h"
-#ifndef NDEBUG
 #include "base/logging.h"
-#endif
+#include "base/macros.h"
 #include "base/threading/thread_collision_warner.h"
 #include "build/build_config.h"
 
@@ -32,16 +30,16 @@ class BASE_EXPORT RefCountedBase {
  protected:
   RefCountedBase()
       : ref_count_(0)
-  #ifndef NDEBUG
-      , in_dtor_(false)
-  #endif
-      {
+#if DCHECK_IS_ON()
+        , in_dtor_(false)
+#endif
+  {
   }
 
   ~RefCountedBase() {
-  #ifndef NDEBUG
+#if DCHECK_IS_ON()
     DCHECK(in_dtor_) << "RefCounted object deleted without calling Release()";
-  #endif
+#endif
   }
 
 
@@ -50,9 +48,9 @@ class BASE_EXPORT RefCountedBase {
     // Current thread books the critical section "AddRelease"
     // without release it.
     // DFAKE_SCOPED_LOCK_THREAD_LOCKED(add_release_);
-  #ifndef NDEBUG
+#if DCHECK_IS_ON()
     DCHECK(!in_dtor_);
-  #endif
+#endif
     ++ref_count_;
   }
 
@@ -62,21 +60,21 @@ class BASE_EXPORT RefCountedBase {
     // Current thread books the critical section "AddRelease"
     // without release it.
     // DFAKE_SCOPED_LOCK_THREAD_LOCKED(add_release_);
-  #ifndef NDEBUG
+#if DCHECK_IS_ON()
     DCHECK(!in_dtor_);
-  #endif
+#endif
     if (--ref_count_ == 0) {
-  #ifndef NDEBUG
+#if DCHECK_IS_ON()
       in_dtor_ = true;
-  #endif
+#endif
       return true;
     }
     return false;
   }
 
  private:
-  mutable int ref_count_;
-#ifndef NDEBUG
+  mutable size_t ref_count_;
+#if DCHECK_IS_ON()
   mutable bool in_dtor_;
 #endif
 
@@ -100,7 +98,7 @@ class BASE_EXPORT RefCountedThreadSafeBase {
 
  private:
   mutable AtomicRefCount ref_count_;
-#ifndef NDEBUG
+#if DCHECK_IS_ON()
   mutable bool in_dtor_;
 #endif
 
@@ -126,7 +124,7 @@ class BASE_EXPORT RefCountedThreadSafeBase {
 template <class T>
 class RefCounted : public subtle::RefCountedBase {
  public:
-  RefCounted() {}
+  RefCounted() = default;
 
   void AddRef() const {
     subtle::RefCountedBase::AddRef();
@@ -139,7 +137,7 @@ class RefCounted : public subtle::RefCountedBase {
   }
 
  protected:
-  ~RefCounted() {}
+  ~RefCounted() = default;
 
  private:
   DISALLOW_COPY_AND_ASSIGN(RefCounted<T>);
@@ -176,7 +174,7 @@ struct DefaultRefCountedThreadSafeTraits {
 template <class T, typename Traits = DefaultRefCountedThreadSafeTraits<T> >
 class RefCountedThreadSafe : public subtle::RefCountedThreadSafeBase {
  public:
-  RefCountedThreadSafe() {}
+  RefCountedThreadSafe() = default;
 
   void AddRef() const {
     subtle::RefCountedThreadSafeBase::AddRef();
@@ -189,7 +187,7 @@ class RefCountedThreadSafe : public subtle::RefCountedThreadSafeBase {
   }
 
  protected:
-  ~RefCountedThreadSafe() {}
+  ~RefCountedThreadSafe() = default;
 
  private:
   friend struct DefaultRefCountedThreadSafeTraits<T>;
@@ -213,7 +211,7 @@ class RefCountedData
 
  private:
   friend class base::RefCountedThreadSafe<base::RefCountedData<T> >;
-  ~RefCountedData() {}
+  ~RefCountedData() = default;
 };
 
 }  // namespace base
@@ -226,6 +224,9 @@ class RefCountedData
 //
 //   class MyFoo : public RefCounted<MyFoo> {
 //    ...
+//    private:
+//     friend class RefCounted<MyFoo>;  // Allow destruction by RefCounted<>.
+//     ~MyFoo();                        // Destructor must be private/protected.
 //   };
 //
 //   void some_function() {
@@ -237,7 +238,7 @@ class RefCountedData
 //   void some_other_function() {
 //     scoped_refptr<MyFoo> foo = new MyFoo();
 //     ...
-//     foo = NULL;  // explicitly releases |foo|
+//     foo = nullptr;  // explicitly releases |foo|
 //     ...
 //     if (foo)
 //       foo->Method(param);
@@ -252,7 +253,7 @@ class RefCountedData
 //     scoped_refptr<MyFoo> b;
 //
 //     b.swap(a);
-//     // now, |b| references the MyFoo object, and |a| references NULL.
+//     // now, |b| references the MyFoo object, and |a| references nullptr.
 //   }
 //
 // To make both |a| and |b| in the above example reference the same MyFoo
@@ -271,8 +272,7 @@ class scoped_refptr {
  public:
   typedef T element_type;
 
-  scoped_refptr() : ptr_(NULL) {
-  }
+  scoped_refptr() {}
 
   scoped_refptr(T* p) : ptr_(p) {
     if (ptr_)
@@ -314,12 +314,12 @@ class scoped_refptr {
   T* get() const { return ptr_; }
 
   T& operator*() const {
-    assert(ptr_ != NULL);
+    assert(ptr_ != nullptr);
     return *ptr_;
   }
 
   T* operator->() const {
-    assert(ptr_ != NULL);
+    assert(ptr_ != nullptr);
     return ptr_;
   }
 
@@ -382,7 +382,7 @@ class scoped_refptr {
   }
 
  protected:
-  T* ptr_;
+  T* ptr_ = nullptr;
 
  private:
   // Friend required for move constructors that set r.ptr_ to null.
@@ -397,11 +397,13 @@ class scoped_refptr {
   static void Release(T* ptr);
 };
 
+// static
 template <typename T>
 void scoped_refptr<T>::AddRef(T* ptr) {
   ptr->AddRef();
 }
 
+// static
 template <typename T>
 void scoped_refptr<T>::Release(T* ptr) {
   ptr->Release();
diff --git a/src/base/memory/scoped_vector.h b/src/base/memory/scoped_vector.h
index ebc2617..a320b1e 100644
--- a/src/base/memory/scoped_vector.h
+++ b/src/base/memory/scoped_vector.h
@@ -12,7 +12,6 @@
 
 #include "base/logging.h"
 #include "base/macros.h"
-#include "base/stl_util.h"
 
 // ScopedVector wraps a vector deleting the elements from its
 // destructor.
@@ -88,8 +87,10 @@ class ScopedVector {
 
   // Resize, deleting elements in the disappearing range if we are shrinking.
   void resize(size_t new_size) {
-    if (v_.size() > new_size)
-      base::STLDeleteContainerPointers(v_.begin() + new_size, v_.end());
+    if (v_.size() > new_size) {
+      for (auto it = v_.begin() + new_size; it != v_.end(); ++it)
+        delete *it;
+    }
     v_.resize(new_size);
   }
 
@@ -98,7 +99,11 @@ class ScopedVector {
     v_.assign(begin, end);
   }
 
-  void clear() { base::STLDeleteElements(&v_); }
+  void clear() {
+    for (auto* item : *this)
+      delete item;
+    v_.clear();
+  }
 
   // Like |clear()|, but doesn't delete any elements.
   void weak_clear() { v_.clear(); }
@@ -124,7 +129,8 @@ class ScopedVector {
   }
 
   iterator erase(iterator first, iterator last) {
-    base::STLDeleteContainerPointers(first, last);
+    for (auto it = first; it != last; ++it)
+      delete *it;
     return v_.erase(first, last);
   }
 
diff --git a/src/base/memory/shared_memory.h b/src/base/memory/shared_memory.h
index e1c9fa7..f68c861 100644
--- a/src/base/memory/shared_memory.h
+++ b/src/base/memory/shared_memory.h
@@ -34,31 +34,29 @@ class FilePath;
 
 // Options for creating a shared memory object.
 struct BASE_EXPORT SharedMemoryCreateOptions {
-  SharedMemoryCreateOptions();
-
 #if !(defined(OS_MACOSX) && !defined(OS_IOS))
   // DEPRECATED (crbug.com/345734):
   // If NULL, the object is anonymous.  This pointer is owned by the caller
   // and must live through the call to Create().
-  const std::string* name_deprecated;
+  const std::string* name_deprecated = nullptr;
 
   // DEPRECATED (crbug.com/345734):
   // If true, and the shared memory already exists, Create() will open the
   // existing shared memory and ignore the size parameter.  If false,
   // shared memory must not exist.  This flag is meaningless unless
   // name_deprecated is non-NULL.
-  bool open_existing_deprecated;
+  bool open_existing_deprecated = false;
 #endif  // !(defined(OS_MACOSX) && !defined(OS_IOS))
 
   // Size of the shared memory object to be created.
   // When opening an existing object, this has no effect.
-  size_t size;
+  size_t size = 0;
 
   // If true, mappings might need to be made executable later.
-  bool executable;
+  bool executable = false;
 
   // If true, the file can be shared read-only to a process.
-  bool share_read_only;
+  bool share_read_only = false;
 };
 
 // Platform abstraction for shared memory.  Provides a C++ wrapper
@@ -194,6 +192,13 @@ class BASE_EXPORT SharedMemory {
   // identifier is not portable.
   SharedMemoryHandle handle() const;
 
+  // Returns the underlying OS handle for this segment. The caller also gets
+  // ownership of the handle. This is logically equivalent to:
+  //   SharedMemoryHandle dup = DuplicateHandle(handle());
+  //   Close();
+  //   return dup;
+  SharedMemoryHandle TakeHandle();
+
   // Closes the open shared memory segment. The memory will remain mapped if
   // it was previously mapped.
   // It is safe to call Close repeatedly.
diff --git a/src/base/memory/shared_memory_handle.h b/src/base/memory/shared_memory_handle.h
index 8eff26b..c3fd7ae 100644
--- a/src/base/memory/shared_memory_handle.h
+++ b/src/base/memory/shared_memory_handle.h
@@ -24,8 +24,6 @@
 
 namespace base {
 
-class Pickle;
-
 // SharedMemoryHandle is a platform specific type which represents
 // the underlying OS handle to a shared memory segment.
 #if defined(OS_POSIX) && !(defined(OS_MACOSX) && !defined(OS_IOS))
diff --git a/src/base/memory/shared_memory_mac.cc b/src/base/memory/shared_memory_mac.cc
index a716db7..d42c7d9 100644
--- a/src/base/memory/shared_memory_mac.cc
+++ b/src/base/memory/shared_memory_mac.cc
@@ -73,11 +73,6 @@ bool MakeMachSharedMemoryHandleReadOnly(SharedMemoryHandle* new_handle,
 
 }  // namespace
 
-SharedMemoryCreateOptions::SharedMemoryCreateOptions()
-    : size(0),
-      executable(false),
-      share_read_only(false) {}
-
 SharedMemory::SharedMemory()
     : mapped_size_(0), memory_(NULL), read_only_(false), requested_size_(0) {}
 
@@ -188,6 +183,12 @@ SharedMemoryHandle SharedMemory::handle() const {
   return shm_;
 }
 
+SharedMemoryHandle SharedMemory::TakeHandle() {
+  SharedMemoryHandle dup = DuplicateHandle(handle());
+  Close();
+  return dup;
+}
+
 void SharedMemory::Close() {
   shm_.Close();
   shm_ = SharedMemoryHandle();
diff --git a/src/base/memory/shared_memory_posix.cc b/src/base/memory/shared_memory_posix.cc
index 54e0c49..0ad9f89 100644
--- a/src/base/memory/shared_memory_posix.cc
+++ b/src/base/memory/shared_memory_posix.cc
@@ -110,13 +110,6 @@ bool CreateAnonymousSharedMemory(const SharedMemoryCreateOptions& options,
 #endif  // !defined(OS_ANDROID)
 }
 
-SharedMemoryCreateOptions::SharedMemoryCreateOptions()
-    : name_deprecated(nullptr),
-      open_existing_deprecated(false),
-      size(0),
-      executable(false),
-      share_read_only(false) {}
-
 SharedMemory::SharedMemory()
     : mapped_file_(-1),
       readonly_mapped_file_(-1),
@@ -398,6 +391,14 @@ SharedMemoryHandle SharedMemory::handle() const {
   return FileDescriptor(mapped_file_, false);
 }
 
+SharedMemoryHandle SharedMemory::TakeHandle() {
+  FileDescriptor handle(mapped_file_, true);
+  mapped_file_ = -1;
+  memory_ = nullptr;
+  mapped_size_ = 0;
+  return handle;
+}
+
 void SharedMemory::Close() {
   if (mapped_file_ > 0) {
     if (IGNORE_EINTR(close(mapped_file_)) < 0)
diff --git a/src/base/message_loop/incoming_task_queue.h b/src/base/message_loop/incoming_task_queue.h
index aff71d2..157e47f 100644
--- a/src/base/message_loop/incoming_task_queue.h
+++ b/src/base/message_loop/incoming_task_queue.h
@@ -16,7 +16,6 @@
 namespace base {
 
 class MessageLoop;
-class WaitableEvent;
 
 namespace internal {
 
diff --git a/src/base/message_loop/message_loop.cc b/src/base/message_loop/message_loop.cc
index 8a2f213..1581f6c 100644
--- a/src/base/message_loop/message_loop.cc
+++ b/src/base/message_loop/message_loop.cc
@@ -5,7 +5,6 @@
 #include "base/message_loop/message_loop.h"
 
 #include <algorithm>
-#include <memory>
 #include <utility>
 
 #include "base/bind.h"
@@ -14,17 +13,12 @@
 #include "base/logging.h"
 #include "base/memory/ptr_util.h"
 #include "base/message_loop/message_pump_default.h"
-#include "base/metrics/histogram.h"
-#include "base/metrics/statistics_recorder.h"
 #include "base/run_loop.h"
 #include "base/third_party/dynamic_annotations/dynamic_annotations.h"
 #include "base/threading/thread_id_name_manager.h"
 #include "base/threading/thread_local.h"
 #include "base/threading/thread_task_runner_handle.h"
-#include "base/time/time.h"
 #include "base/trace_event/trace_event.h"
-#include "base/tracked_objects.h"
-#include "build/build_config.h"
 
 #if defined(OS_MACOSX)
 #include "base/message_loop/message_pump_mac.h"
@@ -48,47 +42,6 @@ namespace {
 LazyInstance<base::ThreadLocalPointer<MessageLoop> >::Leaky lazy_tls_ptr =
     LAZY_INSTANCE_INITIALIZER;
 
-// Logical events for Histogram profiling. Run with --message-loop-histogrammer
-// to get an accounting of messages and actions taken on each thread.
-const int kTaskRunEvent = 0x1;
-#if !defined(OS_NACL)
-const int kTimerEvent = 0x2;
-
-// Provide range of message IDs for use in histogramming and debug display.
-const int kLeastNonZeroMessageId = 1;
-const int kMaxMessageId = 1099;
-const int kNumberOfDistinctMessagesDisplayed = 1100;
-
-// Provide a macro that takes an expression (such as a constant, or macro
-// constant) and creates a pair to initialize an array of pairs.  In this case,
-// our pair consists of the expressions value, and the "stringized" version
-// of the expression (i.e., the expression put in quotes).  For example, if
-// we have:
-//    #define FOO 2
-//    #define BAR 5
-// then the following:
-//    VALUE_TO_NUMBER_AND_NAME(FOO + BAR)
-// will expand to:
-//   {7, "FOO + BAR"}
-// We use the resulting array as an argument to our histogram, which reads the
-// number as a bucket identifier, and proceeds to use the corresponding name
-// in the pair (i.e., the quoted string) when printing out a histogram.
-#define VALUE_TO_NUMBER_AND_NAME(name) {name, #name},
-
-const LinearHistogram::DescriptionPair event_descriptions_[] = {
-  // Provide some pretty print capability in our histogram for our internal
-  // messages.
-
-  // A few events we handle (kindred to messages), and used to profile actions.
-  VALUE_TO_NUMBER_AND_NAME(kTaskRunEvent)
-  VALUE_TO_NUMBER_AND_NAME(kTimerEvent)
-
-  {-1, NULL}  // The list must be null-terminated, per API to histogram.
-};
-#endif  // !defined(OS_NACL)
-
-bool enable_histogrammer_ = false;
-
 MessageLoop::MessagePumpFactory* message_pump_for_ui_factory_ = NULL;
 
 #if defined(OS_IOS)
@@ -171,8 +124,8 @@ MessageLoop::~MessageLoop() {
   DCHECK(!did_work);
 
   // Let interested parties have one last shot at accessing this.
-  FOR_EACH_OBSERVER(DestructionObserver, destruction_observers_,
-                    WillDestroyCurrentMessageLoop());
+  for (auto& observer : destruction_observers_)
+    observer.WillDestroyCurrentMessageLoop();
 
   thread_task_runner_handle_.reset();
 
@@ -196,11 +149,6 @@ MessageLoop* MessageLoop::current() {
 }
 
 // static
-void MessageLoop::EnableHistogrammer(bool enable) {
-  enable_histogrammer_ = enable;
-}
-
-// static
 bool MessageLoop::InitMessagePumpForUIFactory(MessagePumpFactory* factory) {
   if (message_pump_for_ui_factory_)
     return false;
@@ -268,41 +216,16 @@ void MessageLoop::RemoveDestructionObserver(
 
 void MessageLoop::AddNestingObserver(NestingObserver* observer) {
   DCHECK_EQ(this, current());
+  CHECK(allow_nesting_);
   nesting_observers_.AddObserver(observer);
 }
 
 void MessageLoop::RemoveNestingObserver(NestingObserver* observer) {
   DCHECK_EQ(this, current());
+  CHECK(allow_nesting_);
   nesting_observers_.RemoveObserver(observer);
 }
 
-#if !(defined(OS_MACOSX) && !defined(OS_IOS))
-void MessageLoop::PostTask(
-    const tracked_objects::Location& from_here,
-    const Closure& task) {
-  task_runner_->PostTask(from_here, task);
-}
-
-void MessageLoop::PostDelayedTask(
-    const tracked_objects::Location& from_here,
-    const Closure& task,
-    TimeDelta delay) {
-  task_runner_->PostDelayedTask(from_here, task, delay);
-}
-#endif  // !(defined(OS_MACOSX) && !defined(OS_IOS))
-
-void MessageLoop::Run() {
-  DCHECK(pump_);
-  RunLoop run_loop;
-  run_loop.Run();
-}
-
-void MessageLoop::RunUntilIdle() {
-  DCHECK(pump_);
-  RunLoop run_loop;
-  run_loop.RunUntilIdle();
-}
-
 void MessageLoop::QuitWhenIdle() {
   DCHECK_EQ(this, current());
   if (run_loop_) {
@@ -336,6 +259,8 @@ Closure MessageLoop::QuitWhenIdleClosure() {
 
 void MessageLoop::SetNestableTasksAllowed(bool allowed) {
   if (allowed) {
+    CHECK(allow_nesting_);
+
     // Kick the native pump just in case we enter a OS-driven nested message
     // loop.
     pump_->ScheduleWork();
@@ -353,11 +278,13 @@ bool MessageLoop::IsNested() {
 
 void MessageLoop::AddTaskObserver(TaskObserver* task_observer) {
   DCHECK_EQ(this, current());
+  CHECK(allow_task_observers_);
   task_observers_.AddObserver(task_observer);
 }
 
 void MessageLoop::RemoveTaskObserver(TaskObserver* task_observer) {
   DCHECK_EQ(this, current());
+  CHECK(allow_task_observers_);
   task_observers_.RemoveObserver(task_observer);
 }
 
@@ -393,7 +320,6 @@ MessageLoop::MessageLoop(Type type, MessagePumpFactoryCallback pump_factory)
 #endif
       nestable_tasks_allowed_(true),
       pump_factory_(pump_factory),
-      message_histogram_(NULL),
       run_loop_(NULL),
       incoming_task_queue_(new internal::IncomingTaskQueue(this)),
       unbound_task_runner_(
@@ -447,7 +373,8 @@ void MessageLoop::SetThreadTaskRunnerHandle() {
 
 void MessageLoop::RunHandler() {
   DCHECK_EQ(this, current());
-  StartHistogrammer();
+  DCHECK(run_loop_);
+  CHECK(allow_nesting_ || run_loop_->run_depth_ == 1);
   pump_->Run(this);
 }
 
@@ -462,15 +389,15 @@ bool MessageLoop::ProcessNextDelayedNonNestableTask() {
       std::move(deferred_non_nestable_work_queue_.front());
   deferred_non_nestable_work_queue_.pop();
 
-  RunTask(pending_task);
+  RunTask(&pending_task);
   return true;
 }
 
-void MessageLoop::RunTask(const PendingTask& pending_task) {
+void MessageLoop::RunTask(PendingTask* pending_task) {
   DCHECK(nestable_tasks_allowed_);
 
 #if defined(OS_WIN)
-  if (pending_task.is_high_res) {
+  if (pending_task->is_high_res) {
     pending_high_res_tasks_--;
     CHECK_GE(pending_high_res_tasks_, 0);
   }
@@ -479,22 +406,20 @@ void MessageLoop::RunTask(const PendingTask& pending_task) {
   // Execute the task and assume the worst: It is probably not reentrant.
   nestable_tasks_allowed_ = false;
 
-  HistogramEvent(kTaskRunEvent);
-
-  TRACE_TASK_EXECUTION("MessageLoop::RunTask", pending_task);
+  TRACE_TASK_EXECUTION("MessageLoop::RunTask", *pending_task);
 
-  FOR_EACH_OBSERVER(TaskObserver, task_observers_,
-                    WillProcessTask(pending_task));
+  for (auto& observer : task_observers_)
+    observer.WillProcessTask(*pending_task);
   task_annotator_.RunTask("MessageLoop::PostTask", pending_task);
-  FOR_EACH_OBSERVER(TaskObserver, task_observers_,
-                    DidProcessTask(pending_task));
+  for (auto& observer : task_observers_)
+    observer.DidProcessTask(*pending_task);
 
   nestable_tasks_allowed_ = true;
 }
 
 bool MessageLoop::DeferOrRunPendingTask(PendingTask pending_task) {
   if (pending_task.nestable || run_loop_->run_depth_ == 1) {
-    RunTask(pending_task);
+    RunTask(&pending_task);
     // Show that we ran a task (Note: a new one might arrive as a
     // consequence!).
     return true;
@@ -559,40 +484,9 @@ void MessageLoop::ScheduleWork() {
   pump_->ScheduleWork();
 }
 
-#if defined(OS_WIN)
-bool MessageLoop::MessagePumpWasSignaled() {
-  return pump_->WasSignaled();
-}
-#endif
-
-//------------------------------------------------------------------------------
-// Method and data for histogramming events and actions taken by each instance
-// on each thread.
-
-void MessageLoop::StartHistogrammer() {
-#if !defined(OS_NACL)  // NaCl build has no metrics code.
-  if (enable_histogrammer_ && !message_histogram_
-      && StatisticsRecorder::IsActive()) {
-    std::string thread_name = GetThreadName();
-    DCHECK(!thread_name.empty());
-    message_histogram_ = LinearHistogram::FactoryGetWithRangeDescription(
-        "MsgLoop:" + thread_name, kLeastNonZeroMessageId, kMaxMessageId,
-        kNumberOfDistinctMessagesDisplayed,
-        HistogramBase::kHexRangePrintingFlag, event_descriptions_);
-  }
-#endif
-}
-
-void MessageLoop::HistogramEvent(int event) {
-#if !defined(OS_NACL)
-  if (message_histogram_)
-    message_histogram_->Add(event);
-#endif
-}
-
 void MessageLoop::NotifyBeginNestedLoop() {
-  FOR_EACH_OBSERVER(NestingObserver, nesting_observers_,
-                    OnBeginNestedMessageLoop());
+  for (auto& observer : nesting_observers_)
+    observer.OnBeginNestedMessageLoop();
 }
 
 bool MessageLoop::DoWork() {
@@ -682,21 +576,6 @@ bool MessageLoop::DoIdleWork() {
   return false;
 }
 
-#if !(defined(OS_MACOSX) && !defined(OS_IOS))
-void MessageLoop::DeleteSoonInternal(const tracked_objects::Location& from_here,
-                                     void(*deleter)(const void*),
-                                     const void* object) {
-  task_runner()->PostNonNestableTask(from_here, Bind(deleter, object));
-}
-
-void MessageLoop::ReleaseSoonInternal(
-    const tracked_objects::Location& from_here,
-    void(*releaser)(const void*),
-    const void* object) {
-  task_runner()->PostNonNestableTask(from_here, Bind(releaser, object));
-}
-#endif  // !(defined(OS_MACOSX) && !defined(OS_IOS))
-
 #if !defined(OS_NACL)
 //------------------------------------------------------------------------------
 // MessageLoopForUI
diff --git a/src/base/message_loop/message_loop.h b/src/base/message_loop/message_loop.h
index 1957b99..ac7a303 100644
--- a/src/base/message_loop/message_loop.h
+++ b/src/base/message_loop/message_loop.h
@@ -13,7 +13,6 @@
 #include "base/callback_forward.h"
 #include "base/debug/task_annotator.h"
 #include "base/gtest_prod_util.h"
-#include "base/location.h"
 #include "base/macros.h"
 #include "base/memory/ref_counted.h"
 #include "base/message_loop/incoming_task_queue.h"
@@ -22,10 +21,8 @@
 #include "base/message_loop/timer_slack.h"
 #include "base/observer_list.h"
 #include "base/pending_task.h"
-#include "base/sequenced_task_runner_helpers.h"
 #include "base/synchronization/lock.h"
 #include "base/time/time.h"
-#include "base/tracking_info.h"
 #include "build/build_config.h"
 
 // TODO(sky): these includes should not be necessary. Nuke them.
@@ -49,7 +46,6 @@ class JavaMessageHandlerFactory;
 
 namespace base {
 
-class HistogramBase;
 class RunLoop;
 class ThreadTaskRunnerHandle;
 class WaitableEvent;
@@ -57,8 +53,8 @@ class WaitableEvent;
 // A MessageLoop is used to process events for a particular thread.  There is
 // at most one MessageLoop instance per thread.
 //
-// Events include at a minimum Task instances submitted to PostTask and its
-// variants.  Depending on the type of message pump used by the MessageLoop
+// Events include at a minimum Task instances submitted to the MessageLoop's
+// TaskRunner. Depending on the type of message pump used by the MessageLoop
 // other events such as UI messages may be processed.  On Windows APC calls (as
 // time permits) and signals sent to a registered set of HANDLEs may also be
 // processed.
@@ -132,8 +128,6 @@ class BASE_EXPORT MessageLoop : public MessagePump::Delegate {
   // Returns the MessageLoop object for the current thread, or null if none.
   static MessageLoop* current();
 
-  static void EnableHistogrammer(bool enable_histogrammer);
-
   typedef std::unique_ptr<MessagePump>(MessagePumpFactory)();
   // Uses the given base::MessagePumpForUIFactory to override the default
   // MessagePump implementation for 'TYPE_UI'. Returns true if the factory
@@ -181,96 +175,6 @@ class BASE_EXPORT MessageLoop : public MessagePump::Delegate {
   void AddNestingObserver(NestingObserver* observer);
   void RemoveNestingObserver(NestingObserver* observer);
 
-#if !(defined(OS_MACOSX) && !defined(OS_IOS))
-  // NOTE: Deprecated; prefer task_runner() and the TaskRunner interfaces.
-  // TODO(skyostil): Remove these functions (crbug.com/465354).
-  //
-  // The "PostTask" family of methods call the task's Run method asynchronously
-  // from within a message loop at some point in the future.
-  //
-  // With the PostTask variant, tasks are invoked in FIFO order, inter-mixed
-  // with normal UI or IO event processing.  With the PostDelayedTask variant,
-  // tasks are called after at least approximately 'delay_ms' have elapsed.
-  //
-  // The NonNestable variants work similarly except that they promise never to
-  // dispatch the task from a nested invocation of MessageLoop::Run.  Instead,
-  // such tasks get deferred until the top-most MessageLoop::Run is executing.
-  //
-  // The MessageLoop takes ownership of the Task, and deletes it after it has
-  // been Run().
-  //
-  // PostTask(from_here, task) is equivalent to
-  // PostDelayedTask(from_here, task, 0).
-  //
-  // NOTE: These methods may be called on any thread.  The Task will be invoked
-  // on the thread that executes MessageLoop::Run().
-  void PostTask(const tracked_objects::Location& from_here,
-                const Closure& task);
-
-  void PostDelayedTask(const tracked_objects::Location& from_here,
-                       const Closure& task,
-                       TimeDelta delay);
-
-  // A variant on PostTask that deletes the given object.  This is useful
-  // if the object needs to live until the next run of the MessageLoop (for
-  // example, deleting a RenderProcessHost from within an IPC callback is not
-  // good).
-  //
-  // NOTE: This method may be called on any thread.  The object will be deleted
-  // on the thread that executes MessageLoop::Run().
-  template <class T>
-  void DeleteSoon(const tracked_objects::Location& from_here, const T* object) {
-    base::subtle::DeleteHelperInternal<T, void>::DeleteViaSequencedTaskRunner(
-        this, from_here, object);
-  }
-
-  // A variant on PostTask that releases the given reference counted object
-  // (by calling its Release method).  This is useful if the object needs to
-  // live until the next run of the MessageLoop, or if the object needs to be
-  // released on a particular thread.
-  //
-  // A common pattern is to manually increment the object's reference count
-  // (AddRef), clear the pointer, then issue a ReleaseSoon.  The reference count
-  // is incremented manually to ensure clearing the pointer does not trigger a
-  // delete and to account for the upcoming decrement (ReleaseSoon).  For
-  // example:
-  //
-  // scoped_refptr<Foo> foo = ...
-  // foo->AddRef();
-  // Foo* raw_foo = foo.get();
-  // foo = NULL;
-  // message_loop->ReleaseSoon(raw_foo);
-  //
-  // NOTE: This method may be called on any thread.  The object will be
-  // released (and thus possibly deleted) on the thread that executes
-  // MessageLoop::Run().  If this is not the same as the thread that calls
-  // ReleaseSoon(FROM_HERE, ), then T MUST inherit from
-  // RefCountedThreadSafe<T>!
-  template <class T>
-  void ReleaseSoon(const tracked_objects::Location& from_here,
-                   const T* object) {
-    base::subtle::ReleaseHelperInternal<T, void>::ReleaseViaSequencedTaskRunner(
-        this, from_here, object);
-  }
-#endif  // !(defined(OS_MACOSX) && !defined(OS_IOS))
-
-#if defined(OS_MACOSX) && !defined(OS_IOS)
- protected:
-#endif  // defined(OS_MACOSX) && !defined(OS_IOS)
-
-  // Deprecated: use RunLoop instead.
-  // Run the message loop.
-  void Run();
-
-  // Deprecated: use RunLoop instead.
-  // Process all pending tasks, windows messages, etc., but don't wait/sleep.
-  // Return as soon as all items that can be run are taken care of.
-  void RunUntilIdle();
-
-#if defined(OS_MACOSX) && !defined(OS_IOS)
- public:
-#endif  // defined(OS_MACOSX) && !defined(OS_IOS)
-
   // Deprecated: use RunLoop instead.
   //
   // Signals the Run method to return when it becomes idle. It will continue to
@@ -410,16 +314,15 @@ class BASE_EXPORT MessageLoop : public MessagePump::Delegate {
   debug::TaskAnnotator* task_annotator() { return &task_annotator_; }
 
   // Runs the specified PendingTask.
-  void RunTask(const PendingTask& pending_task);
+  void RunTask(PendingTask* pending_task);
 
-#if defined(OS_WIN)
-  // TODO (stanisc): crbug.com/596190: Remove this after the signaling issue
-  // has been investigated.
-  // This should be used for diagnostic only. If message pump wake-up mechanism
-  // is based on auto-reset event this call would reset the event to unset
-  // state.
-  bool MessagePumpWasSignaled();
-#endif
+  // Disallow nesting. After this is called, running a nested RunLoop or calling
+  // Add/RemoveNestingObserver() on this MessageLoop will crash.
+  void DisallowNesting() { allow_nesting_ = false; }
+
+  // Disallow task observers. After this is called, calling
+  // Add/RemoveTaskObserver() on this MessageLoop will crash.
+  void DisallowTaskObservers() { allow_task_observers_ = false; }
 
   //----------------------------------------------------------------------------
  protected:
@@ -490,15 +393,6 @@ class BASE_EXPORT MessageLoop : public MessagePump::Delegate {
   // responsible for synchronizing ScheduleWork() calls.
   void ScheduleWork();
 
-  // Start recording histogram info about events and action IF it was enabled
-  // and IF the statistics recorder can accept a registration of our histogram.
-  void StartHistogrammer();
-
-  // Add occurrence of event to our histogram, so that we can see what is being
-  // done in a specific MessageLoop instance (i.e., specific thread).
-  // If message_histogram_ is NULL, this is a no-op.
-  void HistogramEvent(int event);
-
   // Notify observers that a nested message loop is starting.
   void NotifyBeginNestedLoop();
 
@@ -546,9 +440,6 @@ class BASE_EXPORT MessageLoop : public MessagePump::Delegate {
   // if type_ is TYPE_CUSTOM and pump_ is null.
   MessagePumpFactoryCallback pump_factory_;
 
-  // A profiling histogram showing the counts of various messages and events.
-  HistogramBase* message_histogram_;
-
   RunLoop* run_loop_;
 
   ObserverList<TaskObserver> task_observers_;
@@ -568,17 +459,11 @@ class BASE_EXPORT MessageLoop : public MessagePump::Delegate {
   // MessageLoop is bound to its thread and constant forever after.
   PlatformThreadId thread_id_;
 
-#if !(defined(OS_MACOSX) && !defined(OS_IOS))
-  template <class T, class R> friend class base::subtle::DeleteHelperInternal;
-  template <class T, class R> friend class base::subtle::ReleaseHelperInternal;
+  // Whether nesting is allowed.
+  bool allow_nesting_ = true;
 
-  void DeleteSoonInternal(const tracked_objects::Location& from_here,
-                          void(*deleter)(const void*),
-                          const void* object);
-  void ReleaseSoonInternal(const tracked_objects::Location& from_here,
-                           void(*releaser)(const void*),
-                           const void* object);
-#endif  // !(defined(OS_MACOSX) && !defined(OS_IOS))
+  // Whether task observers are allowed.
+  bool allow_task_observers_ = true;
 
   DISALLOW_COPY_AND_ASSIGN(MessageLoop);
 };
@@ -594,9 +479,6 @@ class BASE_EXPORT MessageLoop : public MessagePump::Delegate {
 //
 class BASE_EXPORT MessageLoopForUI : public MessageLoop {
  public:
-  using MessageLoop::Run;
-  using MessageLoop::RunUntilIdle;
-
   MessageLoopForUI() : MessageLoop(TYPE_UI) {
   }
 
@@ -662,9 +544,6 @@ static_assert(sizeof(MessageLoop) == sizeof(MessageLoopForUI),
 //
 class BASE_EXPORT MessageLoopForIO : public MessageLoop {
  public:
-  using MessageLoop::Run;
-  using MessageLoop::RunUntilIdle;
-
   MessageLoopForIO() : MessageLoop(TYPE_IO) {
   }
 
diff --git a/src/base/message_loop/message_pump.cc b/src/base/message_loop/message_pump.cc
index 2f740f2..3d85b9b 100644
--- a/src/base/message_loop/message_pump.cc
+++ b/src/base/message_loop/message_pump.cc
@@ -15,11 +15,4 @@ MessagePump::~MessagePump() {
 void MessagePump::SetTimerSlack(TimerSlack) {
 }
 
-#if defined(OS_WIN)
-bool MessagePump::WasSignaled() {
-  NOTREACHED();
-  return false;
-}
-#endif
-
 }  // namespace base
diff --git a/src/base/message_loop/message_pump.h b/src/base/message_loop/message_pump.h
index af8ed41..c53be80 100644
--- a/src/base/message_loop/message_pump.h
+++ b/src/base/message_loop/message_pump.h
@@ -124,15 +124,6 @@ class BASE_EXPORT MessagePump : public NonThreadSafe {
 
   // Sets the timer slack to the specified value.
   virtual void SetTimerSlack(TimerSlack timer_slack);
-
-#if defined(OS_WIN)
-  // TODO (stanisc): crbug.com/596190: Remove this after the signaling issue
-  // has been investigated.
-  // This should be used for diagnostic only. If message pump wake-up mechanism
-  // is based on auto-reset event this call would reset the event to unset
-  // state.
-  virtual bool WasSignaled();
-#endif
 };
 
 }  // namespace base
diff --git a/src/base/message_loop/message_pump_default.cc b/src/base/message_loop/message_pump_default.cc
index 3449aec..cf68270 100644
--- a/src/base/message_loop/message_pump_default.cc
+++ b/src/base/message_loop/message_pump_default.cc
@@ -4,8 +4,6 @@
 
 #include "base/message_loop/message_pump_default.h"
 
-#include <algorithm>
-
 #include "base/logging.h"
 #include "base/threading/thread_restrictions.h"
 #include "build/build_config.h"
@@ -54,38 +52,11 @@ void MessagePumpDefault::Run(Delegate* delegate) {
     if (delayed_work_time_.is_null()) {
       event_.Wait();
     } else {
-      TimeDelta delay = delayed_work_time_ - TimeTicks::Now();
-      if (delay > TimeDelta()) {
-#if defined(OS_WIN)
-        // TODO(stanisc): crbug.com/623223: Consider moving the OS_WIN specific
-        // logic into TimedWait implementation in waitable_event_win.cc.
-
-        // crbug.com/487724: on Windows, waiting for less than 1 ms results in
-        // returning from TimedWait promptly and spinning
-        // MessagePumpDefault::Run loop for up to 1 ms - until it is time to
-        // run a delayed task. |min_delay| is the minimum possible wait to
-        // to avoid the spinning.
-        constexpr TimeDelta min_delay = TimeDelta::FromMilliseconds(1);
-        do {
-          delay = std::max(delay, min_delay);
-          if (event_.TimedWait(delay))
-            break;
-
-          // TimedWait can time out earlier than the specified |delay| on
-          // Windows. It doesn't make sense to run the outer loop in that case
-          // because there isn't going to be any new work. It is less overhead
-          // to just go back to wait.
-          // In practice this inner wait loop might have up to 3 iterations.
-          delay = delayed_work_time_ - TimeTicks::Now();
-        } while (delay > TimeDelta());
-#else
-        event_.TimedWait(delay);
-#endif
-      } else {
-        // It looks like delayed_work_time_ indicates a time in the past, so we
-        // need to call DoDelayedWork now.
-        delayed_work_time_ = TimeTicks();
-      }
+      // No need to handle already expired |delayed_work_time_| in any special
+      // way. When |delayed_work_time_| is in the past TimeWaitUntil returns
+      // promptly and |delayed_work_time_| will re-initialized on a next
+      // DoDelayedWork call which has to be called in order to get here again.
+      event_.TimedWaitUntil(delayed_work_time_);
     }
     // Since event_ is auto-reset, we don't need to do anything special here
     // other than service each delegate method.
diff --git a/src/base/message_loop/message_pump_libevent.cc b/src/base/message_loop/message_pump_libevent.cc
index fef01da..bc7f14d 100644
--- a/src/base/message_loop/message_pump_libevent.cc
+++ b/src/base/message_loop/message_pump_libevent.cc
@@ -73,21 +73,22 @@ bool MessagePumpLibevent::FileDescriptorWatcher::StopWatchingFileDescriptor() {
   return (rv == 0);
 }
 
-void MessagePumpLibevent::FileDescriptorWatcher::Init(event *e) {
+void MessagePumpLibevent::FileDescriptorWatcher::Init(event* e) {
   DCHECK(e);
   DCHECK(!event_);
 
   event_ = e;
 }
 
-event *MessagePumpLibevent::FileDescriptorWatcher::ReleaseEvent() {
-  struct event *e = event_;
+event* MessagePumpLibevent::FileDescriptorWatcher::ReleaseEvent() {
+  struct event* e = event_;
   event_ = NULL;
   return e;
 }
 
 void MessagePumpLibevent::FileDescriptorWatcher::OnFileCanReadWithoutBlocking(
-    int fd, MessagePumpLibevent* pump) {
+    int fd,
+    MessagePumpLibevent* pump) {
   // Since OnFileCanWriteWithoutBlocking() gets called first, it can stop
   // watching the file descriptor.
   if (!watcher_)
@@ -96,7 +97,8 @@ void MessagePumpLibevent::FileDescriptorWatcher::OnFileCanReadWithoutBlocking(
 }
 
 void MessagePumpLibevent::FileDescriptorWatcher::OnFileCanWriteWithoutBlocking(
-    int fd, MessagePumpLibevent* pump) {
+    int fd,
+    MessagePumpLibevent* pump) {
   DCHECK(watcher_);
   watcher_->OnFileCanWriteWithoutBlocking(fd);
 }
@@ -109,7 +111,7 @@ MessagePumpLibevent::MessagePumpLibevent()
       wakeup_pipe_in_(-1),
       wakeup_pipe_out_(-1) {
   if (!Init())
-     NOTREACHED();
+    NOTREACHED();
 }
 
 MessagePumpLibevent::~MessagePumpLibevent() {
@@ -131,8 +133,8 @@ MessagePumpLibevent::~MessagePumpLibevent() {
 bool MessagePumpLibevent::WatchFileDescriptor(int fd,
                                               bool persistent,
                                               int mode,
-                                              FileDescriptorWatcher *controller,
-                                              Watcher *delegate) {
+                                              FileDescriptorWatcher* controller,
+                                              Watcher* delegate) {
   DCHECK_GE(fd, 0);
   DCHECK(controller);
   DCHECK(delegate);
@@ -195,9 +197,8 @@ bool MessagePumpLibevent::WatchFileDescriptor(int fd,
 }
 
 // Tell libevent to break out of inner loop.
-static void timer_callback(int fd, short events, void *context)
-{
-  event_base_loopbreak((struct event_base *)context);
+static void timer_callback(int fd, short events, void* context) {
+  event_base_loopbreak((struct event_base*)context);
 }
 
 // Reentrant!
@@ -290,16 +291,8 @@ void MessagePumpLibevent::ScheduleDelayedWork(
 
 bool MessagePumpLibevent::Init() {
   int fds[2];
-  if (pipe(fds)) {
-    DLOG(ERROR) << "pipe() failed, errno: " << errno;
-    return false;
-  }
-  if (!SetNonBlocking(fds[0])) {
-    DLOG(ERROR) << "SetNonBlocking for pipe fd[0] failed, errno: " << errno;
-    return false;
-  }
-  if (!SetNonBlocking(fds[1])) {
-    DLOG(ERROR) << "SetNonBlocking for pipe fd[1] failed, errno: " << errno;
+  if (!CreateLocalNonBlockingPipe(fds)) {
+    DPLOG(ERROR) << "pipe creation failed";
     return false;
   }
   wakeup_pipe_out_ = fds[0];
diff --git a/src/base/message_loop/message_pump_libevent.h b/src/base/message_loop/message_pump_libevent.h
index 76f882f..752dc92 100644
--- a/src/base/message_loop/message_pump_libevent.h
+++ b/src/base/message_loop/message_pump_libevent.h
@@ -100,8 +100,8 @@ class BASE_EXPORT MessagePumpLibevent : public MessagePump {
   bool WatchFileDescriptor(int fd,
                            bool persistent,
                            int mode,
-                           FileDescriptorWatcher *controller,
-                           Watcher *delegate);
+                           FileDescriptorWatcher* controller,
+                           Watcher* delegate);
 
   // MessagePump methods:
   void Run(Delegate* delegate) override;
@@ -112,15 +112,11 @@ class BASE_EXPORT MessagePumpLibevent : public MessagePump {
  private:
   friend class MessagePumpLibeventTest;
 
-  void WillProcessIOEvent();
-  void DidProcessIOEvent();
-
   // Risky part of constructor.  Returns true on success.
   bool Init();
 
   // Called by libevent to tell us a registered FD can be read/written to.
-  static void OnLibeventNotification(int fd, short flags,
-                                     void* context);
+  static void OnLibeventNotification(int fd, short flags, void* context);
 
   // Unix pipe used to implement ScheduleWork()
   // ... callback; called by libevent inside Run() when pipe is ready to read
diff --git a/src/base/message_loop/message_pump_mac.mm b/src/base/message_loop/message_pump_mac.mm
index b50ea68..d924ead 100644
--- a/src/base/message_loop/message_pump_mac.mm
+++ b/src/base/message_loop/message_pump_mac.mm
@@ -4,7 +4,6 @@
 
 #import "base/message_loop/message_pump_mac.h"
 
-#include <dlfcn.h>
 #import <Foundation/Foundation.h>
 
 #include <limits>
@@ -72,33 +71,6 @@ const CFTimeInterval kCFTimeIntervalMax =
 bool g_not_using_cr_app = false;
 #endif
 
-// Call through to CFRunLoopTimerSetTolerance(), which is only available on
-// OS X 10.9.
-void SetTimerTolerance(CFRunLoopTimerRef timer, CFTimeInterval tolerance) {
-  typedef void (*CFRunLoopTimerSetTolerancePtr)(CFRunLoopTimerRef timer,
-      CFTimeInterval tolerance);
-
-  static CFRunLoopTimerSetTolerancePtr settimertolerance_function_ptr;
-
-  static dispatch_once_t get_timer_tolerance_function_ptr_once;
-  dispatch_once(&get_timer_tolerance_function_ptr_once, ^{
-      NSBundle* bundle =[NSBundle
-        bundleWithPath:@"/System/Library/Frameworks/CoreFoundation.framework"];
-      const char* path = [[bundle executablePath] fileSystemRepresentation];
-      CHECK(path);
-      void* library_handle = dlopen(path, RTLD_LAZY | RTLD_LOCAL);
-      CHECK(library_handle) << dlerror();
-      settimertolerance_function_ptr =
-          reinterpret_cast<CFRunLoopTimerSetTolerancePtr>(
-              dlsym(library_handle, "CFRunLoopTimerSetTolerance"));
-
-      dlclose(library_handle);
-  });
-
-  if (settimertolerance_function_ptr)
-    settimertolerance_function_ptr(timer, tolerance);
-}
-
 }  // namespace
 
 // static
@@ -273,9 +245,9 @@ void MessagePumpCFRunLoopBase::ScheduleDelayedWork(
   delayed_work_fire_time_ = CFAbsoluteTimeGetCurrent() + delta.InSecondsF();
   CFRunLoopTimerSetNextFireDate(delayed_work_timer_, delayed_work_fire_time_);
   if (timer_slack_ == TIMER_SLACK_MAXIMUM) {
-    SetTimerTolerance(delayed_work_timer_, delta.InSecondsF() * 0.5);
+    CFRunLoopTimerSetTolerance(delayed_work_timer_, delta.InSecondsF() * 0.5);
   } else {
-    SetTimerTolerance(delayed_work_timer_, 0);
+    CFRunLoopTimerSetTolerance(delayed_work_timer_, 0);
   }
 }
 
diff --git a/src/base/metrics/histogram.cc b/src/base/metrics/histogram.cc
index ab6cdd0..e1d0df6 100644
--- a/src/base/metrics/histogram.cc
+++ b/src/base/metrics/histogram.cc
@@ -216,7 +216,7 @@ HistogramBase* Histogram::Factory::Build() {
     ReportHistogramActivity(*histogram, HISTOGRAM_LOOKUP);
   }
 
-  DCHECK_EQ(histogram_type_, histogram->GetHistogramType()) << name_;
+  CHECK_EQ(histogram_type_, histogram->GetHistogramType()) << name_;
   if (bucket_count_ != 0 &&
       !histogram->HasConstructionArguments(minimum_, maximum_, bucket_count_)) {
     // The construction arguments do not match the existing histogram.  This can
@@ -673,15 +673,14 @@ void Histogram::WriteAsciiHeader(const SampleVector& samples,
                 "Histogram: %s recorded %d samples",
                 histogram_name().c_str(),
                 sample_count);
-  if (0 == sample_count) {
+  if (sample_count == 0) {
     DCHECK_EQ(samples.sum(), 0);
   } else {
-    double average = static_cast<float>(samples.sum()) / sample_count;
-
-    StringAppendF(output, ", average = %.1f", average);
+    double mean = static_cast<float>(samples.sum()) / sample_count;
+    StringAppendF(output, ", mean = %.1f", mean);
   }
-  if (flags() & ~kHexRangePrintingFlag)
-    StringAppendF(output, " (flags = 0x%x)", flags() & ~kHexRangePrintingFlag);
+  if (flags())
+    StringAppendF(output, " (flags = 0x%x)", flags());
 }
 
 void Histogram::WriteAsciiBucketContext(const int64_t past,
diff --git a/src/base/metrics/histogram.h b/src/base/metrics/histogram.h
index 2283a4d..0f05945 100644
--- a/src/base/metrics/histogram.h
+++ b/src/base/metrics/histogram.h
@@ -92,7 +92,6 @@ class BooleanHistogram;
 class CustomHistogram;
 class Histogram;
 class LinearHistogram;
-class PersistentMemoryAllocator;
 class Pickle;
 class PickleIterator;
 class SampleVector;
diff --git a/src/base/metrics/histogram_base.cc b/src/base/metrics/histogram_base.cc
index c2daf3c..750f048 100644
--- a/src/base/metrics/histogram_base.cc
+++ b/src/base/metrics/histogram_base.cc
@@ -118,7 +118,7 @@ void HistogramBase::WriteJSON(std::string* output) const {
   root.SetInteger("flags", flags());
   root.Set("params", std::move(parameters));
   root.Set("buckets", std::move(buckets));
-  root.SetInteger("pid", GetCurrentProcId());
+  root.SetInteger("pid", GetUniqueIdForProcess());
   serializer.Serialize(root);
 }
 
@@ -173,12 +173,7 @@ void HistogramBase::WriteAsciiBucketGraph(double current_size,
 
 const std::string HistogramBase::GetSimpleAsciiBucketRange(
     Sample sample) const {
-  std::string result;
-  if (kHexRangePrintingFlag & flags())
-    StringAppendF(&result, "%#x", sample);
-  else
-    StringAppendF(&result, "%d", sample);
-  return result;
+  return StringPrintf("%d", sample);
 }
 
 void HistogramBase::WriteAsciiBucketValue(Count current,
diff --git a/src/base/metrics/histogram_base.h b/src/base/metrics/histogram_base.h
index d240099..4f5ba04 100644
--- a/src/base/metrics/histogram_base.h
+++ b/src/base/metrics/histogram_base.h
@@ -21,7 +21,6 @@
 
 namespace base {
 
-class BucketRanges;
 class DictionaryValue;
 class HistogramBase;
 class HistogramSamples;
@@ -92,7 +91,7 @@ class BASE_EXPORT HistogramBase {
   static const Sample kSampleType_MAX;  // INT_MAX
 
   enum Flags {
-    kNoFlags = 0,
+    kNoFlags = 0x0,
 
     // Histogram should be UMA uploaded.
     kUmaTargetedHistogramFlag = 0x1,
@@ -121,9 +120,6 @@ class BASE_EXPORT HistogramBase {
     // MemoryAllocator, and that loaded into the Histogram module before this
     // histogram is created.
     kIsPersistent = 0x40,
-
-    // Only for Histogram and its sub classes: fancy bucket-naming support.
-    kHexRangePrintingFlag = 0x8000,
   };
 
   // Histogram data inconsistency types.
diff --git a/src/base/metrics/histogram_macros.h b/src/base/metrics/histogram_macros.h
index 1307257..9e3caec 100644
--- a/src/base/metrics/histogram_macros.h
+++ b/src/base/metrics/histogram_macros.h
@@ -5,317 +5,278 @@
 #ifndef BASE_METRICS_HISTOGRAM_MACROS_H_
 #define BASE_METRICS_HISTOGRAM_MACROS_H_
 
-#include "base/atomicops.h"
-#include "base/logging.h"
 #include "base/metrics/histogram.h"
+#include "base/metrics/histogram_macros_internal.h"
+#include "base/metrics/histogram_macros_local.h"
 #include "base/time/time.h"
 
-// Macros for efficient use of histograms. See documentation in histogram.h.
+
+// Macros for efficient use of histograms.
 //
-// UMA_HISTOGRAM_SPARSE_SLOWLY is defined in sparse_histogram.h as it has
-// different #include dependencies.
+// For best practices on deciding when to emit to a histogram and what form
+// the histogram should take, see
+// https://chromium.googlesource.com/chromium/src.git/+/HEAD/tools/metrics/histograms/README.md
+
+// TODO(rkaplow): Link to proper documentation on metric creation once we have
+// it in a good state.
+
+// All of these macros must be called with |name| as a runtime constant - it
+// doesn't have to literally be a constant, but it must be the same string on
+// all calls from a particular call site. If this rule is violated, it is
+// possible the data will be written to the wrong histogram.
 
 //------------------------------------------------------------------------------
-// Histograms are often put in areas where they are called many many times, and
-// performance is critical.  As a result, they are designed to have a very low
-// recurring cost of executing (adding additional samples).  Toward that end,
-// the macros declare a static pointer to the histogram in question, and only
-// take a "slow path" to construct (or find) the histogram on the first run
-// through the macro.  We leak the histograms at shutdown time so that we don't
-// have to validate using the pointers at any time during the running of the
-// process.
-
-// The following code is generally what a thread-safe static pointer
-// initialization looks like for a histogram (after a macro is expanded).  This
-// sample is an expansion (with comments) of the code for
-// LOCAL_HISTOGRAM_CUSTOM_COUNTS().
-
-/*
-  do {
-    // The pointer's presence indicates the initialization is complete.
-    // Initialization is idempotent, so it can safely be atomically repeated.
-    static base::subtle::AtomicWord atomic_histogram_pointer = 0;
-
-    // Acquire_Load() ensures that we acquire visibility to the pointed-to data
-    // in the histogram.
-    base::Histogram* histogram_pointer(reinterpret_cast<base::Histogram*>(
-        base::subtle::Acquire_Load(&atomic_histogram_pointer)));
-
-    if (!histogram_pointer) {
-      // This is the slow path, which will construct OR find the matching
-      // histogram.  FactoryGet includes locks on a global histogram name map
-      // and is completely thread safe.
-      histogram_pointer = base::Histogram::FactoryGet(
-          name, min, max, bucket_count, base::HistogramBase::kNoFlags);
-
-      // Use Release_Store to ensure that the histogram data is made available
-      // globally before we make the pointer visible.
-      // Several threads may perform this store, but the same value will be
-      // stored in all cases (for a given named/spec'ed histogram).
-      // We could do this without any barrier, since FactoryGet entered and
-      // exited a lock after construction, but this barrier makes things clear.
-      base::subtle::Release_Store(&atomic_histogram_pointer,
-          reinterpret_cast<base::subtle::AtomicWord>(histogram_pointer));
-    }
-
-    // Ensure calling contract is upheld, and the name does NOT vary.
-    DCHECK(histogram_pointer->histogram_name() == constant_histogram_name);
-
-    histogram_pointer->Add(sample);
-  } while (0);
-*/
-
-// The above pattern is repeated in several macros.  The only elements that
-// vary are the invocation of the Add(sample) vs AddTime(sample), and the choice
-// of which FactoryGet method to use.  The different FactoryGet methods have
-// various argument lists, so the function with its argument list is provided as
-// a macro argument here.  The name is only used in a DCHECK, to assure that
-// callers don't try to vary the name of the histogram (which would tend to be
-// ignored by the one-time initialization of the histogtram_pointer).
-
-// In some cases (integration into 3rd party code), it's useful to seperate the
-// definition of |atomic_histogram_poiner| from its use. To achieve this we
-// define HISTOGRAM_POINTER_USE, which uses an |atomic_histogram_pointer|, and
-// STATIC_HISTOGRAM_POINTER_BLOCK, which defines an |atomic_histogram_pointer|
-// and forwards to HISTOGRAM_POINTER_USE.
-#define HISTOGRAM_POINTER_USE(atomic_histogram_pointer,                   \
-                              constant_histogram_name,                    \
-                              histogram_add_method_invocation,            \
-                              histogram_factory_get_invocation)           \
-  do {                                                                    \
-    base::HistogramBase* histogram_pointer(                               \
-        reinterpret_cast<base::HistogramBase*>(                           \
-            base::subtle::Acquire_Load(atomic_histogram_pointer)));       \
-    if (!histogram_pointer) {                                             \
-      histogram_pointer = histogram_factory_get_invocation;               \
-      base::subtle::Release_Store(                                        \
-          atomic_histogram_pointer,                                       \
-          reinterpret_cast<base::subtle::AtomicWord>(histogram_pointer)); \
-    }                                                                     \
-    if (DCHECK_IS_ON())                                                   \
-      histogram_pointer->CheckName(constant_histogram_name);              \
-    histogram_pointer->histogram_add_method_invocation;                   \
-  } while (0)
-
-// Defines the static |atomic_histogram_pointer| and forwards to
-// HISTOGRAM_POINTER_USE.
-#define STATIC_HISTOGRAM_POINTER_BLOCK(constant_histogram_name,               \
-                                       histogram_add_method_invocation,       \
-                                       histogram_factory_get_invocation)      \
-  do {                                                                        \
-    static base::subtle::AtomicWord atomic_histogram_pointer = 0;             \
-    HISTOGRAM_POINTER_USE(&atomic_histogram_pointer, constant_histogram_name, \
-                          histogram_add_method_invocation,                    \
-                          histogram_factory_get_invocation);                  \
-  } while (0)
+// Enumeration histograms.
+
+// These macros create histograms for enumerated data. Ideally, the data should
+// be of the form of "event occurs, log the result". We recommended not putting
+// related but not directly connected data as enums within the same histogram.
+// You should be defining an associated Enum, and the input sample should be
+// an element of the Enum.
+// All of these macros must be called with |name| as a runtime constant.
+
+// Sample usage:
+//   UMA_HISTOGRAM_ENUMERATION("My.Enumeration", VALUE, EVENT_MAX_VALUE);
+// New Enum values can be added, but existing enums must never be renumbered or
+// delete and reused. The value in |sample| must be strictly less than
+// |enum_max|.
+
+#define UMA_HISTOGRAM_ENUMERATION(name, sample, enum_max)                      \
+    INTERNAL_HISTOGRAM_ENUMERATION_WITH_FLAG(                                  \
+        name, sample, enum_max,                                                \
+        base::HistogramBase::kUmaTargetedHistogramFlag)
+
+// Histogram for boolean values.
+
+// Sample usage:
+//   UMA_HISTOGRAM_BOOLEAN("Histogram.Boolean", bool);
+#define UMA_HISTOGRAM_BOOLEAN(name, sample)                                    \
+    STATIC_HISTOGRAM_POINTER_BLOCK(name, AddBoolean(sample),                   \
+        base::BooleanHistogram::FactoryGet(name,                               \
+            base::HistogramBase::kUmaTargetedHistogramFlag))
 
 //------------------------------------------------------------------------------
-// Provide easy general purpose histogram in a macro, just like stats counters.
-// Most of these macros use 50 buckets, but check the definition for details.
-//
-// All of these macros must be called with |name| as a runtime constant --- it
-// doesn't have to literally be a constant, but it must be the same string on
-// all calls from a particular call site. If this rule is violated,
-// STATIC_HISTOGRAM_POINTER_BLOCK will DCHECK, and if DCHECKS are disabled, the
-// data will be written to the wrong histogram.
+// Linear histograms.
 
-#define LOCAL_HISTOGRAM_TIMES(name, sample) LOCAL_HISTOGRAM_CUSTOM_TIMES( \
-    name, sample, base::TimeDelta::FromMilliseconds(1), \
-    base::TimeDelta::FromSeconds(10), 50)
+// All of these macros must be called with |name| as a runtime constant.
+
+// Used for capturing integer data with a linear bucketing scheme. This can be
+// used when you want the exact value of some small numeric count, with a max of
+// 100 or less. If you need to capture a range of greater than 100, we recommend
+// the use of the COUNT histograms below.
+
+// Sample usage:
+//   UMA_HISTOGRAM_EXACT_LINEAR("Histogram.Linear", count, 10);
+#define UMA_HISTOGRAM_EXACT_LINEAR(name, sample, value_max) \
+  UMA_HISTOGRAM_ENUMERATION(name, sample, value_max)
+
+// Used for capturing basic percentages. This will be 100 buckets of size 1.
+
+// Sample usage:
+//   UMA_HISTOGRAM_PERCENTAGE("Histogram.Percent", percent_as_int);
+#define UMA_HISTOGRAM_PERCENTAGE(name, percent_as_int)                         \
+    UMA_HISTOGRAM_ENUMERATION(name, percent_as_int, 101)
+
+//------------------------------------------------------------------------------
+// Count histograms. These are used for collecting numeric data. Note that we
+// have macros for more specialized use cases below (memory, time, percentages).
+
+// The number suffixes here refer to the max size of the sample, i.e. COUNT_1000
+// will be able to collect samples of counts up to 1000. The default number of
+// buckets in all default macros is 50. We recommend erring on the side of too
+// large a range versus too short a range.
+// These macros default to exponential histograms - i.e. the lengths of the
+// bucket ranges exponentially increase as the sample range increases.
+// These should *not* be used if you are interested in exact counts, i.e. a
+// bucket range of 1. In these cases, you should use the ENUMERATION macros
+// defined later. These should also not be used to capture the number of some
+// event, i.e. "button X was clicked N times". In this cases, an enum should be
+// used, ideally with an appropriate baseline enum entry included.
+// All of these macros must be called with |name| as a runtime constant.
+
+// Sample usage:
+//   UMA_HISTOGRAM_COUNTS_1M("My.Histogram", sample);
+
+#define UMA_HISTOGRAM_COUNTS_100(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS(    \
+    name, sample, 1, 100, 50)
+
+#define UMA_HISTOGRAM_COUNTS_1000(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS(   \
+    name, sample, 1, 1000, 50)
 
-// For folks that need real specific times, use this to select a precise range
-// of times you want plotted, and the number of buckets you want used.
-#define LOCAL_HISTOGRAM_CUSTOM_TIMES(name, sample, min, max, bucket_count) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(name, AddTime(sample), \
-        base::Histogram::FactoryTimeGet(name, min, max, bucket_count, \
-                                        base::HistogramBase::kNoFlags))
+#define UMA_HISTOGRAM_COUNTS_10000(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS(  \
+    name, sample, 1, 10000, 50)
+
+#define UMA_HISTOGRAM_COUNTS_100000(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS( \
+    name, sample, 1, 100000, 50)
 
-#define LOCAL_HISTOGRAM_COUNTS(name, sample) LOCAL_HISTOGRAM_CUSTOM_COUNTS( \
+#define UMA_HISTOGRAM_COUNTS_1M(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS(     \
     name, sample, 1, 1000000, 50)
 
-#define LOCAL_HISTOGRAM_COUNTS_100(name, sample) \
-    LOCAL_HISTOGRAM_CUSTOM_COUNTS(name, sample, 1, 100, 50)
-
-#define LOCAL_HISTOGRAM_COUNTS_10000(name, sample) \
-    LOCAL_HISTOGRAM_CUSTOM_COUNTS(name, sample, 1, 10000, 50)
-
-#define LOCAL_HISTOGRAM_CUSTOM_COUNTS(name, sample, min, max, bucket_count) \
-    INTERNAL_HISTOGRAM_CUSTOM_COUNTS_WITH_FLAG(                             \
-        name, sample, min, max, bucket_count, base::HistogramBase::kNoFlags)
-
-// This is a helper macro used by other macros and shouldn't be used directly.
-#define INTERNAL_HISTOGRAM_CUSTOM_COUNTS_WITH_FLAG(name, sample, min, max, \
-                                                   bucket_count, flag)     \
-    STATIC_HISTOGRAM_POINTER_BLOCK(                                        \
-        name, Add(sample),                                                 \
-        base::Histogram::FactoryGet(name, min, max, bucket_count, flag))
-
-// This is a helper macro used by other macros and shouldn't be used directly.
-// One additional bucket is created in the LinearHistogram for the illegal
-// values >= boundary_value so that mistakes in calling the UMA enumeration
-// macros can be detected.
-#define INTERNAL_HISTOGRAM_ENUMERATION_WITH_FLAG(name, sample, boundary, flag) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(                                            \
-        name, Add(sample),                                                     \
-        base::LinearHistogram::FactoryGet(                                     \
-            name, 1, boundary, boundary + 1, flag))
-
-#define LOCAL_HISTOGRAM_PERCENTAGE(name, under_one_hundred) \
-    LOCAL_HISTOGRAM_ENUMERATION(name, under_one_hundred, 101)
-
-#define LOCAL_HISTOGRAM_BOOLEAN(name, sample) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(name, AddBoolean(sample), \
-        base::BooleanHistogram::FactoryGet(name, base::Histogram::kNoFlags))
-
-// Support histograming of an enumerated value.  The samples should always be
-// strictly less than |boundary_value| -- this prevents you from running into
-// problems down the line if you add additional buckets to the histogram.  Note
-// also that, despite explicitly setting the minimum bucket value to |1| below,
-// it is fine for enumerated histograms to be 0-indexed -- this is because
-// enumerated histograms should never have underflow. One additional bucket is
-// created in the LinearHistogram for the illegal values >= boundary_value so
-// that mistakes in calling this macro can be detected.
-#define LOCAL_HISTOGRAM_ENUMERATION(name, sample, boundary_value) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(name, Add(sample), \
-        base::LinearHistogram::FactoryGet(name, 1, boundary_value, \
-            boundary_value + 1, base::HistogramBase::kNoFlags))
-
-// Support histograming of an enumerated value. Samples should be one of the
-// std::vector<int> list provided via |custom_ranges|. See comments above
-// CustomRanges::FactoryGet about the requirement of |custom_ranges|.
-// You can use the helper function CustomHistogram::ArrayToCustomRanges to
-// transform a C-style array of valid sample values to a std::vector<int>.
-#define LOCAL_HISTOGRAM_CUSTOM_ENUMERATION(name, sample, custom_ranges) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(name, Add(sample), \
-        base::CustomHistogram::FactoryGet(name, custom_ranges, \
-                                          base::HistogramBase::kNoFlags))
-
-#define LOCAL_HISTOGRAM_MEMORY_KB(name, sample) LOCAL_HISTOGRAM_CUSTOM_COUNTS( \
-    name, sample, 1000, 500000, 50)
+#define UMA_HISTOGRAM_COUNTS_10M(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS(    \
+    name, sample, 1, 10000000, 50)
+
+// This can be used when the default ranges are not sufficient. This macro lets
+// the metric developer customize the min and max of the sampled range, as well
+// as the number of buckets recorded.
+// Any data outside the range here will be put in underflow and overflow
+// buckets. Min values should be >=1 as emitted 0s will still go into the
+// underflow bucket.
+
+// Sample usage:
+//   UMA_HISTOGRAM_CUSTOM_COUNTS("My.Histogram", 1, 100000000, 100);
+#define UMA_HISTOGRAM_CUSTOM_COUNTS(name, sample, min, max, bucket_count)      \
+    INTERNAL_HISTOGRAM_CUSTOM_COUNTS_WITH_FLAG(                                \
+        name, sample, min, max, bucket_count,                                  \
+        base::HistogramBase::kUmaTargetedHistogramFlag)
 
 //------------------------------------------------------------------------------
-// The following macros provide typical usage scenarios for callers that wish
-// to record histogram data, and have the data submitted/uploaded via UMA.
-// Not all systems support such UMA, but if they do, the following macros
-// should work with the service.
+// Timing histograms. These are used for collecting timing data (generally
+// latencies).
+
+// These macros create exponentially sized histograms (lengths of the bucket
+// ranges exponentially increase as the sample range increases). The input
+// sample is a base::TimeDelta. The output data is measured in ms granularity.
+// All of these macros must be called with |name| as a runtime constant.
 
-#define UMA_HISTOGRAM_TIMES(name, sample) UMA_HISTOGRAM_CUSTOM_TIMES( \
-    name, sample, base::TimeDelta::FromMilliseconds(1), \
+// Sample usage:
+//   UMA_HISTOGRAM_TIMES("My.Timing.Histogram", time_delta);
+
+// Short timings - up to 10 seconds.
+#define UMA_HISTOGRAM_TIMES(name, sample) UMA_HISTOGRAM_CUSTOM_TIMES(          \
+    name, sample, base::TimeDelta::FromMilliseconds(1),                        \
     base::TimeDelta::FromSeconds(10), 50)
 
-#define UMA_HISTOGRAM_MEDIUM_TIMES(name, sample) UMA_HISTOGRAM_CUSTOM_TIMES( \
-    name, sample, base::TimeDelta::FromMilliseconds(10), \
+// Medium timings - up to 3 minutes. Note this starts at 10ms (no good reason,
+// but not worth changing).
+#define UMA_HISTOGRAM_MEDIUM_TIMES(name, sample) UMA_HISTOGRAM_CUSTOM_TIMES(   \
+    name, sample, base::TimeDelta::FromMilliseconds(10),                       \
     base::TimeDelta::FromMinutes(3), 50)
 
-// Use this macro when times can routinely be much longer than 10 seconds.
-#define UMA_HISTOGRAM_LONG_TIMES(name, sample) UMA_HISTOGRAM_CUSTOM_TIMES( \
-    name, sample, base::TimeDelta::FromMilliseconds(1), \
+// Long timings - up to an hour.
+#define UMA_HISTOGRAM_LONG_TIMES(name, sample) UMA_HISTOGRAM_CUSTOM_TIMES(     \
+    name, sample, base::TimeDelta::FromMilliseconds(1),                        \
     base::TimeDelta::FromHours(1), 50)
 
-// Use this macro when times can routinely be much longer than 10 seconds and
-// you want 100 buckets.
+// Long timings with higher granularity - up to an hour with 100 buckets.
 #define UMA_HISTOGRAM_LONG_TIMES_100(name, sample) UMA_HISTOGRAM_CUSTOM_TIMES( \
-    name, sample, base::TimeDelta::FromMilliseconds(1), \
+    name, sample, base::TimeDelta::FromMilliseconds(1),                        \
     base::TimeDelta::FromHours(1), 100)
 
-#define UMA_HISTOGRAM_CUSTOM_TIMES(name, sample, min, max, bucket_count) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(name, AddTime(sample), \
-        base::Histogram::FactoryTimeGet(name, min, max, bucket_count, \
-            base::HistogramBase::kUmaTargetedHistogramFlag))
+// This can be used when the default ranges are not sufficient. This macro lets
+// the metric developer customize the min and max of the sampled range, as well
+// as the number of buckets recorded.
 
-#define UMA_HISTOGRAM_COUNTS(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS( \
-    name, sample, 1, 1000000, 50)
+// Sample usage:
+//   UMA_HISTOGRAM_CUSTOM_TIMES("Very.Long.Timing.Histogram", duration_in_ms,
+//       base::TimeDelta::FromSeconds(1), base::TimeDelta::FromDays(1), 100);
+#define UMA_HISTOGRAM_CUSTOM_TIMES(name, sample, min, max, bucket_count)       \
+    STATIC_HISTOGRAM_POINTER_BLOCK(name, AddTime(sample),                      \
+        base::Histogram::FactoryTimeGet(name, min, max, bucket_count,          \
+            base::HistogramBase::kUmaTargetedHistogramFlag))
 
-#define UMA_HISTOGRAM_COUNTS_100(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS( \
-    name, sample, 1, 100, 50)
+// Scoped class which logs its time on this earth as a UMA statistic. This is
+// recommended for when you want a histogram which measures the time it takes
+// for a method to execute. This measures up to 10 seconds. It uses
+// UMA_HISTOGRAM_TIMES under the hood.
 
-#define UMA_HISTOGRAM_COUNTS_1000(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS( \
-    name, sample, 1, 1000, 50)
+// Sample usage:
+//   void Function() {
+//     SCOPED_UMA_HISTOGRAM_TIMER("Component.FunctionTime");
+//     ...
+//   }
+#define SCOPED_UMA_HISTOGRAM_TIMER(name)                                       \
+  INTERNAL_SCOPED_UMA_HISTOGRAM_TIMER_EXPANDER(name, false, __COUNTER__)
 
-#define UMA_HISTOGRAM_COUNTS_10000(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS( \
-    name, sample, 1, 10000, 50)
+// Similar scoped histogram timer, but this uses UMA_HISTOGRAM_LONG_TIMES_100,
+// which measures up to an hour, and uses 100 buckets. This is more expensive
+// to store, so only use if this often takes >10 seconds.
+#define SCOPED_UMA_HISTOGRAM_LONG_TIMER(name)                                  \
+  INTERNAL_SCOPED_UMA_HISTOGRAM_TIMER_EXPANDER(name, true, __COUNTER__)
 
-#define UMA_HISTOGRAM_CUSTOM_COUNTS(name, sample, min, max, bucket_count) \
-    INTERNAL_HISTOGRAM_CUSTOM_COUNTS_WITH_FLAG(                           \
-        name, sample, min, max, bucket_count,                             \
-        base::HistogramBase::kUmaTargetedHistogramFlag)
 
-#define UMA_STABILITY_HISTOGRAM_COUNTS_100(name, sample) \
-    UMA_STABILITY_HISTOGRAM_CUSTOM_COUNTS(name, sample, 1, 100, 50)
+//------------------------------------------------------------------------------
+// Memory histograms.
 
-#define UMA_STABILITY_HISTOGRAM_CUSTOM_COUNTS(name, sample, min, max, \
-                                              bucket_count)           \
-    INTERNAL_HISTOGRAM_CUSTOM_COUNTS_WITH_FLAG(                       \
-        name, sample, min, max, bucket_count,                         \
-        base::HistogramBase::kUmaStabilityHistogramFlag)
+// These macros create exponentially sized histograms (lengths of the bucket
+// ranges exponentially increase as the sample range increases). The input
+// sample must be a number measured in kilobytes.
+// All of these macros must be called with |name| as a runtime constant.
 
-#define UMA_HISTOGRAM_MEMORY_KB(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS( \
-    name, sample, 1000, 500000, 50)
+// Sample usage:
+//   UMA_HISTOGRAM_MEMORY_KB("My.Memory.Histogram", memory_in_kb);
 
-#define UMA_HISTOGRAM_MEMORY_MB(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS( \
-    name, sample, 1, 1000, 50)
+// Used to measure common KB-granularity memory stats. Range is up to 500000KB -
+// approximately 500M.
+#define UMA_HISTOGRAM_MEMORY_KB(name, sample)                                  \
+    UMA_HISTOGRAM_CUSTOM_COUNTS(name, sample, 1000, 500000, 50)
 
-#define UMA_HISTOGRAM_MEMORY_LARGE_MB(name, sample) \
+// Used to measure common MB-granularity memory stats. Range is up to ~64G.
+#define UMA_HISTOGRAM_MEMORY_LARGE_MB(name, sample)                            \
     UMA_HISTOGRAM_CUSTOM_COUNTS(name, sample, 1, 64000, 100)
 
-#define UMA_HISTOGRAM_PERCENTAGE(name, under_one_hundred) \
-    UMA_HISTOGRAM_ENUMERATION(name, under_one_hundred, 101)
 
-#define UMA_HISTOGRAM_BOOLEAN(name, sample) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(name, AddBoolean(sample), \
-        base::BooleanHistogram::FactoryGet(name, \
-            base::HistogramBase::kUmaTargetedHistogramFlag))
+//------------------------------------------------------------------------------
+// Stability-specific histograms.
 
-// The samples should always be strictly less than |boundary_value|.  For more
-// details, see the comment for the |LOCAL_HISTOGRAM_ENUMERATION| macro, above.
-#define UMA_HISTOGRAM_ENUMERATION(name, sample, boundary_value) \
-    INTERNAL_HISTOGRAM_ENUMERATION_WITH_FLAG(                   \
-        name, sample, boundary_value,                           \
-        base::HistogramBase::kUmaTargetedHistogramFlag)
+// Histograms logged in as stability histograms will be included in the initial
+// stability log. See comments by declaration of
+// MetricsService::PrepareInitialStabilityLog().
+// All of these macros must be called with |name| as a runtime constant.
 
-// Similar to UMA_HISTOGRAM_ENUMERATION, but used for recording stability
-// histograms.  Use this if recording a histogram that should be part of the
-// initial stability log.
-#define UMA_STABILITY_HISTOGRAM_ENUMERATION(name, sample, boundary_value) \
-    INTERNAL_HISTOGRAM_ENUMERATION_WITH_FLAG(                             \
-        name, sample, boundary_value,                                     \
+// For details on usage, see the documentation on the non-stability equivalents.
+
+#define UMA_STABILITY_HISTOGRAM_COUNTS_100(name, sample)                       \
+    UMA_STABILITY_HISTOGRAM_CUSTOM_COUNTS(name, sample, 1, 100, 50)
+
+#define UMA_STABILITY_HISTOGRAM_CUSTOM_COUNTS(name, sample, min, max,          \
+                                              bucket_count)                    \
+    INTERNAL_HISTOGRAM_CUSTOM_COUNTS_WITH_FLAG(                                \
+        name, sample, min, max, bucket_count,                                  \
         base::HistogramBase::kUmaStabilityHistogramFlag)
 
-#define UMA_HISTOGRAM_CUSTOM_ENUMERATION(name, sample, custom_ranges) \
-    STATIC_HISTOGRAM_POINTER_BLOCK(name, Add(sample), \
-        base::CustomHistogram::FactoryGet(name, custom_ranges, \
-            base::HistogramBase::kUmaTargetedHistogramFlag))
+#define UMA_STABILITY_HISTOGRAM_ENUMERATION(name, sample, enum_max)            \
+    INTERNAL_HISTOGRAM_ENUMERATION_WITH_FLAG(                                  \
+        name, sample, enum_max,                                                \
+        base::HistogramBase::kUmaStabilityHistogramFlag)
 
-// Scoped class which logs its time on this earth as a UMA statistic. This is
-// recommended for when you want a histogram which measures the time it takes
-// for a method to execute. This measures up to 10 seconds.
-#define SCOPED_UMA_HISTOGRAM_TIMER(name) \
-  SCOPED_UMA_HISTOGRAM_TIMER_EXPANDER(name, false, __COUNTER__)
+//------------------------------------------------------------------------------
+// Sparse histograms.
 
-// Similar scoped histogram timer, but this uses UMA_HISTOGRAM_LONG_TIMES_100,
-// which measures up to an hour, and uses 100 buckets. This is more expensive
-// to store, so only use if this often takes >10 seconds.
-#define SCOPED_UMA_HISTOGRAM_LONG_TIMER(name) \
-  SCOPED_UMA_HISTOGRAM_TIMER_EXPANDER(name, true, __COUNTER__)
-
-// This nested macro is necessary to expand __COUNTER__ to an actual value.
-#define SCOPED_UMA_HISTOGRAM_TIMER_EXPANDER(name, is_long, key) \
-  SCOPED_UMA_HISTOGRAM_TIMER_UNIQUE(name, is_long, key)
-
-#define SCOPED_UMA_HISTOGRAM_TIMER_UNIQUE(name, is_long, key) \
-  class ScopedHistogramTimer##key { \
-   public: \
-    ScopedHistogramTimer##key() : constructed_(base::TimeTicks::Now()) {} \
-    ~ScopedHistogramTimer##key() { \
-      base::TimeDelta elapsed = base::TimeTicks::Now() - constructed_; \
-      if (is_long) { \
-        UMA_HISTOGRAM_LONG_TIMES_100(name, elapsed); \
-      } else { \
-        UMA_HISTOGRAM_TIMES(name, elapsed); \
-      } \
-    } \
-   private: \
-    base::TimeTicks constructed_; \
-  } scoped_histogram_timer_##key
+// Sparse histograms are well suited for recording counts of exact sample values
+// that are sparsely distributed over a large range.
+//
+// UMA_HISTOGRAM_SPARSE_SLOWLY is good for sparsely distributed and/or
+// infrequently recorded values since the implementation is slower
+// and takes more memory.
+//
+// For instance, Sqlite.Version.* are sparse because for any given database,
+// there's going to be exactly one version logged.
+// The |sample| can be a negative or non-negative number.
+#define UMA_HISTOGRAM_SPARSE_SLOWLY(name, sample)                              \
+    INTERNAL_HISTOGRAM_SPARSE_SLOWLY(name, sample)
+
+//------------------------------------------------------------------------------
+// Deprecated histogram macros. Not recommended for current use.
+
+// Legacy name for UMA_HISTOGRAM_COUNTS_1M. Suggest using explicit naming
+// and not using this macro going forward.
+#define UMA_HISTOGRAM_COUNTS(name, sample) UMA_HISTOGRAM_CUSTOM_COUNTS(        \
+    name, sample, 1, 1000000, 50)
+
+// MB-granularity memory metric. This has a short max (1G).
+#define UMA_HISTOGRAM_MEMORY_MB(name, sample)                                  \
+    UMA_HISTOGRAM_CUSTOM_COUNTS(name, sample, 1, 1000, 50)
+
+// For an enum with customized range. In general, sparse histograms should be
+// used instead.
+// Samples should be one of the std::vector<int> list provided via
+// |custom_ranges|. See comments above CustomRanges::FactoryGet about the
+// requirement of |custom_ranges|. You can use the helper function
+// CustomHistogram::ArrayToCustomRanges to transform a C-style array of valid
+// sample values to a std::vector<int>.
+#define UMA_HISTOGRAM_CUSTOM_ENUMERATION(name, sample, custom_ranges)          \
+    STATIC_HISTOGRAM_POINTER_BLOCK(name, Add(sample),                          \
+        base::CustomHistogram::FactoryGet(name, custom_ranges,                 \
+            base::HistogramBase::kUmaTargetedHistogramFlag))
 
 #endif  // BASE_METRICS_HISTOGRAM_MACROS_H_
diff --git a/src/base/metrics/histogram_samples.h b/src/base/metrics/histogram_samples.h
index e28573f..93f6d21 100644
--- a/src/base/metrics/histogram_samples.h
+++ b/src/base/metrics/histogram_samples.h
@@ -27,6 +27,9 @@ class SampleCountIterator;
 class BASE_EXPORT HistogramSamples {
  public:
   struct Metadata {
+    // Expected size for 32/64-bit check.
+    static constexpr size_t kExpectedInstanceSize = 24;
+
     // Initialized when the sample-set is first created with a value provided
     // by the caller. It is generally used to identify the sample-set across
     // threads and processes, though not necessarily uniquely as it is possible
@@ -55,7 +58,21 @@ class BASE_EXPORT HistogramSamples {
     // might mismatch even when no memory corruption has happened.
     HistogramBase::AtomicCount redundant_count;
 
-    Metadata() : id(0), sum(0), redundant_count(0) {}
+    // 4 bytes of padding to explicitly extend this structure to a multiple of
+    // 64-bits. This is required to ensure the structure is the same size on
+    // both 32-bit and 64-bit builds.
+    char padding[4];
+  };
+
+  // Because sturctures held in persistent memory must be POD, there can be no
+  // default constructor to clear the fields. This derived class exists just
+  // to clear them when being allocated on the heap.
+  struct LocalMetadata : Metadata {
+    LocalMetadata() {
+      id = 0;
+      sum = 0;
+      redundant_count = 0;
+    }
   };
 
   explicit HistogramSamples(uint64_t id);
@@ -102,7 +119,7 @@ class BASE_EXPORT HistogramSamples {
   // In order to support histograms shared through an external memory segment,
   // meta values may be the local storage or external storage depending on the
   // wishes of the derived class.
-  Metadata local_meta_;
+  LocalMetadata local_meta_;
   Metadata* meta_;
 
   DISALLOW_COPY_AND_ASSIGN(HistogramSamples);
diff --git a/src/base/metrics/persistent_histogram_allocator.cc b/src/base/metrics/persistent_histogram_allocator.cc
index 14855df..26fbfd7 100644
--- a/src/base/metrics/persistent_histogram_allocator.cc
+++ b/src/base/metrics/persistent_histogram_allocator.cc
@@ -37,9 +37,11 @@ const char kResultHistogram[] = "UMA.CreatePersistentHistogram.Result";
 // so that, if the structure of that object changes, stored older versions
 // will be safely ignored.
 enum : uint32_t {
-  kTypeIdHistogram   = 0xF1645910 + 2,  // SHA1(Histogram)   v2
+  kTypeIdHistogram = 0xF1645910 + 3,    // SHA1(Histogram)   v3
   kTypeIdRangesArray = 0xBCEA225A + 1,  // SHA1(RangesArray) v1
   kTypeIdCountsArray = 0x53215530 + 1,  // SHA1(CountsArray) v1
+
+  kTypeIdHistogramUnderConstruction = ~kTypeIdHistogram,
 };
 
 // The current globally-active persistent allocator for all new histograms.
@@ -226,6 +228,10 @@ PersistentMemoryAllocator::Reference PersistentSampleMapRecords::CreateNew(
 // This data will be held in persistent memory in order for processes to
 // locate and use histograms created elsewhere.
 struct PersistentHistogramAllocator::PersistentHistogramData {
+  // Expected size for 32/64-bit check.
+  static constexpr size_t kExpectedInstanceSize =
+      40 + 2 * HistogramSamples::Metadata::kExpectedInstanceSize;
+
   int32_t histogram_type;
   int32_t flags;
   int32_t minimum;
@@ -240,7 +246,7 @@ struct PersistentHistogramAllocator::PersistentHistogramData {
   // Space for the histogram name will be added during the actual allocation
   // request. This must be the last field of the structure. A zero-size array
   // or a "flexible" array would be preferred but is not (yet) valid C++.
-  char name[1];
+  char name[sizeof(uint64_t)];  // Force 64-bit alignment on 32-bit builds.
 };
 
 PersistentHistogramAllocator::Iterator::Iterator(
@@ -276,8 +282,15 @@ std::unique_ptr<HistogramBase> PersistentHistogramAllocator::GetHistogram(
       memory_allocator_->GetAsObject<PersistentHistogramData>(
           ref, kTypeIdHistogram);
   size_t length = memory_allocator_->GetAllocSize(ref);
+
+  // Check that metadata is reasonable: name is NUL terminated and non-empty,
+  // ID fields have been loaded with a hash of the name (0 is considered
+  // unset/invalid).
   if (!histogram_data ||
-      reinterpret_cast<char*>(histogram_data)[length - 1] != '\0') {
+      reinterpret_cast<char*>(histogram_data)[length - 1] != '\0' ||
+      histogram_data->name[0] == '\0' ||
+      histogram_data->samples_metadata.id == 0 ||
+      histogram_data->logged_metadata.id == 0) {
     RecordCreateHistogramResult(CREATE_HISTOGRAM_INVALID_METADATA);
     NOTREACHED();
     return nullptr;
@@ -304,14 +317,17 @@ std::unique_ptr<HistogramBase> PersistentHistogramAllocator::AllocateHistogram(
 
   // Create the metadata necessary for a persistent sparse histogram. This
   // is done first because it is a small subset of what is required for
-  // other histograms.
+  // other histograms. The type is "under construction" so that a crash
+  // during the datafill doesn't leave a bad record around that could cause
+  // confusion by another process trying to read it. It will be corrected
+  // once histogram construction is complete.
   PersistentMemoryAllocator::Reference histogram_ref =
       memory_allocator_->Allocate(
           offsetof(PersistentHistogramData, name) + name.length() + 1,
-          kTypeIdHistogram);
+          kTypeIdHistogramUnderConstruction);
   PersistentHistogramData* histogram_data =
-      memory_allocator_->GetAsObject<PersistentHistogramData>(histogram_ref,
-                                                              kTypeIdHistogram);
+      memory_allocator_->GetAsObject<PersistentHistogramData>(
+          histogram_ref, kTypeIdHistogramUnderConstruction);
   if (histogram_data) {
     memcpy(histogram_data->name, name.c_str(), name.size() + 1);
     histogram_data->histogram_type = histogram_type;
@@ -328,14 +344,15 @@ std::unique_ptr<HistogramBase> PersistentHistogramAllocator::AllocateHistogram(
       return nullptr;
     }
 
-    size_t ranges_bytes = (bucket_count + 1) * sizeof(HistogramBase::Sample);
+    size_t ranges_count = bucket_count + 1;
+    size_t ranges_bytes = ranges_count * sizeof(HistogramBase::Sample);
     PersistentMemoryAllocator::Reference counts_ref =
         memory_allocator_->Allocate(counts_bytes, kTypeIdCountsArray);
     PersistentMemoryAllocator::Reference ranges_ref =
         memory_allocator_->Allocate(ranges_bytes, kTypeIdRangesArray);
     HistogramBase::Sample* ranges_data =
-        memory_allocator_->GetAsObject<HistogramBase::Sample>(
-            ranges_ref, kTypeIdRangesArray);
+        memory_allocator_->GetAsArray<HistogramBase::Sample>(
+            ranges_ref, kTypeIdRangesArray, ranges_count);
 
     // Only continue here if all allocations were successful. If they weren't,
     // there is no way to free the space but that's not really a problem since
@@ -367,6 +384,11 @@ std::unique_ptr<HistogramBase> PersistentHistogramAllocator::AllocateHistogram(
     // correct before commiting the new histogram to persistent space.
     std::unique_ptr<HistogramBase> histogram = CreateHistogram(histogram_data);
     DCHECK(histogram);
+    DCHECK_NE(0U, histogram_data->samples_metadata.id);
+    DCHECK_NE(0U, histogram_data->logged_metadata.id);
+    memory_allocator_->ChangeType(histogram_ref, kTypeIdHistogram,
+                                  kTypeIdHistogramUnderConstruction);
+
     if (ref_ptr != nullptr)
       *ref_ptr = histogram_ref;
 
@@ -480,14 +502,9 @@ PersistentHistogramAllocator::GetCreateHistogramResultHistogram() {
     if (!initialized) {
       initialized = true;
       if (g_allocator) {
-// Don't log in release-with-asserts builds, otherwise the test_installer step
-// fails because this code writes to a log file before the installer code had a
-// chance to set the log file's location.
-#if !defined(DCHECK_ALWAYS_ON)
-        DLOG(WARNING) << "Creating the results-histogram inside persistent"
-                      << " memory can cause future allocations to crash if"
-                      << " that memory is ever released (for testing).";
-#endif
+        DVLOG(1) << "Creating the results-histogram inside persistent"
+                 << " memory can cause future allocations to crash if"
+                 << " that memory is ever released (for testing).";
       }
 
       histogram_pointer = LinearHistogram::FactoryGet(
@@ -529,8 +546,9 @@ std::unique_ptr<HistogramBase> PersistentHistogramAllocator::CreateHistogram(
   PersistentHistogramData histogram_data = *histogram_data_ptr;
 
   HistogramBase::Sample* ranges_data =
-      memory_allocator_->GetAsObject<HistogramBase::Sample>(
-          histogram_data.ranges_ref, kTypeIdRangesArray);
+      memory_allocator_->GetAsArray<HistogramBase::Sample>(
+          histogram_data.ranges_ref, kTypeIdRangesArray,
+          PersistentMemoryAllocator::kSizeAny);
 
   const uint32_t max_buckets =
       std::numeric_limits<uint32_t>::max() / sizeof(HistogramBase::Sample);
@@ -559,8 +577,9 @@ std::unique_ptr<HistogramBase> PersistentHistogramAllocator::CreateHistogram(
           created_ranges.release());
 
   HistogramBase::AtomicCount* counts_data =
-      memory_allocator_->GetAsObject<HistogramBase::AtomicCount>(
-          histogram_data.counts_ref, kTypeIdCountsArray);
+      memory_allocator_->GetAsArray<HistogramBase::AtomicCount>(
+          histogram_data.counts_ref, kTypeIdCountsArray,
+          PersistentMemoryAllocator::kSizeAny);
   size_t counts_bytes =
       CalculateRequiredCountsBytes(histogram_data.bucket_count);
   if (!counts_data || counts_bytes == 0 ||
@@ -689,7 +708,7 @@ void GlobalHistogramAllocator::CreateWithLocalMemory(
 #if 0
 #if !defined(OS_NACL)
 // static
-void GlobalHistogramAllocator::CreateWithFile(
+bool GlobalHistogramAllocator::CreateWithFile(
     const FilePath& file_path,
     size_t size,
     uint64_t id,
@@ -709,14 +728,55 @@ void GlobalHistogramAllocator::CreateWithFile(
   if (!mmfile->IsValid() ||
       !FilePersistentMemoryAllocator::IsFileAcceptable(*mmfile, true)) {
     NOTREACHED();
-    return;
+    return false;
   }
 
   Set(WrapUnique(
       new GlobalHistogramAllocator(MakeUnique<FilePersistentMemoryAllocator>(
           std::move(mmfile), size, id, name, false))));
+  Get()->SetPersistentLocation(file_path);
+  return true;
 }
-#endif
+
+// static
+bool GlobalHistogramAllocator::CreateWithActiveFile(const FilePath& base_path,
+                                                    const FilePath& active_path,
+                                                    size_t size,
+                                                    uint64_t id,
+                                                    StringPiece name) {
+  if (!base::ReplaceFile(active_path, base_path, nullptr))
+    base::DeleteFile(base_path, /*recursive=*/false);
+
+  return base::GlobalHistogramAllocator::CreateWithFile(active_path, size, id,
+                                                        name);
+}
+
+// static
+bool GlobalHistogramAllocator::CreateWithActiveFileInDir(const FilePath& dir,
+                                                         size_t size,
+                                                         uint64_t id,
+                                                         StringPiece name) {
+  FilePath base_path, active_path;
+  ConstructFilePaths(dir, name, &base_path, &active_path);
+  return CreateWithActiveFile(base_path, active_path, size, id, name);
+}
+
+// static
+void GlobalHistogramAllocator::ConstructFilePaths(const FilePath& dir,
+                                                  StringPiece name,
+                                                  FilePath* out_base_path,
+                                                  FilePath* out_active_path) {
+  if (out_base_path) {
+    *out_base_path = dir.AppendASCII(name).AddExtension(
+        PersistentMemoryAllocator::kFileExtension);
+  }
+  if (out_active_path) {
+    *out_active_path =
+        dir.AppendASCII(name.as_string() + std::string("-active"))
+            .AddExtension(PersistentMemoryAllocator::kFileExtension);
+  }
+}
+#endif  // !defined(OS_NACL)
 
 // static
 void GlobalHistogramAllocator::CreateWithSharedMemory(
@@ -846,10 +906,30 @@ bool GlobalHistogramAllocator::WriteToPersistentLocation() {
 #endif
 }
 
+void GlobalHistogramAllocator::DeletePersistentLocation() {
+#if defined(OS_NACL)
+  NOTREACHED();
+#else
+  if (persistent_location_.empty())
+    return;
+
+  // Open (with delete) and then immediately close the file by going out of
+  // scope. This is the only cross-platform safe way to delete a file that may
+  // be open elsewhere. Open handles will continue to operate normally but
+  // new opens will not be possible.
+  File file(persistent_location_,
+            File::FLAG_OPEN | File::FLAG_READ | File::FLAG_DELETE_ON_CLOSE);
+#endif
+}
+
 GlobalHistogramAllocator::GlobalHistogramAllocator(
     std::unique_ptr<PersistentMemoryAllocator> memory)
     : PersistentHistogramAllocator(std::move(memory)),
-      import_iterator_(this) {}
+      import_iterator_(this) {
+  // Make sure the StatisticsRecorder is initialized to prevent duplicate
+  // histograms from being created. It's safe to call this multiple times.
+  StatisticsRecorder::Initialize();
+}
 
 void GlobalHistogramAllocator::ImportHistogramsToStatisticsRecorder() {
   // Skip the import if it's the histogram that was last created. Should a
diff --git a/src/base/metrics/persistent_histogram_allocator.h b/src/base/metrics/persistent_histogram_allocator.h
index aa712ec..6857984 100644
--- a/src/base/metrics/persistent_histogram_allocator.h
+++ b/src/base/metrics/persistent_histogram_allocator.h
@@ -21,6 +21,7 @@
 
 namespace base {
 
+class BucketRanges;
 class FilePath;
 class PersistentSampleMapRecords;
 class PersistentSparseHistogramDataManager;
@@ -396,11 +397,40 @@ class BASE_EXPORT GlobalHistogramAllocator
   // Create a global allocator by memory-mapping a |file|. If the file does
   // not exist, it will be created with the specified |size|. If the file does
   // exist, the allocator will use and add to its contents, ignoring the passed
-  // size in favor of the existing size.
-  static void CreateWithFile(const FilePath& file_path,
+  // size in favor of the existing size. Returns whether the global allocator
+  // was set.
+  static bool CreateWithFile(const FilePath& file_path,
                              size_t size,
                              uint64_t id,
                              StringPiece name);
+
+  // Creates a new file at |active_path|. If it already exists, it will first be
+  // moved to |base_path|. In all cases, any old file at |base_path| will be
+  // removed. The file will be created using the given size, id, and name.
+  // Returns whether the global allocator was set.
+  static bool CreateWithActiveFile(const FilePath& base_path,
+                                   const FilePath& active_path,
+                                   size_t size,
+                                   uint64_t id,
+                                   StringPiece name);
+
+  // Uses ConstructBaseActivePairFilePaths() to build a pair of file names which
+  // are then used for CreateWithActiveFile(). |name| is used for both the
+  // internal name for the allocator and also for the name of the file inside
+  // |dir|.
+  static bool CreateWithActiveFileInDir(const FilePath& dir,
+                                        size_t size,
+                                        uint64_t id,
+                                        StringPiece name);
+
+  // Constructs a pair of names in |dir| based on name that can be used for a
+  // base + active persistent memory mapped location for CreateWithActiveFile().
+  // |name| will be used as the basename of the file inside |dir|.
+  // |out_base_path| or |out_active_path| may be null if not needed.
+  static void ConstructFilePaths(const FilePath& dir,
+                                 StringPiece name,
+                                 FilePath* out_base_path,
+                                 FilePath* out_active_path);
 #endif
 
 #if 0
@@ -453,6 +483,10 @@ class BASE_EXPORT GlobalHistogramAllocator
   // indicates success.
   bool WriteToPersistentLocation();
 
+  // If there is a global metrics file being updated on disk, mark it to be
+  // deleted when the process exits.
+  void DeletePersistentLocation();
+
  private:
   friend class StatisticsRecorder;
 
diff --git a/src/base/metrics/persistent_memory_allocator.cc b/src/base/metrics/persistent_memory_allocator.cc
index dfa408f..4e6b7ef 100644
--- a/src/base/metrics/persistent_memory_allocator.cc
+++ b/src/base/metrics/persistent_memory_allocator.cc
@@ -17,6 +17,7 @@
 #include "base/logging.h"
 #include "base/memory/shared_memory.h"
 #include "base/metrics/histogram_macros.h"
+#include "base/metrics/sparse_histogram.h"
 
 namespace {
 
@@ -132,7 +133,19 @@ PersistentMemoryAllocator::Iterator::Iterator(
 PersistentMemoryAllocator::Iterator::Iterator(
     const PersistentMemoryAllocator* allocator,
     Reference starting_after)
-    : allocator_(allocator), last_record_(starting_after), record_count_(0) {
+    : allocator_(allocator), last_record_(0), record_count_(0) {
+  Reset(starting_after);
+}
+
+void PersistentMemoryAllocator::Iterator::Reset() {
+  last_record_.store(kReferenceQueue, std::memory_order_relaxed);
+  record_count_.store(0, std::memory_order_relaxed);
+}
+
+void PersistentMemoryAllocator::Iterator::Reset(Reference starting_after) {
+  last_record_.store(starting_after, std::memory_order_relaxed);
+  record_count_.store(0, std::memory_order_relaxed);
+
   // Ensure that the starting point is a valid, iterable block (meaning it can
   // be read and has a non-zero "next" pointer).
   const volatile BlockHeader* block =
@@ -144,6 +157,14 @@ PersistentMemoryAllocator::Iterator::Iterator(
 }
 
 PersistentMemoryAllocator::Reference
+PersistentMemoryAllocator::Iterator::GetLast() {
+  Reference last = last_record_.load(std::memory_order_relaxed);
+  if (last == kReferenceQueue)
+    return kReferenceNull;
+  return last;
+}
+
+PersistentMemoryAllocator::Reference
 PersistentMemoryAllocator::Iterator::GetNext(uint32_t* type_return) {
   // Make a copy of the existing count of found-records, acquiring all changes
   // made to the allocator, notably "freeptr" (see comment in loop for why
@@ -247,20 +268,41 @@ bool PersistentMemoryAllocator::IsMemoryAcceptable(const void* base,
           (page_size == 0 || size % page_size == 0 || readonly));
 }
 
-PersistentMemoryAllocator::PersistentMemoryAllocator(
-    void* base,
-    size_t size,
-    size_t page_size,
-    uint64_t id,
-    base::StringPiece name,
-    bool readonly)
-    : mem_base_(static_cast<char*>(base)),
+PersistentMemoryAllocator::PersistentMemoryAllocator(void* base,
+                                                     size_t size,
+                                                     size_t page_size,
+                                                     uint64_t id,
+                                                     base::StringPiece name,
+                                                     bool readonly)
+    : PersistentMemoryAllocator(Memory(base, MEM_EXTERNAL),
+                                size,
+                                page_size,
+                                id,
+                                name,
+                                readonly) {}
+
+PersistentMemoryAllocator::PersistentMemoryAllocator(Memory memory,
+                                                     size_t size,
+                                                     size_t page_size,
+                                                     uint64_t id,
+                                                     base::StringPiece name,
+                                                     bool readonly)
+    : mem_base_(static_cast<char*>(memory.base)),
+      mem_type_(memory.type),
       mem_size_(static_cast<uint32_t>(size)),
       mem_page_(static_cast<uint32_t>((page_size ? page_size : size))),
       readonly_(readonly),
       corrupt_(0),
       allocs_histogram_(nullptr),
       used_histogram_(nullptr) {
+  // These asserts ensure that the structures are 32/64-bit agnostic and meet
+  // all the requirements of use within the allocator. They access private
+  // definitions and so cannot be moved to the global scope.
+  static_assert(sizeof(PersistentMemoryAllocator::BlockHeader) == 16,
+                "struct is not portable across different natural word widths");
+  static_assert(sizeof(PersistentMemoryAllocator::SharedMetadata) == 56,
+                "struct is not portable across different natural word widths");
+
   static_assert(sizeof(BlockHeader) % kAllocAlignment == 0,
                 "BlockHeader is not a multiple of kAllocAlignment");
   static_assert(sizeof(SharedMetadata) % kAllocAlignment == 0,
@@ -269,7 +311,7 @@ PersistentMemoryAllocator::PersistentMemoryAllocator(
                 "\"queue\" is not aligned properly; must be at end of struct");
 
   // Ensure that memory segment is of acceptable size.
-  CHECK(IsMemoryAcceptable(base, size, page_size, readonly));
+  CHECK(IsMemoryAcceptable(memory.base, size, page_size, readonly));
 
   // These atomics operate inter-process and so must be lock-free. The local
   // casts are to make sure it can be evaluated at compile time to a constant.
@@ -326,7 +368,7 @@ PersistentMemoryAllocator::PersistentMemoryAllocator(
     if (!name.empty()) {
       const size_t name_length = name.length() + 1;
       shared_meta()->name = Allocate(name_length, 0);
-      char* name_cstr = GetAsObject<char>(shared_meta()->name, 0);
+      char* name_cstr = GetAsArray<char>(shared_meta()->name, 0, name_length);
       if (name_cstr)
         memcpy(name_cstr, name.data(), name.length());
     }
@@ -355,7 +397,7 @@ PersistentMemoryAllocator::PersistentMemoryAllocator(
         *const_cast<uint32_t*>(&mem_page_) = shared_meta()->page_size;
 
       // Ensure that settings are still valid after the above adjustments.
-      if (!IsMemoryAcceptable(base, mem_size_, mem_page_, readonly))
+      if (!IsMemoryAcceptable(memory.base, mem_size_, mem_page_, readonly))
         SetCorrupt();
     }
   }
@@ -374,7 +416,8 @@ uint64_t PersistentMemoryAllocator::Id() const {
 
 const char* PersistentMemoryAllocator::Name() const {
   Reference name_ref = shared_meta()->name;
-  const char* name_cstr = GetAsObject<char>(name_ref, 0);
+  const char* name_cstr =
+      GetAsArray<char>(name_ref, 0, PersistentMemoryAllocator::kSizeAny);
   if (!name_cstr)
     return "";
 
@@ -410,6 +453,24 @@ size_t PersistentMemoryAllocator::used() const {
                   mem_size_);
 }
 
+PersistentMemoryAllocator::Reference PersistentMemoryAllocator::GetAsReference(
+    const void* memory,
+    uint32_t type_id) const {
+  uintptr_t address = reinterpret_cast<uintptr_t>(memory);
+  if (address < reinterpret_cast<uintptr_t>(mem_base_))
+    return kReferenceNull;
+
+  uintptr_t offset = address - reinterpret_cast<uintptr_t>(mem_base_);
+  if (offset >= mem_size_ || offset < sizeof(BlockHeader))
+    return kReferenceNull;
+
+  Reference ref = static_cast<Reference>(offset) - sizeof(BlockHeader);
+  if (!GetBlockData(ref, type_id, kSizeAny))
+    return kReferenceNull;
+
+  return ref;
+}
+
 size_t PersistentMemoryAllocator::GetAllocSize(Reference ref) const {
   const volatile BlockHeader* const block = GetBlock(ref, 0, 0, false, false);
   if (!block)
@@ -739,37 +800,60 @@ LocalPersistentMemoryAllocator::LocalPersistentMemoryAllocator(
                                 size, 0, id, name, false) {}
 
 LocalPersistentMemoryAllocator::~LocalPersistentMemoryAllocator() {
-  DeallocateLocalMemory(const_cast<char*>(mem_base_), mem_size_);
+  DeallocateLocalMemory(const_cast<char*>(mem_base_), mem_size_, mem_type_);
 }
 
 // static
-void* LocalPersistentMemoryAllocator::AllocateLocalMemory(size_t size) {
+PersistentMemoryAllocator::Memory
+LocalPersistentMemoryAllocator::AllocateLocalMemory(size_t size) {
+  void* address;
+
 #if defined(OS_WIN)
-  void* address =
+  address =
       ::VirtualAlloc(nullptr, size, MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE);
-  DPCHECK(address);
-  return address;
+  if (address)
+    return Memory(address, MEM_VIRTUAL);
+  UMA_HISTOGRAM_SPARSE_SLOWLY("UMA.LocalPersistentMemoryAllocator.Failures.Win",
+                              ::GetLastError());
 #elif defined(OS_POSIX)
   // MAP_ANON is deprecated on Linux but MAP_ANONYMOUS is not universal on Mac.
   // MAP_SHARED is not available on Linux <2.4 but required on Mac.
-  void* address = ::mmap(nullptr, size, PROT_READ | PROT_WRITE,
-                         MAP_ANON | MAP_SHARED, -1, 0);
-  DPCHECK(MAP_FAILED != address);
-  return address;
+  address = ::mmap(nullptr, size, PROT_READ | PROT_WRITE,
+                   MAP_ANON | MAP_SHARED, -1, 0);
+  if (address != MAP_FAILED)
+    return Memory(address, MEM_VIRTUAL);
+  UMA_HISTOGRAM_SPARSE_SLOWLY(
+      "UMA.LocalPersistentMemoryAllocator.Failures.Posix", errno);
 #else
 #error This architecture is not (yet) supported.
 #endif
+
+  // As a last resort, just allocate the memory from the heap. This will
+  // achieve the same basic result but the acquired memory has to be
+  // explicitly zeroed and thus realized immediately (i.e. all pages are
+  // added to the process now istead of only when first accessed).
+  address = malloc(size);
+  DPCHECK(address);
+  memset(address, 0, size);
+  return Memory(address, MEM_MALLOC);
 }
 
 // static
 void LocalPersistentMemoryAllocator::DeallocateLocalMemory(void* memory,
-                                                           size_t size) {
+                                                           size_t size,
+                                                           MemoryType type) {
+  if (type == MEM_MALLOC) {
+    free(memory);
+    return;
+  }
+
+  DCHECK_EQ(MEM_VIRTUAL, type);
 #if defined(OS_WIN)
   BOOL success = ::VirtualFree(memory, 0, MEM_DECOMMIT);
-  DPCHECK(success);
+  DCHECK(success);
 #elif defined(OS_POSIX)
   int result = ::munmap(memory, size);
-  DPCHECK(0 == result);
+  DCHECK_EQ(0, result);
 #else
 #error This architecture is not (yet) supported.
 #endif
@@ -783,12 +867,13 @@ SharedPersistentMemoryAllocator::SharedPersistentMemoryAllocator(
     uint64_t id,
     base::StringPiece name,
     bool read_only)
-    : PersistentMemoryAllocator(static_cast<uint8_t*>(memory->memory()),
-                                memory->mapped_size(),
-                                0,
-                                id,
-                                name,
-                                read_only),
+    : PersistentMemoryAllocator(
+          Memory(static_cast<uint8_t*>(memory->memory()), MEM_SHARED),
+          memory->mapped_size(),
+          0,
+          id,
+          name,
+          read_only),
       shared_memory_(std::move(memory)) {}
 
 SharedPersistentMemoryAllocator::~SharedPersistentMemoryAllocator() {}
@@ -809,12 +894,13 @@ FilePersistentMemoryAllocator::FilePersistentMemoryAllocator(
     uint64_t id,
     base::StringPiece name,
     bool read_only)
-    : PersistentMemoryAllocator(const_cast<uint8_t*>(file->data()),
-                                max_size != 0 ? max_size : file->length(),
-                                0,
-                                id,
-                                name,
-                                read_only),
+    : PersistentMemoryAllocator(
+          Memory(const_cast<uint8_t*>(file->data()), MEM_FILE),
+          max_size != 0 ? max_size : file->length(),
+          0,
+          id,
+          name,
+          read_only),
       mapped_file_(std::move(file)) {}
 
 FilePersistentMemoryAllocator::~FilePersistentMemoryAllocator() {}
diff --git a/src/base/metrics/persistent_memory_allocator.h b/src/base/metrics/persistent_memory_allocator.h
index 2fc0d2d..ab9dd9d 100644
--- a/src/base/metrics/persistent_memory_allocator.h
+++ b/src/base/metrics/persistent_memory_allocator.h
@@ -9,6 +9,7 @@
 
 #include <atomic>
 #include <memory>
+#include <type_traits>
 
 #include "base/atomicops.h"
 #include "base/base_export.h"
@@ -47,6 +48,15 @@ class SharedMemory;
 // Note that memory not in active use is not accessed so it is possible to
 // use virtual memory, including memory-mapped files, as backing storage with
 // the OS "pinning" new (zeroed) physical RAM pages only as they are needed.
+//
+// All persistent memory segments can be freely accessed by builds of different
+// natural word widths (i.e. 32/64-bit) but users of this module must manually
+// ensure that the data recorded within are similarly safe. The GetAsObject<>()
+// methods use the kExpectedInstanceSize attribute of the structs to check this.
+//
+// Memory segments can NOT, however, be exchanged between CPUs of different
+// endianess. Attempts to do so will simply see the existing data as corrupt
+// and refuse to access any of it.
 class BASE_EXPORT PersistentMemoryAllocator {
  public:
   typedef uint32_t Reference;
@@ -56,6 +66,11 @@ class BASE_EXPORT PersistentMemoryAllocator {
   // That means that multiple threads can share an iterator and the same
   // reference will not be returned twice.
   //
+  // The order of the items returned by an iterator matches the order in which
+  // MakeIterable() was called on them. Once an allocation is made iterable,
+  // it is always such so the only possible difference between successive
+  // iterations is for more to be added to the end.
+  //
   // Iteration, in general, is tolerant of corrupted memory. It will return
   // what it can and stop only when corruption forces it to. Bad corruption
   // could cause the same object to be returned many times but it will
@@ -76,6 +91,17 @@ class BASE_EXPORT PersistentMemoryAllocator {
     Iterator(const PersistentMemoryAllocator* allocator,
              Reference starting_after);
 
+    // Resets the iterator back to the beginning.
+    void Reset();
+
+    // Resets the iterator, resuming from the |starting_after| reference.
+    void Reset(Reference starting_after);
+
+    // Returns the previously retrieved reference, or kReferenceNull if none.
+    // If constructor or reset with a starting_after location, this will return
+    // that value.
+    Reference GetLast();
+
     // Gets the next iterable, storing that type in |type_return|. The actual
     // return value is a reference to the allocation inside the allocator or
     // zero if there are no more. GetNext() may still be called again at a
@@ -100,6 +126,12 @@ class BASE_EXPORT PersistentMemoryAllocator {
       return allocator_->GetAsObject<T>(ref, type_id);
     }
 
+    // Similar to GetAsObject() but converts references to arrays of objects.
+    template <typename T>
+    const T* GetAsArray(Reference ref, uint32_t type_id, size_t count) const {
+      return allocator_->GetAsArray<T>(ref, type_id, count);
+    }
+
    private:
     // Weak-pointer to memory allocator being iterated over.
     const PersistentMemoryAllocator* allocator_;
@@ -127,6 +159,10 @@ class BASE_EXPORT PersistentMemoryAllocator {
     kTypeIdAny = 0  // Match any type-id inside GetAsObject().
   };
 
+  enum : size_t {
+    kSizeAny = 1  // Constant indicating that any array size is acceptable.
+  };
+
   // This is the standard file extension (suitable for being passed to the
   // AddExtension() method of base::FilePath) for dumps of persistent memory.
   static const base::FilePath::CharType kFileExtension[];
@@ -208,6 +244,27 @@ class BASE_EXPORT PersistentMemoryAllocator {
   // TIME before accessing it or risk crashing! Once dereferenced, the pointer
   // is safe to reuse forever.
   //
+  // It is essential that the object be of a fixed size. All fields must be of
+  // a defined type that does not change based on the compiler or the CPU
+  // natural word size. Acceptable are char, float, double, and (u)intXX_t.
+  // Unacceptable are int, bool, and wchar_t which are implementation defined
+  // with regards to their size.
+  //
+  // Alignment must also be consistent. A uint64_t after a uint32_t will pad
+  // differently between 32 and 64 bit architectures. Either put the bigger
+  // elements first, group smaller elements into blocks the size of larger
+  // elements, or manually insert padding fields as appropriate for the
+  // largest architecture, including at the end.
+  //
+  // To protected against mistakes, all objects must have the attribute
+  // |kExpectedInstanceSize| (static constexpr size_t)  that is a hard-coded
+  // numerical value -- NNN, not sizeof(T) -- that can be tested. If the
+  // instance size is not fixed, at least one build will fail.
+  //
+  // If the size of a structure changes, the type-ID used to recognize it
+  // should also change so later versions of the code don't try to read
+  // incompatible structures from earlier versions.
+  //
   // NOTE: Though this method will guarantee that an object of the specified
   // type can be accessed without going outside the bounds of the memory
   // segment, it makes no guarantees of the validity of the data within the
@@ -221,18 +278,49 @@ class BASE_EXPORT PersistentMemoryAllocator {
   // based on knowledge of how the allocator is being used.
   template <typename T>
   T* GetAsObject(Reference ref, uint32_t type_id) {
-    static_assert(!std::is_polymorphic<T>::value, "no polymorphic objects");
+    static_assert(std::is_pod<T>::value, "only simple objects");
+    static_assert(T::kExpectedInstanceSize == sizeof(T), "inconsistent size");
     return const_cast<T*>(
         reinterpret_cast<volatile T*>(GetBlockData(ref, type_id, sizeof(T))));
   }
   template <typename T>
   const T* GetAsObject(Reference ref, uint32_t type_id) const {
-    static_assert(!std::is_polymorphic<T>::value, "no polymorphic objects");
+    static_assert(std::is_pod<T>::value, "only simple objects");
+    static_assert(T::kExpectedInstanceSize == sizeof(T), "inconsistent size");
     return const_cast<const T*>(
         reinterpret_cast<const volatile T*>(GetBlockData(
             ref, type_id, sizeof(T))));
   }
 
+  // Like GetAsObject but get an array of simple, fixed-size types.
+  //
+  // Use a |count| of the required number of array elements, or kSizeAny.
+  // GetAllocSize() can be used to calculate the upper bound but isn't reliable
+  // because padding can make space for extra elements that were not written.
+  //
+  // Remember that an array of char is a string but may not be NUL terminated.
+  //
+  // There are no compile-time or run-time checks to ensure 32/64-bit size
+  // compatibilty when using these accessors. Only use fixed-size types such
+  // as char, float, double, or (u)intXX_t.
+  template <typename T>
+  T* GetAsArray(Reference ref, uint32_t type_id, size_t count) {
+    static_assert(std::is_fundamental<T>::value, "use GetAsObject<>()");
+    return const_cast<T*>(reinterpret_cast<volatile T*>(
+        GetBlockData(ref, type_id, count * sizeof(T))));
+  }
+  template <typename T>
+  const T* GetAsArray(Reference ref, uint32_t type_id, size_t count) const {
+    static_assert(std::is_fundamental<T>::value, "use GetAsObject<>()");
+    return const_cast<const char*>(reinterpret_cast<const volatile T*>(
+        GetBlockData(ref, type_id, count * sizeof(T))));
+  }
+
+  // Get the corresponding reference for an object held in persistent memory.
+  // If the |memory| is not valid or the type does not match, a kReferenceNull
+  // result will be returned.
+  Reference GetAsReference(const void* memory, uint32_t type_id) const;
+
   // Get the number of bytes allocated to a block. This is useful when storing
   // arrays in order to validate the ending boundary. The returned value will
   // include any padding added to achieve the required alignment and so could
@@ -287,7 +375,30 @@ class BASE_EXPORT PersistentMemoryAllocator {
   void UpdateTrackingHistograms();
 
  protected:
+  enum MemoryType {
+    MEM_EXTERNAL,
+    MEM_MALLOC,
+    MEM_VIRTUAL,
+    MEM_SHARED,
+    MEM_FILE,
+  };
+
+  struct Memory {
+    Memory(void* b, MemoryType t) : base(b), type(t) {}
+
+    void* base;
+    MemoryType type;
+  };
+
+  // Constructs the allocator. Everything is the same as the public allocator
+  // except |memory| which is a structure with additional information besides
+  // the base address.
+  PersistentMemoryAllocator(Memory memory, size_t size, size_t page_size,
+                            uint64_t id, base::StringPiece name,
+                            bool readonly);
+
   volatile char* const mem_base_;  // Memory base. (char so sizeof guaranteed 1)
+  const MemoryType mem_type_;      // Type of memory allocation.
   const uint32_t mem_size_;        // Size of entire memory segment.
   const uint32_t mem_page_;        // Page size allocations shouldn't cross.
 
@@ -359,10 +470,10 @@ class BASE_EXPORT LocalPersistentMemoryAllocator
   // Allocates a block of local memory of the specified |size|, ensuring that
   // the memory will not be physically allocated until accessed and will read
   // as zero when that happens.
-  static void* AllocateLocalMemory(size_t size);
+  static Memory AllocateLocalMemory(size_t size);
 
   // Deallocates a block of local |memory| of the specified |size|.
-  static void DeallocateLocalMemory(void* memory, size_t size);
+  static void DeallocateLocalMemory(void* memory, size_t size, MemoryType type);
 
   DISALLOW_COPY_AND_ASSIGN(LocalPersistentMemoryAllocator);
 };
@@ -382,7 +493,7 @@ class BASE_EXPORT SharedPersistentMemoryAllocator
 
   SharedMemory* shared_memory() { return shared_memory_.get(); }
 
-  // Ensure that the memory isn't so invalid that it won't crash when passing it
+  // Ensure that the memory isn't so invalid that it would crash when passing it
   // to the allocator. This doesn't guarantee the data is valid, just that it
   // won't cause the program to abort. The existing IsCorrupt() call will handle
   // the rest.
@@ -411,7 +522,7 @@ class BASE_EXPORT FilePersistentMemoryAllocator
                                 bool read_only);
   ~FilePersistentMemoryAllocator() override;
 
-  // Ensure that the file isn't so invalid that it won't crash when passing it
+  // Ensure that the file isn't so invalid that it would crash when passing it
   // to the allocator. This doesn't guarantee the file is valid, just that it
   // won't cause the program to abort. The existing IsCorrupt() call will handle
   // the rest.
diff --git a/src/base/metrics/persistent_sample_map.cc b/src/base/metrics/persistent_sample_map.cc
index 15f83cd..e6a0879 100644
--- a/src/base/metrics/persistent_sample_map.cc
+++ b/src/base/metrics/persistent_sample_map.cc
@@ -82,6 +82,9 @@ void PersistentSampleMapIterator::SkipEmptyBuckets() {
 // memory allocator. The "id" must be unique across all maps held by an
 // allocator or they will get attached to the wrong sample map.
 struct SampleRecord {
+  // Expected size for 32/64-bit check.
+  static constexpr size_t kExpectedInstanceSize = 16;
+
   uint64_t id;   // Unique identifier of owner.
   Sample value;  // The value for which this record holds a count.
   Count count;   // The count associated with the above value.
diff --git a/src/base/metrics/persistent_sample_map.h b/src/base/metrics/persistent_sample_map.h
index 3c175db..853f862 100644
--- a/src/base/metrics/persistent_sample_map.h
+++ b/src/base/metrics/persistent_sample_map.h
@@ -24,7 +24,6 @@ namespace base {
 
 class PersistentHistogramAllocator;
 class PersistentSampleMapRecords;
-class PersistentSparseHistogramDataManager;
 
 // The logic here is similar to that of SampleMap but with different data
 // structures. Changes here likely need to be duplicated there.
diff --git a/src/base/metrics/sparse_histogram.cc b/src/base/metrics/sparse_histogram.cc
index deba570..415d7f9 100644
--- a/src/base/metrics/sparse_histogram.cc
+++ b/src/base/metrics/sparse_histogram.cc
@@ -68,7 +68,7 @@ HistogramBase* SparseHistogram::FactoryGet(const std::string& name,
     ReportHistogramActivity(*histogram, HISTOGRAM_LOOKUP);
   }
 
-  DCHECK_EQ(SPARSE_HISTOGRAM, histogram->GetHistogramType());
+  CHECK_EQ(SPARSE_HISTOGRAM, histogram->GetHistogramType());
   return histogram;
 }
 
@@ -282,8 +282,8 @@ void SparseHistogram::WriteAsciiHeader(const Count total_count,
                 "Histogram: %s recorded %d samples",
                 histogram_name().c_str(),
                 total_count);
-  if (flags() & ~kHexRangePrintingFlag)
-    StringAppendF(output, " (flags = 0x%x)", flags() & ~kHexRangePrintingFlag);
+  if (flags())
+    StringAppendF(output, " (flags = 0x%x)", flags());
 }
 
 }  // namespace base
diff --git a/src/base/metrics/sparse_histogram.h b/src/base/metrics/sparse_histogram.h
index 3b302d6..97709ba 100644
--- a/src/base/metrics/sparse_histogram.h
+++ b/src/base/metrics/sparse_histogram.h
@@ -13,45 +13,17 @@
 #include <string>
 
 #include "base/base_export.h"
-#include "base/compiler_specific.h"
-#include "base/logging.h"
 #include "base/macros.h"
 #include "base/metrics/histogram_base.h"
-#include "base/metrics/sample_map.h"
+#include "base/metrics/histogram_samples.h"
 #include "base/synchronization/lock.h"
 
 namespace base {
 
-// Sparse histograms are well suited for recording counts of exact sample values
-// that are sparsely distributed over a large range.
-//
-// The implementation uses a lock and a map, whereas other histogram types use a
-// vector and no lock. It is thus more costly to add values to, and each value
-// stored has more overhead, compared to the other histogram types. However it
-// may be more efficient in memory if the total number of sample values is small
-// compared to the range of their values.
-//
-// UMA_HISTOGRAM_ENUMERATION would be better suited for a smaller range of
-// enumerations that are (nearly) contiguous. Also for code that is expected to
-// run often or in a tight loop.
-//
-// UMA_HISTOGRAM_SPARSE_SLOWLY is good for sparsely distributed and or
-// infrequently recorded values.
-//
-// For instance, Sqlite.Version.* are SPARSE because for any given database,
-// there's going to be exactly one version logged, meaning no gain to having a
-// pre-allocated vector of slots once the fleet gets to version 4 or 5 or 10.
-// Likewise Sqlite.Error.* are SPARSE, because most databases generate few or no
-// errors and there are large gaps in the set of possible errors.
-#define UMA_HISTOGRAM_SPARSE_SLOWLY(name, sample) \
-    do { \
-      base::HistogramBase* histogram = base::SparseHistogram::FactoryGet( \
-          name, base::HistogramBase::kUmaTargetedHistogramFlag); \
-      histogram->Add(sample); \
-    } while (0)
-
 class HistogramSamples;
 class PersistentHistogramAllocator;
+class Pickle;
+class PickleIterator;
 
 class BASE_EXPORT SparseHistogram : public HistogramBase {
  public:
diff --git a/src/base/metrics/statistics_recorder.cc b/src/base/metrics/statistics_recorder.cc
index a53f8f2..6b1b0bf 100644
--- a/src/base/metrics/statistics_recorder.cc
+++ b/src/base/metrics/statistics_recorder.cc
@@ -93,6 +93,17 @@ StatisticsRecorder::~StatisticsRecorder() {
 
 // static
 void StatisticsRecorder::Initialize() {
+  // Tests sometimes create local StatisticsRecorders in order to provide a
+  // contained environment of histograms that can be later discarded. If a
+  // true global instance gets created in this environment then it will
+  // eventually get disconnected when the local instance destructs and
+  // restores the previous state, resulting in no StatisticsRecorder at all.
+  // The global lazy instance, however, will remain valid thus ensuring that
+  // another never gets installed via this method. If a |histograms_| map
+  // exists then assume the StatisticsRecorder is already "initialized".
+  if (histograms_)
+    return;
+
   // Ensure that an instance of the StatisticsRecorder object is created.
   g_statistics_recorder_.Get();
 }
diff --git a/src/base/metrics/statistics_recorder.h b/src/base/metrics/statistics_recorder.h
index c3c6ace..b4dae87 100644
--- a/src/base/metrics/statistics_recorder.h
+++ b/src/base/metrics/statistics_recorder.h
@@ -26,8 +26,6 @@
 #include "base/metrics/histogram_base.h"
 #include "base/strings/string_piece.h"
 
-class SubprocessMetricsProviderTest;
-
 namespace base {
 
 class BucketRanges;
diff --git a/src/base/numerics/safe_conversions.h b/src/base/numerics/safe_conversions.h
index 6b558af..6e04b46 100644
--- a/src/base/numerics/safe_conversions.h
+++ b/src/base/numerics/safe_conversions.h
@@ -8,13 +8,42 @@
 #include <stddef.h>
 
 #include <limits>
+#include <ostream>
 #include <type_traits>
 
-#include "base/logging.h"
 #include "base/numerics/safe_conversions_impl.h"
 
 namespace base {
 
+// The following are helper constexpr template functions and classes for safely
+// performing a range of conversions, assignments, and tests:
+//
+//  checked_cast<> - Analogous to static_cast<> for numeric types, except
+//      that it CHECKs that the specified numeric conversion will not overflow
+//      or underflow. NaN source will always trigger a CHECK.
+//      The default CHECK triggers a crash, but the handler can be overriden.
+//  saturated_cast<> - Analogous to static_cast<> for numeric types, except
+//      that it returns a saturated result when the specified numeric conversion
+//      would otherwise overflow or underflow. An NaN source returns 0 by
+//      default, but can be overridden to return a different result.
+//  strict_cast<> - Analogous to static_cast<> for numeric types, except that
+//      it will cause a compile failure if the destination type is not large
+//      enough to contain any value in the source type. It performs no runtime
+//      checking and thus introduces no runtime overhead.
+//  IsValueInRangeForNumericType<>() - A convenience function that returns true
+//      if the type supplied to the template parameter can represent the value
+//      passed as an argument to the function.
+//  IsValueNegative<>() - A convenience function that will accept any arithmetic
+//      type as an argument and will return whether the value is less than zero.
+//      Unsigned types always return false.
+//  StrictNumeric<> - A wrapper type that performs assignments and copies via
+//      the strict_cast<> template, and can perform valid arithmetic comparisons
+//      across any range of arithmetic types. StrictNumeric is the return type
+//      for values extracted from a CheckedNumeric class instance. The raw
+//      arithmetic value is extracted via static_cast to the underlying type.
+//  MakeStrictNum() - Creates a new StrictNumeric from the underlying type of
+//      the supplied arithmetic or StrictNumeric type.
+
 // Convenience function that returns true if the supplied value is in range
 // for the destination type.
 template <typename Dst, typename Src>
@@ -25,65 +54,92 @@ constexpr bool IsValueInRangeForNumericType(Src value) {
 
 // Convenience function for determining if a numeric value is negative without
 // throwing compiler warnings on: unsigned(value) < 0.
-template <typename T>
-constexpr typename std::enable_if<std::numeric_limits<T>::is_signed, bool>::type
-IsValueNegative(T value) {
-  static_assert(std::numeric_limits<T>::is_specialized,
-                "Argument must be numeric.");
+template <typename T,
+          typename std::enable_if<std::is_signed<T>::value>::type* = nullptr>
+constexpr bool IsValueNegative(T value) {
+  static_assert(std::is_arithmetic<T>::value, "Argument must be numeric.");
   return value < 0;
 }
 
-template <typename T>
-constexpr typename std::enable_if<!std::numeric_limits<T>::is_signed,
-                                  bool>::type IsValueNegative(T) {
-  static_assert(std::numeric_limits<T>::is_specialized,
-                "Argument must be numeric.");
+template <typename T,
+          typename std::enable_if<!std::is_signed<T>::value>::type* = nullptr>
+constexpr bool IsValueNegative(T) {
+  static_assert(std::is_arithmetic<T>::value, "Argument must be numeric.");
   return false;
 }
 
-// checked_cast<> is analogous to static_cast<> for numeric types,
-// except that it CHECKs that the specified numeric conversion will not
-// overflow or underflow. NaN source will always trigger a CHECK.
-template <typename Dst, typename Src>
-inline Dst checked_cast(Src value) {
-  CHECK(IsValueInRangeForNumericType<Dst>(value));
-  return static_cast<Dst>(value);
-}
-
-// HandleNaN will cause this class to CHECK(false).
-struct SaturatedCastNaNBehaviorCheck {
+// Forces a crash, like a CHECK(false). Used for numeric boundary errors.
+struct CheckOnFailure {
   template <typename T>
-  static T HandleNaN() {
-    CHECK(false);
+  static T HandleFailure() {
+#if defined(__GNUC__) || defined(__clang__)
+    __builtin_trap();
+#else
+    ((void)(*(volatile char*)0 = 0));
+#endif
     return T();
   }
 };
 
+// checked_cast<> is analogous to static_cast<> for numeric types,
+// except that it CHECKs that the specified numeric conversion will not
+// overflow or underflow. NaN source will always trigger a CHECK.
+template <typename Dst,
+          class CheckHandler = CheckOnFailure,
+          typename Src>
+constexpr Dst checked_cast(Src value) {
+  // This throws a compile-time error on evaluating the constexpr if it can be
+  // determined at compile-time as failing, otherwise it will CHECK at runtime.
+  using SrcType = typename internal::UnderlyingType<Src>::type;
+  return IsValueInRangeForNumericType<Dst, SrcType>(value)
+             ? static_cast<Dst>(static_cast<SrcType>(value))
+             : CheckHandler::template HandleFailure<Dst>();
+}
+
 // HandleNaN will return 0 in this case.
 struct SaturatedCastNaNBehaviorReturnZero {
   template <typename T>
-  static constexpr T HandleNaN() {
+  static constexpr T HandleFailure() {
     return T();
   }
 };
 
 namespace internal {
-// This wrapper is used for C++11 constexpr support by avoiding the declaration
-// of local variables in the saturated_cast template function.
-template <typename Dst, class NaNHandler, typename Src>
+// These wrappers are used for C++11 constexpr support by avoiding both the
+// declaration of local variables and invalid evaluation resulting from the
+// lack of "constexpr if" support in the saturated_cast template function.
+// TODO(jschuh): Convert to single function with a switch once we support C++14.
+template <
+    typename Dst,
+    class NaNHandler,
+    typename Src,
+    typename std::enable_if<std::is_integral<Dst>::value>::type* = nullptr>
 constexpr Dst saturated_cast_impl(const Src value,
                                   const RangeConstraint constraint) {
   return constraint == RANGE_VALID
              ? static_cast<Dst>(value)
              : (constraint == RANGE_UNDERFLOW
-                    ? std::numeric_limits<Dst>::min()
+                    ? std::numeric_limits<Dst>::lowest()
                     : (constraint == RANGE_OVERFLOW
                            ? std::numeric_limits<Dst>::max()
-                           : (constraint == RANGE_INVALID
-                                  ? NaNHandler::template HandleNaN<Dst>()
-                                  : (NOTREACHED(), static_cast<Dst>(value)))));
+                           : NaNHandler::template HandleFailure<Dst>()));
+}
+
+template <typename Dst,
+          class NaNHandler,
+          typename Src,
+          typename std::enable_if<std::is_floating_point<Dst>::value>::type* =
+              nullptr>
+constexpr Dst saturated_cast_impl(const Src value,
+                                  const RangeConstraint constraint) {
+  return constraint == RANGE_VALID
+             ? static_cast<Dst>(value)
+             : (constraint == RANGE_UNDERFLOW
+                    ? -std::numeric_limits<Dst>::infinity()
+                    : (constraint == RANGE_OVERFLOW
+                           ? std::numeric_limits<Dst>::infinity()
+                           : std::numeric_limits<Dst>::quiet_NaN()));
 }
-}  // namespace internal
 
 // saturated_cast<> is analogous to static_cast<> for numeric types, except
 // that the specified numeric conversion will saturate rather than overflow or
@@ -93,10 +149,9 @@ template <typename Dst,
           class NaNHandler = SaturatedCastNaNBehaviorReturnZero,
           typename Src>
 constexpr Dst saturated_cast(Src value) {
-  return std::numeric_limits<Dst>::is_iec559
-             ? static_cast<Dst>(value)  // Floating point optimization.
-             : internal::saturated_cast_impl<Dst, NaNHandler>(
-                   value, internal::DstRangeRelationToSrcRange<Dst>(value));
+  using SrcType = typename UnderlyingType<Src>::type;
+  return internal::saturated_cast_impl<Dst, NaNHandler>(
+      value, internal::DstRangeRelationToSrcRange<Dst, SrcType>(value));
 }
 
 // strict_cast<> is analogous to static_cast<> for numeric types, except that
@@ -104,22 +159,40 @@ constexpr Dst saturated_cast(Src value) {
 // to contain any value in the source type. It performs no runtime checking.
 template <typename Dst, typename Src>
 constexpr Dst strict_cast(Src value) {
-  static_assert(std::numeric_limits<Src>::is_specialized,
-                "Argument must be numeric.");
-  static_assert(std::numeric_limits<Dst>::is_specialized,
-                "Result must be numeric.");
-  static_assert((internal::StaticDstRangeRelationToSrcRange<Dst, Src>::value ==
-                 internal::NUMERIC_RANGE_CONTAINED),
-                "The numeric conversion is out of range for this type. You "
-                "should probably use one of the following conversion "
-                "mechanisms on the value you want to pass:\n"
-                "- base::checked_cast\n"
-                "- base::saturated_cast\n"
-                "- base::CheckedNumeric");
-
-  return static_cast<Dst>(value);
+  using SrcType = typename UnderlyingType<Src>::type;
+  static_assert(UnderlyingType<Src>::is_numeric, "Argument must be numeric.");
+  static_assert(std::is_arithmetic<Dst>::value, "Result must be numeric.");
+
+  // If you got here from a compiler error, it's because you tried to assign
+  // from a source type to a destination type that has insufficient range.
+  // The solution may be to change the destination type you're assigning to,
+  // and use one large enough to represent the source.
+  // Alternatively, you may be better served with the checked_cast<> or
+  // saturated_cast<> template functions for your particular use case.
+  static_assert(StaticDstRangeRelationToSrcRange<Dst, SrcType>::value ==
+                    NUMERIC_RANGE_CONTAINED,
+                "The source type is out of range for the destination type. "
+                "Please see strict_cast<> comments for more information.");
+
+  return static_cast<Dst>(static_cast<SrcType>(value));
 }
 
+// Some wrappers to statically check that a type is in range.
+template <typename Dst, typename Src, class Enable = void>
+struct IsNumericRangeContained {
+  static const bool value = false;
+};
+
+template <typename Dst, typename Src>
+struct IsNumericRangeContained<
+    Dst,
+    Src,
+    typename std::enable_if<ArithmeticOrUnderlyingEnum<Dst>::value &&
+                            ArithmeticOrUnderlyingEnum<Src>::value>::type> {
+  static const bool value = StaticDstRangeRelationToSrcRange<Dst, Src>::value ==
+                            NUMERIC_RANGE_CONTAINED;
+};
+
 // StrictNumeric implements compile time range checking between numeric types by
 // wrapping assignment operations in a strict_cast. This class is intended to be
 // used for function arguments and return types, to ensure the destination type
@@ -133,7 +206,7 @@ constexpr Dst strict_cast(Src value) {
 template <typename T>
 class StrictNumeric {
  public:
-  typedef T type;
+  using type = T;
 
   constexpr StrictNumeric() : value_(0) {}
 
@@ -145,21 +218,72 @@ class StrictNumeric {
   // This is not an explicit constructor because we implicitly upgrade regular
   // numerics to StrictNumerics to make them easier to use.
   template <typename Src>
-  constexpr StrictNumeric(Src value)
+  constexpr StrictNumeric(Src value)  // NOLINT(runtime/explicit)
       : value_(strict_cast<T>(value)) {}
 
-  // The numeric cast operator basically handles all the magic.
-  template <typename Dst>
+  // If you got here from a compiler error, it's because you tried to assign
+  // from a source type to a destination type that has insufficient range.
+  // The solution may be to change the destination type you're assigning to,
+  // and use one large enough to represent the source.
+  // If you're assigning from a CheckedNumeric<> class, you may be able to use
+  // the AssignIfValid() member function, specify a narrower destination type to
+  // the member value functions (e.g. val.template ValueOrDie<Dst>()), use one
+  // of the value helper functions (e.g. ValueOrDieForType<Dst>(val)).
+  // If you've encountered an _ambiguous overload_ you can use a static_cast<>
+  // to explicitly cast the result to the destination type.
+  // If none of that works, you may be better served with the checked_cast<> or
+  // saturated_cast<> template functions for your particular use case.
+  template <typename Dst,
+            typename std::enable_if<
+                IsNumericRangeContained<Dst, T>::value>::type* = nullptr>
   constexpr operator Dst() const {
-    return strict_cast<Dst>(value_);
+    return static_cast<typename ArithmeticOrUnderlyingEnum<Dst>::type>(value_);
   }
 
  private:
   const T value_;
 };
 
-// Explicitly make a shorter size_t typedef for convenience.
-typedef StrictNumeric<size_t> SizeT;
+// Convience wrapper returns a StrictNumeric from the provided arithmetic type.
+template <typename T>
+constexpr StrictNumeric<typename UnderlyingType<T>::type> MakeStrictNum(
+    const T value) {
+  return value;
+}
+
+// Overload the ostream output operator to make logging work nicely.
+template <typename T>
+std::ostream& operator<<(std::ostream& os, const StrictNumeric<T>& value) {
+  os << static_cast<T>(value);
+  return os;
+}
+
+#define STRICT_COMPARISON_OP(NAME, OP)                               \
+  template <typename L, typename R,                                  \
+            typename std::enable_if<                                 \
+                internal::IsStrictOp<L, R>::value>::type* = nullptr> \
+  constexpr bool operator OP(const L lhs, const R rhs) {             \
+    return SafeCompare<NAME, typename UnderlyingType<L>::type,       \
+                       typename UnderlyingType<R>::type>(lhs, rhs);  \
+  }
+
+STRICT_COMPARISON_OP(IsLess, <);
+STRICT_COMPARISON_OP(IsLessOrEqual, <=);
+STRICT_COMPARISON_OP(IsGreater, >);
+STRICT_COMPARISON_OP(IsGreaterOrEqual, >=);
+STRICT_COMPARISON_OP(IsEqual, ==);
+STRICT_COMPARISON_OP(IsNotEqual, !=);
+
+#undef STRICT_COMPARISON_OP
+};
+
+using internal::strict_cast;
+using internal::saturated_cast;
+using internal::StrictNumeric;
+using internal::MakeStrictNum;
+
+// Explicitly make a shorter size_t alias for convenience.
+using SizeT = StrictNumeric<size_t>;
 
 }  // namespace base
 
diff --git a/src/base/numerics/safe_conversions_impl.h b/src/base/numerics/safe_conversions_impl.h
index bdce167..f383d9c 100644
--- a/src/base/numerics/safe_conversions_impl.h
+++ b/src/base/numerics/safe_conversions_impl.h
@@ -5,10 +5,8 @@
 #ifndef BASE_NUMERICS_SAFE_CONVERSIONS_IMPL_H_
 #define BASE_NUMERICS_SAFE_CONVERSIONS_IMPL_H_
 
-#include <limits.h>
 #include <stdint.h>
 
-#include <climits>
 #include <limits>
 #include <type_traits>
 
@@ -16,16 +14,20 @@ namespace base {
 namespace internal {
 
 // The std library doesn't provide a binary max_exponent for integers, however
-// we can compute one by adding one to the number of non-sign bits. This allows
-// for accurate range comparisons between floating point and integer types.
+// we can compute an analog using std::numeric_limits<>::digits.
 template <typename NumericType>
 struct MaxExponent {
-  static_assert(std::is_arithmetic<NumericType>::value,
-                "Argument must be numeric.");
-  static const int value = std::numeric_limits<NumericType>::is_iec559
+  static const int value = std::is_floating_point<NumericType>::value
                                ? std::numeric_limits<NumericType>::max_exponent
-                               : (sizeof(NumericType) * CHAR_BIT + 1 -
-                                  std::numeric_limits<NumericType>::is_signed);
+                               : std::numeric_limits<NumericType>::digits + 1;
+};
+
+// The number of bits (including the sign) in an integer. Eliminates sizeof
+// hacks.
+template <typename NumericType>
+struct IntegerBitsPlusSign {
+  static const int value = std::numeric_limits<NumericType>::digits +
+                           std::is_signed<NumericType>::value;
 };
 
 enum IntegerRepresentation {
@@ -35,7 +37,7 @@ enum IntegerRepresentation {
 
 // A range for a given nunmeric Src type is contained for a given numeric Dst
 // type if both numeric_limits<Src>::max() <= numeric_limits<Dst>::max() and
-// numeric_limits<Src>::min() >= numeric_limits<Dst>::min() are true.
+// numeric_limits<Src>::lowest() >= numeric_limits<Dst>::lowest() are true.
 // We implement this as template specializations rather than simple static
 // comparisons to ensure type correctness in our comparisons.
 enum NumericRangeRepresentation {
@@ -46,16 +48,14 @@ enum NumericRangeRepresentation {
 // Helper templates to statically determine if our destination type can contain
 // maximum and minimum values represented by the source type.
 
-template <
-    typename Dst,
-    typename Src,
-    IntegerRepresentation DstSign = std::numeric_limits<Dst>::is_signed
-                                            ? INTEGER_REPRESENTATION_SIGNED
-                                            : INTEGER_REPRESENTATION_UNSIGNED,
-    IntegerRepresentation SrcSign =
-        std::numeric_limits<Src>::is_signed
-            ? INTEGER_REPRESENTATION_SIGNED
-            : INTEGER_REPRESENTATION_UNSIGNED >
+template <typename Dst,
+          typename Src,
+          IntegerRepresentation DstSign = std::is_signed<Dst>::value
+                                              ? INTEGER_REPRESENTATION_SIGNED
+                                              : INTEGER_REPRESENTATION_UNSIGNED,
+          IntegerRepresentation SrcSign = std::is_signed<Src>::value
+                                              ? INTEGER_REPRESENTATION_SIGNED
+                                              : INTEGER_REPRESENTATION_UNSIGNED>
 struct StaticDstRangeRelationToSrcRange;
 
 // Same sign: Dst is guaranteed to contain Src only if its range is equal or
@@ -137,8 +137,8 @@ constexpr inline RangeConstraint GetRangeConstraint(bool is_in_upper_bound,
 // such that the resulting maximum is represented exactly as a floating point.
 template <typename Dst, typename Src>
 struct NarrowingRange {
-  typedef typename std::numeric_limits<Src> SrcLimits;
-  typedef typename std::numeric_limits<Dst> DstLimits;
+  using SrcLimits = typename std::numeric_limits<Src>;
+  using DstLimits = typename std::numeric_limits<Dst>;
   // The following logic avoids warnings where the max function is
   // instantiated with invalid values for a bit shift (even though
   // such a function can never be called).
@@ -156,23 +156,19 @@ struct NarrowingRange {
     return DstLimits::max() - static_cast<Dst>((UINTMAX_C(1) << shift) - 1);
   }
 
-  static constexpr Dst min() {
-    return std::numeric_limits<Dst>::is_iec559 ? -DstLimits::max()
-                                               : DstLimits::min();
-  }
+  static constexpr Dst lowest() { return DstLimits::lowest(); }
 };
 
-template <
-    typename Dst,
-    typename Src,
-    IntegerRepresentation DstSign = std::numeric_limits<Dst>::is_signed
-                                            ? INTEGER_REPRESENTATION_SIGNED
-                                            : INTEGER_REPRESENTATION_UNSIGNED,
-    IntegerRepresentation SrcSign = std::numeric_limits<Src>::is_signed
-                                            ? INTEGER_REPRESENTATION_SIGNED
-                                            : INTEGER_REPRESENTATION_UNSIGNED,
-    NumericRangeRepresentation DstRange =
-        StaticDstRangeRelationToSrcRange<Dst, Src>::value >
+template <typename Dst,
+          typename Src,
+          IntegerRepresentation DstSign = std::is_signed<Dst>::value
+                                              ? INTEGER_REPRESENTATION_SIGNED
+                                              : INTEGER_REPRESENTATION_UNSIGNED,
+          IntegerRepresentation SrcSign = std::is_signed<Src>::value
+                                              ? INTEGER_REPRESENTATION_SIGNED
+                                              : INTEGER_REPRESENTATION_UNSIGNED,
+          NumericRangeRepresentation DstRange =
+              StaticDstRangeRelationToSrcRange<Dst, Src>::value>
 struct DstRangeRelationToSrcRangeImpl;
 
 // The following templates are for ranges that must be verified at runtime. We
@@ -202,7 +198,7 @@ struct DstRangeRelationToSrcRangeImpl<Dst,
                                       NUMERIC_RANGE_NOT_CONTAINED> {
   static constexpr RangeConstraint Check(Src value) {
     return GetRangeConstraint((value <= NarrowingRange<Dst, Src>::max()),
-                              (value >= NarrowingRange<Dst, Src>::min()));
+                              (value >= NarrowingRange<Dst, Src>::lowest()));
   }
 };
 
@@ -226,7 +222,7 @@ struct DstRangeRelationToSrcRangeImpl<Dst,
                                       INTEGER_REPRESENTATION_UNSIGNED,
                                       NUMERIC_RANGE_NOT_CONTAINED> {
   static constexpr RangeConstraint Check(Src value) {
-    return sizeof(Dst) > sizeof(Src)
+    return IntegerBitsPlusSign<Dst>::value > IntegerBitsPlusSign<Src>::value
                ? RANGE_VALID
                : GetRangeConstraint(
                      value <= static_cast<Src>(NarrowingRange<Dst, Src>::max()),
@@ -253,13 +249,367 @@ struct DstRangeRelationToSrcRangeImpl<Dst,
 
 template <typename Dst, typename Src>
 constexpr RangeConstraint DstRangeRelationToSrcRange(Src value) {
-  static_assert(std::numeric_limits<Src>::is_specialized,
-                "Argument must be numeric.");
-  static_assert(std::numeric_limits<Dst>::is_specialized,
-                "Result must be numeric.");
+  static_assert(std::is_arithmetic<Src>::value, "Argument must be numeric.");
+  static_assert(std::is_arithmetic<Dst>::value, "Result must be numeric.");
   return DstRangeRelationToSrcRangeImpl<Dst, Src>::Check(value);
 }
 
+// Integer promotion templates used by the portable checked integer arithmetic.
+template <size_t Size, bool IsSigned>
+struct IntegerForDigitsAndSign;
+
+#define INTEGER_FOR_DIGITS_AND_SIGN(I)                          \
+  template <>                                                   \
+  struct IntegerForDigitsAndSign<IntegerBitsPlusSign<I>::value, \
+                                 std::is_signed<I>::value> {    \
+    using type = I;                                             \
+  }
+
+INTEGER_FOR_DIGITS_AND_SIGN(int8_t);
+INTEGER_FOR_DIGITS_AND_SIGN(uint8_t);
+INTEGER_FOR_DIGITS_AND_SIGN(int16_t);
+INTEGER_FOR_DIGITS_AND_SIGN(uint16_t);
+INTEGER_FOR_DIGITS_AND_SIGN(int32_t);
+INTEGER_FOR_DIGITS_AND_SIGN(uint32_t);
+INTEGER_FOR_DIGITS_AND_SIGN(int64_t);
+INTEGER_FOR_DIGITS_AND_SIGN(uint64_t);
+#undef INTEGER_FOR_DIGITS_AND_SIGN
+
+// WARNING: We have no IntegerForSizeAndSign<16, *>. If we ever add one to
+// support 128-bit math, then the ArithmeticPromotion template below will need
+// to be updated (or more likely replaced with a decltype expression).
+static_assert(IntegerBitsPlusSign<intmax_t>::value == 64,
+              "Max integer size not supported for this toolchain.");
+
+template <typename Integer, bool IsSigned = std::is_signed<Integer>::value>
+struct TwiceWiderInteger {
+  using type =
+      typename IntegerForDigitsAndSign<IntegerBitsPlusSign<Integer>::value * 2,
+                                       IsSigned>::type;
+};
+
+template <typename Integer>
+struct PositionOfSignBit {
+  static const size_t value = IntegerBitsPlusSign<Integer>::value - 1;
+};
+
+enum ArithmeticPromotionCategory {
+  LEFT_PROMOTION,  // Use the type of the left-hand argument.
+  RIGHT_PROMOTION  // Use the type of the right-hand argument.
+};
+
+// Determines the type that can represent the largest positive value.
+template <typename Lhs,
+          typename Rhs,
+          ArithmeticPromotionCategory Promotion =
+              (MaxExponent<Lhs>::value > MaxExponent<Rhs>::value)
+                  ? LEFT_PROMOTION
+                  : RIGHT_PROMOTION>
+struct MaxExponentPromotion;
+
+template <typename Lhs, typename Rhs>
+struct MaxExponentPromotion<Lhs, Rhs, LEFT_PROMOTION> {
+  using type = Lhs;
+};
+
+template <typename Lhs, typename Rhs>
+struct MaxExponentPromotion<Lhs, Rhs, RIGHT_PROMOTION> {
+  using type = Rhs;
+};
+
+// Determines the type that can represent the lowest arithmetic value.
+template <typename Lhs,
+          typename Rhs,
+          ArithmeticPromotionCategory Promotion =
+              std::is_signed<Lhs>::value
+                  ? (std::is_signed<Rhs>::value
+                         ? (MaxExponent<Lhs>::value > MaxExponent<Rhs>::value
+                                ? LEFT_PROMOTION
+                                : RIGHT_PROMOTION)
+                         : LEFT_PROMOTION)
+                  : (std::is_signed<Rhs>::value
+                         ? RIGHT_PROMOTION
+                         : (MaxExponent<Lhs>::value < MaxExponent<Rhs>::value
+                                ? LEFT_PROMOTION
+                                : RIGHT_PROMOTION))>
+struct LowestValuePromotion;
+
+template <typename Lhs, typename Rhs>
+struct LowestValuePromotion<Lhs, Rhs, LEFT_PROMOTION> {
+  using type = Lhs;
+};
+
+template <typename Lhs, typename Rhs>
+struct LowestValuePromotion<Lhs, Rhs, RIGHT_PROMOTION> {
+  using type = Rhs;
+};
+
+// Determines the type that is best able to represent an arithmetic result.
+template <
+    typename Lhs,
+    typename Rhs = Lhs,
+    bool is_intmax_type =
+        std::is_integral<typename MaxExponentPromotion<Lhs, Rhs>::type>::value&&
+            IntegerBitsPlusSign<typename MaxExponentPromotion<Lhs, Rhs>::type>::
+                value == IntegerBitsPlusSign<intmax_t>::value,
+    bool is_max_exponent =
+        StaticDstRangeRelationToSrcRange<
+            typename MaxExponentPromotion<Lhs, Rhs>::type,
+            Lhs>::value ==
+        NUMERIC_RANGE_CONTAINED&& StaticDstRangeRelationToSrcRange<
+            typename MaxExponentPromotion<Lhs, Rhs>::type,
+            Rhs>::value == NUMERIC_RANGE_CONTAINED>
+struct BigEnoughPromotion;
+
+// The side with the max exponent is big enough.
+template <typename Lhs, typename Rhs, bool is_intmax_type>
+struct BigEnoughPromotion<Lhs, Rhs, is_intmax_type, true> {
+  using type = typename MaxExponentPromotion<Lhs, Rhs>::type;
+  static const bool is_contained = true;
+};
+
+// We can use a twice wider type to fit.
+template <typename Lhs, typename Rhs>
+struct BigEnoughPromotion<Lhs, Rhs, false, false> {
+  using type =
+      typename TwiceWiderInteger<typename MaxExponentPromotion<Lhs, Rhs>::type,
+                                 std::is_signed<Lhs>::value ||
+                                     std::is_signed<Rhs>::value>::type;
+  static const bool is_contained = true;
+};
+
+// No type is large enough.
+template <typename Lhs, typename Rhs>
+struct BigEnoughPromotion<Lhs, Rhs, true, false> {
+  using type = typename MaxExponentPromotion<Lhs, Rhs>::type;
+  static const bool is_contained = false;
+};
+
+// We can statically check if operations on the provided types can wrap, so we
+// can skip the checked operations if they're not needed. So, for an integer we
+// care if the destination type preserves the sign and is twice the width of
+// the source.
+template <typename T, typename Lhs, typename Rhs>
+struct IsIntegerArithmeticSafe {
+  static const bool value =
+      !std::is_floating_point<T>::value &&
+      StaticDstRangeRelationToSrcRange<T, Lhs>::value ==
+          NUMERIC_RANGE_CONTAINED &&
+      IntegerBitsPlusSign<T>::value >= (2 * IntegerBitsPlusSign<Lhs>::value) &&
+      StaticDstRangeRelationToSrcRange<T, Rhs>::value !=
+          NUMERIC_RANGE_CONTAINED &&
+      IntegerBitsPlusSign<T>::value >= (2 * IntegerBitsPlusSign<Rhs>::value);
+};
+
+// This hacks around libstdc++ 4.6 missing stuff in type_traits.
+#if defined(__GLIBCXX__)
+#define PRIV_GLIBCXX_4_7_0 20120322
+#define PRIV_GLIBCXX_4_5_4 20120702
+#define PRIV_GLIBCXX_4_6_4 20121127
+#if (__GLIBCXX__ < PRIV_GLIBCXX_4_7_0 || __GLIBCXX__ == PRIV_GLIBCXX_4_5_4 || \
+     __GLIBCXX__ == PRIV_GLIBCXX_4_6_4)
+#define PRIV_USE_FALLBACKS_FOR_OLD_GLIBCXX
+#undef PRIV_GLIBCXX_4_7_0
+#undef PRIV_GLIBCXX_4_5_4
+#undef PRIV_GLIBCXX_4_6_4
+#endif
+#endif
+
+// Extracts the underlying type from an enum.
+template <typename T, bool is_enum = std::is_enum<T>::value>
+struct ArithmeticOrUnderlyingEnum;
+
+template <typename T>
+struct ArithmeticOrUnderlyingEnum<T, true> {
+#if defined(PRIV_USE_FALLBACKS_FOR_OLD_GLIBCXX)
+  using type = __underlying_type(T);
+#else
+  using type = typename std::underlying_type<T>::type;
+#endif
+  static const bool value = std::is_arithmetic<type>::value;
+};
+
+#if defined(PRIV_USE_FALLBACKS_FOR_OLD_GLIBCXX)
+#undef PRIV_USE_FALLBACKS_FOR_OLD_GLIBCXX
+#endif
+
+template <typename T>
+struct ArithmeticOrUnderlyingEnum<T, false> {
+  using type = T;
+  static const bool value = std::is_arithmetic<type>::value;
+};
+
+// The following are helper templates used in the CheckedNumeric class.
+template <typename T>
+class CheckedNumeric;
+
+template <typename T>
+class StrictNumeric;
+
+// Used to treat CheckedNumeric and arithmetic underlying types the same.
+template <typename T>
+struct UnderlyingType {
+  using type = typename ArithmeticOrUnderlyingEnum<T>::type;
+  static const bool is_numeric = std::is_arithmetic<type>::value;
+  static const bool is_checked = false;
+  static const bool is_strict = false;
+};
+
+template <typename T>
+struct UnderlyingType<CheckedNumeric<T>> {
+  using type = T;
+  static const bool is_numeric = true;
+  static const bool is_checked = true;
+  static const bool is_strict = false;
+};
+
+template <typename T>
+struct UnderlyingType<StrictNumeric<T>> {
+  using type = T;
+  static const bool is_numeric = true;
+  static const bool is_checked = false;
+  static const bool is_strict = true;
+};
+
+template <typename L, typename R>
+struct IsCheckedOp {
+  static const bool value =
+      UnderlyingType<L>::is_numeric && UnderlyingType<R>::is_numeric &&
+      (UnderlyingType<L>::is_checked || UnderlyingType<R>::is_checked);
+};
+
+template <typename L, typename R>
+struct IsStrictOp {
+  static const bool value =
+      UnderlyingType<L>::is_numeric && UnderlyingType<R>::is_numeric &&
+      (UnderlyingType<L>::is_strict || UnderlyingType<R>::is_strict);
+};
+
+template <typename L, typename R>
+constexpr bool IsLessImpl(const L lhs,
+                          const R rhs,
+                          const RangeConstraint l_range,
+                          const RangeConstraint r_range) {
+  return l_range == RANGE_UNDERFLOW || r_range == RANGE_OVERFLOW ||
+         (l_range == r_range &&
+          static_cast<decltype(lhs + rhs)>(lhs) <
+              static_cast<decltype(lhs + rhs)>(rhs));
+}
+
+template <typename L, typename R>
+struct IsLess {
+  static_assert(std::is_arithmetic<L>::value && std::is_arithmetic<R>::value,
+                "Types must be numeric.");
+  static constexpr bool Test(const L lhs, const R rhs) {
+    return IsLessImpl(lhs, rhs, DstRangeRelationToSrcRange<R>(lhs),
+                      DstRangeRelationToSrcRange<L>(rhs));
+  }
+};
+
+template <typename L, typename R>
+constexpr bool IsLessOrEqualImpl(const L lhs,
+                                 const R rhs,
+                                 const RangeConstraint l_range,
+                                 const RangeConstraint r_range) {
+  return l_range == RANGE_UNDERFLOW || r_range == RANGE_OVERFLOW ||
+         (l_range == r_range &&
+          static_cast<decltype(lhs + rhs)>(lhs) <=
+              static_cast<decltype(lhs + rhs)>(rhs));
+}
+
+template <typename L, typename R>
+struct IsLessOrEqual {
+  static_assert(std::is_arithmetic<L>::value && std::is_arithmetic<R>::value,
+                "Types must be numeric.");
+  static constexpr bool Test(const L lhs, const R rhs) {
+    return IsLessOrEqualImpl(lhs, rhs, DstRangeRelationToSrcRange<R>(lhs),
+                             DstRangeRelationToSrcRange<L>(rhs));
+  }
+};
+
+template <typename L, typename R>
+constexpr bool IsGreaterImpl(const L lhs,
+                             const R rhs,
+                             const RangeConstraint l_range,
+                             const RangeConstraint r_range) {
+  return l_range == RANGE_OVERFLOW || r_range == RANGE_UNDERFLOW ||
+         (l_range == r_range &&
+          static_cast<decltype(lhs + rhs)>(lhs) >
+              static_cast<decltype(lhs + rhs)>(rhs));
+}
+
+template <typename L, typename R>
+struct IsGreater {
+  static_assert(std::is_arithmetic<L>::value && std::is_arithmetic<R>::value,
+                "Types must be numeric.");
+  static constexpr bool Test(const L lhs, const R rhs) {
+    return IsGreaterImpl(lhs, rhs, DstRangeRelationToSrcRange<R>(lhs),
+                         DstRangeRelationToSrcRange<L>(rhs));
+  }
+};
+
+template <typename L, typename R>
+constexpr bool IsGreaterOrEqualImpl(const L lhs,
+                                    const R rhs,
+                                    const RangeConstraint l_range,
+                                    const RangeConstraint r_range) {
+  return l_range == RANGE_OVERFLOW || r_range == RANGE_UNDERFLOW ||
+         (l_range == r_range &&
+          static_cast<decltype(lhs + rhs)>(lhs) >=
+              static_cast<decltype(lhs + rhs)>(rhs));
+}
+
+template <typename L, typename R>
+struct IsGreaterOrEqual {
+  static_assert(std::is_arithmetic<L>::value && std::is_arithmetic<R>::value,
+                "Types must be numeric.");
+  static constexpr bool Test(const L lhs, const R rhs) {
+    return IsGreaterOrEqualImpl(lhs, rhs, DstRangeRelationToSrcRange<R>(lhs),
+                                DstRangeRelationToSrcRange<L>(rhs));
+  }
+};
+
+template <typename L, typename R>
+struct IsEqual {
+  static_assert(std::is_arithmetic<L>::value && std::is_arithmetic<R>::value,
+                "Types must be numeric.");
+  static constexpr bool Test(const L lhs, const R rhs) {
+    return DstRangeRelationToSrcRange<R>(lhs) ==
+               DstRangeRelationToSrcRange<L>(rhs) &&
+           static_cast<decltype(lhs + rhs)>(lhs) ==
+               static_cast<decltype(lhs + rhs)>(rhs);
+  }
+};
+
+template <typename L, typename R>
+struct IsNotEqual {
+  static_assert(std::is_arithmetic<L>::value && std::is_arithmetic<R>::value,
+                "Types must be numeric.");
+  static constexpr bool Test(const L lhs, const R rhs) {
+    return DstRangeRelationToSrcRange<R>(lhs) !=
+               DstRangeRelationToSrcRange<L>(rhs) ||
+           static_cast<decltype(lhs + rhs)>(lhs) !=
+               static_cast<decltype(lhs + rhs)>(rhs);
+  }
+};
+
+// These perform the actual math operations on the CheckedNumerics.
+// Binary arithmetic operations.
+template <template <typename, typename> class C, typename L, typename R>
+constexpr bool SafeCompare(const L lhs, const R rhs) {
+  static_assert(std::is_arithmetic<L>::value && std::is_arithmetic<R>::value,
+                "Types must be numeric.");
+  using Promotion = BigEnoughPromotion<L, R>;
+  using BigType = typename Promotion::type;
+  return Promotion::is_contained
+             // Force to a larger type for speed if both are contained.
+             ? C<BigType, BigType>::Test(
+                   static_cast<BigType>(static_cast<L>(lhs)),
+                   static_cast<BigType>(static_cast<R>(rhs)))
+             // Let the template functions figure it out for mixed types.
+             : C<L, R>::Test(lhs, rhs);
+};
+
 }  // namespace internal
 }  // namespace base
 
diff --git a/src/base/numerics/safe_math.h b/src/base/numerics/safe_math.h
index d0003b7..32f0dfd 100644
--- a/src/base/numerics/safe_math.h
+++ b/src/base/numerics/safe_math.h
@@ -10,155 +10,260 @@
 #include <limits>
 #include <type_traits>
 
-#include "base/logging.h"
 #include "base/numerics/safe_math_impl.h"
 
 namespace base {
-
 namespace internal {
 
-// CheckedNumeric implements all the logic and operators for detecting integer
+// CheckedNumeric<> implements all the logic and operators for detecting integer
 // boundary conditions such as overflow, underflow, and invalid conversions.
 // The CheckedNumeric type implicitly converts from floating point and integer
 // data types, and contains overloads for basic arithmetic operations (i.e.: +,
-// -, *, /, %).
+// -, *, / for all types and %, <<, >>, &, |, ^ for integers). Type promotions
+// are a slightly modified version of the standard C arithmetic rules with the
+// two differences being that there is no default promotion to int and bitwise
+// logical operations always return an unsigned of the wider type.
+//
+// You may also use one of the variadic convenience functions, which accept
+// standard arithmetic or CheckedNumeric types, perform arithmetic operations,
+// and return a CheckedNumeric result. The supported functions are:
+//  CheckAdd() - Addition.
+//  CheckSub() - Subtraction.
+//  CheckMul() - Multiplication.
+//  CheckDiv() - Division.
+//  CheckMod() - Modulous (integer only).
+//  CheckLsh() - Left integer shift (integer only).
+//  CheckRsh() - Right integer shift (integer only).
+//  CheckAnd() - Bitwise AND (integer only with unsigned result).
+//  CheckOr()  - Bitwise OR (integer only with unsigned result).
+//  CheckXor() - Bitwise XOR (integer only with unsigned result).
+//  CheckMax() - Maximum of supplied arguments.
+//  CheckMin() - Minimum of supplied arguments.
+//
+// The unary negation, increment, and decrement operators are supported, along
+// with the following unary arithmetic methods, which return a new
+// CheckedNumeric as a result of the operation:
+//  Abs() - Absolute value.
+//  UnsignedAbs() - Absolute value as an equal-width unsigned underlying type
+//          (valid for only integral types).
+//  Max() - Returns whichever is greater of the current instance or argument.
+//          The underlying return type is whichever has the greatest magnitude.
+//  Min() - Returns whichever is lowest of the current instance or argument.
+//          The underlying return type is whichever has can represent the lowest
+//          number in the smallest width (e.g. int8_t over unsigned, int over
+//          int8_t, and float over int).
 //
 // The following methods convert from CheckedNumeric to standard numeric values:
-// IsValid() - Returns true if the underlying numeric value is valid (i.e. has
-//             has not wrapped and is not the result of an invalid conversion).
-// ValueOrDie() - Returns the underlying value. If the state is not valid this
-//                call will crash on a CHECK.
-// ValueOrDefault() - Returns the current value, or the supplied default if the
-//                    state is not valid.
-// ValueFloating() - Returns the underlying floating point value (valid only
-//                   only for floating point CheckedNumeric types).
+//  AssignIfValid() - Assigns the underlying value to the supplied destination
+//          pointer if the value is currently valid and within the range
+//          supported by the destination type. Returns true on success.
+//  ****************************************************************************
+//  *  WARNING: All of the following functions return a StrictNumeric, which   *
+//  *  is valid for comparison and assignment operations, but will trigger a   *
+//  *  compile failure on attempts to assign to a type of insufficient range.  *
+//  ****************************************************************************
+//  IsValid() - Returns true if the underlying numeric value is valid (i.e. has
+//          has not wrapped and is not the result of an invalid conversion).
+//  ValueOrDie() - Returns the underlying value. If the state is not valid this
+//          call will crash on a CHECK.
+//  ValueOrDefault() - Returns the current value, or the supplied default if the
+//          state is not valid (will not trigger a CHECK).
 //
-// Bitwise operations are explicitly not supported, because correct
-// handling of some cases (e.g. sign manipulation) is ambiguous. Comparison
-// operations are explicitly not supported because they could result in a crash
-// on a CHECK condition. You should use patterns like the following for these
-// operations:
-// Bitwise operation:
-//     CheckedNumeric<int> checked_int = untrusted_input_value;
-//     int x = checked_int.ValueOrDefault(0) | kFlagValues;
-// Comparison:
+// The following wrapper functions can be used to avoid the template
+// disambiguator syntax when converting a destination type.
+//   IsValidForType<>() in place of: a.template IsValid<Dst>()
+//   ValueOrDieForType<>() in place of: a.template ValueOrDie()
+//   ValueOrDefaultForType<>() in place of: a.template ValueOrDefault(default)
+//
+// The following are general utility methods that are useful for converting
+// between arithmetic types and CheckedNumeric types:
+//  CheckedNumeric::Cast<Dst>() - Instance method returning a CheckedNumeric
+//          derived from casting the current instance to a CheckedNumeric of
+//          the supplied destination type.
+//  MakeCheckedNum() - Creates a new CheckedNumeric from the underlying type of
+//          the supplied arithmetic, CheckedNumeric, or StrictNumeric type.
+//
+// Comparison operations are explicitly not supported because they could result
+// in a crash on an unexpected CHECK condition. You should use patterns like the
+// following for comparisons:
 //   CheckedNumeric<size_t> checked_size = untrusted_input_value;
 //   checked_size += HEADER LENGTH;
 //   if (checked_size.IsValid() && checked_size.ValueOrDie() < buffer_size)
 //     Do stuff...
+
 template <typename T>
 class CheckedNumeric {
   static_assert(std::is_arithmetic<T>::value,
                 "CheckedNumeric<T>: T must be a numeric type.");
 
  public:
-  typedef T type;
+  using type = T;
 
-  CheckedNumeric() {}
+  constexpr CheckedNumeric() {}
 
   // Copy constructor.
   template <typename Src>
-  CheckedNumeric(const CheckedNumeric<Src>& rhs)
-      : state_(rhs.ValueUnsafe(), rhs.validity()) {}
+  constexpr CheckedNumeric(const CheckedNumeric<Src>& rhs)
+      : state_(rhs.state_.value(), rhs.IsValid()) {}
 
   template <typename Src>
-  CheckedNumeric(Src value, RangeConstraint validity)
-      : state_(value, validity) {}
+  friend class CheckedNumeric;
 
   // This is not an explicit constructor because we implicitly upgrade regular
   // numerics to CheckedNumerics to make them easier to use.
   template <typename Src>
-  CheckedNumeric(Src value)  // NOLINT(runtime/explicit)
+  constexpr CheckedNumeric(Src value)  // NOLINT(runtime/explicit)
       : state_(value) {
-    static_assert(std::numeric_limits<Src>::is_specialized,
-                  "Argument must be numeric.");
+    static_assert(std::is_arithmetic<Src>::value, "Argument must be numeric.");
   }
 
   // This is not an explicit constructor because we want a seamless conversion
   // from StrictNumeric types.
   template <typename Src>
-  CheckedNumeric(StrictNumeric<Src> value)  // NOLINT(runtime/explicit)
-      : state_(static_cast<Src>(value)) {
+  constexpr CheckedNumeric(
+      StrictNumeric<Src> value)  // NOLINT(runtime/explicit)
+      : state_(static_cast<Src>(value)) {}
+
+  // IsValid() - The public API to test if a CheckedNumeric is currently valid.
+  // A range checked destination type can be supplied using the Dst template
+  // parameter.
+  template <typename Dst = T>
+  constexpr bool IsValid() const {
+    return state_.is_valid() &&
+           IsValueInRangeForNumericType<Dst>(state_.value());
   }
 
-  // IsValid() is the public API to test if a CheckedNumeric is currently valid.
-  bool IsValid() const { return validity() == RANGE_VALID; }
+  // AssignIfValid(Dst) - Assigns the underlying value if it is currently valid
+  // and is within the range supported by the destination type. Returns true if
+  // successful and false otherwise.
+  template <typename Dst>
+  constexpr bool AssignIfValid(Dst* result) const {
+    return IsValid<Dst>() ? ((*result = static_cast<Dst>(state_.value())), true)
+                          : false;
+  }
 
-  // ValueOrDie() The primary accessor for the underlying value. If the current
-  // state is not valid it will CHECK and crash.
-  T ValueOrDie() const {
-    CHECK(IsValid());
-    return state_.value();
+  // ValueOrDie() - The primary accessor for the underlying value. If the
+  // current state is not valid it will CHECK and crash.
+  // A range checked destination type can be supplied using the Dst template
+  // parameter, which will trigger a CHECK if the value is not in bounds for
+  // the destination.
+  // The CHECK behavior can be overridden by supplying a handler as a
+  // template parameter, for test code, etc. However, the handler cannot access
+  // the underlying value, and it is not available through other means.
+  template <typename Dst = T, class CheckHandler = CheckOnFailure>
+  constexpr StrictNumeric<Dst> ValueOrDie() const {
+    return IsValid<Dst>() ? static_cast<Dst>(state_.value())
+                          : CheckHandler::template HandleFailure<Dst>();
   }
 
-  // ValueOrDefault(T default_value) A convenience method that returns the
+  // ValueOrDefault(T default_value) - A convenience method that returns the
   // current value if the state is valid, and the supplied default_value for
   // any other state.
-  T ValueOrDefault(T default_value) const {
-    return IsValid() ? state_.value() : default_value;
+  // A range checked destination type can be supplied using the Dst template
+  // parameter. WARNING: This function may fail to compile or CHECK at runtime
+  // if the supplied default_value is not within range of the destination type.
+  template <typename Dst = T, typename Src>
+  constexpr StrictNumeric<Dst> ValueOrDefault(const Src default_value) const {
+    return IsValid<Dst>() ? static_cast<Dst>(state_.value())
+                          : checked_cast<Dst>(default_value);
   }
 
-  // ValueFloating() - Since floating point values include their validity state,
-  // we provide an easy method for extracting them directly, without a risk of
-  // crashing on a CHECK.
-  T ValueFloating() const {
-    static_assert(std::numeric_limits<T>::is_iec559, "Argument must be float.");
-    return CheckedNumeric<T>::cast(*this).ValueUnsafe();
+  // Returns a checked numeric of the specified type, cast from the current
+  // CheckedNumeric. If the current state is invalid or the destination cannot
+  // represent the result then the returned CheckedNumeric will be invalid.
+  template <typename Dst>
+  constexpr CheckedNumeric<typename UnderlyingType<Dst>::type> Cast() const {
+    return *this;
   }
 
-  // validity() - DO NOT USE THIS IN EXTERNAL CODE - It is public right now for
-  // tests and to avoid a big matrix of friend operator overloads. But the
-  // values it returns are likely to change in the future.
-  // Returns: current validity state (i.e. valid, overflow, underflow, nan).
-  // TODO(jschuh): crbug.com/332611 Figure out and implement semantics for
-  // saturation/wrapping so we can expose this state consistently and implement
-  // saturated arithmetic.
-  RangeConstraint validity() const { return state_.validity(); }
-
-  // ValueUnsafe() - DO NOT USE THIS IN EXTERNAL CODE - It is public right now
-  // for tests and to avoid a big matrix of friend operator overloads. But the
-  // values it returns are likely to change in the future.
-  // Returns: the raw numeric value, regardless of the current state.
-  // TODO(jschuh): crbug.com/332611 Figure out and implement semantics for
-  // saturation/wrapping so we can expose this state consistently and implement
-  // saturated arithmetic.
-  T ValueUnsafe() const { return state_.value(); }
+  // This friend method is available solely for providing more detailed logging
+  // in the the tests. Do not implement it in production code, because the
+  // underlying values may change at any time.
+  template <typename U>
+  friend U GetNumericValueForTest(const CheckedNumeric<U>& src);
 
   // Prototypes for the supported arithmetic operator overloads.
-  template <typename Src> CheckedNumeric& operator+=(Src rhs);
-  template <typename Src> CheckedNumeric& operator-=(Src rhs);
-  template <typename Src> CheckedNumeric& operator*=(Src rhs);
-  template <typename Src> CheckedNumeric& operator/=(Src rhs);
-  template <typename Src> CheckedNumeric& operator%=(Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator+=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator-=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator*=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator/=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator%=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator<<=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator>>=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator&=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator|=(const Src rhs);
+  template <typename Src>
+  CheckedNumeric& operator^=(const Src rhs);
 
   CheckedNumeric operator-() const {
-    RangeConstraint validity;
-    T value = CheckedNeg(state_.value(), &validity);
     // Negation is always valid for floating point.
-    if (std::numeric_limits<T>::is_iec559)
-      return CheckedNumeric<T>(value);
+    T value = 0;
+    bool is_valid = (std::is_floating_point<T>::value || IsValid()) &&
+                    CheckedNeg(state_.value(), &value);
+    return CheckedNumeric<T>(value, is_valid);
+  }
 
-    validity = GetRangeConstraint(state_.validity() | validity);
-    return CheckedNumeric<T>(value, validity);
+  CheckedNumeric operator~() const {
+    static_assert(!std::is_signed<T>::value, "Type must be unsigned.");
+    T value = 0;
+    bool is_valid = IsValid() && CheckedInv(state_.value(), &value);
+    return CheckedNumeric<T>(value, is_valid);
   }
 
   CheckedNumeric Abs() const {
-    RangeConstraint validity;
-    T value = CheckedAbs(state_.value(), &validity);
     // Absolute value is always valid for floating point.
-    if (std::numeric_limits<T>::is_iec559)
-      return CheckedNumeric<T>(value);
+    T value = 0;
+    bool is_valid = (std::is_floating_point<T>::value || IsValid()) &&
+                    CheckedAbs(state_.value(), &value);
+    return CheckedNumeric<T>(value, is_valid);
+  }
 
-    validity = GetRangeConstraint(state_.validity() | validity);
-    return CheckedNumeric<T>(value, validity);
+  template <typename U>
+  constexpr CheckedNumeric<typename MathWrapper<CheckedMaxOp, T, U>::type> Max(
+      const U rhs) const {
+    using R = typename UnderlyingType<U>::type;
+    using result_type = typename MathWrapper<CheckedMaxOp, T, U>::type;
+    // TODO(jschuh): This can be converted to the MathOp version and remain
+    // constexpr once we have C++14 support.
+    return CheckedNumeric<result_type>(
+        static_cast<result_type>(
+            IsGreater<T, R>::Test(state_.value(), Wrapper<U>::value(rhs))
+                ? state_.value()
+                : Wrapper<U>::value(rhs)),
+        state_.is_valid() && Wrapper<U>::is_valid(rhs));
+  }
+
+  template <typename U>
+  constexpr CheckedNumeric<typename MathWrapper<CheckedMinOp, T, U>::type> Min(
+      const U rhs) const {
+    using R = typename UnderlyingType<U>::type;
+    using result_type = typename MathWrapper<CheckedMinOp, T, U>::type;
+    // TODO(jschuh): This can be converted to the MathOp version and remain
+    // constexpr once we have C++14 support.
+    return CheckedNumeric<result_type>(
+        static_cast<result_type>(
+            IsLess<T, R>::Test(state_.value(), Wrapper<U>::value(rhs))
+                ? state_.value()
+                : Wrapper<U>::value(rhs)),
+        state_.is_valid() && Wrapper<U>::is_valid(rhs));
   }
 
   // This function is available only for integral types. It returns an unsigned
   // integer of the same width as the source type, containing the absolute value
   // of the source, and properly handling signed min.
-  CheckedNumeric<typename UnsignedOrFloatForSize<T>::type> UnsignedAbs() const {
+  constexpr CheckedNumeric<typename UnsignedOrFloatForSize<T>::type>
+  UnsignedAbs() const {
     return CheckedNumeric<typename UnsignedOrFloatForSize<T>::type>(
-        CheckedUnsignedAbs(state_.value()), state_.validity());
+        SafeUnsignedAbs(state_.value()), state_.is_valid());
   }
 
   CheckedNumeric& operator++() {
@@ -183,126 +288,221 @@ class CheckedNumeric {
     return value;
   }
 
-  // These static methods behave like a convenience cast operator targeting
-  // the desired CheckedNumeric type. As an optimization, a reference is
-  // returned when Src is the same type as T.
-  template <typename Src>
-  static CheckedNumeric<T> cast(
-      Src u,
-      typename std::enable_if<std::numeric_limits<Src>::is_specialized,
-                              int>::type = 0) {
-    return u;
-  }
+  // These perform the actual math operations on the CheckedNumerics.
+  // Binary arithmetic operations.
+  template <template <typename, typename, typename> class M,
+            typename L,
+            typename R>
+  static CheckedNumeric MathOp(const L lhs, const R rhs) {
+    using Math = typename MathWrapper<M, L, R>::math;
+    T result = 0;
+    bool is_valid =
+        Wrapper<L>::is_valid(lhs) && Wrapper<R>::is_valid(rhs) &&
+        Math::Do(Wrapper<L>::value(lhs), Wrapper<R>::value(rhs), &result);
+    return CheckedNumeric<T>(result, is_valid);
+  };
+
+  // Assignment arithmetic operations.
+  template <template <typename, typename, typename> class M, typename R>
+  CheckedNumeric& MathOp(const R rhs) {
+    using Math = typename MathWrapper<M, T, R>::math;
+    T result = 0;  // Using T as the destination saves a range check.
+    bool is_valid = state_.is_valid() && Wrapper<R>::is_valid(rhs) &&
+                    Math::Do(state_.value(), Wrapper<R>::value(rhs), &result);
+    *this = CheckedNumeric<T>(result, is_valid);
+    return *this;
+  };
+
+ private:
+  CheckedNumericState<T> state_;
 
   template <typename Src>
-  static CheckedNumeric<T> cast(
-      const CheckedNumeric<Src>& u,
-      typename std::enable_if<!std::is_same<Src, T>::value, int>::type = 0) {
-    return u;
-  }
+  constexpr CheckedNumeric(Src value, bool is_valid)
+      : state_(value, is_valid) {}
 
-  static const CheckedNumeric<T>& cast(const CheckedNumeric<T>& u) { return u; }
+  // These wrappers allow us to handle state the same way for both
+  // CheckedNumeric and POD arithmetic types.
+  template <typename Src>
+  struct Wrapper {
+    static constexpr bool is_valid(Src) { return true; }
+    static constexpr Src value(Src value) { return value; }
+  };
 
- private:
-  template <typename NumericType>
-  struct UnderlyingType {
-    using type = NumericType;
+  template <typename Src>
+  struct Wrapper<CheckedNumeric<Src>> {
+    static constexpr bool is_valid(const CheckedNumeric<Src> v) {
+      return v.IsValid();
+    }
+    static constexpr Src value(const CheckedNumeric<Src> v) {
+      return v.state_.value();
+    }
   };
 
-  template <typename NumericType>
-  struct UnderlyingType<CheckedNumeric<NumericType>> {
-    using type = NumericType;
+  template <typename Src>
+  struct Wrapper<StrictNumeric<Src>> {
+    static constexpr bool is_valid(const StrictNumeric<Src>) { return true; }
+    static constexpr Src value(const StrictNumeric<Src> v) {
+      return static_cast<Src>(v);
+    }
   };
+};
 
-  CheckedNumericState<T> state_;
+// Convenience functions to avoid the ugly template disambiguator syntax.
+template <typename Dst, typename Src>
+constexpr bool IsValidForType(const CheckedNumeric<Src> value) {
+  return value.template IsValid<Dst>();
+}
+
+template <typename Dst, typename Src>
+constexpr StrictNumeric<Dst> ValueOrDieForType(
+    const CheckedNumeric<Src> value) {
+  return value.template ValueOrDie<Dst>();
+}
+
+template <typename Dst, typename Src, typename Default>
+constexpr StrictNumeric<Dst> ValueOrDefaultForType(
+    const CheckedNumeric<Src> value,
+    const Default default_value) {
+  return value.template ValueOrDefault<Dst>(default_value);
+}
+
+// These variadic templates work out the return types.
+// TODO(jschuh): Rip all this out once we have C++14 non-trailing auto support.
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R,
+          typename... Args>
+struct ResultType;
+
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R>
+struct ResultType<M, L, R> {
+  using type = typename MathWrapper<M, L, R>::type;
 };
 
-// This is the boilerplate for the standard arithmetic operator overloads. A
-// macro isn't the prettiest solution, but it beats rewriting these five times.
-// Some details worth noting are:
-//  * We apply the standard arithmetic promotions.
-//  * We skip range checks for floating points.
-//  * We skip range checks for destination integers with sufficient range.
-// TODO(jschuh): extract these out into templates.
-#define BASE_NUMERIC_ARITHMETIC_OPERATORS(NAME, OP, COMPOUND_OP)              \
-  /* Binary arithmetic operator for CheckedNumerics of the same type. */      \
-  template <typename T>                                                       \
-  CheckedNumeric<typename ArithmeticPromotion<T>::type> operator OP(          \
-      const CheckedNumeric<T>& lhs, const CheckedNumeric<T>& rhs) {           \
-    typedef typename ArithmeticPromotion<T>::type Promotion;                  \
-    /* Floating point always takes the fast path */                           \
-    if (std::numeric_limits<T>::is_iec559)                                    \
-      return CheckedNumeric<T>(lhs.ValueUnsafe() OP rhs.ValueUnsafe());       \
-    if (IsIntegerArithmeticSafe<Promotion, T, T>::value)                      \
-      return CheckedNumeric<Promotion>(                                       \
-          lhs.ValueUnsafe() OP rhs.ValueUnsafe(),                             \
-          GetRangeConstraint(rhs.validity() | lhs.validity()));               \
-    RangeConstraint validity = RANGE_VALID;                                   \
-    T result = static_cast<T>(                                                \
-        Checked##NAME(static_cast<Promotion>(lhs.ValueUnsafe()),              \
-                      static_cast<Promotion>(rhs.ValueUnsafe()), &validity)); \
-    return CheckedNumeric<Promotion>(                                         \
-        result,                                                               \
-        GetRangeConstraint(validity | lhs.validity() | rhs.validity()));      \
-  }                                                                           \
-  /* Assignment arithmetic operator implementation from CheckedNumeric. */    \
-  template <typename T>                                                       \
-  template <typename Src>                                                     \
-  CheckedNumeric<T>& CheckedNumeric<T>::operator COMPOUND_OP(Src rhs) {       \
-    *this = CheckedNumeric<T>::cast(*this)                                    \
-        OP CheckedNumeric<typename UnderlyingType<Src>::type>::cast(rhs);     \
-    return *this;                                                             \
-  }                                                                           \
-  /* Binary arithmetic operator for CheckedNumeric of different type. */      \
-  template <typename T, typename Src>                                         \
-  CheckedNumeric<typename ArithmeticPromotion<T, Src>::type> operator OP(     \
-      const CheckedNumeric<Src>& lhs, const CheckedNumeric<T>& rhs) {         \
-    typedef typename ArithmeticPromotion<T, Src>::type Promotion;             \
-    if (IsIntegerArithmeticSafe<Promotion, T, Src>::value)                    \
-      return CheckedNumeric<Promotion>(                                       \
-          lhs.ValueUnsafe() OP rhs.ValueUnsafe(),                             \
-          GetRangeConstraint(rhs.validity() | lhs.validity()));               \
-    return CheckedNumeric<Promotion>::cast(lhs)                               \
-        OP CheckedNumeric<Promotion>::cast(rhs);                              \
-  }                                                                           \
-  /* Binary arithmetic operator for left CheckedNumeric and right numeric. */ \
-  template <typename T, typename Src,                                         \
-            typename std::enable_if<std::is_arithmetic<Src>::value>::type* =  \
-                nullptr>                                                      \
-  CheckedNumeric<typename ArithmeticPromotion<T, Src>::type> operator OP(     \
-      const CheckedNumeric<T>& lhs, Src rhs) {                                \
-    typedef typename ArithmeticPromotion<T, Src>::type Promotion;             \
-    if (IsIntegerArithmeticSafe<Promotion, T, Src>::value)                    \
-      return CheckedNumeric<Promotion>(lhs.ValueUnsafe() OP rhs,              \
-                                       lhs.validity());                       \
-    return CheckedNumeric<Promotion>::cast(lhs)                               \
-        OP CheckedNumeric<Promotion>::cast(rhs);                              \
-  }                                                                           \
-  /* Binary arithmetic operator for left numeric and right CheckedNumeric. */ \
-  template <typename T, typename Src,                                         \
-            typename std::enable_if<std::is_arithmetic<Src>::value>::type* =  \
-                nullptr>                                                      \
-  CheckedNumeric<typename ArithmeticPromotion<T, Src>::type> operator OP(     \
-      Src lhs, const CheckedNumeric<T>& rhs) {                                \
-    typedef typename ArithmeticPromotion<T, Src>::type Promotion;             \
-    if (IsIntegerArithmeticSafe<Promotion, T, Src>::value)                    \
-      return CheckedNumeric<Promotion>(lhs OP rhs.ValueUnsafe(),              \
-                                       rhs.validity());                       \
-    return CheckedNumeric<Promotion>::cast(lhs)                               \
-        OP CheckedNumeric<Promotion>::cast(rhs);                              \
-  }
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R,
+          typename... Args>
+struct ResultType {
+  using type =
+      typename ResultType<M, typename ResultType<M, L, R>::type, Args...>::type;
+};
 
-BASE_NUMERIC_ARITHMETIC_OPERATORS(Add, +, += )
-BASE_NUMERIC_ARITHMETIC_OPERATORS(Sub, -, -= )
-BASE_NUMERIC_ARITHMETIC_OPERATORS(Mul, *, *= )
-BASE_NUMERIC_ARITHMETIC_OPERATORS(Div, /, /= )
-BASE_NUMERIC_ARITHMETIC_OPERATORS(Mod, %, %= )
+// Convience wrapper to return a new CheckedNumeric from the provided arithmetic
+// or CheckedNumericType.
+template <typename T>
+constexpr CheckedNumeric<typename UnderlyingType<T>::type> MakeCheckedNum(
+    const T value) {
+  return value;
+}
+
+// These implement the variadic wrapper for the math operations.
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R>
+CheckedNumeric<typename MathWrapper<M, L, R>::type> ChkMathOp(const L lhs,
+                                                              const R rhs) {
+  using Math = typename MathWrapper<M, L, R>::math;
+  return CheckedNumeric<typename Math::result_type>::template MathOp<M>(lhs,
+                                                                        rhs);
+}
+
+// General purpose wrapper template for arithmetic operations.
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R,
+          typename... Args>
+CheckedNumeric<typename ResultType<M, L, R, Args...>::type>
+ChkMathOp(const L lhs, const R rhs, const Args... args) {
+  auto tmp = ChkMathOp<M>(lhs, rhs);
+  return tmp.IsValid() ? ChkMathOp<M>(tmp, args...)
+                       : decltype(ChkMathOp<M>(tmp, args...))(tmp);
+};
 
+// The following macros are just boilerplate for the standard arithmetic
+// operator overloads and variadic function templates. A macro isn't the nicest
+// solution, but it beats rewriting these over and over again.
+#define BASE_NUMERIC_ARITHMETIC_VARIADIC(NAME)                                \
+  template <typename L, typename R, typename... Args>                         \
+  CheckedNumeric<typename ResultType<Checked##NAME##Op, L, R, Args...>::type> \
+      Check##NAME(const L lhs, const R rhs, const Args... args) {             \
+    return ChkMathOp<Checked##NAME##Op, L, R, Args...>(lhs, rhs, args...);    \
+  }
+
+#define BASE_NUMERIC_ARITHMETIC_OPERATORS(NAME, OP, COMPOUND_OP)               \
+  /* Binary arithmetic operator for all CheckedNumeric operations. */          \
+  template <typename L, typename R,                                            \
+            typename std::enable_if<IsCheckedOp<L, R>::value>::type* =         \
+                nullptr>                                                       \
+  CheckedNumeric<typename MathWrapper<Checked##NAME##Op, L, R>::type>          \
+  operator OP(const L lhs, const R rhs) {                                      \
+    return decltype(lhs OP rhs)::template MathOp<Checked##NAME##Op>(lhs, rhs); \
+  }                                                                            \
+  /* Assignment arithmetic operator implementation from CheckedNumeric. */     \
+  template <typename L>                                                        \
+  template <typename R>                                                        \
+  CheckedNumeric<L>& CheckedNumeric<L>::operator COMPOUND_OP(const R rhs) {    \
+    return MathOp<Checked##NAME##Op>(rhs);                                     \
+  }                                                                            \
+  /* Variadic arithmetic functions that return CheckedNumeric. */              \
+  BASE_NUMERIC_ARITHMETIC_VARIADIC(NAME)
+
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Add, +, +=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Sub, -, -=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Mul, *, *=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Div, /, /=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Mod, %, %=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Lsh, <<, <<=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Rsh, >>, >>=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(And, &, &=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Or, |, |=)
+BASE_NUMERIC_ARITHMETIC_OPERATORS(Xor, ^, ^=)
+BASE_NUMERIC_ARITHMETIC_VARIADIC(Max)
+BASE_NUMERIC_ARITHMETIC_VARIADIC(Min)
+
+#undef BASE_NUMERIC_ARITHMETIC_VARIADIC
 #undef BASE_NUMERIC_ARITHMETIC_OPERATORS
 
+// These are some extra StrictNumeric operators to support simple pointer
+// arithmetic with our result types. Since wrapping on a pointer is always
+// bad, we trigger the CHECK condition here.
+template <typename L, typename R>
+L* operator+(L* lhs, const StrictNumeric<R> rhs) {
+  uintptr_t result = CheckAdd(reinterpret_cast<uintptr_t>(lhs),
+                              CheckMul(sizeof(L), static_cast<R>(rhs)))
+                         .template ValueOrDie<uintptr_t>();
+  return reinterpret_cast<L*>(result);
+}
+
+template <typename L, typename R>
+L* operator-(L* lhs, const StrictNumeric<R> rhs) {
+  uintptr_t result = CheckSub(reinterpret_cast<uintptr_t>(lhs),
+                              CheckMul(sizeof(L), static_cast<R>(rhs)))
+                         .template ValueOrDie<uintptr_t>();
+  return reinterpret_cast<L*>(result);
+}
+
 }  // namespace internal
 
 using internal::CheckedNumeric;
+using internal::IsValidForType;
+using internal::ValueOrDieForType;
+using internal::ValueOrDefaultForType;
+using internal::MakeCheckedNum;
+using internal::CheckMax;
+using internal::CheckMin;
+using internal::CheckAdd;
+using internal::CheckSub;
+using internal::CheckMul;
+using internal::CheckDiv;
+using internal::CheckMod;
+using internal::CheckLsh;
+using internal::CheckRsh;
+using internal::CheckAnd;
+using internal::CheckOr;
+using internal::CheckXor;
 
 }  // namespace base
 
diff --git a/src/base/numerics/safe_math_impl.h b/src/base/numerics/safe_math_impl.h
index 94ae894..ae0a5b1 100644
--- a/src/base/numerics/safe_math_impl.h
+++ b/src/base/numerics/safe_math_impl.h
@@ -23,93 +23,23 @@ namespace internal {
 // but it may not be fast. This code could be split based on
 // platform/architecture and replaced with potentially faster implementations.
 
-// Integer promotion templates used by the portable checked integer arithmetic.
-template <size_t Size, bool IsSigned>
-struct IntegerForSizeAndSign;
-template <>
-struct IntegerForSizeAndSign<1, true> {
-  typedef int8_t type;
-};
-template <>
-struct IntegerForSizeAndSign<1, false> {
-  typedef uint8_t type;
-};
-template <>
-struct IntegerForSizeAndSign<2, true> {
-  typedef int16_t type;
-};
-template <>
-struct IntegerForSizeAndSign<2, false> {
-  typedef uint16_t type;
-};
-template <>
-struct IntegerForSizeAndSign<4, true> {
-  typedef int32_t type;
-};
-template <>
-struct IntegerForSizeAndSign<4, false> {
-  typedef uint32_t type;
-};
-template <>
-struct IntegerForSizeAndSign<8, true> {
-  typedef int64_t type;
-};
-template <>
-struct IntegerForSizeAndSign<8, false> {
-  typedef uint64_t type;
-};
-
-// WARNING: We have no IntegerForSizeAndSign<16, *>. If we ever add one to
-// support 128-bit math, then the ArithmeticPromotion template below will need
-// to be updated (or more likely replaced with a decltype expression).
-
-template <typename Integer>
-struct UnsignedIntegerForSize {
-  typedef typename std::enable_if<
-      std::numeric_limits<Integer>::is_integer,
-      typename IntegerForSizeAndSign<sizeof(Integer), false>::type>::type type;
-};
-
-template <typename Integer>
-struct SignedIntegerForSize {
-  typedef typename std::enable_if<
-      std::numeric_limits<Integer>::is_integer,
-      typename IntegerForSizeAndSign<sizeof(Integer), true>::type>::type type;
-};
-
-template <typename Integer>
-struct TwiceWiderInteger {
-  typedef typename std::enable_if<
-      std::numeric_limits<Integer>::is_integer,
-      typename IntegerForSizeAndSign<
-          sizeof(Integer) * 2,
-          std::numeric_limits<Integer>::is_signed>::type>::type type;
-};
-
-template <typename Integer>
-struct PositionOfSignBit {
-  static const typename std::enable_if<std::numeric_limits<Integer>::is_integer,
-                                       size_t>::type value =
-      CHAR_BIT * sizeof(Integer) - 1;
-};
-
 // This is used for UnsignedAbs, where we need to support floating-point
 // template instantiations even though we don't actually support the operations.
-// However, there is no corresponding implementation of e.g. CheckedUnsignedAbs,
+// However, there is no corresponding implementation of e.g. SafeUnsignedAbs,
 // so the float versions will not compile.
 template <typename Numeric,
-          bool IsInteger = std::numeric_limits<Numeric>::is_integer,
-          bool IsFloat = std::numeric_limits<Numeric>::is_iec559>
+          bool IsInteger = std::is_integral<Numeric>::value,
+          bool IsFloat = std::is_floating_point<Numeric>::value>
 struct UnsignedOrFloatForSize;
 
 template <typename Numeric>
 struct UnsignedOrFloatForSize<Numeric, true, false> {
-  typedef typename UnsignedIntegerForSize<Numeric>::type type;
+  using type = typename std::make_unsigned<Numeric>::type;
 };
 
 template <typename Numeric>
 struct UnsignedOrFloatForSize<Numeric, false, true> {
-  typedef Numeric type;
+  using type = Numeric;
 };
 
 // Helper templates for integer manipulations.
@@ -117,7 +47,7 @@ struct UnsignedOrFloatForSize<Numeric, false, true> {
 template <typename T>
 constexpr bool HasSignBit(T x) {
   // Cast to unsigned since right shift on signed is undefined.
-  return !!(static_cast<typename UnsignedIntegerForSize<T>::type>(x) >>
+  return !!(static_cast<typename std::make_unsigned<T>::type>(x) >>
             PositionOfSignBit<T>::value);
 }
 
@@ -127,244 +57,550 @@ constexpr T BinaryComplement(T x) {
   return static_cast<T>(~x);
 }
 
-// Here are the actual portable checked integer math implementations.
-// TODO(jschuh): Break this code out from the enable_if pattern and find a clean
-// way to coalesce things into the CheckedNumericState specializations below.
-
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer, T>::type
-CheckedAdd(T x, T y, RangeConstraint* validity) {
+// Probe for builtin math overflow support on Clang and version check on GCC.
+#if defined(__has_builtin)
+#define USE_OVERFLOW_BUILTINS (__has_builtin(__builtin_add_overflow))
+#elif defined(__GNUC__)
+#define USE_OVERFLOW_BUILTINS (__GNUC__ >= 5)
+#else
+#define USE_OVERFLOW_BUILTINS (0)
+#endif
+
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+bool CheckedAddImpl(T x, T y, T* result) {
   // Since the value of x+y is undefined if we have a signed type, we compute
   // it using the unsigned type of the same size.
-  typedef typename UnsignedIntegerForSize<T>::type UnsignedDst;
+  using UnsignedDst = typename std::make_unsigned<T>::type;
   UnsignedDst ux = static_cast<UnsignedDst>(x);
   UnsignedDst uy = static_cast<UnsignedDst>(y);
   UnsignedDst uresult = static_cast<UnsignedDst>(ux + uy);
+  *result = static_cast<T>(uresult);
   // Addition is valid if the sign of (x + y) is equal to either that of x or
   // that of y.
-  if (std::numeric_limits<T>::is_signed) {
-    if (HasSignBit(BinaryComplement(
-            static_cast<UnsignedDst>((uresult ^ ux) & (uresult ^ uy))))) {
-      *validity = RANGE_VALID;
-    } else {  // Direction of wrap is inverse of result sign.
-      *validity = HasSignBit(uresult) ? RANGE_OVERFLOW : RANGE_UNDERFLOW;
+  return (std::is_signed<T>::value)
+             ? HasSignBit(BinaryComplement(
+                   static_cast<UnsignedDst>((uresult ^ ux) & (uresult ^ uy))))
+             : (BinaryComplement(x) >=
+                y);  // Unsigned is either valid or underflow.
+}
+
+template <typename T, typename U, class Enable = void>
+struct CheckedAddOp {};
+
+template <typename T, typename U>
+struct CheckedAddOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = typename MaxExponentPromotion<T, U>::type;
+  template <typename V>
+  static bool Do(T x, U y, V* result) {
+#if USE_OVERFLOW_BUILTINS
+    return !__builtin_add_overflow(x, y, result);
+#else
+    using Promotion = typename BigEnoughPromotion<T, U>::type;
+    Promotion presult;
+    // Fail if either operand is out of range for the promoted type.
+    // TODO(jschuh): This could be made to work for a broader range of values.
+    bool is_valid = IsValueInRangeForNumericType<Promotion>(x) &&
+                    IsValueInRangeForNumericType<Promotion>(y);
+
+    if (IsIntegerArithmeticSafe<Promotion, T, U>::value) {
+      presult = static_cast<Promotion>(x) + static_cast<Promotion>(y);
+    } else {
+      is_valid &= CheckedAddImpl(static_cast<Promotion>(x),
+                                 static_cast<Promotion>(y), &presult);
     }
-  } else {  // Unsigned is either valid or overflow.
-    *validity = BinaryComplement(x) >= y ? RANGE_VALID : RANGE_OVERFLOW;
+    *result = static_cast<V>(presult);
+    return is_valid && IsValueInRangeForNumericType<V>(presult);
+#endif
   }
-  return static_cast<T>(uresult);
-}
+};
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer, T>::type
-CheckedSub(T x, T y, RangeConstraint* validity) {
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+bool CheckedSubImpl(T x, T y, T* result) {
   // Since the value of x+y is undefined if we have a signed type, we compute
   // it using the unsigned type of the same size.
-  typedef typename UnsignedIntegerForSize<T>::type UnsignedDst;
+  using UnsignedDst = typename std::make_unsigned<T>::type;
   UnsignedDst ux = static_cast<UnsignedDst>(x);
   UnsignedDst uy = static_cast<UnsignedDst>(y);
   UnsignedDst uresult = static_cast<UnsignedDst>(ux - uy);
+  *result = static_cast<T>(uresult);
   // Subtraction is valid if either x and y have same sign, or (x-y) and x have
   // the same sign.
-  if (std::numeric_limits<T>::is_signed) {
-    if (HasSignBit(BinaryComplement(
-            static_cast<UnsignedDst>((uresult ^ ux) & (ux ^ uy))))) {
-      *validity = RANGE_VALID;
-    } else {  // Direction of wrap is inverse of result sign.
-      *validity = HasSignBit(uresult) ? RANGE_OVERFLOW : RANGE_UNDERFLOW;
+  return (std::is_signed<T>::value)
+             ? HasSignBit(BinaryComplement(
+                   static_cast<UnsignedDst>((uresult ^ ux) & (ux ^ uy))))
+             : (x >= y);
+}
+
+template <typename T, typename U, class Enable = void>
+struct CheckedSubOp {};
+
+template <typename T, typename U>
+struct CheckedSubOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = typename MaxExponentPromotion<T, U>::type;
+  template <typename V>
+  static bool Do(T x, U y, V* result) {
+#if USE_OVERFLOW_BUILTINS
+    return !__builtin_sub_overflow(x, y, result);
+#else
+    using Promotion = typename BigEnoughPromotion<T, U>::type;
+    Promotion presult;
+    // Fail if either operand is out of range for the promoted type.
+    // TODO(jschuh): This could be made to work for a broader range of values.
+    bool is_valid = IsValueInRangeForNumericType<Promotion>(x) &&
+                    IsValueInRangeForNumericType<Promotion>(y);
+
+    if (IsIntegerArithmeticSafe<Promotion, T, U>::value) {
+      presult = static_cast<Promotion>(x) - static_cast<Promotion>(y);
+    } else {
+      is_valid &= CheckedSubImpl(static_cast<Promotion>(x),
+                                 static_cast<Promotion>(y), &presult);
     }
-  } else {  // Unsigned is either valid or underflow.
-    *validity = x >= y ? RANGE_VALID : RANGE_UNDERFLOW;
+    *result = static_cast<V>(presult);
+    return is_valid && IsValueInRangeForNumericType<V>(presult);
+#endif
   }
-  return static_cast<T>(uresult);
-}
+};
 
 // Integer multiplication is a bit complicated. In the fast case we just
 // we just promote to a twice wider type, and range check the result. In the
 // slow case we need to manually check that the result won't be truncated by
 // checking with division against the appropriate bound.
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            sizeof(T) * 2 <= sizeof(uintmax_t),
-                        T>::type
-CheckedMul(T x, T y, RangeConstraint* validity) {
-  typedef typename TwiceWiderInteger<T>::type IntermediateType;
+template <typename T,
+          typename std::enable_if<
+              std::is_integral<T>::value &&
+              ((IntegerBitsPlusSign<T>::value * 2) <=
+               IntegerBitsPlusSign<intmax_t>::value)>::type* = nullptr>
+bool CheckedMulImpl(T x, T y, T* result) {
+  using IntermediateType = typename TwiceWiderInteger<T>::type;
   IntermediateType tmp =
       static_cast<IntermediateType>(x) * static_cast<IntermediateType>(y);
-  *validity = DstRangeRelationToSrcRange<T>(tmp);
-  return static_cast<T>(tmp);
+  *result = static_cast<T>(tmp);
+  return DstRangeRelationToSrcRange<T>(tmp) == RANGE_VALID;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            std::numeric_limits<T>::is_signed &&
-                            (sizeof(T) * 2 > sizeof(uintmax_t)),
-                        T>::type
-CheckedMul(T x, T y, RangeConstraint* validity) {
-  // If either side is zero then the result will be zero.
-  if (!x || !y) {
-    *validity = RANGE_VALID;
-    return static_cast<T>(0);
-
-  } else if (x > 0) {
-    if (y > 0)
-      *validity =
-          x <= std::numeric_limits<T>::max() / y ? RANGE_VALID : RANGE_OVERFLOW;
-    else
-      *validity = y >= std::numeric_limits<T>::min() / x ? RANGE_VALID
-                                                         : RANGE_UNDERFLOW;
-
-  } else {
-    if (y > 0)
-      *validity = x >= std::numeric_limits<T>::min() / y ? RANGE_VALID
-                                                         : RANGE_UNDERFLOW;
-    else
-      *validity =
-          y >= std::numeric_limits<T>::max() / x ? RANGE_VALID : RANGE_OVERFLOW;
+template <typename T,
+          typename std::enable_if<
+              std::is_integral<T>::value && std::is_signed<T>::value &&
+              ((IntegerBitsPlusSign<T>::value * 2) >
+               IntegerBitsPlusSign<intmax_t>::value)>::type* = nullptr>
+bool CheckedMulImpl(T x, T y, T* result) {
+  if (x && y) {
+    if (x > 0) {
+      if (y > 0) {
+        if (x > std::numeric_limits<T>::max() / y)
+          return false;
+      } else {
+        if (y < std::numeric_limits<T>::lowest() / x)
+          return false;
+      }
+    } else {
+      if (y > 0) {
+        if (x < std::numeric_limits<T>::lowest() / y)
+          return false;
+      } else {
+        if (y < std::numeric_limits<T>::max() / x)
+          return false;
+      }
+    }
   }
-
-  return static_cast<T>(*validity == RANGE_VALID ? x * y : 0);
+  *result = x * y;
+  return true;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            !std::numeric_limits<T>::is_signed &&
-                            (sizeof(T) * 2 > sizeof(uintmax_t)),
-                        T>::type
-CheckedMul(T x, T y, RangeConstraint* validity) {
-  *validity = (y == 0 || x <= std::numeric_limits<T>::max() / y)
-                  ? RANGE_VALID
-                  : RANGE_OVERFLOW;
-  return static_cast<T>(*validity == RANGE_VALID ? x * y : 0);
+template <typename T,
+          typename std::enable_if<
+              std::is_integral<T>::value && !std::is_signed<T>::value &&
+              ((IntegerBitsPlusSign<T>::value * 2) >
+               IntegerBitsPlusSign<uintmax_t>::value)>::type* = nullptr>
+bool CheckedMulImpl(T x, T y, T* result) {
+  *result = x * y;
+  return (y == 0 || x <= std::numeric_limits<T>::max() / y);
 }
 
-// Division just requires a check for an invalid negation on signed min/-1.
-template <typename T>
-T CheckedDiv(T x,
-             T y,
-             RangeConstraint* validity,
-             typename std::enable_if<std::numeric_limits<T>::is_integer,
-                                     int>::type = 0) {
-  if (std::numeric_limits<T>::is_signed && x == std::numeric_limits<T>::min() &&
-      y == static_cast<T>(-1)) {
-    *validity = RANGE_OVERFLOW;
-    return std::numeric_limits<T>::min();
+template <typename T, typename U, class Enable = void>
+struct CheckedMulOp {};
+
+template <typename T, typename U>
+struct CheckedMulOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = typename MaxExponentPromotion<T, U>::type;
+  template <typename V>
+  static bool Do(T x, U y, V* result) {
+#if USE_OVERFLOW_BUILTINS
+#if defined(__clang__)
+    // TODO(jschuh): Get the Clang runtime library issues sorted out so we can
+    // support full-width, mixed-sign multiply builtins.
+    // https://crbug.com/613003
+    static const bool kUseMaxInt =
+        // Narrower type than uintptr_t is always safe.
+        std::numeric_limits<__typeof__(x * y)>::digits <
+            std::numeric_limits<intptr_t>::digits ||
+        // Safe for intptr_t and uintptr_t if the sign matches.
+        (IntegerBitsPlusSign<__typeof__(x * y)>::value ==
+             IntegerBitsPlusSign<intptr_t>::value &&
+         std::is_signed<T>::value == std::is_signed<U>::value);
+#else
+    static const bool kUseMaxInt = true;
+#endif
+    if (kUseMaxInt)
+      return !__builtin_mul_overflow(x, y, result);
+#endif
+    using Promotion = typename BigEnoughPromotion<T, U>::type;
+    Promotion presult;
+    // Fail if either operand is out of range for the promoted type.
+    // TODO(jschuh): This could be made to work for a broader range of values.
+    bool is_valid = IsValueInRangeForNumericType<Promotion>(x) &&
+                    IsValueInRangeForNumericType<Promotion>(y);
+
+    if (IsIntegerArithmeticSafe<Promotion, T, U>::value) {
+      presult = static_cast<Promotion>(x) * static_cast<Promotion>(y);
+    } else {
+      is_valid &= CheckedMulImpl(static_cast<Promotion>(x),
+                                 static_cast<Promotion>(y), &presult);
+    }
+    *result = static_cast<V>(presult);
+    return is_valid && IsValueInRangeForNumericType<V>(presult);
   }
+};
 
-  *validity = RANGE_VALID;
-  return static_cast<T>(x / y);
+// Avoid poluting the namespace once we're done with the macro.
+#undef USE_OVERFLOW_BUILTINS
+
+// Division just requires a check for a zero denominator or an invalid negation
+// on signed min/-1.
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+bool CheckedDivImpl(T x, T y, T* result) {
+  if (y && (!std::is_signed<T>::value ||
+            x != std::numeric_limits<T>::lowest() || y != static_cast<T>(-1))) {
+    *result = x / y;
+    return true;
+  }
+  return false;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            std::numeric_limits<T>::is_signed,
-                        T>::type
-CheckedMod(T x, T y, RangeConstraint* validity) {
-  *validity = y > 0 ? RANGE_VALID : RANGE_INVALID;
-  return static_cast<T>(*validity == RANGE_VALID ? x % y: 0);
-}
+template <typename T, typename U, class Enable = void>
+struct CheckedDivOp {};
+
+template <typename T, typename U>
+struct CheckedDivOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = typename MaxExponentPromotion<T, U>::type;
+  template <typename V>
+  static bool Do(T x, U y, V* result) {
+    using Promotion = typename BigEnoughPromotion<T, U>::type;
+    Promotion presult;
+    // Fail if either operand is out of range for the promoted type.
+    // TODO(jschuh): This could be made to work for a broader range of values.
+    bool is_valid = IsValueInRangeForNumericType<Promotion>(x) &&
+                    IsValueInRangeForNumericType<Promotion>(y);
+    is_valid &= CheckedDivImpl(static_cast<Promotion>(x),
+                               static_cast<Promotion>(y), &presult);
+    *result = static_cast<V>(presult);
+    return is_valid && IsValueInRangeForNumericType<V>(presult);
+  }
+};
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            !std::numeric_limits<T>::is_signed,
-                        T>::type
-CheckedMod(T x, T y, RangeConstraint* validity) {
-  *validity = RANGE_VALID;
-  return static_cast<T>(x % y);
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+bool CheckedModImpl(T x, T y, T* result) {
+  if (y > 0) {
+    *result = static_cast<T>(x % y);
+    return true;
+  }
+  return false;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            std::numeric_limits<T>::is_signed,
-                        T>::type
-CheckedNeg(T value, RangeConstraint* validity) {
-  *validity =
-      value != std::numeric_limits<T>::min() ? RANGE_VALID : RANGE_OVERFLOW;
+template <typename T, typename U, class Enable = void>
+struct CheckedModOp {};
+
+template <typename T, typename U>
+struct CheckedModOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = typename MaxExponentPromotion<T, U>::type;
+  template <typename V>
+  static bool Do(T x, U y, V* result) {
+    using Promotion = typename BigEnoughPromotion<T, U>::type;
+    Promotion presult;
+    bool is_valid = CheckedModImpl(static_cast<Promotion>(x),
+                                   static_cast<Promotion>(y), &presult);
+    *result = static_cast<V>(presult);
+    return is_valid && IsValueInRangeForNumericType<V>(presult);
+  }
+};
+
+template <typename T, typename U, class Enable = void>
+struct CheckedLshOp {};
+
+// Left shift. Shifts less than 0 or greater than or equal to the number
+// of bits in the promoted type are undefined. Shifts of negative values
+// are undefined. Otherwise it is defined when the result fits.
+template <typename T, typename U>
+struct CheckedLshOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = T;
+  template <typename V>
+  static bool Do(T x, U shift, V* result) {
+    using ShiftType = typename std::make_unsigned<T>::type;
+    static const ShiftType kBitWidth = IntegerBitsPlusSign<T>::value;
+    const ShiftType real_shift = static_cast<ShiftType>(shift);
+    // Signed shift is not legal on negative values.
+    if (!IsValueNegative(x) && real_shift < kBitWidth) {
+      // Just use a multiplication because it's easy.
+      // TODO(jschuh): This could probably be made more efficient.
+      if (!std::is_signed<T>::value || real_shift != kBitWidth - 1)
+        return CheckedMulOp<T, T>::Do(x, static_cast<T>(1) << shift, result);
+      return !x;  // Special case zero for a full width signed shift.
+    }
+    return false;
+  }
+};
+
+template <typename T, typename U, class Enable = void>
+struct CheckedRshOp {};
+
+// Right shift. Shifts less than 0 or greater than or equal to the number
+// of bits in the promoted type are undefined. Otherwise, it is always defined,
+// but a right shift of a negative value is implementation-dependent.
+template <typename T, typename U>
+struct CheckedRshOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = T;
+  template <typename V = result_type>
+  static bool Do(T x, U shift, V* result) {
+    // Use the type conversion push negative values out of range.
+    using ShiftType = typename std::make_unsigned<T>::type;
+    if (static_cast<ShiftType>(shift) < IntegerBitsPlusSign<T>::value) {
+      T tmp = x >> shift;
+      *result = static_cast<V>(tmp);
+      return IsValueInRangeForNumericType<V>(tmp);
+    }
+    return false;
+  }
+};
+
+template <typename T, typename U, class Enable = void>
+struct CheckedAndOp {};
+
+// For simplicity we support only unsigned integer results.
+template <typename T, typename U>
+struct CheckedAndOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = typename std::make_unsigned<
+      typename MaxExponentPromotion<T, U>::type>::type;
+  template <typename V = result_type>
+  static bool Do(T x, U y, V* result) {
+    result_type tmp = static_cast<result_type>(x) & static_cast<result_type>(y);
+    *result = static_cast<V>(tmp);
+    return IsValueInRangeForNumericType<V>(tmp);
+  }
+};
+
+template <typename T, typename U, class Enable = void>
+struct CheckedOrOp {};
+
+// For simplicity we support only unsigned integers.
+template <typename T, typename U>
+struct CheckedOrOp<T,
+                   U,
+                   typename std::enable_if<std::is_integral<T>::value &&
+                                           std::is_integral<U>::value>::type> {
+  using result_type = typename std::make_unsigned<
+      typename MaxExponentPromotion<T, U>::type>::type;
+  template <typename V = result_type>
+  static bool Do(T x, U y, V* result) {
+    result_type tmp = static_cast<result_type>(x) | static_cast<result_type>(y);
+    *result = static_cast<V>(tmp);
+    return IsValueInRangeForNumericType<V>(tmp);
+  }
+};
+
+template <typename T, typename U, class Enable = void>
+struct CheckedXorOp {};
+
+// For simplicity we support only unsigned integers.
+template <typename T, typename U>
+struct CheckedXorOp<T,
+                    U,
+                    typename std::enable_if<std::is_integral<T>::value &&
+                                            std::is_integral<U>::value>::type> {
+  using result_type = typename std::make_unsigned<
+      typename MaxExponentPromotion<T, U>::type>::type;
+  template <typename V = result_type>
+  static bool Do(T x, U y, V* result) {
+    result_type tmp = static_cast<result_type>(x) ^ static_cast<result_type>(y);
+    *result = static_cast<V>(tmp);
+    return IsValueInRangeForNumericType<V>(tmp);
+  }
+};
+
+// Max doesn't really need to be implemented this way because it can't fail,
+// but it makes the code much cleaner to use the MathOp wrappers.
+template <typename T, typename U, class Enable = void>
+struct CheckedMaxOp {};
+
+template <typename T, typename U>
+struct CheckedMaxOp<
+    T,
+    U,
+    typename std::enable_if<std::is_arithmetic<T>::value &&
+                            std::is_arithmetic<U>::value>::type> {
+  using result_type = typename MaxExponentPromotion<T, U>::type;
+  template <typename V = result_type>
+  static bool Do(T x, U y, V* result) {
+    *result = IsGreater<T, U>::Test(x, y) ? static_cast<result_type>(x)
+                                          : static_cast<result_type>(y);
+    return true;
+  }
+};
+
+// Min doesn't really need to be implemented this way because it can't fail,
+// but it makes the code much cleaner to use the MathOp wrappers.
+template <typename T, typename U, class Enable = void>
+struct CheckedMinOp {};
+
+template <typename T, typename U>
+struct CheckedMinOp<
+    T,
+    U,
+    typename std::enable_if<std::is_arithmetic<T>::value &&
+                            std::is_arithmetic<U>::value>::type> {
+  using result_type = typename LowestValuePromotion<T, U>::type;
+  template <typename V = result_type>
+  static bool Do(T x, U y, V* result) {
+    *result = IsLess<T, U>::Test(x, y) ? static_cast<result_type>(x)
+                                       : static_cast<result_type>(y);
+    return true;
+  }
+};
+
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value &&
+                                  std::is_signed<T>::value>::type* = nullptr>
+bool CheckedNeg(T value, T* result) {
   // The negation of signed min is min, so catch that one.
-  return static_cast<T>(*validity == RANGE_VALID ? -value : 0);
+  if (value != std::numeric_limits<T>::lowest()) {
+    *result = static_cast<T>(-value);
+    return true;
+  }
+  return false;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            !std::numeric_limits<T>::is_signed,
-                        T>::type
-CheckedNeg(T value, RangeConstraint* validity) {
-  // The only legal unsigned negation is zero.
-  *validity = value ? RANGE_UNDERFLOW : RANGE_VALID;
-  return static_cast<T>(*validity == RANGE_VALID ?
-      -static_cast<typename SignedIntegerForSize<T>::type>(value) : 0);
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value &&
+                                  !std::is_signed<T>::value>::type* = nullptr>
+bool CheckedNeg(T value, T* result) {
+  if (!value) {
+    *result = static_cast<T>(0);
+    return true;
+  }
+  return false;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            std::numeric_limits<T>::is_signed,
-                        T>::type
-CheckedAbs(T value, RangeConstraint* validity) {
-  *validity =
-      value != std::numeric_limits<T>::min() ? RANGE_VALID : RANGE_OVERFLOW;
-  return static_cast<T>(*validity == RANGE_VALID ? std::abs(value) : 0);
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value &&
+                                  !std::is_signed<T>::value>::type* = nullptr>
+bool CheckedInv(T value, T* result) {
+  *result = ~value;
+  return true;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            !std::numeric_limits<T>::is_signed,
-                        T>::type
-CheckedAbs(T value, RangeConstraint* validity) {
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value &&
+                                  std::is_signed<T>::value>::type* = nullptr>
+bool CheckedAbs(T value, T* result) {
+  if (value != std::numeric_limits<T>::lowest()) {
+    *result = std::abs(value);
+    return true;
+  }
+  return false;
+}
+
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value &&
+                                  !std::is_signed<T>::value>::type* = nullptr>
+bool CheckedAbs(T value, T* result) {
   // T is unsigned, so |value| must already be positive.
-  *validity = RANGE_VALID;
-  return value;
+  *result = value;
+  return true;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            std::numeric_limits<T>::is_signed,
-                        typename UnsignedIntegerForSize<T>::type>::type
-CheckedUnsignedAbs(T value) {
-  typedef typename UnsignedIntegerForSize<T>::type UnsignedT;
-  return value == std::numeric_limits<T>::min()
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value &&
+                                  std::is_signed<T>::value>::type* = nullptr>
+constexpr typename std::make_unsigned<T>::type SafeUnsignedAbs(T value) {
+  using UnsignedT = typename std::make_unsigned<T>::type;
+  return value == std::numeric_limits<T>::lowest()
              ? static_cast<UnsignedT>(std::numeric_limits<T>::max()) + 1
              : static_cast<UnsignedT>(std::abs(value));
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_integer &&
-                            !std::numeric_limits<T>::is_signed,
-                        T>::type
-CheckedUnsignedAbs(T value) {
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value &&
+                                  !std::is_signed<T>::value>::type* = nullptr>
+constexpr T SafeUnsignedAbs(T value) {
   // T is unsigned, so |value| must already be positive.
   return static_cast<T>(value);
 }
 
-// These are the floating point stubs that the compiler needs to see. Only the
-// negation operation is ever called.
-#define BASE_FLOAT_ARITHMETIC_STUBS(NAME)                             \
-  template <typename T>                                               \
-  typename std::enable_if<std::numeric_limits<T>::is_iec559, T>::type \
-      Checked##NAME(T, T, RangeConstraint*) {                         \
-    NOTREACHED();                                                     \
-    return static_cast<T>(0);                                         \
-  }
-
-BASE_FLOAT_ARITHMETIC_STUBS(Add)
-BASE_FLOAT_ARITHMETIC_STUBS(Sub)
-BASE_FLOAT_ARITHMETIC_STUBS(Mul)
-BASE_FLOAT_ARITHMETIC_STUBS(Div)
-BASE_FLOAT_ARITHMETIC_STUBS(Mod)
-
-#undef BASE_FLOAT_ARITHMETIC_STUBS
-
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_iec559, T>::type CheckedNeg(
-    T value,
-    RangeConstraint*) {
-  return static_cast<T>(-value);
+// This is just boilerplate that wraps the standard floating point arithmetic.
+// A macro isn't the nicest solution, but it beats rewriting these repeatedly.
+#define BASE_FLOAT_ARITHMETIC_OPS(NAME, OP)                                    \
+  template <typename T, typename U>                                            \
+  struct Checked##NAME##Op<                                                    \
+      T, U, typename std::enable_if<std::is_floating_point<T>::value ||        \
+                                    std::is_floating_point<U>::value>::type> { \
+    using result_type = typename MaxExponentPromotion<T, U>::type;             \
+    template <typename V>                                                      \
+    static bool Do(T x, U y, V* result) {                                      \
+      using Promotion = typename MaxExponentPromotion<T, U>::type;             \
+      Promotion presult = x OP y;                                              \
+      *result = static_cast<V>(presult);                                       \
+      return IsValueInRangeForNumericType<V>(presult);                         \
+    }                                                                          \
+  };
+
+BASE_FLOAT_ARITHMETIC_OPS(Add, +)
+BASE_FLOAT_ARITHMETIC_OPS(Sub, -)
+BASE_FLOAT_ARITHMETIC_OPS(Mul, *)
+BASE_FLOAT_ARITHMETIC_OPS(Div, /)
+
+#undef BASE_FLOAT_ARITHMETIC_OPS
+
+template <
+    typename T,
+    typename std::enable_if<std::is_floating_point<T>::value>::type* = nullptr>
+bool CheckedNeg(T value, T* result) {
+  *result = static_cast<T>(-value);
+  return true;
 }
 
-template <typename T>
-typename std::enable_if<std::numeric_limits<T>::is_iec559, T>::type CheckedAbs(
-    T value,
-    RangeConstraint*) {
-  return static_cast<T>(std::abs(value));
+template <
+    typename T,
+    typename std::enable_if<std::is_floating_point<T>::value>::type* = nullptr>
+bool CheckedAbs(T value, T* result) {
+  *result = static_cast<T>(std::abs(value));
+  return true;
 }
 
 // Floats carry around their validity state with them, but integers do not. So,
@@ -379,10 +615,10 @@ enum NumericRepresentation {
 template <typename NumericType>
 struct GetNumericRepresentation {
   static const NumericRepresentation value =
-      std::numeric_limits<NumericType>::is_integer
+      std::is_integral<NumericType>::value
           ? NUMERIC_INTEGER
-          : (std::numeric_limits<NumericType>::is_iec559 ? NUMERIC_FLOATING
-                                                         : NUMERIC_UNKNOWN);
+          : (std::is_floating_point<NumericType>::value ? NUMERIC_FLOATING
+                                                        : NUMERIC_UNKNOWN);
 };
 
 template <typename T, NumericRepresentation type =
@@ -393,41 +629,48 @@ class CheckedNumericState {};
 template <typename T>
 class CheckedNumericState<T, NUMERIC_INTEGER> {
  private:
+  // is_valid_ precedes value_ because member intializers in the constructors
+  // are evaluated in field order, and is_valid_ must be read when initializing
+  // value_.
+  bool is_valid_;
   T value_;
-  RangeConstraint validity_ : CHAR_BIT;  // Actually requires only two bits.
+
+  // Ensures that a type conversion does not trigger undefined behavior.
+  template <typename Src>
+  static constexpr T WellDefinedConversionOrZero(const Src value,
+                                                 const bool is_valid) {
+    using SrcType = typename internal::UnderlyingType<Src>::type;
+    return (std::is_integral<SrcType>::value || is_valid)
+               ? static_cast<T>(value)
+               : static_cast<T>(0);
+  }
 
  public:
   template <typename Src, NumericRepresentation type>
   friend class CheckedNumericState;
 
-  CheckedNumericState() : value_(0), validity_(RANGE_VALID) {}
+  constexpr CheckedNumericState() : is_valid_(true), value_(0) {}
 
   template <typename Src>
-  CheckedNumericState(Src value, RangeConstraint validity)
-      : value_(static_cast<T>(value)),
-        validity_(GetRangeConstraint(validity |
-                                     DstRangeRelationToSrcRange<T>(value))) {
-    static_assert(std::numeric_limits<Src>::is_specialized,
-                  "Argument must be numeric.");
+  constexpr CheckedNumericState(Src value, bool is_valid)
+      : is_valid_(is_valid && IsValueInRangeForNumericType<T>(value)),
+        value_(WellDefinedConversionOrZero(value, is_valid_)) {
+    static_assert(std::is_arithmetic<Src>::value, "Argument must be numeric.");
   }
 
   // Copy constructor.
   template <typename Src>
-  CheckedNumericState(const CheckedNumericState<Src>& rhs)
-      : value_(static_cast<T>(rhs.value())),
-        validity_(GetRangeConstraint(
-            rhs.validity() | DstRangeRelationToSrcRange<T>(rhs.value()))) {}
+  constexpr CheckedNumericState(const CheckedNumericState<Src>& rhs)
+      : is_valid_(rhs.IsValid()),
+        value_(WellDefinedConversionOrZero(rhs.value(), is_valid_)) {}
 
   template <typename Src>
-  explicit CheckedNumericState(
-      Src value,
-      typename std::enable_if<std::numeric_limits<Src>::is_specialized,
-                              int>::type = 0)
-      : value_(static_cast<T>(value)),
-        validity_(DstRangeRelationToSrcRange<T>(value)) {}
-
-  RangeConstraint validity() const { return validity_; }
-  T value() const { return value_; }
+  constexpr explicit CheckedNumericState(Src value)
+      : is_valid_(IsValueInRangeForNumericType<T>(value)),
+        value_(WellDefinedConversionOrZero(value, is_valid_)) {}
+
+  constexpr bool is_valid() const { return is_valid_; }
+  constexpr T value() const { return value_; }
 };
 
 // Floating points maintain their own validity, but need translation wrappers.
@@ -436,94 +679,58 @@ class CheckedNumericState<T, NUMERIC_FLOATING> {
  private:
   T value_;
 
+  // Ensures that a type conversion does not trigger undefined behavior.
+  template <typename Src>
+  static constexpr T WellDefinedConversionOrNaN(const Src value,
+                                                const bool is_valid) {
+    using SrcType = typename internal::UnderlyingType<Src>::type;
+    return (StaticDstRangeRelationToSrcRange<T, SrcType>::value ==
+                NUMERIC_RANGE_CONTAINED ||
+            is_valid)
+               ? static_cast<T>(value)
+               : std::numeric_limits<T>::quiet_NaN();
+  }
+
  public:
   template <typename Src, NumericRepresentation type>
   friend class CheckedNumericState;
 
-  CheckedNumericState() : value_(0.0) {}
+  constexpr CheckedNumericState() : value_(0.0) {}
 
   template <typename Src>
-  CheckedNumericState(
-      Src value,
-      RangeConstraint validity,
-      typename std::enable_if<std::numeric_limits<Src>::is_integer, int>::type =
-          0) {
-    switch (DstRangeRelationToSrcRange<T>(value)) {
-      case RANGE_VALID:
-        value_ = static_cast<T>(value);
-        break;
-
-      case RANGE_UNDERFLOW:
-        value_ = -std::numeric_limits<T>::infinity();
-        break;
-
-      case RANGE_OVERFLOW:
-        value_ = std::numeric_limits<T>::infinity();
-        break;
-
-      case RANGE_INVALID:
-        value_ = std::numeric_limits<T>::quiet_NaN();
-        break;
-
-      default:
-        NOTREACHED();
-    }
-  }
+  constexpr CheckedNumericState(Src value, bool is_valid)
+      : value_(WellDefinedConversionOrNaN(value, is_valid)) {}
 
   template <typename Src>
-  explicit CheckedNumericState(
-      Src value,
-      typename std::enable_if<std::numeric_limits<Src>::is_specialized,
-                              int>::type = 0)
-      : value_(static_cast<T>(value)) {}
+  constexpr explicit CheckedNumericState(Src value)
+      : value_(WellDefinedConversionOrNaN(
+            value,
+            IsValueInRangeForNumericType<T>(value))) {}
 
   // Copy constructor.
   template <typename Src>
-  CheckedNumericState(const CheckedNumericState<Src>& rhs)
-      : value_(static_cast<T>(rhs.value())) {}
-
-  RangeConstraint validity() const {
-    return GetRangeConstraint(value_ <= std::numeric_limits<T>::max(),
-                              value_ >= -std::numeric_limits<T>::max());
+  constexpr CheckedNumericState(const CheckedNumericState<Src>& rhs)
+      : value_(WellDefinedConversionOrNaN(
+            rhs.value(),
+            rhs.is_valid() && IsValueInRangeForNumericType<T>(rhs.value()))) {}
+
+  constexpr bool is_valid() const {
+    // Written this way because std::isfinite is not reliably constexpr.
+    // TODO(jschuh): Fix this if the libraries ever get fixed.
+    return value_ <= std::numeric_limits<T>::max() &&
+           value_ >= std::numeric_limits<T>::lowest();
   }
-  T value() const { return value_; }
-};
-
-// For integers less than 128-bit and floats 32-bit or larger, we have the type
-// with the larger maximum exponent take precedence.
-enum ArithmeticPromotionCategory { LEFT_PROMOTION, RIGHT_PROMOTION };
-
-template <typename Lhs,
-          typename Rhs = Lhs,
-          ArithmeticPromotionCategory Promotion =
-              (MaxExponent<Lhs>::value > MaxExponent<Rhs>::value)
-                  ? LEFT_PROMOTION
-                  : RIGHT_PROMOTION>
-struct ArithmeticPromotion;
-
-template <typename Lhs, typename Rhs>
-struct ArithmeticPromotion<Lhs, Rhs, LEFT_PROMOTION> {
-  typedef Lhs type;
-};
-
-template <typename Lhs, typename Rhs>
-struct ArithmeticPromotion<Lhs, Rhs, RIGHT_PROMOTION> {
-  typedef Rhs type;
+  constexpr T value() const { return value_; }
 };
 
-// We can statically check if operations on the provided types can wrap, so we
-// can skip the checked operations if they're not needed. So, for an integer we
-// care if the destination type preserves the sign and is twice the width of
-// the source.
-template <typename T, typename Lhs, typename Rhs>
-struct IsIntegerArithmeticSafe {
-  static const bool value = !std::numeric_limits<T>::is_iec559 &&
-                            StaticDstRangeRelationToSrcRange<T, Lhs>::value ==
-                                NUMERIC_RANGE_CONTAINED &&
-                            sizeof(T) >= (2 * sizeof(Lhs)) &&
-                            StaticDstRangeRelationToSrcRange<T, Rhs>::value !=
-                                NUMERIC_RANGE_CONTAINED &&
-                            sizeof(T) >= (2 * sizeof(Rhs));
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R>
+struct MathWrapper {
+  using math = M<typename UnderlyingType<L>::type,
+                 typename UnderlyingType<R>::type,
+                 void>;
+  using type = typename math::result_type;
 };
 
 }  // namespace internal
diff --git a/src/base/observer_list.h b/src/base/observer_list.h
index afe1f46..0572ba6 100644
--- a/src/base/observer_list.h
+++ b/src/base/observer_list.h
@@ -11,6 +11,7 @@
 #include <limits>
 #include <vector>
 
+#include "base/gtest_prod_util.h"
 #include "base/logging.h"
 #include "base/macros.h"
 #include "base/memory/weak_ptr.h"
@@ -46,11 +47,14 @@
 //     }
 //
 //     void NotifyFoo() {
-//       FOR_EACH_OBSERVER(Observer, observer_list_, OnFoo(this));
+//       for (auto& observer : observer_list_)
+//         observer.OnFoo(this);
 //     }
 //
 //     void NotifyBar(int x, int y) {
-//       FOR_EACH_OBSERVER(Observer, observer_list_, OnBar(this, x, y));
+//       for (FooList::iterator i = observer_list.begin(),
+//           e = observer_list.end(); i != e; ++i)
+//        i->OnBar(this, x, y);
 //     }
 //
 //    private:
@@ -80,20 +84,66 @@ class ObserverListBase
     NOTIFY_EXISTING_ONLY
   };
 
-  // An iterator class that can be used to access the list of observers.  See
-  // also the FOR_EACH_OBSERVER macro defined below.
-  class Iterator {
+  // An iterator class that can be used to access the list of observers.
+  template <class ContainerType>
+  class Iter {
    public:
-    explicit Iterator(ObserverListBase<ObserverType>* list);
-    ~Iterator();
-    ObserverType* GetNext();
+    Iter();
+    explicit Iter(ContainerType* list);
+    ~Iter();
+
+    // A workaround for C2244. MSVC requires fully qualified type name for
+    // return type on a function definition to match a function declaration.
+    using ThisType =
+        typename ObserverListBase<ObserverType>::template Iter<ContainerType>;
+
+    bool operator==(const Iter& other) const;
+    bool operator!=(const Iter& other) const;
+    ThisType& operator++();
+    ObserverType* operator->() const;
+    ObserverType& operator*() const;
 
    private:
+    FRIEND_TEST_ALL_PREFIXES(ObserverListTest, BasicStdIterator);
+    FRIEND_TEST_ALL_PREFIXES(ObserverListTest, StdIteratorRemoveFront);
+
+    ObserverType* GetCurrent() const;
+    void EnsureValidIndex();
+
+    size_t clamped_max_index() const {
+      return std::min(max_index_, list_->observers_.size());
+    }
+
+    bool is_end() const { return !list_ || index_ == clamped_max_index(); }
+
     WeakPtr<ObserverListBase<ObserverType>> list_;
+    // When initially constructed and each time the iterator is incremented,
+    // |index_| is guaranteed to point to a non-null index if the iterator
+    // has not reached the end of the ObserverList.
     size_t index_;
     size_t max_index_;
   };
 
+  using Iterator = Iter<ObserverListBase<ObserverType>>;
+
+  using iterator = Iter<ObserverListBase<ObserverType>>;
+  iterator begin() {
+    // An optimization: do not involve weak pointers for empty list.
+    // Note: can't use ?: operator here due to some MSVC bug (unit tests fail)
+    if (observers_.empty())
+      return iterator();
+    return iterator(this);
+  }
+  iterator end() { return iterator(); }
+
+  using const_iterator = Iter<const ObserverListBase<ObserverType>>;
+  const_iterator begin() const {
+    if (observers_.empty())
+      return const_iterator();
+    return const_iterator(this);
+  }
+  const_iterator end() const { return const_iterator(); }
+
   ObserverListBase() : notify_depth_(0), type_(NOTIFY_ALL) {}
   explicit ObserverListBase(NotificationType type)
       : notify_depth_(0), type_(type) {}
@@ -124,37 +174,99 @@ class ObserverListBase
   int notify_depth_;
   NotificationType type_;
 
-  friend class ObserverListBase::Iterator;
+  template <class ContainerType>
+  friend class Iter;
 
   DISALLOW_COPY_AND_ASSIGN(ObserverListBase);
 };
 
 template <class ObserverType>
-ObserverListBase<ObserverType>::Iterator::Iterator(
-    ObserverListBase<ObserverType>* list)
-    : list_(list->AsWeakPtr()),
+template <class ContainerType>
+ObserverListBase<ObserverType>::Iter<ContainerType>::Iter()
+    : index_(0), max_index_(0) {}
+
+template <class ObserverType>
+template <class ContainerType>
+ObserverListBase<ObserverType>::Iter<ContainerType>::Iter(ContainerType* list)
+    : list_(const_cast<ObserverListBase<ObserverType>*>(list)->AsWeakPtr()),
       index_(0),
       max_index_(list->type_ == NOTIFY_ALL ? std::numeric_limits<size_t>::max()
                                            : list->observers_.size()) {
+  EnsureValidIndex();
+  DCHECK(list_);
   ++list_->notify_depth_;
 }
 
 template <class ObserverType>
-ObserverListBase<ObserverType>::Iterator::~Iterator() {
-  if (list_.get() && --list_->notify_depth_ == 0)
+template <class ContainerType>
+ObserverListBase<ObserverType>::Iter<ContainerType>::~Iter() {
+  if (list_ && --list_->notify_depth_ == 0)
     list_->Compact();
 }
 
 template <class ObserverType>
-ObserverType* ObserverListBase<ObserverType>::Iterator::GetNext() {
-  if (!list_.get())
+template <class ContainerType>
+bool ObserverListBase<ObserverType>::Iter<ContainerType>::operator==(
+    const Iter& other) const {
+  if (is_end() && other.is_end())
+    return true;
+  return list_.get() == other.list_.get() && index_ == other.index_;
+}
+
+template <class ObserverType>
+template <class ContainerType>
+bool ObserverListBase<ObserverType>::Iter<ContainerType>::operator!=(
+    const Iter& other) const {
+  return !operator==(other);
+}
+
+template <class ObserverType>
+template <class ContainerType>
+typename ObserverListBase<ObserverType>::template Iter<ContainerType>&
+    ObserverListBase<ObserverType>::Iter<ContainerType>::operator++() {
+  if (list_) {
+    ++index_;
+    EnsureValidIndex();
+  }
+  return *this;
+}
+
+template <class ObserverType>
+template <class ContainerType>
+ObserverType* ObserverListBase<ObserverType>::Iter<ContainerType>::operator->()
+    const {
+  ObserverType* current = GetCurrent();
+  DCHECK(current);
+  return current;
+}
+
+template <class ObserverType>
+template <class ContainerType>
+ObserverType& ObserverListBase<ObserverType>::Iter<ContainerType>::operator*()
+    const {
+  ObserverType* current = GetCurrent();
+  DCHECK(current);
+  return *current;
+}
+
+template <class ObserverType>
+template <class ContainerType>
+ObserverType* ObserverListBase<ObserverType>::Iter<ContainerType>::GetCurrent()
+    const {
+  if (!list_)
     return nullptr;
-  ListType& observers = list_->observers_;
-  // Advance if the current element is null
-  size_t max_index = std::min(max_index_, observers.size());
-  while (index_ < max_index && !observers[index_])
+  return index_ < clamped_max_index() ? list_->observers_[index_] : nullptr;
+}
+
+template <class ObserverType>
+template <class ContainerType>
+void ObserverListBase<ObserverType>::Iter<ContainerType>::EnsureValidIndex() {
+  if (!list_)
+    return;
+
+  size_t max_index = clamped_max_index();
+  while (index_ < max_index && !list_->observers_[index_])
     ++index_;
-  return index_ < max_index ? observers[index_++] : nullptr;
 }
 
 template <class ObserverType>
@@ -205,9 +317,8 @@ void ObserverListBase<ObserverType>::Clear() {
 
 template <class ObserverType>
 void ObserverListBase<ObserverType>::Compact() {
-  observers_.erase(
-      std::remove(observers_.begin(), observers_.end(), nullptr),
-      observers_.end());
+  observers_.erase(std::remove(observers_.begin(), observers_.end(), nullptr),
+                   observers_.end());
 }
 
 template <class ObserverType, bool check_empty = false>
@@ -233,17 +344,6 @@ class ObserverList : public ObserverListBase<ObserverType> {
   }
 };
 
-#define FOR_EACH_OBSERVER(ObserverType, observer_list, func)             \
-  do {                                                                   \
-    if ((observer_list).might_have_observers()) {                        \
-      typename base::ObserverListBase<ObserverType>::Iterator            \
-          it_inside_observer_macro(&observer_list);                      \
-      ObserverType* obs;                                                 \
-      while ((obs = it_inside_observer_macro.GetNext()) != nullptr)      \
-        obs->func;                                                       \
-    }                                                                    \
-  } while (0)
-
 }  // namespace base
 
 #endif  // BASE_OBSERVER_LIST_H_
diff --git a/src/base/pending_task.cc b/src/base/pending_task.cc
index 73834bd..cca9ebf 100644
--- a/src/base/pending_task.cc
+++ b/src/base/pending_task.cc
@@ -9,17 +9,16 @@
 namespace base {
 
 PendingTask::PendingTask(const tracked_objects::Location& posted_from,
-                         base::Closure task)
+                         OnceClosure task)
     : base::TrackingInfo(posted_from, TimeTicks()),
       task(std::move(task)),
       posted_from(posted_from),
       sequence_num(0),
       nestable(true),
-      is_high_res(false) {
-}
+      is_high_res(false) {}
 
 PendingTask::PendingTask(const tracked_objects::Location& posted_from,
-                         base::Closure task,
+                         OnceClosure task,
                          TimeTicks delayed_run_time,
                          bool nestable)
     : base::TrackingInfo(posted_from, delayed_run_time),
@@ -27,8 +26,7 @@ PendingTask::PendingTask(const tracked_objects::Location& posted_from,
       posted_from(posted_from),
       sequence_num(0),
       nestable(nestable),
-      is_high_res(false) {
-}
+      is_high_res(false) {}
 
 PendingTask::PendingTask(PendingTask&& other) = default;
 
diff --git a/src/base/pending_task.h b/src/base/pending_task.h
index 5761653..a55fa51 100644
--- a/src/base/pending_task.h
+++ b/src/base/pending_task.h
@@ -18,10 +18,9 @@ namespace base {
 // Contains data about a pending task. Stored in TaskQueue and DelayedTaskQueue
 // for use by classes that queue and execute tasks.
 struct BASE_EXPORT PendingTask : public TrackingInfo {
+  PendingTask(const tracked_objects::Location& posted_from, OnceClosure task);
   PendingTask(const tracked_objects::Location& posted_from,
-              Closure task);
-  PendingTask(const tracked_objects::Location& posted_from,
-              Closure task,
+              OnceClosure task,
               TimeTicks delayed_run_time,
               bool nestable);
   PendingTask(PendingTask&& other);
@@ -33,7 +32,7 @@ struct BASE_EXPORT PendingTask : public TrackingInfo {
   bool operator<(const PendingTask& other) const;
 
   // The task to run.
-  Closure task;
+  OnceClosure task;
 
   // The site this PendingTask was posted from.
   tracked_objects::Location posted_from;
diff --git a/src/base/pickle.cc b/src/base/pickle.cc
index cfb316c..02f39b5 100644
--- a/src/base/pickle.cc
+++ b/src/base/pickle.cc
@@ -233,7 +233,6 @@ void PickleSizer::AddBytes(int length) {
 
 void PickleSizer::AddAttachment() {
   // From IPC::Message::WriteAttachment
-  AddBool();
   AddInt();
 }
 
diff --git a/src/base/process/process.h b/src/base/process/process.h
index 70c8260..5538475 100644
--- a/src/base/process/process.h
+++ b/src/base/process/process.h
@@ -15,8 +15,17 @@
 #include "base/win/scoped_handle.h"
 #endif
 
+#if defined(OS_MACOSX)
+#include "base/feature_list.h"
+#include "base/process/port_provider_mac.h"
+#endif
+
 namespace base {
 
+#if defined(OS_MACOSX)
+extern const Feature kMacAllowBackgroundingProcesses;
+#endif
+
 // Provides a move-only encapsulation of a process.
 //
 // This object is not tied to the lifetime of the underlying process: the
@@ -106,6 +115,28 @@ class BASE_EXPORT Process {
   // is not required.
   bool WaitForExitWithTimeout(TimeDelta timeout, int* exit_code);
 
+#if defined(OS_MACOSX)
+  // The Mac needs a Mach port in order to manipulate a process's priority,
+  // and there's no good way to get that from base given the pid. These Mac
+  // variants of the IsProcessBackgrounded and SetProcessBackgrounded API take
+  // a port provider for this reason. See crbug.com/460102
+  //
+  // A process is backgrounded when its task priority is
+  // |TASK_BACKGROUND_APPLICATION|.
+  //
+  // Returns true if the port_provider can locate a task port for the process
+  // and it is backgrounded. If port_provider is null, returns false.
+  bool IsProcessBackgrounded(PortProvider* port_provider) const;
+
+  // Set the process as backgrounded. If value is
+  // true, the priority of the associated task will be set to
+  // TASK_BACKGROUND_APPLICATION. If value is false, the
+  // priority of the process will be set to TASK_FOREGROUND_APPLICATION.
+  //
+  // Returns true if the priority was changed, false otherwise. If
+  // |port_provider| is null, this is a no-op and it returns false.
+  bool SetProcessBackgrounded(PortProvider* port_provider, bool value);
+#else
   // A process is backgrounded when it's priority is lower than normal.
   // Return true if this process is backgrounded, false otherwise.
   bool IsProcessBackgrounded() const;
@@ -115,7 +146,7 @@ class BASE_EXPORT Process {
   // will be made "normal" - equivalent to default process priority.
   // Returns true if the priority was changed, false otherwise.
   bool SetProcessBackgrounded(bool value);
-
+#endif  // defined(OS_MACOSX)
   // Returns an integer representing the priority of a process. The meaning
   // of this value is OS dependent.
   int GetPriority() const;
diff --git a/src/base/process/process_posix.cc b/src/base/process/process_posix.cc
index 65dbce7..e26ea36 100644
--- a/src/base/process/process_posix.cc
+++ b/src/base/process/process_posix.cc
@@ -261,12 +261,12 @@ Process Process::DeprecatedGetProcessFromHandle(ProcessHandle handle) {
   return Process(handle);
 }
 
-#if !defined(OS_LINUX)
+#if !defined(OS_LINUX) && !defined(OS_MACOSX)
 // static
 bool Process::CanBackgroundProcesses() {
   return false;
 }
-#endif  // !defined(OS_LINUX)
+#endif  // !defined(OS_LINUX) && !defined(OS_MACOSX)
 
 bool Process::IsValid() const {
   return process_ != kNullProcessHandle;
@@ -367,7 +367,7 @@ bool Process::WaitForExitWithTimeout(TimeDelta timeout, int* exit_code) {
   return WaitForExitWithTimeoutImpl(Handle(), exit_code, timeout);
 }
 
-#if !defined(OS_LINUX)
+#if !defined(OS_LINUX) && !defined(OS_MACOSX)
 bool Process::IsProcessBackgrounded() const {
   // See SetProcessBackgrounded().
   DCHECK(IsValid());
@@ -375,13 +375,13 @@ bool Process::IsProcessBackgrounded() const {
 }
 
 bool Process::SetProcessBackgrounded(bool value) {
-  // Not implemented for POSIX systems other than Linux. With POSIX, if we were
-  // to lower the process priority we wouldn't be able to raise it back to its
-  // initial priority.
+  // Not implemented for POSIX systems other than Linux and Mac. With POSIX, if
+  // we were to lower the process priority we wouldn't be able to raise it back
+  // to its initial priority.
   NOTIMPLEMENTED();
   return false;
 }
-#endif  // !defined(OS_LINUX)
+#endif  // !defined(OS_LINUX) && !defined(OS_MACOSX)
 
 int Process::GetPriority() const {
   DCHECK(IsValid());
diff --git a/src/base/sequence_token.cc b/src/base/sequence_token.cc
index 1178181..264e3b6 100644
--- a/src/base/sequence_token.cc
+++ b/src/base/sequence_token.cc
@@ -37,6 +37,10 @@ bool SequenceToken::IsValid() const {
   return token_ != kInvalidSequenceToken;
 }
 
+int SequenceToken::ToInternalValue() const {
+  return token_;
+}
+
 SequenceToken SequenceToken::Create() {
   return SequenceToken(g_sequence_token_generator.GetNext());
 }
diff --git a/src/base/sequence_token.h b/src/base/sequence_token.h
index 80340c0..6e7d191 100644
--- a/src/base/sequence_token.h
+++ b/src/base/sequence_token.h
@@ -29,6 +29,10 @@ class BASE_EXPORT SequenceToken {
   // Returns true if this is a valid SequenceToken.
   bool IsValid() const;
 
+  // Returns the integer uniquely representing this SequenceToken. This method
+  // should only be used for tracing and debugging.
+  int ToInternalValue() const;
+
   // Returns a valid SequenceToken which isn't equal to any previously returned
   // SequenceToken.
   static SequenceToken Create();
diff --git a/src/base/stl_util.h b/src/base/stl_util.h
index b868337..3f7555d 100644
--- a/src/base/stl_util.h
+++ b/src/base/stl_util.h
@@ -29,38 +29,6 @@ void STLClearObject(T* obj) {
   obj->reserve(0);
 }
 
-// For a range within a container of pointers, calls delete (non-array version)
-// on these pointers.
-// NOTE: for these three functions, we could just implement a DeleteObject
-// functor and then call for_each() on the range and functor, but this
-// requires us to pull in all of algorithm.h, which seems expensive.
-// For hash_[multi]set, it is important that this deletes behind the iterator
-// because the hash_set may call the hash function on the iterator when it is
-// advanced, which could result in the hash function trying to deference a
-// stale pointer.
-template <class ForwardIterator>
-void STLDeleteContainerPointers(ForwardIterator begin, ForwardIterator end) {
-  while (begin != end) {
-    ForwardIterator temp = begin;
-    ++begin;
-    delete *temp;
-  }
-}
-
-// For a range within a container of pairs, calls delete.
-// NOTE: Like STLDeleteContainerPointers, deleting behind the iterator.
-// Deleting the value does not always invalidate the iterator, but it may
-// do so if the key is a pointer into the value object.
-template <class ForwardIterator>
-void STLDeleteContainerPairSecondPointers(ForwardIterator begin,
-                                          ForwardIterator end) {
-  while (begin != end) {
-    ForwardIterator temp = begin;
-    ++begin;
-    delete temp->second;
-  }
-}
-
 // Counts the number of instances of val in a container.
 template <typename Container, typename T>
 typename std::iterator_traits<
@@ -99,7 +67,13 @@ template <class T>
 void STLDeleteElements(T* container) {
   if (!container)
     return;
-  STLDeleteContainerPointers(container->begin(), container->end());
+
+  for (auto it = container->begin(); it != container->end();) {
+    auto temp = it;
+    ++it;
+    delete *temp;
+  }
+
   container->clear();
 }
 
@@ -110,7 +84,13 @@ template <class T>
 void STLDeleteValues(T* container) {
   if (!container)
     return;
-  STLDeleteContainerPairSecondPointers(container->begin(), container->end());
+
+  for (auto it = container->begin(); it != container->end();) {
+    auto temp = it;
+    ++it;
+    delete temp->second;
+  }
+
   container->clear();
 }
 
diff --git a/src/base/strings/string_number_conversions.cc b/src/base/strings/string_number_conversions.cc
index 755811d..9148def 100644
--- a/src/base/strings/string_number_conversions.cc
+++ b/src/base/strings/string_number_conversions.cc
@@ -10,6 +10,7 @@
 #include <wctype.h>
 
 #include <limits>
+#include <type_traits>
 
 #include "base/logging.h"
 #include "base/numerics/safe_math.h"
@@ -35,7 +36,8 @@ struct IntToStringT {
 
     // The ValueOrDie call below can never fail, because UnsignedAbs is valid
     // for all valid inputs.
-    auto res = CheckedNumeric<INT>(value).UnsignedAbs().ValueOrDie();
+    typename std::make_unsigned<INT>::type res =
+        CheckedNumeric<INT>(value).UnsignedAbs().ValueOrDie();
 
     CHR* end = outbuf + kOutputBufSize;
     CHR* i = end;
diff --git a/src/base/strings/string_split.cc b/src/base/strings/string_split.cc
index 6c949b9..a8180b2 100644
--- a/src/base/strings/string_split.cc
+++ b/src/base/strings/string_split.cc
@@ -227,18 +227,22 @@ bool SplitStringIntoKeyValuePairs(StringPiece input,
   return success;
 }
 
-void SplitStringUsingSubstr(StringPiece16 input,
-                            StringPiece16 delimiter,
-                            std::vector<string16>* result) {
-  SplitStringUsingSubstrT(input, delimiter, TRIM_WHITESPACE, SPLIT_WANT_ALL,
-                          result);
+std::vector<string16> SplitStringUsingSubstr(StringPiece16 input,
+                                             StringPiece16 delimiter,
+                                             WhitespaceHandling whitespace,
+                                             SplitResult result_type) {
+  std::vector<string16> result;
+  SplitStringUsingSubstrT(input, delimiter, whitespace, result_type, &result);
+  return result;
 }
 
-void SplitStringUsingSubstr(StringPiece input,
-                            StringPiece delimiter,
-                            std::vector<std::string>* result) {
-  SplitStringUsingSubstrT(input, delimiter, TRIM_WHITESPACE, SPLIT_WANT_ALL,
-                          result);
+std::vector<std::string> SplitStringUsingSubstr(StringPiece input,
+                                                StringPiece delimiter,
+                                                WhitespaceHandling whitespace,
+                                                SplitResult result_type) {
+  std::vector<std::string> result;
+  SplitStringUsingSubstrT(input, delimiter, whitespace, result_type, &result);
+  return result;
 }
 
 std::vector<StringPiece16> SplitStringPieceUsingSubstr(
diff --git a/src/base/strings/string_split.h b/src/base/strings/string_split.h
index ec9f246..24b9dfa 100644
--- a/src/base/strings/string_split.h
+++ b/src/base/strings/string_split.h
@@ -90,16 +90,16 @@ BASE_EXPORT bool SplitStringIntoKeyValuePairs(StringPiece input,
 
 // Similar to SplitString, but use a substring delimiter instead of a list of
 // characters that are all possible delimiters.
-//
-// TODO(brettw) this should probably be changed and expanded to provide a
-// mirror of the SplitString[Piece] API above, just with the different
-// delimiter handling.
-BASE_EXPORT void SplitStringUsingSubstr(StringPiece16 input,
-                                        StringPiece16 delimiter,
-                                        std::vector<string16>* result);
-BASE_EXPORT void SplitStringUsingSubstr(StringPiece input,
-                                        StringPiece delimiter,
-                                        std::vector<std::string>* result);
+BASE_EXPORT std::vector<string16> SplitStringUsingSubstr(
+    StringPiece16 input,
+    StringPiece16 delimiter,
+    WhitespaceHandling whitespace,
+    SplitResult result_type);
+BASE_EXPORT std::vector<std::string> SplitStringUsingSubstr(
+    StringPiece input,
+    StringPiece delimiter,
+    WhitespaceHandling whitespace,
+    SplitResult result_type);
 
 // Like SplitStringUsingSubstr above except it returns a vector of StringPieces
 // which reference the original buffer without copying. Although you have to be
diff --git a/src/base/strings/utf_string_conversions.cc b/src/base/strings/utf_string_conversions.cc
index 6b17eac..85450c6 100644
--- a/src/base/strings/utf_string_conversions.cc
+++ b/src/base/strings/utf_string_conversions.cc
@@ -180,10 +180,6 @@ bool UTF16ToUTF8(const char16* src, size_t src_len, std::string* output) {
 }
 
 std::string UTF16ToUTF8(StringPiece16 utf16) {
-  if (IsStringASCII(utf16)) {
-    return std::string(utf16.begin(), utf16.end());
-  }
-
   std::string ret;
   // Ignore the success flag of this call, it will do the best it can for
   // invalid input, which is what we want here.
diff --git a/src/base/synchronization/cancellation_flag.h b/src/base/synchronization/cancellation_flag.h
deleted file mode 100644
index 39094e2..0000000
--- a/src/base/synchronization/cancellation_flag.h
+++ /dev/null
@@ -1,20 +0,0 @@
-// Copyright (c) 2011 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef BASE_SYNCHRONIZATION_CANCELLATION_FLAG_H_
-#define BASE_SYNCHRONIZATION_CANCELLATION_FLAG_H_
-
-#include "base/synchronization/atomic_flag.h"
-
-namespace base {
-
-// Use inheritance instead of "using" to allow forward declaration of "class
-// CancellationFlag".
-// TODO(fdoray): Replace CancellationFlag with AtomicFlag throughout the
-// codebase and delete this file. crbug.com/630251
-class CancellationFlag : public AtomicFlag {};
-
-}  // namespace base
-
-#endif  // BASE_SYNCHRONIZATION_CANCELLATION_FLAG_H_
diff --git a/src/base/synchronization/condition_variable.h b/src/base/synchronization/condition_variable.h
index ebf90d2..b567751 100644
--- a/src/base/synchronization/condition_variable.h
+++ b/src/base/synchronization/condition_variable.h
@@ -91,11 +91,13 @@ class BASE_EXPORT ConditionVariable {
   ~ConditionVariable();
 
   // Wait() releases the caller's critical section atomically as it starts to
-  // sleep, and the reacquires it when it is signaled.
+  // sleep, and the reacquires it when it is signaled. The wait functions are
+  // susceptible to spurious wakeups. (See usage note 1 for more details.)
   void Wait();
   void TimedWait(const TimeDelta& max_time);
 
-  // Broadcast() revives all waiting threads.
+  // Broadcast() revives all waiting threads. (See usage note 2 for more
+  // details.)
   void Broadcast();
   // Signal() revives one waiting thread.
   void Signal();
diff --git a/src/base/synchronization/waitable_event.h b/src/base/synchronization/waitable_event.h
index 3863e98..761965f 100644
--- a/src/base/synchronization/waitable_event.h
+++ b/src/base/synchronization/waitable_event.h
@@ -25,6 +25,7 @@
 namespace base {
 
 class TimeDelta;
+class TimeTicks;
 
 // A WaitableEvent can be a useful thread synchronization tool when you want to
 // allow one thread to wait for another thread to finish some work. For
@@ -86,12 +87,17 @@ class BASE_EXPORT WaitableEvent {
   //   delete e;
   void Wait();
 
-  // Wait up until max_time has passed for the event to be signaled.  Returns
-  // true if the event was signaled.  If this method returns false, then it
-  // does not necessarily mean that max_time was exceeded.
+  // Wait up until wait_delta has passed for the event to be signaled.  Returns
+  // true if the event was signaled.
   //
   // TimedWait can synchronise its own destruction like |Wait|.
-  bool TimedWait(const TimeDelta& max_time);
+  bool TimedWait(const TimeDelta& wait_delta);
+
+  // Wait up until end_time deadline has passed for the event to be signaled.
+  // Return true if the event was signaled.
+  //
+  // TimedWaitUntil can synchronise its own destruction like |Wait|.
+  bool TimedWaitUntil(const TimeTicks& end_time);
 
 #if defined(OS_WIN)
   HANDLE handle() const { return handle_.Get(); }
diff --git a/src/base/synchronization/waitable_event_posix.cc b/src/base/synchronization/waitable_event_posix.cc
index a8b686b..5dfff46 100644
--- a/src/base/synchronization/waitable_event_posix.cc
+++ b/src/base/synchronization/waitable_event_posix.cc
@@ -153,17 +153,22 @@ class SyncWaiter : public WaitableEvent::Waiter {
 };
 
 void WaitableEvent::Wait() {
-  bool result = TimedWait(TimeDelta::FromSeconds(-1));
+  bool result = TimedWaitUntil(TimeTicks::Max());
   DCHECK(result) << "TimedWait() should never fail with infinite timeout";
 }
 
-bool WaitableEvent::TimedWait(const TimeDelta& max_time) {
+bool WaitableEvent::TimedWait(const TimeDelta& wait_delta) {
+  // TimeTicks takes care of overflow including the cases when wait_delta
+  // is a maximum value.
+  return TimedWaitUntil(TimeTicks::Now() + wait_delta);
+}
+
+bool WaitableEvent::TimedWaitUntil(const TimeTicks& end_time) {
+  base::ThreadRestrictions::AssertWaitAllowed();
   // Record the event that this thread is blocking upon (for hang diagnosis).
   base::debug::ScopedEventWaitActivity event_activity(this);
 
-  base::ThreadRestrictions::AssertWaitAllowed();
-  const TimeTicks end_time(TimeTicks::Now() + max_time);
-  const bool finite_time = max_time.ToInternalValue() >= 0;
+  const bool finite_time = !end_time.is_max();
 
   kernel_->lock_.Acquire();
   if (kernel_->signaled_) {
diff --git a/src/base/sys_info.h b/src/base/sys_info.h
index b107477..e35feff 100644
--- a/src/base/sys_info.h
+++ b/src/base/sys_info.h
@@ -107,9 +107,19 @@ class BASE_EXPORT SysInfo {
   static bool GetLsbReleaseValue(const std::string& key, std::string* value);
 
   // Convenience function for GetLsbReleaseValue("CHROMEOS_RELEASE_BOARD",...).
-  // Returns "unknown" if CHROMEOS_RELEASE_BOARD is not set.
+  // Returns "unknown" if CHROMEOS_RELEASE_BOARD is not set. Otherwise returns
+  // the full name of the board. WARNING: the returned value often differs in
+  // developer built system compared to devices that use the official version.
+  // E.g. for developer built version, the function could return 'glimmer' while
+  // for officially used versions it would be like 'glimmer-signed-mp-v4keys'.
+  // Use GetStrippedReleaseBoard() function if you need only the short name of
+  // the board (would be 'glimmer' in the case described above).
   static std::string GetLsbReleaseBoard();
 
+  // Convenience function for GetLsbReleaseBoard() removing trailing "-signed-*"
+  // if present. Returns "unknown" if CHROMEOS_RELEASE_BOARD is not set.
+  static std::string GetStrippedReleaseBoard();
+
   // Returns the creation time of /etc/lsb-release. (Used to get the date and
   // time of the Chrome OS build).
   static Time GetLsbReleaseTime();
diff --git a/src/base/task_scheduler/delayed_task_manager.cc b/src/base/task_scheduler/delayed_task_manager.cc
index d648b9d..1cc928b 100644
--- a/src/base/task_scheduler/delayed_task_manager.cc
+++ b/src/base/task_scheduler/delayed_task_manager.cc
@@ -6,49 +6,18 @@
 
 #include <utility>
 
+#include "base/bind.h"
 #include "base/logging.h"
+#include "base/task_runner.h"
 #include "base/task_scheduler/scheduler_worker_pool.h"
 
 namespace base {
 namespace internal {
 
-struct DelayedTaskManager::DelayedTask {
-  DelayedTask(std::unique_ptr<Task> task,
-              scoped_refptr<Sequence> sequence,
-              SchedulerWorker* worker,
-              SchedulerWorkerPool* worker_pool,
-              uint64_t index)
-      : task(std::move(task)),
-        sequence(std::move(sequence)),
-        worker(worker),
-        worker_pool(worker_pool),
-        index(index) {}
-
-  DelayedTask(DelayedTask&& other) = default;
-
-  ~DelayedTask() = default;
-
-  DelayedTask& operator=(DelayedTask&& other) = default;
-
-  // |task| will be posted to |worker_pool| with |sequence| and |worker|
-  // when it becomes ripe for execution.
-  std::unique_ptr<Task> task;
-  scoped_refptr<Sequence> sequence;
-  SchedulerWorker* worker;
-  SchedulerWorkerPool* worker_pool;
-
-  // Ensures that tasks that have the same |delayed_run_time| are sorted
-  // according to the order in which they were added to the DelayedTaskManager.
-  uint64_t index;
-
- private:
-  DISALLOW_COPY_AND_ASSIGN(DelayedTask);
-};
-
 DelayedTaskManager::DelayedTaskManager(
-    const Closure& on_delayed_run_time_updated)
-    : on_delayed_run_time_updated_(on_delayed_run_time_updated) {
-  DCHECK(!on_delayed_run_time_updated_.is_null());
+    scoped_refptr<TaskRunner> service_thread_task_runner)
+    : service_thread_task_runner_(std::move(service_thread_task_runner)) {
+  DCHECK(service_thread_task_runner_);
 }
 
 DelayedTaskManager::~DelayedTaskManager() = default;
@@ -61,92 +30,16 @@ void DelayedTaskManager::AddDelayedTask(std::unique_ptr<Task> task,
   DCHECK(sequence);
   DCHECK(worker_pool);
 
-  const TimeTicks new_task_delayed_run_time = task->delayed_run_time;
-  TimeTicks current_delayed_run_time;
-
-  {
-    AutoSchedulerLock auto_lock(lock_);
-
-    if (!delayed_tasks_.empty())
-      current_delayed_run_time = delayed_tasks_.top().task->delayed_run_time;
-
-    delayed_tasks_.emplace(std::move(task), std::move(sequence), worker,
-                           worker_pool, ++delayed_task_index_);
-  }
-
-  if (current_delayed_run_time.is_null() ||
-      new_task_delayed_run_time < current_delayed_run_time) {
-    on_delayed_run_time_updated_.Run();
-  }
-}
-
-void DelayedTaskManager::PostReadyTasks() {
-  const TimeTicks now = Now();
-
-  // Move delayed tasks that are ready for execution into |ready_tasks|. Don't
-  // post them right away to avoid imposing an unecessary lock dependency on
-  // PostTaskNowHelper.
-  std::vector<DelayedTask> ready_tasks;
-
-  {
-    AutoSchedulerLock auto_lock(lock_);
-    while (!delayed_tasks_.empty() &&
-           delayed_tasks_.top().task->delayed_run_time <= now) {
-      // The const_cast for std::move is okay since we're immediately popping
-      // the task from |delayed_tasks_|. See DelayedTaskComparator::operator()
-      // for minor debug-check implications.
-      ready_tasks.push_back(
-          std::move(const_cast<DelayedTask&>(delayed_tasks_.top())));
-      delayed_tasks_.pop();
-    }
-  }
-
-  // Post delayed tasks that are ready for execution.
-  for (auto& delayed_task : ready_tasks) {
-    delayed_task.worker_pool->PostTaskWithSequenceNow(
-        std::move(delayed_task.task), std::move(delayed_task.sequence),
-        delayed_task.worker);
-  }
-}
-
-TimeTicks DelayedTaskManager::GetDelayedRunTime() const {
-  AutoSchedulerLock auto_lock(lock_);
-
-  if (delayed_tasks_.empty())
-    return TimeTicks();
-
-  return delayed_tasks_.top().task->delayed_run_time;
-}
-
-// In std::priority_queue, the largest element is on top. Therefore, this
-// comparator returns true if the delayed run time of |right| is earlier than
-// the delayed run time of |left|.
-bool DelayedTaskManager::DelayedTaskComparator::operator()(
-    const DelayedTask& left,
-    const DelayedTask& right) const {
-#ifndef NDEBUG
-  // Due to STL consistency checks in Windows and const_cast'ing right before
-  // popping the DelayedTask, a null task can be passed to this comparator in
-  // Debug builds. To satisfy these consistency checks, this comparator
-  // considers null tasks to be the larger than anything.
-  DCHECK(left.task || right.task);
-  if (!left.task)
-    return false;
-  if (!right.task)
-    return true;
-#else
-  DCHECK(left.task);
-  DCHECK(right.task);
-#endif  // NDEBUG
-  if (left.task->delayed_run_time > right.task->delayed_run_time)
-    return true;
-  if (left.task->delayed_run_time < right.task->delayed_run_time)
-    return false;
-  return left.index > right.index;
-}
+  const TimeDelta delay = task->delay;
+  DCHECK(!delay.is_zero());
 
-TimeTicks DelayedTaskManager::Now() const {
-  return TimeTicks::Now();
+  // TODO(fdoray): Use |task->delayed_run_time| on the service thread
+  // MessageLoop rather than recomputing it from |delay|.
+  service_thread_task_runner_->PostDelayedTask(
+      FROM_HERE, Bind(&SchedulerWorkerPool::PostTaskWithSequenceNow,
+                      Unretained(worker_pool), Passed(std::move(task)),
+                      std::move(sequence), Unretained(worker)),
+      delay);
 }
 
 }  // namespace internal
diff --git a/src/base/task_scheduler/delayed_task_manager.h b/src/base/task_scheduler/delayed_task_manager.h
index d773fe5..3bfb355 100644
--- a/src/base/task_scheduler/delayed_task_manager.h
+++ b/src/base/task_scheduler/delayed_task_manager.h
@@ -5,40 +5,37 @@
 #ifndef BASE_TASK_SCHEDULER_DELAYED_TASK_MANAGER_H_
 #define BASE_TASK_SCHEDULER_DELAYED_TASK_MANAGER_H_
 
-#include <stdint.h>
-
 #include <memory>
-#include <queue>
-#include <vector>
 
 #include "base/base_export.h"
-#include "base/callback.h"
 #include "base/macros.h"
 #include "base/memory/ref_counted.h"
-#include "base/task_scheduler/scheduler_lock.h"
-#include "base/task_scheduler/sequence.h"
-#include "base/task_scheduler/task.h"
 #include "base/time/time.h"
 
 namespace base {
+
+class TaskRunner;
+
 namespace internal {
 
 class SchedulerWorker;
 class SchedulerWorkerPool;
+class Sequence;
+struct Task;
 
-// A DelayedTaskManager holds delayed Tasks until they become ripe for
-// execution. This class is thread-safe.
+// A DelayedTaskManager forwards Tasks to a SchedulerWorkerPool when they become
+// ripe for execution. This class is thread-safe.
 class BASE_EXPORT DelayedTaskManager {
  public:
-  // |on_delayed_run_time_updated| is invoked when the delayed run time is
-  // updated as a result of adding a delayed task to the manager.
-  explicit DelayedTaskManager(const Closure& on_delayed_run_time_updated);
+  // |service_thread_task_runner| posts tasks to the TaskScheduler service
+  // thread.
+  explicit DelayedTaskManager(
+      scoped_refptr<TaskRunner> service_thread_task_runner);
   ~DelayedTaskManager();
 
-  // Adds |task| to a queue of delayed tasks. The task will be posted to
-  // |worker_pool| with |sequence| and |worker| the first time that
-  // PostReadyTasks() is called while Now() is passed |task->delayed_run_time|.
-  // |worker| is a SchedulerWorker owned by |worker_pool| or nullptr.
+  // Posts |task|. The task will be forwarded to |worker_pool| with |sequence|
+  // and |worker| when it becomes ripe for execution. |worker| is a
+  // SchedulerWorker owned by |worker_pool| or nullptr.
   //
   // TODO(robliao): Find a concrete way to manage the memory of |worker| and
   // |worker_pool|. These objects are never deleted in production, but it is
@@ -48,36 +45,8 @@ class BASE_EXPORT DelayedTaskManager {
                       SchedulerWorker* worker,
                       SchedulerWorkerPool* worker_pool);
 
-  // Posts delayed tasks that are ripe for execution.
-  void PostReadyTasks();
-
-  // Returns the next time at which a delayed task will become ripe for
-  // execution, or a null TimeTicks if there are no pending delayed tasks.
-  TimeTicks GetDelayedRunTime() const;
-
-  // Returns the current time. Can be overridden for tests.
-  virtual TimeTicks Now() const;
-
  private:
-  struct DelayedTask;
-  struct DelayedTaskComparator {
-    bool operator()(const DelayedTask& left, const DelayedTask& right) const;
-  };
-
-  const Closure on_delayed_run_time_updated_;
-
-  // Synchronizes access to all members below.
-  mutable SchedulerLock lock_;
-
-  // Priority queue of delayed tasks. The delayed task with the smallest
-  // |task->delayed_run_time| is in front of the priority queue.
-  using DelayedTaskQueue = std::priority_queue<DelayedTask,
-                                               std::vector<DelayedTask>,
-                                               DelayedTaskComparator>;
-  DelayedTaskQueue delayed_tasks_;
-
-  // The index to assign to the next delayed task added to the manager.
-  uint64_t delayed_task_index_ = 0;
+  const scoped_refptr<TaskRunner> service_thread_task_runner_;
 
   DISALLOW_COPY_AND_ASSIGN(DelayedTaskManager);
 };
diff --git a/src/base/task_scheduler/post_task.cc b/src/base/task_scheduler/post_task.cc
index f415cd3..737a219 100644
--- a/src/base/task_scheduler/post_task.cc
+++ b/src/base/task_scheduler/post_task.cc
@@ -13,7 +13,7 @@ namespace {
 
 class PostTaskAndReplyTaskRunner : public internal::PostTaskAndReplyImpl {
  public:
-  explicit PostTaskAndReplyTaskRunner(TaskTraits traits)
+  explicit PostTaskAndReplyTaskRunner(const TaskTraits& traits)
       : traits_(traits) {}
 
  private:
@@ -40,23 +40,32 @@ void PostTaskAndReply(const tracked_objects::Location& from_here,
 }
 
 void PostTaskWithTraits(const tracked_objects::Location& from_here,
-                        TaskTraits traits,
+                        const TaskTraits& traits,
                         const Closure& task) {
   TaskScheduler::GetInstance()->PostTaskWithTraits(from_here, traits, task);
 }
 
 void PostTaskWithTraitsAndReply(const tracked_objects::Location& from_here,
-                                TaskTraits traits,
+                                const TaskTraits& traits,
                                 const Closure& task,
                                 const Closure& reply) {
   PostTaskAndReplyTaskRunner(traits).PostTaskAndReply(from_here, task, reply);
 }
 
-scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(
-    TaskTraits traits,
-    ExecutionMode execution_mode) {
-  return TaskScheduler::GetInstance()->CreateTaskRunnerWithTraits(
-      traits, execution_mode);
+scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(const TaskTraits& traits) {
+  return TaskScheduler::GetInstance()->CreateTaskRunnerWithTraits(traits);
+}
+
+scoped_refptr<SequencedTaskRunner> CreateSequencedTaskRunnerWithTraits(
+    const TaskTraits& traits) {
+  return TaskScheduler::GetInstance()->CreateSequencedTaskRunnerWithTraits(
+      traits);
+}
+
+scoped_refptr<SingleThreadTaskRunner> CreateSingleThreadTaskRunnerWithTraits(
+    const TaskTraits& traits) {
+  return TaskScheduler::GetInstance()->CreateSingleThreadTaskRunnerWithTraits(
+      traits);
 }
 
 }  // namespace base
diff --git a/src/base/task_scheduler/post_task.h b/src/base/task_scheduler/post_task.h
index a7a2114..a537984 100644
--- a/src/base/task_scheduler/post_task.h
+++ b/src/base/task_scheduler/post_task.h
@@ -6,9 +6,13 @@
 #define BASE_TASK_SCHEDULER_POST_TASK_H_
 
 #include "base/base_export.h"
+#include "base/bind.h"
 #include "base/callback_forward.h"
 #include "base/location.h"
 #include "base/memory/ref_counted.h"
+#include "base/post_task_and_reply_with_result_internal.h"
+#include "base/sequenced_task_runner.h"
+#include "base/single_thread_task_runner.h"
 #include "base/task_runner.h"
 #include "base/task_scheduler/task_traits.h"
 
@@ -32,18 +36,17 @@ namespace base {
 //         Bind(...));
 //
 // To post tasks that must run in sequence:
-//     scoped_refptr<TaskRunner> task_runner = CreateTaskRunnerWithTraits(
-//         TaskTraits(), ExecutionMode::SEQUENCED);
+//     scoped_refptr<SequencedTaskRunner> task_runner =
+//         CreateSequencedTaskRunnerWithTraits(TaskTraits());
 //     task_runner.PostTask(FROM_HERE, Bind(...));
 //     task_runner.PostTask(FROM_HERE, Bind(...));
 //
 // To post file I/O tasks that must run in sequence and can be skipped on
 // shutdown:
-//     scoped_refptr<TaskRunner> task_runner =
-//         CreateTaskRunnerWithTraits(
+//     scoped_refptr<SequencedTaskRunner> task_runner =
+//         CreateSequencedTaskRunnerWithTraits(
 //             TaskTraits().WithFileIO().WithShutdownBehavior(
-//                 TaskShutdownBehavior::SKIP_ON_SHUTDOWN),
-//             ExecutionMode::SEQUENCED);
+//                 TaskShutdownBehavior::SKIP_ON_SHUTDOWN));
 //     task_runner.PostTask(FROM_HERE, Bind(...));
 //     task_runner.PostTask(FROM_HERE, Bind(...));
 //
@@ -70,9 +73,21 @@ BASE_EXPORT void PostTaskAndReply(const tracked_objects::Location& from_here,
                                   const Closure& task,
                                   const Closure& reply);
 
+// Posts |task| to the TaskScheduler and posts |reply| with the return value of
+// |task| as argument on the caller's execution context (i.e. same sequence or
+// thread and same TaskTraits if applicable) when |task| completes. Calling this
+// is equivalent to calling PostTaskWithTraitsAndReplyWithResult with plain
+// TaskTraits. Can only be called when SequencedTaskRunnerHandle::IsSet().
+template <typename TaskReturnType, typename ReplyArgType>
+void PostTaskAndReplyWithResult(const tracked_objects::Location& from_here,
+                                const Callback<TaskReturnType(void)>& task,
+                                const Callback<void(ReplyArgType)>& reply) {
+  PostTaskWithTraitsAndReplyWithResult(from_here, TaskTraits(), task, reply);
+}
+
 // Posts |task| with specific |traits| to the TaskScheduler.
 BASE_EXPORT void PostTaskWithTraits(const tracked_objects::Location& from_here,
-                                    TaskTraits traits,
+                                    const TaskTraits& traits,
                                     const Closure& task);
 
 // Posts |task| with specific |traits| to the TaskScheduler and posts |reply| on
@@ -81,15 +96,54 @@ BASE_EXPORT void PostTaskWithTraits(const tracked_objects::Location& from_here,
 // SequencedTaskRunnerHandle::IsSet().
 BASE_EXPORT void PostTaskWithTraitsAndReply(
     const tracked_objects::Location& from_here,
-    TaskTraits traits,
+    const TaskTraits& traits,
     const Closure& task,
     const Closure& reply);
 
-// Returns a TaskRunner whose PostTask invocations will result in scheduling
-// tasks using |traits| which will be executed according to |execution_mode|.
+// Posts |task| with specific |traits| to the TaskScheduler and posts |reply|
+// with the return value of |task| as argument on the caller's execution context
+// (i.e. same sequence or thread and same TaskTraits if applicable) when |task|
+// completes. Can only be called when SequencedTaskRunnerHandle::IsSet().
+template <typename TaskReturnType, typename ReplyArgType>
+void PostTaskWithTraitsAndReplyWithResult(
+    const tracked_objects::Location& from_here,
+    const TaskTraits& traits,
+    const Callback<TaskReturnType(void)>& task,
+    const Callback<void(ReplyArgType)>& reply) {
+  TaskReturnType* result = new TaskReturnType();
+  return PostTaskWithTraitsAndReply(
+      from_here, traits,
+      Bind(&internal::ReturnAsParamAdapter<TaskReturnType>, task, result),
+      Bind(&internal::ReplyAdapter<TaskReturnType, ReplyArgType>, reply,
+           Owned(result)));
+}
+
+// Delayed tasks posted to TaskRunners returned by the functions below may be
+// coalesced (i.e. delays may be adjusted to reduce the number of wakeups and
+// hence power consumption).
+
+// Returns a TaskRunner whose PostTask invocations result in scheduling tasks
+// using |traits|. Tasks may run in any order and in parallel.
 BASE_EXPORT scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(
-    TaskTraits traits,
-    ExecutionMode execution_mode);
+    const TaskTraits& traits);
+
+// Returns a SequencedTaskRunner whose PostTask invocations result in scheduling
+// tasks using |traits|. Tasks run one at a time in posting order.
+BASE_EXPORT scoped_refptr<SequencedTaskRunner>
+CreateSequencedTaskRunnerWithTraits(const TaskTraits& traits);
+
+// Returns a SingleThreadTaskRunner whose PostTask invocations result in
+// scheduling tasks using |traits|. Tasks run on a single thread in posting
+// order.
+//
+// If all you need is to make sure that tasks don't run concurrently (e.g.
+// because they access a data structure which is not thread-safe), use
+// CreateSequencedTaskRunnerWithTraits(). Only use this if you rely on a thread-
+// affine API (it might be safer to assume thread-affinity when dealing with
+// under-documented third-party APIs, e.g. other OS') or share data across tasks
+// using thread-local storage.
+BASE_EXPORT scoped_refptr<SingleThreadTaskRunner>
+CreateSingleThreadTaskRunnerWithTraits(const TaskTraits& traits);
 
 }  // namespace base
 
diff --git a/src/base/task_scheduler/scheduler_service_thread.cc b/src/base/task_scheduler/scheduler_service_thread.cc
deleted file mode 100644
index 9f6936b..0000000
--- a/src/base/task_scheduler/scheduler_service_thread.cc
+++ /dev/null
@@ -1,101 +0,0 @@
-// Copyright 2016 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "base/task_scheduler/scheduler_service_thread.h"
-
-#include <utility>
-
-#include "base/logging.h"
-#include "base/memory/ptr_util.h"
-#include "base/synchronization/waitable_event.h"
-#include "base/task_scheduler/delayed_task_manager.h"
-#include "base/task_scheduler/scheduler_worker.h"
-#include "base/task_scheduler/sequence.h"
-#include "base/threading/thread_checker.h"
-#include "base/time/time.h"
-
-namespace base {
-namespace internal {
-namespace {
-
-class ServiceThreadDelegate : public SchedulerWorker::Delegate {
- public:
-  ServiceThreadDelegate(DelayedTaskManager* delayed_task_manager)
-      : delayed_task_manager_(delayed_task_manager) {}
-
-  // SchedulerWorker::Delegate:
-  void OnMainEntry(SchedulerWorker* worker,
-                   const TimeDelta& detach_duration) override {
-    DCHECK(detach_duration.is_max());
-  }
-
-  scoped_refptr<Sequence> GetWork(SchedulerWorker* worker) override {
-    delayed_task_manager_->PostReadyTasks();
-    return nullptr;
-  }
-
-  void DidRunTask(const Task* task, const TimeDelta& task_latency) override {
-    NOTREACHED()
-        << "GetWork() never returns a sequence so no task should ever run.";
-  }
-
-  void ReEnqueueSequence(scoped_refptr<Sequence> sequence) override {
-    NOTREACHED() <<
-        "GetWork() never returns a sequence so there's nothing to reenqueue.";
-  }
-
-  TimeDelta GetSleepTimeout() override {
-    const TimeTicks next_time = delayed_task_manager_->GetDelayedRunTime();
-    if (next_time.is_null())
-      return TimeDelta::Max();
-
-    // For delayed tasks with delays that are really close to each other, it is
-    // possible for the current time to advance beyond the required
-    // GetDelayedWaitTime. Return a minimum of TimeDelta() in the event that
-    // happens.
-    TimeDelta sleep_time = next_time - delayed_task_manager_->Now();
-    const TimeDelta zero_delta;
-    return sleep_time < zero_delta ? zero_delta : sleep_time;
-  }
-
-  bool CanDetach(SchedulerWorker* worker) override {
-    return false;
-  }
-
- private:
-  DelayedTaskManager* const delayed_task_manager_;
-
-  DISALLOW_COPY_AND_ASSIGN(ServiceThreadDelegate);
-};
-
-}  // namespace
-
-SchedulerServiceThread::~SchedulerServiceThread() = default;
-
-// static
-std::unique_ptr<SchedulerServiceThread> SchedulerServiceThread::Create(
-    TaskTracker* task_tracker, DelayedTaskManager* delayed_task_manager) {
-  std::unique_ptr<SchedulerWorker> worker = SchedulerWorker::Create(
-      ThreadPriority::NORMAL,
-      MakeUnique<ServiceThreadDelegate>(delayed_task_manager), task_tracker,
-      SchedulerWorker::InitialState::ALIVE);
-  if (!worker)
-    return nullptr;
-
-  return WrapUnique(new SchedulerServiceThread(std::move(worker)));
-}
-
-void SchedulerServiceThread::WakeUp() {
-  worker_->WakeUp();
-}
-
-void SchedulerServiceThread::JoinForTesting() {
-  worker_->JoinForTesting();
-}
-
-SchedulerServiceThread::SchedulerServiceThread(
-    std::unique_ptr<SchedulerWorker> worker) : worker_(std::move(worker)) {}
-
-}  // namespace internal
-}  // namespace base
diff --git a/src/base/task_scheduler/scheduler_service_thread.h b/src/base/task_scheduler/scheduler_service_thread.h
deleted file mode 100644
index e6c9fd0..0000000
--- a/src/base/task_scheduler/scheduler_service_thread.h
+++ /dev/null
@@ -1,50 +0,0 @@
-// Copyright 2016 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef BASE_TASK_SCHEDULER_SERVICE_THREAD_H_
-#define BASE_TASK_SCHEDULER_SERVICE_THREAD_H_
-
-#include <memory>
-
-#include "base/base_export.h"
-#include "base/macros.h"
-
-namespace base {
-namespace internal {
-
-class DelayedTaskManager;
-class SchedulerWorker;
-class TaskTracker;
-
-// A thread dedicated to performing Task Scheduler related work.
-class BASE_EXPORT SchedulerServiceThread {
- public:
-  ~SchedulerServiceThread();
-
-  // Creates a SchedulerServiceThread. |task_tracker| and |delayed_task_manager|
-  // are passed through to the underlying SchedulerWorker. Returns a nullptr on
-  // failure.
-  static std::unique_ptr<SchedulerServiceThread> Create(
-      TaskTracker* task_tracker, DelayedTaskManager* delayed_task_manager);
-
-  // Wakes the SchedulerServiceThread if it wasn't already awake. This also has
-  // the impact of updating the amount of time the thread sleeps for delayed
-  // tasks.
-  void WakeUp();
-
-  // Joins this SchedulerServiceThread. This can only be called once.
-  void JoinForTesting();
-
- private:
-  SchedulerServiceThread(std::unique_ptr<SchedulerWorker> worker);
-
-  const std::unique_ptr<SchedulerWorker> worker_;
-
-  DISALLOW_COPY_AND_ASSIGN(SchedulerServiceThread);
-};
-
-}  // namespace internal
-}  // namespace base
-
-#endif  // BASE_TASK_SCHEDULER_SERVICE_THREAD_H_
diff --git a/src/base/task_scheduler/scheduler_worker.cc b/src/base/task_scheduler/scheduler_worker.cc
index 2bed780..5853bf6 100644
--- a/src/base/task_scheduler/scheduler_worker.cc
+++ b/src/base/task_scheduler/scheduler_worker.cc
@@ -14,6 +14,8 @@
 
 #if defined(OS_MACOSX)
 #include "base/mac/scoped_nsautorelease_pool.h"
+#elif defined(OS_WIN)
+#include "base/win/scoped_com_initializer.h"
 #endif
 
 namespace base {
@@ -36,16 +38,22 @@ class SchedulerWorker::Thread : public PlatformThread::Delegate {
     // Set if this thread was detached.
     std::unique_ptr<Thread> detached_thread;
 
-    outer_->delegate_->OnMainEntry(
-        outer_, outer_->last_detach_time_.is_null()
-                    ? TimeDelta::Max()
-                    : TimeTicks::Now() - outer_->last_detach_time_);
+    outer_->delegate_->OnMainEntry(outer_);
 
     // A SchedulerWorker starts out waiting for work.
     WaitForWork();
 
+#if defined(OS_WIN)
+    // This is required as SequencedWorkerPool previously blindly CoInitialized
+    // all of its threads.
+    // TODO: Get rid of this broad COM scope and force tasks that care about a
+    // CoInitialized environment to request one (via an upcoming execution
+    // mode).
+    win::ScopedCOMInitializer com_initializer;
+#endif
+
     while (!outer_->task_tracker_->IsShutdownComplete() &&
-           !outer_->ShouldExitForTesting()) {
+           !outer_->should_exit_for_testing_.IsSet()) {
       DCHECK(outer_);
 
 #if defined(OS_MACOSX)
@@ -60,9 +68,9 @@ class SchedulerWorker::Thread : public PlatformThread::Delegate {
         if (outer_->delegate_->CanDetach(outer_)) {
           detached_thread = outer_->Detach();
           if (detached_thread) {
+            outer_ = nullptr;
             DCHECK_EQ(detached_thread.get(), this);
             PlatformThread::Detach(thread_handle_);
-            outer_ = nullptr;
             break;
           }
         }
@@ -70,12 +78,13 @@ class SchedulerWorker::Thread : public PlatformThread::Delegate {
         continue;
       }
 
-      const Task* task = sequence->PeekTask();
-      const TimeTicks start_time = TimeTicks::Now();
-      if (outer_->task_tracker_->RunTask(task, sequence->token()))
-        outer_->delegate_->DidRunTask(task, start_time - task->sequenced_time);
+      std::unique_ptr<Task> task = sequence->TakeTask();
+      const TaskPriority task_priority = task->traits.priority();
+      const TimeDelta task_latency = TimeTicks::Now() - task->sequenced_time;
+      if (outer_->task_tracker_->RunTask(std::move(task), sequence->token()))
+        outer_->delegate_->DidRunTaskWithPriority(task_priority, task_latency);
 
-      const bool sequence_became_empty = sequence->PopTask();
+      const bool sequence_became_empty = sequence->Pop();
 
       // If |sequence| isn't empty immediately after the pop, re-enqueue it to
       // maintain the invariant that a non-empty Sequence is always referenced
@@ -216,10 +225,9 @@ void SchedulerWorker::WakeUp() {
 }
 
 void SchedulerWorker::JoinForTesting() {
-  {
-    AutoSchedulerLock auto_lock(should_exit_for_testing_lock_);
-    should_exit_for_testing_ = true;
-  }
+  DCHECK(!should_exit_for_testing_.IsSet());
+  should_exit_for_testing_.Set();
+
   WakeUp();
 
   // Normally holding a lock and joining is dangerous. However, since this is
@@ -249,14 +257,18 @@ SchedulerWorker::SchedulerWorker(ThreadPriority priority_hint,
 }
 
 std::unique_ptr<SchedulerWorker::Thread> SchedulerWorker::Detach() {
-  DCHECK(!ShouldExitForTesting()) << "Worker was already joined";
+  DCHECK(!should_exit_for_testing_.IsSet()) << "Worker was already joined";
   AutoSchedulerLock auto_lock(thread_lock_);
   // If a wakeup is pending, then a WakeUp() came in while we were deciding to
   // detach. This means we can't go away anymore since we would break the
   // guarantee that we call GetWork() after a successful wakeup.
   if (thread_->IsWakeUpPending())
     return nullptr;
-  last_detach_time_ = TimeTicks::Now();
+
+  // Call OnDetach() within the scope of |thread_lock_| to prevent the delegate
+  // from being used concurrently from an old and a new thread.
+  delegate_->OnDetach();
+
   return std::move(thread_);
 }
 
@@ -269,10 +281,5 @@ void SchedulerWorker::CreateThreadAssertSynchronized() {
   CreateThread();
 }
 
-bool SchedulerWorker::ShouldExitForTesting() const {
-  AutoSchedulerLock auto_lock(should_exit_for_testing_lock_);
-  return should_exit_for_testing_;
-}
-
 }  // namespace internal
 }  // namespace base
diff --git a/src/base/task_scheduler/scheduler_worker.h b/src/base/task_scheduler/scheduler_worker.h
index eee2f4a..a9b891a 100644
--- a/src/base/task_scheduler/scheduler_worker.h
+++ b/src/base/task_scheduler/scheduler_worker.h
@@ -10,6 +10,7 @@
 #include "base/base_export.h"
 #include "base/macros.h"
 #include "base/memory/ref_counted.h"
+#include "base/synchronization/atomic_flag.h"
 #include "base/synchronization/waitable_event.h"
 #include "base/task_scheduler/scheduler_lock.h"
 #include "base/task_scheduler/sequence.h"
@@ -37,7 +38,7 @@ class TaskTracker;
 class BASE_EXPORT SchedulerWorker {
  public:
   // Delegate interface for SchedulerWorker. The methods are always called from
-  // a thread managed by the SchedulerWorker instance.
+  // the thread managed by the SchedulerWorker instance.
   class Delegate {
    public:
     virtual ~Delegate() = default;
@@ -46,17 +47,17 @@ class BASE_EXPORT SchedulerWorker {
     // If a thread is recreated after detachment, |detach_duration| is the time
     // elapsed since detachment. Otherwise, if this is the first thread created
     // for |worker|, |detach_duration| is TimeDelta::Max().
-    virtual void OnMainEntry(SchedulerWorker* worker,
-                             const TimeDelta& detach_duration) = 0;
+    virtual void OnMainEntry(SchedulerWorker* worker) = 0;
 
     // Called by a thread managed by |worker| to get a Sequence from which to
     // run a Task.
     virtual scoped_refptr<Sequence> GetWork(SchedulerWorker* worker) = 0;
 
-    // Called by the SchedulerWorker after it ran |task|. |task_latency| is the
-    // time elapsed between when the task was posted and when it started to run.
-    virtual void DidRunTask(const Task* task,
-                            const TimeDelta& task_latency) = 0;
+    // Called by the SchedulerWorker after it ran a task with |task_priority|.
+    // |task_latency| is the time elapsed between when the task was posted and
+    // when it started to run.
+    virtual void DidRunTaskWithPriority(TaskPriority task_priority,
+                                        const TimeDelta& task_latency) = 0;
 
     // Called when |sequence| isn't empty after the SchedulerWorker pops a Task
     // from it. |sequence| is the last Sequence returned by GetWork().
@@ -81,6 +82,11 @@ class BASE_EXPORT SchedulerWorker {
     // This MUST return false if SchedulerWorker::JoinForTesting() is in
     // progress.
     virtual bool CanDetach(SchedulerWorker* worker) = 0;
+
+    // Called by a thread before it detaches. This method is not allowed to
+    // acquire a SchedulerLock because it is called within the scope of another
+    // SchedulerLock.
+    virtual void OnDetach() = 0;
   };
 
   enum class InitialState { ALIVE, DETACHED };
@@ -135,27 +141,18 @@ class BASE_EXPORT SchedulerWorker {
 
   void CreateThreadAssertSynchronized();
 
-  bool ShouldExitForTesting() const;
-
   // Synchronizes access to |thread_|.
   mutable SchedulerLock thread_lock_;
 
   // The underlying thread for this SchedulerWorker.
   std::unique_ptr<Thread> thread_;
 
-  // Time of the last successful Detach(). Is only accessed from the thread
-  // managed by this SchedulerWorker.
-  TimeTicks last_detach_time_;
-
   const ThreadPriority priority_hint_;
   const std::unique_ptr<Delegate> delegate_;
   TaskTracker* const task_tracker_;
 
-  // Synchronizes access to |should_exit_for_testing_|.
-  mutable SchedulerLock should_exit_for_testing_lock_;
-
-  // True once JoinForTesting() has been called.
-  bool should_exit_for_testing_ = false;
+  // Set once JoinForTesting() has been called.
+  AtomicFlag should_exit_for_testing_;
 
   DISALLOW_COPY_AND_ASSIGN(SchedulerWorker);
 };
diff --git a/src/base/task_scheduler/scheduler_worker_pool.h b/src/base/task_scheduler/scheduler_worker_pool.h
index 43dce60..c742ac3 100644
--- a/src/base/task_scheduler/scheduler_worker_pool.h
+++ b/src/base/task_scheduler/scheduler_worker_pool.h
@@ -9,6 +9,8 @@
 
 #include "base/base_export.h"
 #include "base/memory/ref_counted.h"
+#include "base/sequenced_task_runner.h"
+#include "base/single_thread_task_runner.h"
 #include "base/task_runner.h"
 #include "base/task_scheduler/sequence.h"
 #include "base/task_scheduler/task.h"
@@ -25,11 +27,23 @@ class BASE_EXPORT SchedulerWorkerPool {
  public:
   virtual ~SchedulerWorkerPool() = default;
 
-  // Returns a TaskRunner whose PostTask invocations will result in scheduling
-  // Tasks with |traits| and |execution_mode| in this SchedulerWorkerPool.
+  // Returns a TaskRunner whose PostTask invocations result in scheduling tasks
+  // in this SchedulerWorkerPool using |traits|. Tasks may run in any order and
+  // in parallel.
   virtual scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(
-      const TaskTraits& traits,
-      ExecutionMode execution_mode) = 0;
+      const TaskTraits& traits) = 0;
+
+  // Returns a SequencedTaskRunner whose PostTask invocations result in
+  // scheduling tasks in this SchedulerWorkerPool using |traits|. Tasks run one
+  // at a time in posting order.
+  virtual scoped_refptr<SequencedTaskRunner>
+  CreateSequencedTaskRunnerWithTraits(const TaskTraits& traits) = 0;
+
+  // Returns a SingleThreadTaskRunner whose PostTask invocations result in
+  // scheduling tasks in this SchedulerWorkerPool using |traits|. Tasks run on a
+  // single thread in posting order.
+  virtual scoped_refptr<SingleThreadTaskRunner>
+  CreateSingleThreadTaskRunnerWithTraits(const TaskTraits& traits) = 0;
 
   // Inserts |sequence| with |sequence_sort_key| into a queue of Sequences that
   // can be processed by any worker owned by this SchedulerWorkerPool. Must only
diff --git a/src/base/task_scheduler/scheduler_worker_pool_impl.cc b/src/base/task_scheduler/scheduler_worker_pool_impl.cc
index e5599dd..9334c13 100644
--- a/src/base/task_scheduler/scheduler_worker_pool_impl.cc
+++ b/src/base/task_scheduler/scheduler_worker_pool_impl.cc
@@ -15,9 +15,11 @@
 #include "base/lazy_instance.h"
 #include "base/memory/ptr_util.h"
 #include "base/metrics/histogram.h"
+#include "base/sequence_token.h"
 #include "base/sequenced_task_runner.h"
 #include "base/single_thread_task_runner.h"
 #include "base/strings/stringprintf.h"
+#include "base/task_runner.h"
 #include "base/task_scheduler/delayed_task_manager.h"
 #include "base/task_scheduler/task_tracker.h"
 #include "base/threading/platform_thread.h"
@@ -33,12 +35,12 @@ namespace {
 constexpr char kPoolNameSuffix[] = "Pool";
 constexpr char kDetachDurationHistogramPrefix[] =
     "TaskScheduler.DetachDuration.";
+constexpr char kNumTasksBeforeDetachHistogramPrefix[] =
+    "TaskScheduler.NumTasksBeforeDetach.";
+constexpr char kNumTasksBetweenWaitsHistogramPrefix[] =
+    "TaskScheduler.NumTasksBetweenWaits.";
 constexpr char kTaskLatencyHistogramPrefix[] = "TaskScheduler.TaskLatency.";
 
-// SchedulerWorker that owns the current thread, if any.
-LazyInstance<ThreadLocalPointer<const SchedulerWorker>>::Leaky
-    tls_current_worker = LAZY_INSTANCE_INITIALIZER;
-
 // SchedulerWorkerPool that owns the current thread, if any.
 LazyInstance<ThreadLocalPointer<const SchedulerWorkerPool>>::Leaky
     tls_current_worker_pool = LAZY_INSTANCE_INITIALIZER;
@@ -110,7 +112,9 @@ class SchedulerSequencedTaskRunner : public SequencedTaskRunner {
   }
 
   bool RunsTasksOnCurrentThread() const override {
-    return tls_current_worker_pool.Get().Get() == worker_pool_;
+    // TODO(fdoray): Rename TaskRunner::RunsTaskOnCurrentThread() to something
+    // that reflects this behavior more accurately. crbug.com/646905
+    return sequence_->token() == SequenceToken::GetForCurrentThread();
   }
 
  private:
@@ -193,7 +197,10 @@ class SchedulerWorkerPoolImpl::SchedulerSingleThreadTaskRunner :
   }
 
   bool RunsTasksOnCurrentThread() const override {
-    return tls_current_worker.Get().Get() == worker_;
+    // Even though this is a SingleThreadTaskRunner, test the actual sequence
+    // instead of the assigned worker so that another task randomly assigned
+    // to the same worker doesn't return true by happenstance.
+    return sequence_->token() == SequenceToken::GetForCurrentThread();
   }
 
  private:
@@ -230,13 +237,14 @@ class SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl
   }
 
   // SchedulerWorker::Delegate:
-  void OnMainEntry(SchedulerWorker* worker,
-                   const TimeDelta& detach_duration) override;
+  void OnMainEntry(SchedulerWorker* worker) override;
   scoped_refptr<Sequence> GetWork(SchedulerWorker* worker) override;
-  void DidRunTask(const Task* task, const TimeDelta& task_latency) override;
+  void DidRunTaskWithPriority(TaskPriority task_priority,
+                              const TimeDelta& task_latency) override;
   void ReEnqueueSequence(scoped_refptr<Sequence> sequence) override;
   TimeDelta GetSleepTimeout() override;
   bool CanDetach(SchedulerWorker* worker) override;
+  void OnDetach() override;
 
   void RegisterSingleThreadTaskRunner() {
     // No barrier as barriers only affect sequential consistency which is
@@ -260,9 +268,27 @@ class SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl
   // |single_threaded_priority_queue_|.
   bool last_sequence_is_single_threaded_ = false;
 
+  // Time of the last detach.
+  TimeTicks last_detach_time_;
+
   // Time when GetWork() first returned nullptr.
   TimeTicks idle_start_time_;
 
+  // Indicates whether the last call to GetWork() returned nullptr.
+  bool last_get_work_returned_nullptr_ = false;
+
+  // Indicates whether the SchedulerWorker was detached since the last call to
+  // GetWork().
+  bool did_detach_since_last_get_work_ = false;
+
+  // Number of tasks executed since the last time the
+  // TaskScheduler.NumTasksBetweenWaits histogram was recorded.
+  size_t num_tasks_since_last_wait_ = 0;
+
+  // Number of tasks executed since the last time the
+  // TaskScheduler.NumTasksBeforeDetach histogram was recorded.
+  size_t num_tasks_since_last_detach_ = 0;
+
   subtle::Atomic32 num_single_threaded_runners_ = 0;
 
   const int index_;
@@ -282,66 +308,41 @@ std::unique_ptr<SchedulerWorkerPoolImpl> SchedulerWorkerPoolImpl::Create(
     const ReEnqueueSequenceCallback& re_enqueue_sequence_callback,
     TaskTracker* task_tracker,
     DelayedTaskManager* delayed_task_manager) {
-  std::unique_ptr<SchedulerWorkerPoolImpl> worker_pool(
-      new SchedulerWorkerPoolImpl(params.name(),
-                                  params.io_restriction(),
-                                  params.suggested_reclaim_time(),
-                                  task_tracker, delayed_task_manager));
-  if (worker_pool->Initialize(params.priority_hint(), params.max_threads(),
-                              re_enqueue_sequence_callback)) {
+  auto worker_pool = WrapUnique(new SchedulerWorkerPoolImpl(
+      params.name(), params.suggested_reclaim_time(), task_tracker,
+      delayed_task_manager));
+  if (worker_pool->Initialize(
+          params.priority_hint(), params.standby_thread_policy(),
+          params.max_threads(), re_enqueue_sequence_callback)) {
     return worker_pool;
   }
   return nullptr;
 }
 
-void SchedulerWorkerPoolImpl::WaitForAllWorkersIdleForTesting() {
-  AutoSchedulerLock auto_lock(idle_workers_stack_lock_);
-  while (idle_workers_stack_.Size() < workers_.size())
-    idle_workers_stack_cv_for_testing_->Wait();
-}
-
-void SchedulerWorkerPoolImpl::JoinForTesting() {
-  DCHECK(!CanWorkerDetachForTesting() || suggested_reclaim_time_.is_max()) <<
-      "Workers can detach during join.";
-  for (const auto& worker : workers_)
-    worker->JoinForTesting();
-
-  DCHECK(!join_for_testing_returned_.IsSignaled());
-  join_for_testing_returned_.Signal();
+scoped_refptr<TaskRunner> SchedulerWorkerPoolImpl::CreateTaskRunnerWithTraits(
+    const TaskTraits& traits) {
+  return make_scoped_refptr(new SchedulerParallelTaskRunner(traits, this));
 }
 
-void SchedulerWorkerPoolImpl::DisallowWorkerDetachmentForTesting() {
-  worker_detachment_disallowed_.Set();
+scoped_refptr<SequencedTaskRunner>
+SchedulerWorkerPoolImpl::CreateSequencedTaskRunnerWithTraits(
+    const TaskTraits& traits) {
+  return make_scoped_refptr(new SchedulerSequencedTaskRunner(traits, this));
 }
 
-scoped_refptr<TaskRunner> SchedulerWorkerPoolImpl::CreateTaskRunnerWithTraits(
-    const TaskTraits& traits,
-    ExecutionMode execution_mode) {
-  switch (execution_mode) {
-    case ExecutionMode::PARALLEL:
-      return make_scoped_refptr(new SchedulerParallelTaskRunner(traits, this));
-
-    case ExecutionMode::SEQUENCED:
-      return make_scoped_refptr(new SchedulerSequencedTaskRunner(traits, this));
-
-    case ExecutionMode::SINGLE_THREADED: {
-      // TODO(fdoray): Find a way to take load into account when assigning a
-      // SchedulerWorker to a SingleThreadTaskRunner. Also, this code
-      // assumes that all SchedulerWorkers are alive. Eventually, we might
-      // decide to tear down threads that haven't run tasks for a long time.
-      size_t worker_index;
-      {
-        AutoSchedulerLock auto_lock(next_worker_index_lock_);
-        worker_index = next_worker_index_;
-        next_worker_index_ = (next_worker_index_ + 1) % workers_.size();
-      }
-      return make_scoped_refptr(new SchedulerSingleThreadTaskRunner(
-          traits, this, workers_[worker_index].get()));
-    }
+scoped_refptr<SingleThreadTaskRunner>
+SchedulerWorkerPoolImpl::CreateSingleThreadTaskRunnerWithTraits(
+    const TaskTraits& traits) {
+  // TODO(fdoray): Find a way to take load into account when assigning a
+  // SchedulerWorker to a SingleThreadTaskRunner.
+  size_t worker_index;
+  {
+    AutoSchedulerLock auto_lock(next_worker_index_lock_);
+    worker_index = next_worker_index_;
+    next_worker_index_ = (next_worker_index_ + 1) % workers_.size();
   }
-
-  NOTREACHED();
-  return nullptr;
+  return make_scoped_refptr(new SchedulerSingleThreadTaskRunner(
+      traits, this, workers_[worker_index].get()));
 }
 
 void SchedulerWorkerPoolImpl::ReEnqueueSequence(
@@ -393,7 +394,7 @@ void SchedulerWorkerPoolImpl::PostTaskWithSequenceNow(
 
   // Confirm that |task| is ready to run (its delayed run time is either null or
   // in the past).
-  DCHECK_LE(task->delayed_run_time, delayed_task_manager_->Now());
+  DCHECK_LE(task->delayed_run_time, TimeTicks::Now());
 
   // Because |worker| belongs to this worker pool, we know that the type
   // of its delegate is SchedulerWorkerDelegateImpl.
@@ -418,12 +419,47 @@ void SchedulerWorkerPoolImpl::PostTaskWithSequenceNow(
 
     // Wake up a worker to process |sequence|.
     if (worker)
-      worker->WakeUp();
+      WakeUpWorker(worker);
     else
       WakeUpOneWorker();
   }
 }
 
+void SchedulerWorkerPoolImpl::GetHistograms(
+    std::vector<const HistogramBase*>* histograms) const {
+  histograms->push_back(detach_duration_histogram_);
+  histograms->push_back(num_tasks_between_waits_histogram_);
+}
+
+void SchedulerWorkerPoolImpl::WaitForAllWorkersIdleForTesting() {
+  AutoSchedulerLock auto_lock(idle_workers_stack_lock_);
+  while (idle_workers_stack_.Size() < workers_.size())
+    idle_workers_stack_cv_for_testing_->Wait();
+}
+
+void SchedulerWorkerPoolImpl::JoinForTesting() {
+  DCHECK(!CanWorkerDetachForTesting() || suggested_reclaim_time_.is_max())
+      << "Workers can detach during join.";
+  for (const auto& worker : workers_)
+    worker->JoinForTesting();
+
+  DCHECK(!join_for_testing_returned_.IsSignaled());
+  join_for_testing_returned_.Signal();
+}
+
+void SchedulerWorkerPoolImpl::DisallowWorkerDetachmentForTesting() {
+  worker_detachment_disallowed_.Set();
+}
+
+size_t SchedulerWorkerPoolImpl::NumberOfAliveWorkersForTesting() {
+  size_t num_alive_workers = 0;
+  for (const auto& worker : workers_) {
+    if (worker->ThreadAliveForTesting())
+      ++num_alive_workers;
+  }
+  return num_alive_workers;
+}
+
 SchedulerWorkerPoolImpl::SchedulerSingleThreadTaskRunner::
     SchedulerSingleThreadTaskRunner(const TaskTraits& traits,
                                     SchedulerWorkerPool* worker_pool,
@@ -458,8 +494,7 @@ SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::
     ~SchedulerWorkerDelegateImpl() = default;
 
 void SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::OnMainEntry(
-    SchedulerWorker* worker,
-    const TimeDelta& detach_duration) {
+    SchedulerWorker* worker) {
 #if DCHECK_IS_ON()
   // Wait for |outer_->workers_created_| to avoid traversing
   // |outer_->workers_| while it is being filled by Initialize().
@@ -467,23 +502,21 @@ void SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::OnMainEntry(
   DCHECK(ContainsWorker(outer_->workers_, worker));
 #endif
 
-  if (!detach_duration.is_max())
-    outer_->detach_duration_histogram_->AddTime(detach_duration);
+  DCHECK_EQ(num_tasks_since_last_wait_, 0U);
+
+  if (!last_detach_time_.is_null()) {
+    outer_->detach_duration_histogram_->AddTime(TimeTicks::Now() -
+                                                last_detach_time_);
+  }
 
   PlatformThread::SetName(
       StringPrintf("TaskScheduler%sWorker%d", outer_->name_.c_str(), index_));
 
-  DCHECK(!tls_current_worker.Get().Get());
   DCHECK(!tls_current_worker_pool.Get().Get());
-  tls_current_worker.Get().Set(worker);
   tls_current_worker_pool.Get().Set(outer_);
 
-  // New threads haven't run GetWork() yet, so reset the idle_start_time_.
+  // New threads haven't run GetWork() yet, so reset the |idle_start_time_|.
   idle_start_time_ = TimeTicks();
-
-  ThreadRestrictions::SetIOAllowed(
-      outer_->io_restriction_ ==
-          SchedulerWorkerPoolParams::IORestriction::ALLOWED);
 }
 
 scoped_refptr<Sequence>
@@ -491,6 +524,23 @@ SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::GetWork(
     SchedulerWorker* worker) {
   DCHECK(ContainsWorker(outer_->workers_, worker));
 
+  // Record the TaskScheduler.NumTasksBetweenWaits histogram if the
+  // SchedulerWorker waited on its WaitableEvent since the last GetWork().
+  //
+  // Note: When GetWork() starts returning nullptr, the SchedulerWorker waits on
+  // its WaitableEvent. When it wakes up (either because WakeUp() was called or
+  // because the sleep timeout expired), it calls GetWork() again. The code
+  // below records the histogram and, if GetWork() returns nullptr again, the
+  // SchedulerWorker may detach. If that happens,
+  // |did_detach_since_last_get_work_| is set to true and the next call to
+  // GetWork() won't record the histogram  (which is correct since the
+  // SchedulerWorker didn't wait on its WaitableEvent since the last time the
+  // histogram was recorded).
+  if (last_get_work_returned_nullptr_ && !did_detach_since_last_get_work_) {
+    outer_->num_tasks_between_waits_histogram_->Add(num_tasks_since_last_wait_);
+    num_tasks_since_last_wait_ = 0;
+  }
+
   scoped_refptr<Sequence> sequence;
   {
     std::unique_ptr<PriorityQueue::Transaction> shared_transaction(
@@ -517,6 +567,8 @@ SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::GetWork(
       outer_->AddToIdleWorkersStack(worker);
       if (idle_start_time_.is_null())
         idle_start_time_ = TimeTicks::Now();
+      did_detach_since_last_get_work_ = false;
+      last_get_work_returned_nullptr_ = true;
       return nullptr;
     }
 
@@ -540,16 +592,21 @@ SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::GetWork(
   }
   DCHECK(sequence);
 
+  outer_->RemoveFromIdleWorkersStack(worker);
   idle_start_time_ = TimeTicks();
+  did_detach_since_last_get_work_ = false;
+  last_get_work_returned_nullptr_ = false;
 
-  outer_->RemoveFromIdleWorkersStack(worker);
   return sequence;
 }
 
-void SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::DidRunTask(
-    const Task* task,
-    const TimeDelta& task_latency) {
-  const int priority_index = static_cast<int>(task->traits.priority());
+void SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::
+    DidRunTaskWithPriority(TaskPriority task_priority,
+                           const TimeDelta& task_latency) {
+  ++num_tasks_since_last_wait_;
+  ++num_tasks_since_last_detach_;
+
+  const int priority_index = static_cast<int>(task_priority);
 
   // As explained in the header file, histograms are allocated on demand. It
   // doesn't matter if an element of |task_latency_histograms_| is set multiple
@@ -559,7 +616,7 @@ void SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::DidRunTask(
       subtle::Acquire_Load(&outer_->task_latency_histograms_[priority_index]));
   if (!task_latency_histogram) {
     task_latency_histogram =
-        GetTaskLatencyHistogram(outer_->name_, task->traits.priority());
+        GetTaskLatencyHistogram(outer_->name_, task_priority);
     subtle::Release_Store(
         &outer_->task_latency_histograms_[priority_index],
         reinterpret_cast<subtle::AtomicWord>(task_latency_histogram));
@@ -603,14 +660,20 @@ bool SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::CanDetach(
   return can_detach;
 }
 
+void SchedulerWorkerPoolImpl::SchedulerWorkerDelegateImpl::OnDetach() {
+  DCHECK(!did_detach_since_last_get_work_);
+  outer_->num_tasks_before_detach_histogram_->Add(num_tasks_since_last_detach_);
+  num_tasks_since_last_detach_ = 0;
+  did_detach_since_last_get_work_ = true;
+  last_detach_time_ = TimeTicks::Now();
+}
+
 SchedulerWorkerPoolImpl::SchedulerWorkerPoolImpl(
     StringPiece name,
-    SchedulerWorkerPoolParams::IORestriction io_restriction,
     const TimeDelta& suggested_reclaim_time,
     TaskTracker* task_tracker,
     DelayedTaskManager* delayed_task_manager)
     : name_(name.as_string()),
-      io_restriction_(io_restriction),
       suggested_reclaim_time_(suggested_reclaim_time),
       idle_workers_stack_lock_(shared_priority_queue_.container_lock()),
       idle_workers_stack_cv_for_testing_(
@@ -621,12 +684,32 @@ SchedulerWorkerPoolImpl::SchedulerWorkerPoolImpl(
       workers_created_(WaitableEvent::ResetPolicy::MANUAL,
                        WaitableEvent::InitialState::NOT_SIGNALED),
 #endif
+      // Mimics the UMA_HISTOGRAM_LONG_TIMES macro.
       detach_duration_histogram_(Histogram::FactoryTimeGet(
           kDetachDurationHistogramPrefix + name_ + kPoolNameSuffix,
           TimeDelta::FromMilliseconds(1),
           TimeDelta::FromHours(1),
           50,
           HistogramBase::kUmaTargetedHistogramFlag)),
+      // Mimics the UMA_HISTOGRAM_COUNTS_1000 macro. When a worker runs more
+      // than 1000 tasks before detaching, there is no need to know the exact
+      // number of tasks that ran.
+      num_tasks_before_detach_histogram_(Histogram::FactoryGet(
+          kNumTasksBeforeDetachHistogramPrefix + name_ + kPoolNameSuffix,
+          1,
+          1000,
+          50,
+          HistogramBase::kUmaTargetedHistogramFlag)),
+      // Mimics the UMA_HISTOGRAM_COUNTS_100 macro. A SchedulerWorker is
+      // expected to run between zero and a few tens of tasks between waits.
+      // When it runs more than 100 tasks, there is no need to know the exact
+      // number of tasks that ran.
+      num_tasks_between_waits_histogram_(Histogram::FactoryGet(
+          kNumTasksBetweenWaitsHistogramPrefix + name_ + kPoolNameSuffix,
+          1,
+          100,
+          50,
+          HistogramBase::kUmaTargetedHistogramFlag)),
       task_tracker_(task_tracker),
       delayed_task_manager_(delayed_task_manager) {
   DCHECK(task_tracker_);
@@ -635,23 +718,34 @@ SchedulerWorkerPoolImpl::SchedulerWorkerPoolImpl(
 
 bool SchedulerWorkerPoolImpl::Initialize(
     ThreadPriority priority_hint,
+    SchedulerWorkerPoolParams::StandbyThreadPolicy standby_thread_policy,
     size_t max_threads,
     const ReEnqueueSequenceCallback& re_enqueue_sequence_callback) {
   AutoSchedulerLock auto_lock(idle_workers_stack_lock_);
 
   DCHECK(workers_.empty());
-
-  for (size_t i = 0; i < max_threads; ++i) {
+  workers_.resize(max_threads);
+
+  // Create workers and push them to the idle stack in reverse order of index.
+  // This ensures that they are woken up in order of index and that the ALIVE
+  // worker is on top of the stack.
+  for (int index = max_threads - 1; index >= 0; --index) {
+    const bool is_standby_lazy =
+        standby_thread_policy ==
+        SchedulerWorkerPoolParams::StandbyThreadPolicy::LAZY;
+    const SchedulerWorker::InitialState initial_state =
+        (index == 0 && !is_standby_lazy)
+            ? SchedulerWorker::InitialState::ALIVE
+            : SchedulerWorker::InitialState::DETACHED;
     std::unique_ptr<SchedulerWorker> worker = SchedulerWorker::Create(
-        priority_hint, MakeUnique<SchedulerWorkerDelegateImpl>(
-                           this, re_enqueue_sequence_callback,
-                           &shared_priority_queue_, static_cast<int>(i)),
-        task_tracker_, i == 0 ? SchedulerWorker::InitialState::ALIVE
-                              : SchedulerWorker::InitialState::DETACHED);
+        priority_hint,
+        MakeUnique<SchedulerWorkerDelegateImpl>(
+            this, re_enqueue_sequence_callback, &shared_priority_queue_, index),
+        task_tracker_, initial_state);
     if (!worker)
       break;
     idle_workers_stack_.Push(worker.get());
-    workers_.push_back(std::move(worker));
+    workers_[index] = std::move(worker);
   }
 
 #if DCHECK_IS_ON()
@@ -661,6 +755,14 @@ bool SchedulerWorkerPoolImpl::Initialize(
   return !workers_.empty();
 }
 
+void SchedulerWorkerPoolImpl::WakeUpWorker(SchedulerWorker* worker) {
+  DCHECK(worker);
+  RemoveFromIdleWorkersStack(worker);
+  worker->WakeUp();
+  // TODO(robliao): Honor StandbyThreadPolicy::ONE here and consider adding
+  // hysteresis to the CanDetach check. See https://crbug.com/666041.
+}
+
 void SchedulerWorkerPoolImpl::WakeUpOneWorker() {
   SchedulerWorker* worker;
   {
diff --git a/src/base/task_scheduler/scheduler_worker_pool_impl.h b/src/base/task_scheduler/scheduler_worker_pool_impl.h
index 3ab2299..b2dc68a 100644
--- a/src/base/task_scheduler/scheduler_worker_pool_impl.h
+++ b/src/base/task_scheduler/scheduler_worker_pool_impl.h
@@ -20,7 +20,6 @@
 #include "base/strings/string_piece.h"
 #include "base/synchronization/atomic_flag.h"
 #include "base/synchronization/condition_variable.h"
-#include "base/task_runner.h"
 #include "base/task_scheduler/priority_queue.h"
 #include "base/task_scheduler/scheduler_lock.h"
 #include "base/task_scheduler/scheduler_worker.h"
@@ -66,6 +65,32 @@ class BASE_EXPORT SchedulerWorkerPoolImpl : public SchedulerWorkerPool {
       TaskTracker* task_tracker,
       DelayedTaskManager* delayed_task_manager);
 
+  // SchedulerWorkerPool:
+  scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(
+      const TaskTraits& traits) override;
+  scoped_refptr<SequencedTaskRunner> CreateSequencedTaskRunnerWithTraits(
+      const TaskTraits& traits) override;
+  scoped_refptr<SingleThreadTaskRunner> CreateSingleThreadTaskRunnerWithTraits(
+      const TaskTraits& traits) override;
+  void ReEnqueueSequence(scoped_refptr<Sequence> sequence,
+                         const SequenceSortKey& sequence_sort_key) override;
+  bool PostTaskWithSequence(std::unique_ptr<Task> task,
+                            scoped_refptr<Sequence> sequence,
+                            SchedulerWorker* worker) override;
+  void PostTaskWithSequenceNow(std::unique_ptr<Task> task,
+                               scoped_refptr<Sequence> sequence,
+                               SchedulerWorker* worker) override;
+
+  const HistogramBase* num_tasks_before_detach_histogram() const {
+    return num_tasks_before_detach_histogram_;
+  }
+
+  const HistogramBase* num_tasks_between_waits_histogram() const {
+    return num_tasks_between_waits_histogram_;
+  }
+
+  void GetHistograms(std::vector<const HistogramBase*>* histograms) const;
+
   // Waits until all workers are idle.
   void WaitForAllWorkersIdleForTesting();
 
@@ -81,35 +106,28 @@ class BASE_EXPORT SchedulerWorkerPoolImpl : public SchedulerWorkerPool {
   // reclaimed).
   void DisallowWorkerDetachmentForTesting();
 
-  // SchedulerWorkerPool:
-  scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(
-      const TaskTraits& traits,
-      ExecutionMode execution_mode) override;
-  void ReEnqueueSequence(scoped_refptr<Sequence> sequence,
-                         const SequenceSortKey& sequence_sort_key) override;
-  bool PostTaskWithSequence(std::unique_ptr<Task> task,
-                            scoped_refptr<Sequence> sequence,
-                            SchedulerWorker* worker) override;
-  void PostTaskWithSequenceNow(std::unique_ptr<Task> task,
-                               scoped_refptr<Sequence> sequence,
-                               SchedulerWorker* worker) override;
+  // Returns the number of workers alive in this worker pool. The value may
+  // change if workers are woken up or detached during this call.
+  size_t NumberOfAliveWorkersForTesting();
 
  private:
   class SchedulerSingleThreadTaskRunner;
   class SchedulerWorkerDelegateImpl;
 
   SchedulerWorkerPoolImpl(StringPiece name,
-                          SchedulerWorkerPoolParams::IORestriction
-                              io_restriction,
                           const TimeDelta& suggested_reclaim_time,
                           TaskTracker* task_tracker,
                           DelayedTaskManager* delayed_task_manager);
 
   bool Initialize(
       ThreadPriority priority_hint,
+      SchedulerWorkerPoolParams::StandbyThreadPolicy standby_thread_policy,
       size_t max_threads,
       const ReEnqueueSequenceCallback& re_enqueue_sequence_callback);
 
+  // Wakes up |worker|.
+  void WakeUpWorker(SchedulerWorker* worker);
+
   // Wakes up the last worker from this worker pool to go idle, if any.
   void WakeUpOneWorker();
 
@@ -142,9 +160,6 @@ class BASE_EXPORT SchedulerWorkerPoolImpl : public SchedulerWorkerPool {
   // PriorityQueue from which all threads of this worker pool get work.
   PriorityQueue shared_priority_queue_;
 
-  // Indicates whether Tasks on this worker pool are allowed to make I/O calls.
-  const SchedulerWorkerPoolParams::IORestriction io_restriction_;
-
   // Suggested reclaim time for workers.
   const TimeDelta suggested_reclaim_time_;
 
@@ -155,7 +170,11 @@ class BASE_EXPORT SchedulerWorkerPoolImpl : public SchedulerWorkerPool {
   // details in GetWork()).
   mutable SchedulerLock idle_workers_stack_lock_;
 
-  // Stack of idle workers.
+  // Stack of idle workers. Initially, all workers are on this stack. A worker
+  // is removed from the stack before its WakeUp() function is called and when
+  // it receives work from GetWork() (a worker calls GetWork() when its sleep
+  // timeout expires, even if its WakeUp() method hasn't been called). A worker
+  // is pushed on this stack when it receives nullptr from GetWork().
   SchedulerWorkerStack idle_workers_stack_;
 
   // Signaled when all workers become idle.
@@ -177,6 +196,14 @@ class BASE_EXPORT SchedulerWorkerPoolImpl : public SchedulerWorkerPool {
   // leaked.
   HistogramBase* const detach_duration_histogram_;
 
+  // TaskScheduler.NumTasksBeforeDetach.[worker pool name] histogram.
+  // Intentionally leaked.
+  HistogramBase* const num_tasks_before_detach_histogram_;
+
+  // TaskScheduler.NumTasksBetweenWaits.[worker pool name] histogram.
+  // Intentionally leaked.
+  HistogramBase* const num_tasks_between_waits_histogram_;
+
   // TaskScheduler.TaskLatency.[worker pool name].[task priority] histograms.
   // Indexed by task priority. Histograms are allocated on demand to reduce
   // memory usage (some task priorities might never run in this
diff --git a/src/base/task_scheduler/scheduler_worker_pool_params.cc b/src/base/task_scheduler/scheduler_worker_pool_params.cc
index d820460..d08ebf6 100644
--- a/src/base/task_scheduler/scheduler_worker_pool_params.cc
+++ b/src/base/task_scheduler/scheduler_worker_pool_params.cc
@@ -11,12 +11,12 @@ namespace base {
 SchedulerWorkerPoolParams::SchedulerWorkerPoolParams(
     const std::string& name,
     ThreadPriority priority_hint,
-    IORestriction io_restriction,
+    StandbyThreadPolicy standby_thread_policy,
     int max_threads,
     const TimeDelta& suggested_reclaim_time)
     : name_(name),
       priority_hint_(priority_hint),
-      io_restriction_(io_restriction),
+      standby_thread_policy_(standby_thread_policy),
       max_threads_(max_threads),
       suggested_reclaim_time_(suggested_reclaim_time) {}
 
diff --git a/src/base/task_scheduler/scheduler_worker_pool_params.h b/src/base/task_scheduler/scheduler_worker_pool_params.h
index bba7855..f3cd20f 100644
--- a/src/base/task_scheduler/scheduler_worker_pool_params.h
+++ b/src/base/task_scheduler/scheduler_worker_pool_params.h
@@ -16,9 +16,12 @@ class TimeDelta;
 
 class BASE_EXPORT SchedulerWorkerPoolParams final {
  public:
-  enum class IORestriction {
-    ALLOWED,
-    DISALLOWED,
+  enum class StandbyThreadPolicy {
+    // Create threads as needed on demand, reclaimed as necessary.
+    LAZY,
+    // When possible, keep one idle thread alive on standby, reclaimed as
+    // necessary.
+    ONE,
   };
 
   // Construct a scheduler worker pool parameter object. |name| will be used to
@@ -26,13 +29,12 @@ class BASE_EXPORT SchedulerWorkerPoolParams final {
   // ("TaskScheduler." + histogram name + "." + |name| + extra suffixes). The
   // pool will contain up to |max_threads|. |priority_hint| is the preferred
   // thread priority; the actual thread priority depends on shutdown state and
-  // platform capabilities. |io_restriction| indicates whether Tasks on the pool
-  // are allowed to make I/O calls. |suggested_reclaim_time| sets a suggestion
-  // on when to reclaim idle threads. The pool is free to ignore this value for
+  // platform capabilities. |suggested_reclaim_time| sets a suggestion on when
+  // to reclaim idle threads. The pool is free to ignore this value for
   // performance or correctness reasons.
   SchedulerWorkerPoolParams(const std::string& name,
                             ThreadPriority priority_hint,
-                            IORestriction io_restriction,
+                            StandbyThreadPolicy standby_thread_policy,
                             int max_threads,
                             const TimeDelta& suggested_reclaim_time);
   SchedulerWorkerPoolParams(SchedulerWorkerPoolParams&& other);
@@ -40,7 +42,9 @@ class BASE_EXPORT SchedulerWorkerPoolParams final {
 
   const std::string& name() const { return name_; }
   ThreadPriority priority_hint() const { return priority_hint_; }
-  IORestriction io_restriction() const { return io_restriction_; }
+  StandbyThreadPolicy standby_thread_policy() const {
+    return standby_thread_policy_;
+  }
   size_t max_threads() const { return max_threads_; }
   const TimeDelta& suggested_reclaim_time() const {
     return suggested_reclaim_time_;
@@ -49,7 +53,7 @@ class BASE_EXPORT SchedulerWorkerPoolParams final {
  private:
   std::string name_;
   ThreadPriority priority_hint_;
-  IORestriction io_restriction_;
+  StandbyThreadPolicy standby_thread_policy_;
   size_t max_threads_;
   TimeDelta suggested_reclaim_time_;
 
diff --git a/src/base/task_scheduler/sequence.cc b/src/base/task_scheduler/sequence.cc
index 86e99f0..601b540 100644
--- a/src/base/task_scheduler/sequence.cc
+++ b/src/base/task_scheduler/sequence.cc
@@ -26,37 +26,32 @@ bool Sequence::PushTask(std::unique_ptr<Task> task) {
   return queue_.size() == 1;
 }
 
-const Task* Sequence::PeekTask() const {
+std::unique_ptr<Task> Sequence::TakeTask() {
   AutoSchedulerLock auto_lock(lock_);
+  DCHECK(!queue_.empty());
+  DCHECK(queue_.front());
 
-  if (queue_.empty())
-    return nullptr;
+  const int priority_index =
+      static_cast<int>(queue_.front()->traits.priority());
+  DCHECK_GT(num_tasks_per_priority_[priority_index], 0U);
+  --num_tasks_per_priority_[priority_index];
 
-  return queue_.front().get();
+  return std::move(queue_.front());
 }
 
-bool Sequence::PopTask() {
-  // Delete the popped task outside the scope of |lock_|. This prevents a double
-  // acquisition of |lock_| if the task's destructor tries to post a task to
-  // this Sequence and reduces contention.
-  std::unique_ptr<Task> delete_outside_lock_scope;
-  bool sequence_empty_after_pop = false;
-
-  {
-    AutoSchedulerLock auto_lock(lock_);
-    DCHECK(!queue_.empty());
-
-    const int priority_index =
-        static_cast<int>(queue_.front()->traits.priority());
-    DCHECK_GT(num_tasks_per_priority_[priority_index], 0U);
-    --num_tasks_per_priority_[priority_index];
-
-    delete_outside_lock_scope = std::move(queue_.front());
-    queue_.pop();
-    sequence_empty_after_pop = queue_.empty();
-  }
+TaskTraits Sequence::PeekTaskTraits() const {
+  AutoSchedulerLock auto_lock(lock_);
+  DCHECK(!queue_.empty());
+  DCHECK(queue_.front());
+  return queue_.front()->traits;
+}
 
-  return sequence_empty_after_pop;
+bool Sequence::Pop() {
+  AutoSchedulerLock auto_lock(lock_);
+  DCHECK(!queue_.empty());
+  DCHECK(!queue_.front());
+  queue_.pop();
+  return queue_.empty();
 }
 
 SequenceSortKey Sequence::GetSortKey() const {
diff --git a/src/base/task_scheduler/sequence.h b/src/base/task_scheduler/sequence.h
index 8717336..408d99f 100644
--- a/src/base/task_scheduler/sequence.h
+++ b/src/base/task_scheduler/sequence.h
@@ -22,7 +22,10 @@
 namespace base {
 namespace internal {
 
-// A sequence holds tasks that must be executed in posting order.
+// A Sequence holds slots each containing up to a single Task that must be
+// executed in posting order.
+//
+// In comments below, an "empty Sequence" is a Sequence with no slot.
 //
 // Note: there is a known refcounted-ownership cycle in the Scheduler
 // architecture: Sequence -> Task -> TaskRunner -> Sequence -> ...
@@ -41,20 +44,27 @@ class BASE_EXPORT Sequence : public RefCountedThreadSafe<Sequence> {
  public:
   Sequence();
 
-  // Adds |task| at the end of the sequence's queue. Returns true if the
-  // sequence was empty before this operation.
+  // Adds |task| in a new slot at the end of the Sequence. Returns true if the
+  // Sequence was empty before this operation.
   bool PushTask(std::unique_ptr<Task> task);
 
-  // Returns the task in front of the sequence's queue, if any.
-  const Task* PeekTask() const;
+  // Transfers ownership of the Task in the front slot of the Sequence to the
+  // caller. The front slot of the Sequence will be nullptr and remain until
+  // Pop(). Cannot be called on an empty Sequence or a Sequence whose front slot
+  // is already nullptr.
+  std::unique_ptr<Task> TakeTask();
+
+  // Returns the TaskTraits of the Task in front of the Sequence. Cannot be
+  // called on an empty Sequence or on a Sequence whose front slot is empty.
+  TaskTraits PeekTaskTraits() const;
 
-  // Removes the task in front of the sequence's queue. Returns true if the
-  // sequence is empty after this operation. Cannot be called on an empty
-  // sequence.
-  bool PopTask();
+  // Removes the front slot of the Sequence. The front slot must have been
+  // emptied by TakeTask() before this is called. Cannot be called on an empty
+  // Sequence. Returns true if the Sequence is empty after this operation.
+  bool Pop();
 
-  // Returns a SequenceSortKey representing the priority of the sequence. Cannot
-  // be called on an empty sequence.
+  // Returns a SequenceSortKey representing the priority of the Sequence. Cannot
+  // be called on an empty Sequence.
   SequenceSortKey GetSortKey() const;
 
   // Returns a token that uniquely identifies this Sequence.
@@ -72,7 +82,7 @@ class BASE_EXPORT Sequence : public RefCountedThreadSafe<Sequence> {
   // Queue of tasks to execute.
   std::queue<std::unique_ptr<Task>> queue_;
 
-  // Number of tasks contained in the sequence for each priority.
+  // Number of tasks contained in the Sequence for each priority.
   size_t num_tasks_per_priority_[static_cast<int>(TaskPriority::HIGHEST) + 1] =
       {};
 
diff --git a/src/base/task_scheduler/task.cc b/src/base/task_scheduler/task.cc
index 8a589a2..7314099 100644
--- a/src/base/task_scheduler/task.cc
+++ b/src/base/task_scheduler/task.cc
@@ -15,7 +15,15 @@ Task::Task(const tracked_objects::Location& posted_from,
                   task,
                   delay.is_zero() ? TimeTicks() : TimeTicks::Now() + delay,
                   false),  // Not nestable.
-      traits(traits) {}
+      // Prevent a delayed BLOCK_SHUTDOWN task from blocking shutdown before
+      // being scheduled by changing its shutdown behavior to SKIP_ON_SHUTDOWN.
+      traits(!delay.is_zero() &&
+                     traits.shutdown_behavior() ==
+                         TaskShutdownBehavior::BLOCK_SHUTDOWN
+                 ? TaskTraits(traits).WithShutdownBehavior(
+                       TaskShutdownBehavior::SKIP_ON_SHUTDOWN)
+                 : traits),
+      delay(delay) {}
 
 Task::~Task() = default;
 
diff --git a/src/base/task_scheduler/task.h b/src/base/task_scheduler/task.h
index 2b53c69..c014671 100644
--- a/src/base/task_scheduler/task.h
+++ b/src/base/task_scheduler/task.h
@@ -23,8 +23,10 @@ namespace internal {
 // profiling inherited from PendingTask.
 struct BASE_EXPORT Task : public PendingTask {
   // |posted_from| is the site the task was posted from. |task| is the closure
-  // to run. |traits| is metadata about the task. |delay| is a delay that must
-  // expire before the Task runs.
+  // to run. |traits_in| is metadata about the task. |delay| is a delay that
+  // must expire before the Task runs. If |delay| is non-zero and the shutdown
+  // behavior in |traits| is BLOCK_SHUTDOWN, the shutdown behavior is
+  // automatically adjusted to SKIP_ON_SHUTDOWN.
   Task(const tracked_objects::Location& posted_from,
        const Closure& task,
        const TaskTraits& traits,
@@ -34,6 +36,9 @@ struct BASE_EXPORT Task : public PendingTask {
   // The TaskTraits of this task.
   const TaskTraits traits;
 
+  // The delay that must expire before the task runs.
+  const TimeDelta delay;
+
   // The time at which the task was inserted in its sequence. For an undelayed
   // task, this happens at post time. For a delayed task, this happens some
   // time after the task's delay has expired. If the task hasn't been inserted
diff --git a/src/base/task_scheduler/task_scheduler.cc b/src/base/task_scheduler/task_scheduler.cc
index 4b7d0b7..00ca4f1 100644
--- a/src/base/task_scheduler/task_scheduler.cc
+++ b/src/base/task_scheduler/task_scheduler.cc
@@ -4,8 +4,12 @@
 
 #include "base/task_scheduler/task_scheduler.h"
 
+#include "base/bind.h"
 #include "base/logging.h"
+#include "base/task_scheduler/scheduler_worker_pool_params.h"
 #include "base/task_scheduler/task_scheduler_impl.h"
+#include "base/threading/platform_thread.h"
+#include "base/time/time.h"
 
 namespace base {
 
@@ -17,6 +21,18 @@ TaskScheduler* g_task_scheduler = nullptr;
 }  // namespace
 
 // static
+void TaskScheduler::CreateAndSetSimpleTaskScheduler(int max_threads) {
+  std::vector<SchedulerWorkerPoolParams> worker_pool_params_vector;
+  worker_pool_params_vector.emplace_back(
+      "Simple", ThreadPriority::NORMAL,
+      SchedulerWorkerPoolParams::StandbyThreadPolicy::LAZY, max_threads,
+      TimeDelta::FromSeconds(30));
+  CreateAndSetDefaultTaskScheduler(
+      worker_pool_params_vector,
+      Bind([](const TaskTraits&) -> size_t { return 0; }));
+}
+
+// static
 void TaskScheduler::CreateAndSetDefaultTaskScheduler(
     const std::vector<SchedulerWorkerPoolParams>& worker_pool_params_vector,
     const WorkerPoolIndexForTraitsCallback&
diff --git a/src/base/task_scheduler/task_scheduler.h b/src/base/task_scheduler/task_scheduler.h
index 4000c7a..cbfaae9 100644
--- a/src/base/task_scheduler/task_scheduler.h
+++ b/src/base/task_scheduler/task_scheduler.h
@@ -11,6 +11,8 @@
 #include "base/base_export.h"
 #include "base/callback_forward.h"
 #include "base/memory/ref_counted.h"
+#include "base/sequenced_task_runner.h"
+#include "base/single_thread_task_runner.h"
 #include "base/task_runner.h"
 #include "base/task_scheduler/task_traits.h"
 
@@ -20,6 +22,7 @@ class Location;
 
 namespace base {
 
+class HistogramBase;
 class SchedulerWorkerPoolParams;
 
 // Interface for a task scheduler and static methods to manage the instance used
@@ -42,11 +45,24 @@ class BASE_EXPORT TaskScheduler {
                                   const TaskTraits& traits,
                                   const Closure& task) = 0;
 
-  // Returns a TaskRunner whose PostTask invocations will result in scheduling
-  // Tasks with |traits| which will be executed according to |execution_mode|.
+  // Returns a TaskRunner whose PostTask invocations result in scheduling tasks
+  // using |traits|. Tasks may run in any order and in parallel.
   virtual scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(
-      const TaskTraits& traits,
-      ExecutionMode execution_mode) = 0;
+      const TaskTraits& traits) = 0;
+
+  // Returns a SequencedTaskRunner whose PostTask invocations result in
+  // scheduling tasks using |traits|. Tasks run one at a time in posting order.
+  virtual scoped_refptr<SequencedTaskRunner>
+  CreateSequencedTaskRunnerWithTraits(const TaskTraits& traits) = 0;
+
+  // Returns a SingleThreadTaskRunner whose PostTask invocations result in
+  // scheduling tasks using |traits|. Tasks run on a single thread in posting
+  // order.
+  virtual scoped_refptr<SingleThreadTaskRunner>
+  CreateSingleThreadTaskRunnerWithTraits(const TaskTraits& traits) = 0;
+
+  // Returns a vector of all histograms available in this task scheduler.
+  virtual std::vector<const HistogramBase*> GetHistograms() const = 0;
 
   // Synchronously shuts down the scheduler. Once this is called, only tasks
   // posted with the BLOCK_SHUTDOWN behavior will be run. When this returns:
@@ -59,16 +75,32 @@ class BASE_EXPORT TaskScheduler {
   // called once.
   virtual void Shutdown() = 0;
 
-  // CreateAndSetDefaultTaskScheduler() and SetInstance() register a
-  // TaskScheduler to handle tasks posted through the post_task.h API for this
-  // process. The registered TaskScheduler will only be deleted when a new
-  // TaskScheduler is registered and is leaked on shutdown. The methods must
-  // not be called when TaskRunners created by the previous TaskScheduler are
-  // still alive. The methods are not thread-safe; proper synchronization is
-  // required to use the post_task.h API after registering a new TaskScheduler.
-
-  // Creates and sets a default task scheduler. CHECKs on failure.
-  // |worker_pool_params_vector| describes the worker pools to create.
+  // Waits until there are no pending undelayed tasks. May be called in tests
+  // to validate that a condition is met after all undelayed tasks have run.
+  //
+  // Does not wait for delayed tasks. Waits for undelayed tasks posted from
+  // other threads during the call. Returns immediately when shutdown completes.
+  virtual void FlushForTesting() = 0;
+
+  // Joins all threads of this scheduler. Tasks that are already running are
+  // allowed to complete their execution. This can only be called once.
+  virtual void JoinForTesting() = 0;
+
+  // CreateAndSetSimpleTaskScheduler(), CreateAndSetDefaultTaskScheduler(), and
+  // SetInstance() register a TaskScheduler to handle tasks posted through the
+  // post_task.h API for this process. The registered TaskScheduler will only be
+  // deleted when a new TaskScheduler is registered and is leaked on shutdown.
+  // The methods must not be called when TaskRunners created by the previous
+  // TaskScheduler are still alive. The methods are not thread-safe; proper
+  // synchronization is required to use the post_task.h API after registering a
+  // new TaskScheduler.
+
+  // Creates and sets a task scheduler with one worker pool that can have up to
+  // |max_threads| threads. CHECKs on failure.
+  static void CreateAndSetSimpleTaskScheduler(int max_threads);
+
+  // Creates and sets a task scheduler with custom worker pools. CHECKs on
+  // failure. |worker_pool_params_vector| describes the worker pools to create.
   // |worker_pool_index_for_traits_callback| returns the index in |worker_pools|
   // of the worker pool in which a task with given traits should run.
   static void CreateAndSetDefaultTaskScheduler(
diff --git a/src/base/task_scheduler/task_scheduler_impl.cc b/src/base/task_scheduler/task_scheduler_impl.cc
index d93c620..701616e 100644
--- a/src/base/task_scheduler/task_scheduler_impl.cc
+++ b/src/base/task_scheduler/task_scheduler_impl.cc
@@ -9,11 +9,17 @@
 #include "base/bind.h"
 #include "base/bind_helpers.h"
 #include "base/memory/ptr_util.h"
-#include "base/task_scheduler/scheduler_service_thread.h"
+#include "base/task_scheduler/delayed_task_manager.h"
 #include "base/task_scheduler/scheduler_worker_pool_params.h"
 #include "base/task_scheduler/sequence_sort_key.h"
 #include "base/task_scheduler/task.h"
+#include "base/task_scheduler/task_tracker.h"
 #include "base/time/time.h"
+#include "build/build_config.h"
+
+#if defined(OS_POSIX) && !defined(OS_NACL_SFI)
+#include "base/task_scheduler/task_tracker_posix.h"
+#endif
 
 namespace base {
 namespace internal {
@@ -46,15 +52,41 @@ void TaskSchedulerImpl::PostTaskWithTraits(
 }
 
 scoped_refptr<TaskRunner> TaskSchedulerImpl::CreateTaskRunnerWithTraits(
-    const TaskTraits& traits,
-    ExecutionMode execution_mode) {
-  return GetWorkerPoolForTraits(traits)->CreateTaskRunnerWithTraits(
-      traits, execution_mode);
+    const TaskTraits& traits) {
+  return GetWorkerPoolForTraits(traits)->CreateTaskRunnerWithTraits(traits);
+}
+
+scoped_refptr<SequencedTaskRunner>
+TaskSchedulerImpl::CreateSequencedTaskRunnerWithTraits(
+    const TaskTraits& traits) {
+  return GetWorkerPoolForTraits(traits)->CreateSequencedTaskRunnerWithTraits(
+      traits);
+}
+
+scoped_refptr<SingleThreadTaskRunner>
+TaskSchedulerImpl::CreateSingleThreadTaskRunnerWithTraits(
+    const TaskTraits& traits) {
+  return GetWorkerPoolForTraits(traits)->CreateSingleThreadTaskRunnerWithTraits(
+      traits);
+}
+
+std::vector<const HistogramBase*> TaskSchedulerImpl::GetHistograms() const {
+  std::vector<const HistogramBase*> histograms;
+  for (const auto& worker_pool : worker_pools_)
+    worker_pool->GetHistograms(&histograms);
+
+  return histograms;
 }
 
 void TaskSchedulerImpl::Shutdown() {
   // TODO(fdoray): Increase the priority of BACKGROUND tasks blocking shutdown.
-  task_tracker_.Shutdown();
+  DCHECK(task_tracker_);
+  task_tracker_->Shutdown();
+}
+
+void TaskSchedulerImpl::FlushForTesting() {
+  DCHECK(task_tracker_);
+  task_tracker_->Flush();
 }
 
 void TaskSchedulerImpl::JoinForTesting() {
@@ -63,7 +95,7 @@ void TaskSchedulerImpl::JoinForTesting() {
 #endif
   for (const auto& worker_pool : worker_pools_)
     worker_pool->JoinForTesting();
-  service_thread_->JoinForTesting();
+  service_thread_.Stop();
 #if DCHECK_IS_ON()
   join_for_testing_returned_.Set();
 #endif
@@ -71,11 +103,9 @@ void TaskSchedulerImpl::JoinForTesting() {
 
 TaskSchedulerImpl::TaskSchedulerImpl(const WorkerPoolIndexForTraitsCallback&
                                          worker_pool_index_for_traits_callback)
-    : delayed_task_manager_(
-          Bind(&TaskSchedulerImpl::OnDelayedRunTimeUpdated, Unretained(this))),
+    : service_thread_("TaskSchedulerServiceThread"),
       worker_pool_index_for_traits_callback_(
-          worker_pool_index_for_traits_callback)
-{
+          worker_pool_index_for_traits_callback) {
   DCHECK(!worker_pool_index_for_traits_callback_.is_null());
 }
 
@@ -83,23 +113,50 @@ void TaskSchedulerImpl::Initialize(
     const std::vector<SchedulerWorkerPoolParams>& worker_pool_params_vector) {
   DCHECK(!worker_pool_params_vector.empty());
 
+  // Start the service thread. On platforms that support it (POSIX except NaCL
+  // SFI), the service thread runs a MessageLoopForIO which is used to support
+  // FileDescriptorWatcher in the scope in which tasks run.
+  Thread::Options service_thread_options;
+  service_thread_options.message_loop_type =
+#if defined(OS_POSIX) && !defined(OS_NACL_SFI)
+      MessageLoop::TYPE_IO;
+#else
+      MessageLoop::TYPE_DEFAULT;
+#endif
+  service_thread_options.timer_slack = TIMER_SLACK_MAXIMUM;
+  CHECK(service_thread_.StartWithOptions(service_thread_options));
+
+  // Instantiate TaskTracker. Needs to happen after starting the service thread
+  // to get its message_loop().
+  task_tracker_ =
+#if defined(OS_POSIX) && !defined(OS_NACL_SFI)
+      base::MakeUnique<TaskTrackerPosix>(
+          static_cast<MessageLoopForIO*>(service_thread_.message_loop()));
+#else
+      base::MakeUnique<TaskTracker>();
+#endif
+
+  // Instantiate DelayedTaskManager. Needs to happen after starting the service
+  // thread to get its task_runner().
+  delayed_task_manager_ =
+      base::MakeUnique<DelayedTaskManager>(service_thread_.task_runner());
+
+  // Callback invoked by workers to re-enqueue a sequence in the appropriate
+  // PriorityQueue.
   const SchedulerWorkerPoolImpl::ReEnqueueSequenceCallback
       re_enqueue_sequence_callback =
           Bind(&TaskSchedulerImpl::ReEnqueueSequenceCallback, Unretained(this));
 
+  // Start worker pools.
   for (const auto& worker_pool_params : worker_pool_params_vector) {
     // Passing pointers to objects owned by |this| to
     // SchedulerWorkerPoolImpl::Create() is safe because a TaskSchedulerImpl
     // can't be deleted before all its worker pools have been joined.
     worker_pools_.push_back(SchedulerWorkerPoolImpl::Create(
-        worker_pool_params, re_enqueue_sequence_callback, &task_tracker_,
-        &delayed_task_manager_));
+        worker_pool_params, re_enqueue_sequence_callback, task_tracker_.get(),
+        delayed_task_manager_.get()));
     CHECK(worker_pools_.back());
   }
-
-  service_thread_ = SchedulerServiceThread::Create(&task_tracker_,
-                                                   &delayed_task_manager_);
-  CHECK(service_thread_);
 }
 
 SchedulerWorkerPool* TaskSchedulerImpl::GetWorkerPoolForTraits(
@@ -114,20 +171,16 @@ void TaskSchedulerImpl::ReEnqueueSequenceCallback(
   DCHECK(sequence);
 
   const SequenceSortKey sort_key = sequence->GetSortKey();
-  TaskTraits traits(sequence->PeekTask()->traits);
 
-  // Update the priority of |traits| so that the next task in |sequence| runs
-  // with the highest priority in |sequence| as opposed to the next task's
-  // specific priority.
-  traits.WithPriority(sort_key.priority());
+  // The next task in |sequence| should run in a worker pool suited for its
+  // traits, except for the priority which is adjusted to the highest priority
+  // in |sequence|.
+  const TaskTraits traits =
+      sequence->PeekTaskTraits().WithPriority(sort_key.priority());
 
   GetWorkerPoolForTraits(traits)->ReEnqueueSequence(std::move(sequence),
                                                     sort_key);
 }
 
-void TaskSchedulerImpl::OnDelayedRunTimeUpdated() {
-  service_thread_->WakeUp();
-}
-
 }  // namespace internal
 }  // namespace base
diff --git a/src/base/task_scheduler/task_scheduler_impl.h b/src/base/task_scheduler/task_scheduler_impl.h
index 2ab2f29..9a16103 100644
--- a/src/base/task_scheduler/task_scheduler_impl.h
+++ b/src/base/task_scheduler/task_scheduler_impl.h
@@ -8,7 +8,6 @@
 #include <stddef.h>
 
 #include <memory>
-#include <string>
 #include <vector>
 
 #include "base/base_export.h"
@@ -17,22 +16,21 @@
 #include "base/macros.h"
 #include "base/memory/ref_counted.h"
 #include "base/synchronization/atomic_flag.h"
-#include "base/task_runner.h"
-#include "base/task_scheduler/delayed_task_manager.h"
 #include "base/task_scheduler/scheduler_worker_pool_impl.h"
 #include "base/task_scheduler/sequence.h"
 #include "base/task_scheduler/task_scheduler.h"
-#include "base/task_scheduler/task_tracker.h"
 #include "base/task_scheduler/task_traits.h"
 #include "base/threading/thread.h"
 
 namespace base {
 
+class HistogramBase;
 class SchedulerWorkerPoolParams;
 
 namespace internal {
 
-class SchedulerServiceThread;
+class DelayedTaskManager;
+class TaskTracker;
 
 // Default TaskScheduler implementation. This class is thread-safe.
 class BASE_EXPORT TaskSchedulerImpl : public TaskScheduler {
@@ -56,13 +54,15 @@ class BASE_EXPORT TaskSchedulerImpl : public TaskScheduler {
                           const TaskTraits& traits,
                           const Closure& task) override;
   scoped_refptr<TaskRunner> CreateTaskRunnerWithTraits(
-      const TaskTraits& traits,
-      ExecutionMode execution_mode) override;
+      const TaskTraits& traits) override;
+  scoped_refptr<SequencedTaskRunner> CreateSequencedTaskRunnerWithTraits(
+      const TaskTraits& traits) override;
+  scoped_refptr<SingleThreadTaskRunner> CreateSingleThreadTaskRunnerWithTraits(
+      const TaskTraits& traits) override;
+  std::vector<const HistogramBase*> GetHistograms() const override;
   void Shutdown() override;
-
-  // Joins all threads of this scheduler. Tasks that are already running are
-  // allowed to complete their execution. This can only be called once.
-  void JoinForTesting();
+  void FlushForTesting() override;
+  void JoinForTesting() override;
 
  private:
   explicit TaskSchedulerImpl(const WorkerPoolIndexForTraitsCallback&
@@ -78,15 +78,11 @@ class BASE_EXPORT TaskSchedulerImpl : public TaskScheduler {
   // worker pops a Task from it.
   void ReEnqueueSequenceCallback(scoped_refptr<Sequence> sequence);
 
-  // Callback invoked when the delayed run time is changed from the
-  // DelayedTaskManager.
-  void OnDelayedRunTimeUpdated();
-
-  TaskTracker task_tracker_;
-  DelayedTaskManager delayed_task_manager_;
+  Thread service_thread_;
+  std::unique_ptr<TaskTracker> task_tracker_;
+  std::unique_ptr<DelayedTaskManager> delayed_task_manager_;
   const WorkerPoolIndexForTraitsCallback worker_pool_index_for_traits_callback_;
   std::vector<std::unique_ptr<SchedulerWorkerPoolImpl>> worker_pools_;
-  std::unique_ptr<SchedulerServiceThread> service_thread_;
 
 #if DCHECK_IS_ON()
   // Set once JoinForTesting() has returned.
diff --git a/src/base/task_scheduler/task_tracker.cc b/src/base/task_scheduler/task_tracker.cc
index ee20b8b..4c1ee8d 100644
--- a/src/base/task_scheduler/task_tracker.cc
+++ b/src/base/task_scheduler/task_tracker.cc
@@ -6,22 +6,65 @@
 
 #include <limits>
 
-#include "base/atomicops.h"
 #include "base/callback.h"
 #include "base/debug/task_annotator.h"
+#include "base/json/json_writer.h"
 #include "base/logging.h"
+#include "base/memory/ptr_util.h"
 #include "base/metrics/histogram_macros.h"
 #include "base/sequence_token.h"
+#include "base/synchronization/condition_variable.h"
+#include "base/task_scheduler/scoped_set_task_priority_for_current_thread.h"
 #include "base/threading/sequenced_task_runner_handle.h"
 #include "base/threading/thread_restrictions.h"
 #include "base/threading/thread_task_runner_handle.h"
 #include "base/trace_event/trace_event.h"
+#include "base/values.h"
 
 namespace base {
 namespace internal {
 
 namespace {
 
+constexpr char kParallelExecutionMode[] = "parallel";
+constexpr char kSequencedExecutionMode[] = "sequenced";
+constexpr char kSingleThreadExecutionMode[] = "single thread";
+
+// An immutable copy of a scheduler task's info required by tracing.
+class TaskTracingInfo : public trace_event::ConvertableToTraceFormat {
+ public:
+  TaskTracingInfo(const TaskTraits& task_traits,
+                  const char* execution_mode,
+                  const SequenceToken& sequence_token)
+      : task_traits_(task_traits),
+        execution_mode_(execution_mode),
+        sequence_token_(sequence_token) {}
+
+  // trace_event::ConvertableToTraceFormat implementation.
+  void AppendAsTraceFormat(std::string* out) const override;
+
+ private:
+  const TaskTraits task_traits_;
+  const char* const execution_mode_;
+  const SequenceToken sequence_token_;
+
+  DISALLOW_COPY_AND_ASSIGN(TaskTracingInfo);
+};
+
+void TaskTracingInfo::AppendAsTraceFormat(std::string* out) const {
+  DictionaryValue dict;
+
+  dict.SetString("task_priority",
+                 base::TaskPriorityToString(task_traits_.priority()));
+  dict.SetString("execution_mode", execution_mode_);
+  if (execution_mode_ != kParallelExecutionMode)
+    dict.SetInteger("sequence_token", sequence_token_.ToInternalValue());
+
+  std::string tmp;
+  JSONWriter::Write(dict, &tmp);
+  out->append(tmp);
+}
+
 const char kQueueFunctionName[] = "base::PostTask";
 
 // This name conveys that a Task is run by the task scheduler without revealing
@@ -128,10 +171,131 @@ class TaskTracker::State {
   DISALLOW_COPY_AND_ASSIGN(State);
 };
 
-TaskTracker::TaskTracker() : state_(new State) {}
+TaskTracker::TaskTracker()
+    : state_(new State),
+      flush_cv_(flush_lock_.CreateConditionVariable()),
+      shutdown_lock_(&flush_lock_) {}
 TaskTracker::~TaskTracker() = default;
 
 void TaskTracker::Shutdown() {
+  PerformShutdown();
+  DCHECK(IsShutdownComplete());
+
+  // Unblock Flush() when shutdown completes.
+  AutoSchedulerLock auto_lock(flush_lock_);
+  flush_cv_->Signal();
+}
+
+void TaskTracker::Flush() {
+  AutoSchedulerLock auto_lock(flush_lock_);
+  while (subtle::NoBarrier_Load(&num_pending_undelayed_tasks_) != 0 &&
+         !IsShutdownComplete()) {
+    flush_cv_->Wait();
+  }
+}
+
+bool TaskTracker::WillPostTask(const Task* task) {
+  DCHECK(task);
+
+  if (!BeforePostTask(task->traits.shutdown_behavior()))
+    return false;
+
+  if (task->delayed_run_time.is_null())
+    subtle::NoBarrier_AtomicIncrement(&num_pending_undelayed_tasks_, 1);
+
+  debug::TaskAnnotator task_annotator;
+  task_annotator.DidQueueTask(kQueueFunctionName, *task);
+
+  return true;
+}
+
+bool TaskTracker::RunTask(std::unique_ptr<Task> task,
+                          const SequenceToken& sequence_token) {
+  DCHECK(task);
+  DCHECK(sequence_token.IsValid());
+
+  const TaskShutdownBehavior shutdown_behavior =
+      task->traits.shutdown_behavior();
+  const bool can_run_task = BeforeRunTask(shutdown_behavior);
+  const bool is_delayed = !task->delayed_run_time.is_null();
+
+  if (can_run_task) {
+    const bool previous_singleton_allowed =
+        ThreadRestrictions::SetSingletonAllowed(
+            task->traits.shutdown_behavior() !=
+            TaskShutdownBehavior::CONTINUE_ON_SHUTDOWN);
+    const bool previous_io_allowed =
+        ThreadRestrictions::SetIOAllowed(task->traits.with_file_io());
+    const bool previous_wait_allowed =
+        ThreadRestrictions::SetWaitAllowed(task->traits.with_wait());
+
+    {
+      ScopedSetSequenceTokenForCurrentThread
+          scoped_set_sequence_token_for_current_thread(sequence_token);
+      ScopedSetTaskPriorityForCurrentThread
+          scoped_set_task_priority_for_current_thread(task->traits.priority());
+
+      // Set up TaskRunnerHandle as expected for the scope of the task.
+      std::unique_ptr<SequencedTaskRunnerHandle> sequenced_task_runner_handle;
+      std::unique_ptr<ThreadTaskRunnerHandle> single_thread_task_runner_handle;
+      DCHECK(!task->sequenced_task_runner_ref ||
+             !task->single_thread_task_runner_ref);
+      if (task->sequenced_task_runner_ref) {
+        sequenced_task_runner_handle.reset(
+            new SequencedTaskRunnerHandle(task->sequenced_task_runner_ref));
+      } else if (task->single_thread_task_runner_ref) {
+        single_thread_task_runner_handle.reset(
+            new ThreadTaskRunnerHandle(task->single_thread_task_runner_ref));
+      }
+
+      TRACE_TASK_EXECUTION(kRunFunctionName, *task);
+
+      const char* const execution_mode =
+          task->single_thread_task_runner_ref
+              ? kSingleThreadExecutionMode
+              : (task->sequenced_task_runner_ref ? kSequencedExecutionMode
+                                                 : kParallelExecutionMode);
+      // TODO(gab): In a better world this would be tacked on as an extra arg
+      // to the trace event generated above. This is not possible however until
+      // http://crbug.com/652692 is resolved.
+      TRACE_EVENT1("task_scheduler", "TaskTracker::RunTask", "task_info",
+                   MakeUnique<TaskTracingInfo>(task->traits, execution_mode,
+                                               sequence_token));
+
+      PerformRunTask(std::move(task));
+    }
+
+    ThreadRestrictions::SetWaitAllowed(previous_wait_allowed);
+    ThreadRestrictions::SetIOAllowed(previous_io_allowed);
+    ThreadRestrictions::SetSingletonAllowed(previous_singleton_allowed);
+
+    AfterRunTask(shutdown_behavior);
+  }
+
+  if (!is_delayed)
+    DecrementNumPendingUndelayedTasks();
+
+  return can_run_task;
+}
+
+bool TaskTracker::HasShutdownStarted() const {
+  return state_->HasShutdownStarted();
+}
+
+bool TaskTracker::IsShutdownComplete() const {
+  AutoSchedulerLock auto_lock(shutdown_lock_);
+  return shutdown_event_ && shutdown_event_->IsSignaled();
+}
+
+void TaskTracker::SetHasShutdownStartedForTesting() {
+  state_->StartShutdown();
+}
+
+void TaskTracker::PerformRunTask(std::unique_ptr<Task> task) {
+  debug::TaskAnnotator().RunTask(kQueueFunctionName, task.get());
+}
+
+void TaskTracker::PerformShutdown() {
   {
     AutoSchedulerLock auto_lock(shutdown_lock_);
 
@@ -162,7 +326,10 @@ void TaskTracker::Shutdown() {
 
   // It is safe to access |shutdown_event_| without holding |lock_| because the
   // pointer never changes after being set above.
-  shutdown_event_->Wait();
+  {
+    base::ThreadRestrictions::ScopedAllowWait allow_wait;
+    shutdown_event_->Wait();
+  }
 
   {
     AutoSchedulerLock auto_lock(shutdown_lock_);
@@ -179,77 +346,6 @@ void TaskTracker::Shutdown() {
   }
 }
 
-bool TaskTracker::WillPostTask(const Task* task) {
-  DCHECK(task);
-
-  if (!BeforePostTask(task->traits.shutdown_behavior()))
-    return false;
-
-  debug::TaskAnnotator task_annotator;
-  task_annotator.DidQueueTask(kQueueFunctionName, *task);
-
-  return true;
-}
-
-bool TaskTracker::RunTask(const Task* task,
-                          const SequenceToken& sequence_token) {
-  DCHECK(task);
-  DCHECK(sequence_token.IsValid());
-
-  const TaskShutdownBehavior shutdown_behavior =
-      task->traits.shutdown_behavior();
-  if (!BeforeRunTask(shutdown_behavior))
-    return false;
-
-  // All tasks run through here and the scheduler itself doesn't use singletons.
-  // Therefore, it isn't necessary to reset the singleton allowed bit after
-  // running the task.
-  ThreadRestrictions::SetSingletonAllowed(
-      task->traits.shutdown_behavior() !=
-      TaskShutdownBehavior::CONTINUE_ON_SHUTDOWN);
-
-  {
-    // Set up SequenceToken as expected for the scope of the task.
-    ScopedSetSequenceTokenForCurrentThread
-        scoped_set_sequence_token_for_current_thread(sequence_token);
-
-    // Set up TaskRunnerHandle as expected for the scope of the task.
-    std::unique_ptr<SequencedTaskRunnerHandle> sequenced_task_runner_handle;
-    std::unique_ptr<ThreadTaskRunnerHandle> single_thread_task_runner_handle;
-    DCHECK(!task->sequenced_task_runner_ref ||
-           !task->single_thread_task_runner_ref);
-    if (task->sequenced_task_runner_ref) {
-      sequenced_task_runner_handle.reset(
-          new SequencedTaskRunnerHandle(task->sequenced_task_runner_ref));
-    } else if (task->single_thread_task_runner_ref) {
-      single_thread_task_runner_handle.reset(
-          new ThreadTaskRunnerHandle(task->single_thread_task_runner_ref));
-    }
-
-    TRACE_TASK_EXECUTION(kRunFunctionName, *task);
-
-    debug::TaskAnnotator task_annotator;
-    task_annotator.RunTask(kQueueFunctionName, *task);
-  }
-
-  AfterRunTask(shutdown_behavior);
-
-  return true;
-}
-
-bool TaskTracker::HasShutdownStarted() const {
-  return state_->HasShutdownStarted();
-}
-
-bool TaskTracker::IsShutdownComplete() const {
-  AutoSchedulerLock auto_lock(shutdown_lock_);
-  return shutdown_event_ && shutdown_event_->IsSignaled();
-}
-
-void TaskTracker::SetHasShutdownStartedForTesting() {
-  state_->StartShutdown();
-}
-
 bool TaskTracker::BeforePostTask(TaskShutdownBehavior shutdown_behavior) {
   if (shutdown_behavior == TaskShutdownBehavior::BLOCK_SHUTDOWN) {
     // BLOCK_SHUTDOWN tasks block shutdown between the moment they are posted
@@ -349,5 +445,15 @@ void TaskTracker::OnBlockingShutdownTasksComplete() {
   shutdown_event_->Signal();
 }
 
+void TaskTracker::DecrementNumPendingUndelayedTasks() {
+  const auto new_num_pending_undelayed_tasks =
+      subtle::NoBarrier_AtomicIncrement(&num_pending_undelayed_tasks_, -1);
+  DCHECK_GE(new_num_pending_undelayed_tasks, 0);
+  if (new_num_pending_undelayed_tasks == 0) {
+    AutoSchedulerLock auto_lock(flush_lock_);
+    flush_cv_->Signal();
+  }
+}
+
 }  // namespace internal
 }  // namespace base
diff --git a/src/base/task_scheduler/task_tracker.h b/src/base/task_scheduler/task_tracker.h
index 7a43389..a5caf21 100644
--- a/src/base/task_scheduler/task_tracker.h
+++ b/src/base/task_scheduler/task_tracker.h
@@ -7,6 +7,7 @@
 
 #include <memory>
 
+#include "base/atomicops.h"
 #include "base/base_export.h"
 #include "base/callback_forward.h"
 #include "base/macros.h"
@@ -19,6 +20,7 @@
 
 namespace base {
 
+class ConditionVariable;
 class SequenceToken;
 
 namespace internal {
@@ -40,6 +42,13 @@ class BASE_EXPORT TaskTracker {
   // This can only be called once.
   void Shutdown();
 
+  // Waits until there are no pending undelayed tasks. May be called in tests
+  // to validate that a condition is met after all undelayed tasks have run.
+  //
+  // Does not wait for delayed tasks. Waits for undelayed tasks posted from
+  // other threads during the call. Returns immediately when shutdown completes.
+  void Flush();
+
   // Informs this TaskTracker that |task| is about to be posted. Returns true if
   // this operation is allowed (|task| should be posted if-and-only-if it is).
   bool WillPostTask(const Task* task);
@@ -48,7 +57,7 @@ class BASE_EXPORT TaskTracker {
   // |sequence_token| is the token identifying the sequence from which |task|
   // was extracted. Returns true if |task| ran. WillPostTask() must have allowed
   // |task| to be posted before this is called.
-  bool RunTask(const Task* task, const SequenceToken& sequence_token);
+  bool RunTask(std::unique_ptr<Task> task, const SequenceToken& sequence_token);
 
   // Returns true once shutdown has started (Shutdown() has been called but
   // might not have returned). Note: sequential consistency with the thread
@@ -64,9 +73,16 @@ class BASE_EXPORT TaskTracker {
   // cannot be called after this.
   void SetHasShutdownStartedForTesting();
 
+ protected:
+  // Runs |task|. An override is expected to call its parent's implementation
+  // but is free to perform extra work before and after doing so.
+  virtual void PerformRunTask(std::unique_ptr<Task> task);
+
  private:
   class State;
 
+  void PerformShutdown();
+
   // Called before WillPostTask() informs the tracing system that a task has
   // been posted. Updates |num_tasks_blocking_shutdown_| if necessary and
   // returns true if the current shutdown state allows the task to be posted.
@@ -86,10 +102,30 @@ class BASE_EXPORT TaskTracker {
   // shutdown has started.
   void OnBlockingShutdownTasksComplete();
 
+  // Decrements the number of pending undelayed tasks and signals |flush_cv_| if
+  // it reaches zero.
+  void DecrementNumPendingUndelayedTasks();
+
   // Number of tasks blocking shutdown and boolean indicating whether shutdown
   // has started.
   const std::unique_ptr<State> state_;
 
+  // Number of undelayed tasks that haven't completed their execution. Is
+  // incremented and decremented without a barrier. When it reaches zero,
+  // |flush_lock_| is acquired (forcing memory synchronization) and |flush_cv_|
+  // is signaled.
+  subtle::Atomic32 num_pending_undelayed_tasks_ = 0;
+
+  // Lock associated with |flush_cv_|. Partially synchronizes access to
+  // |num_pending_undelayed_tasks_|. Full synchronization isn't needed because
+  // it's atomic, but synchronization is needed to coordinate waking and
+  // sleeping at the right time.
+  mutable SchedulerLock flush_lock_;
+
+  // Signaled when |num_pending_undelayed_tasks_| is zero or when shutdown
+  // completes.
+  const std::unique_ptr<ConditionVariable> flush_cv_;
+
   // Synchronizes access to shutdown related members below.
   mutable SchedulerLock shutdown_lock_;
 
diff --git a/src/base/task_scheduler/task_traits.cc b/src/base/task_scheduler/task_traits.cc
index dd55535..9ebe821 100644
--- a/src/base/task_scheduler/task_traits.cc
+++ b/src/base/task_scheduler/task_traits.cc
@@ -8,6 +8,9 @@
 
 #include <ostream>
 
+#include "base/logging.h"
+#include "base/task_scheduler/scoped_set_task_priority_for_current_thread.h"
+
 namespace base {
 
 // Do not rely on defaults hard-coded below beyond the guarantees described in
@@ -15,7 +18,8 @@ namespace base {
 // request defaults if the behavior is critical to the task.
 TaskTraits::TaskTraits()
     : with_file_io_(false),
-      priority_(TaskPriority::BACKGROUND),
+      with_wait_(false),
+      priority_(internal::GetTaskPriorityForCurrentThread()),
       shutdown_behavior_(TaskShutdownBehavior::SKIP_ON_SHUTDOWN) {}
 
 TaskTraits::~TaskTraits() = default;
@@ -25,6 +29,11 @@ TaskTraits& TaskTraits::WithFileIO() {
   return *this;
 }
 
+TaskTraits& TaskTraits::WithWait() {
+  with_wait_ = true;
+  return *this;
+}
+
 TaskTraits& TaskTraits::WithPriority(TaskPriority priority) {
   priority_ = priority;
   return *this;
@@ -36,34 +45,41 @@ TaskTraits& TaskTraits::WithShutdownBehavior(
   return *this;
 }
 
-std::ostream& operator<<(std::ostream& os, const TaskPriority& task_priority) {
+const char* TaskPriorityToString(TaskPriority task_priority) {
   switch (task_priority) {
     case TaskPriority::BACKGROUND:
-      os << "BACKGROUND";
-      break;
+      return "BACKGROUND";
     case TaskPriority::USER_VISIBLE:
-      os << "USER_VISIBLE";
-      break;
+      return "USER_VISIBLE";
     case TaskPriority::USER_BLOCKING:
-      os << "USER_BLOCKING";
-      break;
+      return "USER_BLOCKING";
   }
-  return os;
+  NOTREACHED();
+  return "";
 }
 
-std::ostream& operator<<(std::ostream& os,
-                         const TaskShutdownBehavior& shutdown_behavior) {
+const char* TaskShutdownBehaviorToString(
+    TaskShutdownBehavior shutdown_behavior) {
   switch (shutdown_behavior) {
     case TaskShutdownBehavior::CONTINUE_ON_SHUTDOWN:
-      os << "CONTINUE_ON_SHUTDOWN";
-      break;
+      return "CONTINUE_ON_SHUTDOWN";
     case TaskShutdownBehavior::SKIP_ON_SHUTDOWN:
-      os << "SKIP_ON_SHUTDOWN";
-      break;
+      return "SKIP_ON_SHUTDOWN";
     case TaskShutdownBehavior::BLOCK_SHUTDOWN:
-      os << "BLOCK_SHUTDOWN";
-      break;
+      return "BLOCK_SHUTDOWN";
   }
+  NOTREACHED();
+  return "";
+}
+
+std::ostream& operator<<(std::ostream& os, const TaskPriority& task_priority) {
+  os << TaskPriorityToString(task_priority);
+  return os;
+}
+
+std::ostream& operator<<(std::ostream& os,
+                         const TaskShutdownBehavior& shutdown_behavior) {
+  os << TaskShutdownBehaviorToString(shutdown_behavior);
   return os;
 }
 
diff --git a/src/base/task_scheduler/task_traits.h b/src/base/task_scheduler/task_traits.h
index 0c0d304..0fcde2d 100644
--- a/src/base/task_scheduler/task_traits.h
+++ b/src/base/task_scheduler/task_traits.h
@@ -80,27 +80,38 @@ class BASE_EXPORT TaskTraits {
  public:
   // Constructs a default TaskTraits for tasks with
   //     (1) no I/O,
-  //     (2) low priority, and
+  //     (2) priority inherited from the calling context, and
   //     (3) may block shutdown or be skipped on shutdown.
-  // Tasks that require stricter guarantees should highlight those by requesting
+  // Tasks that require stricter guarantees and/or know the specific
+  // TaskPriority appropriate for them should highlight those by requesting
   // explicit traits below.
   TaskTraits();
   TaskTraits(const TaskTraits& other) = default;
   TaskTraits& operator=(const TaskTraits& other) = default;
   ~TaskTraits();
 
-  // Allows tasks with these traits to do file I/O.
+  // Allows tasks with these traits to wait on synchronous file I/O.
   TaskTraits& WithFileIO();
 
+  // Allows tasks with these traits to wait on things other than file I/O. In
+  // particular, they may wait on a WaitableEvent or a ConditionVariable, join a
+  // thread or a process, or make a blocking system call that doesn't involve
+  // interactions with the file system.
+  TaskTraits& WithWait();
+
   // Applies |priority| to tasks with these traits.
   TaskTraits& WithPriority(TaskPriority priority);
 
   // Applies |shutdown_behavior| to tasks with these traits.
   TaskTraits& WithShutdownBehavior(TaskShutdownBehavior shutdown_behavior);
 
-  // Returns true if file I/O is allowed by these traits.
+  // Returns true if waiting on synchronous file I/O is allowed by these traits.
   bool with_file_io() const { return with_file_io_; }
 
+  // Returns true if waiting on things other than file I/O is allowed by these
+  // traits.
+  bool with_wait() const { return with_wait_; }
+
   // Returns the priority of tasks with these traits.
   TaskPriority priority() const { return priority_; }
 
@@ -109,28 +120,21 @@ class BASE_EXPORT TaskTraits {
 
  private:
   bool with_file_io_;
+  bool with_wait_;
   TaskPriority priority_;
   TaskShutdownBehavior shutdown_behavior_;
 };
 
-// Describes how tasks are executed by a task runner.
-enum class ExecutionMode {
-  // Can execute multiple tasks at a time in any order.
-  PARALLEL,
-
-  // Executes one task at a time in posting order. The sequence’s priority is
-  // equivalent to the highest priority pending task in the sequence.
-  SEQUENCED,
+// Returns string literals for the enums defined in this file. These methods
+// should only be used for tracing and debugging.
+BASE_EXPORT const char* TaskPriorityToString(TaskPriority task_priority);
+BASE_EXPORT const char* TaskShutdownBehaviorToString(
+    TaskShutdownBehavior task_priority);
 
-  // Executes one task at a time on a single thread in posting order.
-  SINGLE_THREADED,
-};
-
-// Stream operators so TaskPriority and TaskShutdownBehavior can be used in
-// DCHECK statements.
+// Stream operators so that the enums defined in this file can be used in
+// DCHECK and EXPECT statements.
 BASE_EXPORT std::ostream& operator<<(std::ostream& os,
                                      const TaskPriority& shutdown_behavior);
-
 BASE_EXPORT std::ostream& operator<<(
     std::ostream& os,
     const TaskShutdownBehavior& shutdown_behavior);
diff --git a/src/base/third_party/dmg_fp/dtoa.cc b/src/base/third_party/dmg_fp/dtoa.cc
index f3d793e..19dbdeb 100644
--- a/src/base/third_party/dmg_fp/dtoa.cc
+++ b/src/base/third_party/dmg_fp/dtoa.cc
@@ -32,6 +32,7 @@
  */
 
 /* strtod for IEEE-, VAX-, and IBM-arithmetic machines.
+ * (Note that IEEE arithmetic is disabled by gcc's -ffast-math flag.)
  *
  * This strtod returns a nearest machine number to the input decimal
  * string (or sets errno to ERANGE).  With IEEE arithmetic, ties are
@@ -70,7 +71,8 @@
  * #define IBM for IBM mainframe-style floating-point arithmetic.
  * #define VAX for VAX-style floating-point arithmetic (D_floating).
  * #define No_leftright to omit left-right logic in fast floating-point
- *	computation of dtoa.
+ *	computation of dtoa.  This will cause dtoa modes 4 and 5 to be
+ *	treated the same as modes 2 and 3 for some inputs.
  * #define Honor_FLT_ROUNDS if FLT_ROUNDS can assume the values 2 or 3
  *	and strtod and dtoa should round accordingly.  Unless Trust_FLT_ROUNDS
  *	is also #defined, fegetround() will be queried for the rounding mode.
@@ -78,13 +80,18 @@
  *	standard (and are specified to be consistent, with fesetround()
  *	affecting the value of FLT_ROUNDS), but that some (Linux) systems
  *	do not work correctly in this regard, so using fegetround() is more
- *	portable than using FLT_FOUNDS directly.
+ *	portable than using FLT_ROUNDS directly.
  * #define Check_FLT_ROUNDS if FLT_ROUNDS can assume the values 2 or 3
  *	and Honor_FLT_ROUNDS is not #defined.
  * #define RND_PRODQUOT to use rnd_prod and rnd_quot (assembly routines
  *	that use extended-precision instructions to compute rounded
  *	products and quotients) with IBM.
- * #define ROUND_BIASED for IEEE-format with biased rounding.
+ * #define ROUND_BIASED for IEEE-format with biased rounding and arithmetic
+ *	that rounds toward +Infinity.
+ * #define ROUND_BIASED_without_Round_Up for IEEE-format with biased
+ *	rounding when the underlying floating-point arithmetic uses
+ *	unbiased rounding.  This prevent using ordinary floating-point
+ *	arithmetic when the result could be computed with one rounding error.
  * #define Inaccurate_Divide for IEEE-format with correctly rounded
  *	products but inaccurate quotients, e.g., for Intel i860.
  * #define NO_LONG_LONG on machines that do not have a "long long"
@@ -458,6 +465,11 @@ extern int strtod_diglim;
 
 #ifndef IEEE_Arith
 #define ROUND_BIASED
+#else
+#ifdef ROUND_BIASED_without_Round_Up
+#undef  ROUND_BIASED
+#define ROUND_BIASED
+#endif
 #endif
 
 #ifdef RND_PRODQUOT
@@ -663,7 +675,7 @@ s2b
 #ifdef KR_headers
 	(s, nd0, nd, y9, dplen) CONST char *s; int nd0, nd, dplen; ULong y9;
 #else
-	(CONST char *s, int nd0, int nd, ULong y9, int dplen)
+	(const char *s, int nd0, int nd, ULong y9, int dplen)
 #endif
 {
 	Bigint *b;
@@ -1500,14 +1512,11 @@ static CONST double tinytens[] = { 1e-16, 1e-32 };
 #endif
 
 #ifdef Need_Hexdig /*{*/
+#if 0
 static unsigned char hexdig[256];
 
  static void
-#ifdef KR_headers
-htinit(h, s, inc) unsigned char *h; unsigned char *s; int inc;
-#else
 htinit(unsigned char *h, unsigned char *s, int inc)
-#endif
 {
 	int i, j;
 	for(i = 0; (j = s[i]) !=0; i++)
@@ -1515,17 +1524,34 @@ htinit(unsigned char *h, unsigned char *s, int inc)
 	}
 
  static void
-#ifdef KR_headers
-hexdig_init()
-#else
-hexdig_init(void)
-#endif
+hexdig_init(void)	/* Use of hexdig_init omitted 20121220 to avoid a */
+			/* race condition when multiple threads are used. */
 {
 #define USC (unsigned char *)
 	htinit(hexdig, USC "0123456789", 0x10);
 	htinit(hexdig, USC "abcdef", 0x10 + 10);
 	htinit(hexdig, USC "ABCDEF", 0x10 + 10);
 	}
+#else
+static const unsigned char hexdig[256] = {
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	16,17,18,19,20,21,22,23,24,25,0,0,0,0,0,0,
+	0,26,27,28,29,30,31,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,26,27,28,29,30,31,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+	0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
+	};
+#endif
 #endif /* } Need_Hexdig */
 
 #ifdef INFNAN_CHECK
@@ -1543,7 +1569,7 @@ match
 #ifdef KR_headers
 	(sp, t) char **sp, *t;
 #else
-	(CONST char **sp, CONST char *t)
+	(const char **sp, const char *t)
 #endif
 {
 	int c, d;
@@ -1565,15 +1591,14 @@ hexnan
 #ifdef KR_headers
 	(rvp, sp) U *rvp; CONST char **sp;
 #else
-	(U *rvp, CONST char **sp)
+	(U *rvp, const char **sp)
 #endif
 {
 	ULong c, x[2];
 	CONST char *s;
 	int c1, havedig, udx0, xshift;
 
-	if (!hexdig['0'])
-		hexdig_init();
+	/**** if (!hexdig['0']) hexdig_init(); ****/
 	x[0] = x[1] = 0;
 	havedig = xshift = 0;
 	udx0 = 1;
@@ -1640,6 +1665,41 @@ hexnan
 #define kshift 4
 #define kmask 15
 #endif
+
+#if !defined(NO_HEX_FP) || defined(Honor_FLT_ROUNDS) /*{*/
+ static Bigint *
+#ifdef KR_headers
+increment(b) Bigint *b;
+#else
+increment(Bigint *b)
+#endif
+{
+	ULong *x, *xe;
+	Bigint *b1;
+
+	x = b->x;
+	xe = x + b->wds;
+	do {
+		if (*x < (ULong)0xffffffffL) {
+			++*x;
+			return b;
+			}
+		*x++ = 0;
+		} while(x < xe);
+	{
+		if (b->wds >= b->maxwds) {
+			b1 = Balloc(b->k+1);
+			Bcopy(b1,b);
+			Bfree(b);
+			b = b1;
+			}
+		b->x[b->wds++] = 1;
+		}
+	return b;
+	}
+
+#endif /*}*/
+
 #ifndef NO_HEX_FP /*{*/
 
  static void
@@ -1712,37 +1772,6 @@ enum {	/* rounding values: same as FLT_ROUNDS */
 	Round_down = 3
 	};
 
- static Bigint *
-#ifdef KR_headers
-increment(b) Bigint *b;
-#else
-increment(Bigint *b)
-#endif
-{
-	ULong *x, *xe;
-	Bigint *b1;
-
-	x = b->x;
-	xe = x + b->wds;
-	do {
-		if (*x < (ULong)0xffffffffL) {
-			++*x;
-			return b;
-			}
-		*x++ = 0;
-		} while(x < xe);
-	{
-		if (b->wds >= b->maxwds) {
-			b1 = Balloc(b->k+1);
-			Bcopy(b1,b);
-			Bfree(b);
-			b = b1;
-			}
-		b->x[b->wds++] = 1;
-		}
-	return b;
-	}
-
  void
 #ifdef KR_headers
 gethex(sp, rvp, rounding, sign)
@@ -1793,8 +1822,7 @@ gethex( CONST char **sp, U *rvp, int rounding, int sign)
 #endif
 #endif
 
-	if (!hexdig['0'])
-		hexdig_init();
+	/**** if (!hexdig['0']) hexdig_init(); ****/
 	havedig = 0;
 	s0 = *(CONST unsigned char **)sp + 2;
 	while(s0[havedig] == '0')
@@ -1894,6 +1922,8 @@ gethex( CONST char **sp, U *rvp, int rounding, int sign)
 #endif
 			goto retz;
 #ifdef IEEE_Arith
+ ret_tinyf:
+			Bfree(b);
  ret_tiny:
 #ifndef NO_ERRNO
 			errno = ERANGE;
@@ -1994,15 +2024,15 @@ gethex( CONST char **sp, U *rvp, int rounding, int sign)
 			switch (rounding) {
 			  case Round_near:
 				if (n == nbits && (n < 2 || any_on(b,n-1)))
-					goto ret_tiny;
+					goto ret_tinyf;
 				break;
 			  case Round_up:
 				if (!sign)
-					goto ret_tiny;
+					goto ret_tinyf;
 				break;
 			  case Round_down:
 				if (sign)
-					goto ret_tiny;
+					goto ret_tinyf;
 			  }
 #endif /* } IEEE_Arith */
 			Bfree(b);
@@ -2102,7 +2132,7 @@ gethex( CONST char **sp, U *rvp, int rounding, int sign)
 #endif
 	Bfree(b);
 	}
-#endif /*}!NO_HEX_FP*/
+#endif /*!NO_HEX_FP}*/
 
  static int
 #ifdef KR_headers
@@ -2149,7 +2179,13 @@ quorem
 	bxe = bx + n;
 	q = *bxe / (*sxe + 1);	/* ensure q <= true quotient */
 #ifdef DEBUG
+#ifdef NO_STRTOD_BIGCOMP
 	/*debug*/ if (q > 9)
+#else
+	/* An oversized q is possible when quorem is called from bigcomp and */
+	/* the input is near, e.g., twice the smallest denormalized number. */
+	/*debug*/ if (q > 15)
+#endif
 	/*debug*/	Bug("oversized quotient in quorem");
 #endif
 	if (q) {
@@ -2235,15 +2271,36 @@ quorem
 	return q;
 	}
 
-#ifndef NO_STRTOD_BIGCOMP
+#if defined(Avoid_Underflow) || !defined(NO_STRTOD_BIGCOMP) /*{*/
+ static double
+sulp
+#ifdef KR_headers
+	(x, bc) U *x; BCinfo *bc;
+#else
+	(U *x, BCinfo *bc)
+#endif
+{
+	U u;
+	double rv;
+	int i;
+
+	rv = ulp(x);
+	if (!bc->scale || (i = 2*P + 1 - ((word0(x) & Exp_mask) >> Exp_shift)) <= 0)
+		return rv; /* Is there an example where i <= 0 ? */
+	word0(&u) = Exp_1 + (i << Exp_shift);
+	word1(&u) = 0;
+	return rv * u.d;
+	}
+#endif /*}*/
 
+#ifndef NO_STRTOD_BIGCOMP
  static void
 bigcomp
 #ifdef KR_headers
 	(rv, s0, bc)
 	U *rv; CONST char *s0; BCinfo *bc;
 #else
-	(U *rv, CONST char *s0, BCinfo *bc)
+	(U *rv, const char *s0, BCinfo *bc)
 #endif
 {
 	Bigint *b, *d;
@@ -2375,7 +2432,7 @@ bigcomp
 		b = multadd(b, 10, 0);
 		dig = quorem(b,d);
 		}
-	if (b->x[0] || b->wds > 1)
+	if (dig > 0 || b->x[0] || b->wds > 1)
 		dd = -1;
  ret:
 	Bfree(b);
@@ -2398,7 +2455,7 @@ bigcomp
 				}
 			if (!dsign)
 				goto rethi1;
-			dval(rv) += 2.*ulp(rv);
+			dval(rv) += 2.*sulp(rv,bc);
 			}
 		else {
 			bc->inexact = 0;
@@ -2415,17 +2472,27 @@ bigcomp
 	else if (dd < 0) {
 		if (!dsign)	/* does not happen for round-near */
 retlow1:
-			dval(rv) -= ulp(rv);
+			dval(rv) -= sulp(rv,bc);
 		}
 	else if (dd > 0) {
 		if (dsign) {
  rethi1:
-			dval(rv) += ulp(rv);
+			dval(rv) += sulp(rv,bc);
 			}
 		}
 	else {
 		/* Exact half-way case:  apply round-even rule. */
-		if (word1(rv) & 1) {
+		if ((j = ((word0(rv) & Exp_mask) >> Exp_shift) - bc->scale) <= 0) {
+			i = 1 - j;
+			if (i <= 31) {
+				if (word1(rv) & (0x1 << i))
+					goto odd;
+				}
+			else if (word0(rv) & (0x1 << (i-32)))
+				goto odd;
+			}
+		else if (word1(rv) & 1) {
+ odd:
 			if (dsign)
 				goto rethi1;
 			goto retlow1;
@@ -2444,21 +2511,27 @@ strtod
 #ifdef KR_headers
 	(s00, se) CONST char *s00; char **se;
 #else
-	(CONST char *s00, char **se)
+	(const char *s00, char **se)
 #endif
 {
 	int bb2, bb5, bbe, bd2, bd5, bbbits, bs2, c, e, e1;
-	int esign, i, j, k, nd, nd0, nf, nz, nz0, sign;
+	int esign, i, j, k, nd, nd0, nf, nz, nz0, nz1, sign;
 	CONST char *s, *s0, *s1;
 	double aadj, aadj1;
 	Long L;
 	U aadj2, adj, rv, rv0;
 	ULong y, z;
 	BCinfo bc;
-	Bigint *bb, *bb1, *bd, *bd0, *bs, *delta;
+	Bigint *bb = nullptr, *bb1, *bd = nullptr, *bd0, *bs = nullptr, *delta = nullptr;
+#ifdef Avoid_Underflow
+	ULong Lsb, Lsb1;
+#endif
 #ifdef SET_INEXACT
 	int oldinexact;
 #endif
+#ifndef NO_STRTOD_BIGCOMP
+	int req_bigcomp = 0;
+#endif
 #ifdef Honor_FLT_ROUNDS /*{*/
 #ifdef Trust_FLT_ROUNDS /*{{ only define this if FLT_ROUNDS really works! */
 	bc.rounding = Flt_Rounds;
@@ -2475,7 +2548,7 @@ strtod
 	CONST char *s2;
 #endif
 
-	sign = nz0 = nz = bc.dplen = bc.uflchk = 0;
+	sign = nz0 = nz1 = nz = bc.dplen = bc.uflchk = 0;
 	dval(&rv) = 0.;
 	for(s = s00;;s++) switch(*s) {
 		case '-':
@@ -2521,10 +2594,12 @@ strtod
 	for(nd = nf = 0; (c = *s) >= '0' && c <= '9'; nd++, s++)
 		if (nd < 9)
 			y = 10*y + c - '0';
-		else if (nd < 16)
+		else if (nd < DBL_DIG + 2)
 			z = 10*z + c - '0';
 	nd0 = nd;
 	bc.dp0 = bc.dp1 = s - s0;
+	for(s1 = s; s1 > s0 && *--s1 == '0'; )
+		++nz1;
 #ifdef USE_LOCALE
 	s1 = localeconv()->decimal_point;
 	if (c == *s1) {
@@ -2552,6 +2627,8 @@ strtod
 			for(; c == '0'; c = *++s)
 				nz++;
 			if (c > '0' && c <= '9') {
+				bc.dp0 = s0 - s;
+				bc.dp1 = bc.dp0 + bc.dplen;
 				s0 = s;
 				nf += nz;
 				nz = 0;
@@ -2567,13 +2644,13 @@ strtod
 				for(i = 1; i < nz; i++)
 					if (nd++ < 9)
 						y *= 10;
-					else if (nd <= DBL_DIG + 1)
+					else if (nd <= DBL_DIG + 2)
 						z *= 10;
 				if (nd++ < 9)
 					y = 10*y + c;
-				else if (nd <= DBL_DIG + 1)
+				else if (nd <= DBL_DIG + 2)
 					z = 10*z + c;
-				nz = 0;
+				nz = nz1 = 0;
 				}
 			}
 		}
@@ -2598,9 +2675,9 @@ strtod
 				L = c - '0';
 				s1 = s;
 				while((c = *++s) >= '0' && c <= '9') {
-					L = 10*L + c - '0';
-					if (L > DBL_MAX_10_EXP)
-						break;
+					if (L < (INT_MAX - 10) / 10) {
+						L = 10*L + (c - '0');
+					}
 				}
 				if (s - s1 > 8 || L > 19999)
 					/* Avoid confusion from exponents
@@ -2663,7 +2740,7 @@ strtod
 
 	if (!nd0)
 		nd0 = nd;
-	k = nd < DBL_DIG + 1 ? nd : DBL_DIG + 1;
+	k = nd < DBL_DIG + 2 ? nd : DBL_DIG + 2;
 	dval(&rv) = y;
 	if (k > 9) {
 #ifdef SET_INEXACT
@@ -2682,6 +2759,7 @@ strtod
 			) {
 		if (!e)
 			goto ret;
+#ifndef ROUND_BIASED_without_Round_Up
 		if (e > 0) {
 			if (e <= Ten_pmax) {
 #ifdef VAX
@@ -2742,6 +2820,7 @@ strtod
 			goto ret;
 			}
 #endif
+#endif /* ROUND_BIASED_without_Round_Up */
 		}
 	e1 += nd - k;
 
@@ -2774,9 +2853,6 @@ strtod
 		if (e1 &= ~15) {
 			if (e1 > DBL_MAX_10_EXP) {
  ovfl:
-#ifndef NO_ERRNO
-				errno = ERANGE;
-#endif
 				/* Can't trust HUGE_VAL */
 #ifdef IEEE_Arith
 #ifdef Honor_FLT_ROUNDS
@@ -2803,6 +2879,17 @@ strtod
 				word0(&rv) = Big0;
 				word1(&rv) = Big1;
 #endif /*IEEE_Arith*/
+ range_err:
+				if (bd0) {
+					Bfree(bb);
+					Bfree(bd);
+					Bfree(bs);
+					Bfree(bd0);
+					Bfree(delta);
+					}
+#ifndef NO_ERRNO
+				errno = ERANGE;
+#endif
 				goto ret;
 				}
 			e1 >>= 4;
@@ -2843,6 +2930,8 @@ strtod
 						>> Exp_shift)) > 0) {
 				/* scaled rv is denormal; clear j low bits */
 				if (j >= 32) {
+					if (j > 54)
+						goto undfl;
 					word1(&rv) = 0;
 					if (j >= 53)
 					 word0(&rv) = (P+2)*Exp_msk1;
@@ -2866,10 +2955,7 @@ strtod
 				if (!dval(&rv)) {
  undfl:
 					dval(&rv) = 0.;
-#ifndef NO_ERRNO
-					errno = ERANGE;
-#endif
-					goto ret;
+					goto range_err;
 					}
 #ifndef Avoid_Underflow
 				word0(&rv) = Tiny0;
@@ -2886,7 +2972,7 @@ strtod
 
 	/* Put digits into bd: true value = bd * 10^e */
 
-	bc.nd = nd;
+	bc.nd = nd - nz1;
 #ifndef NO_STRTOD_BIGCOMP
 	bc.nd0 = nd0;	/* Only needed if nd > strtod_diglim, but done here */
 			/* to silence an erroneous warning about bc.nd0 */
@@ -2899,7 +2985,7 @@ strtod
 		if (i > nd0)
 			j += bc.dplen;
 		for(;;) {
-			if (--j <= bc.dp1 && j >= bc.dp0)
+			if (--j < bc.dp1 && j >= bc.dp0)
 				j = bc.dp0 - 1;
 			if (s0[j] != '0')
 				break;
@@ -2944,12 +3030,21 @@ strtod
 			bs2++;
 #endif
 #ifdef Avoid_Underflow
+		Lsb = LSB;
+		Lsb1 = 0;
 		j = bbe - bc.scale;
 		i = j + bbbits - 1;	/* logb(rv) */
-		if (i < Emin)	/* denormal */
-			j += P - Emin;
-		else
-			j = P + 1 - bbbits;
+		j = P + 1 - bbbits;
+		if (i < Emin) {	/* denormal */
+			i = Emin - i;
+			j -= i;
+			if (i < 32)
+				Lsb <<= i;
+			else if (i < 52)
+				Lsb1 = Lsb << (i-32);
+			else
+				Lsb1 = Exp_mask;
+			}
 #else /*Avoid_Underflow*/
 #ifdef Sudden_Underflow
 #ifdef IBM
@@ -2997,24 +3092,26 @@ strtod
 		bc.dsign = delta->sign;
 		delta->sign = 0;
 		i = cmp(delta, bs);
-#ifndef NO_STRTOD_BIGCOMP
+#ifndef NO_STRTOD_BIGCOMP /*{*/
 		if (bc.nd > nd && i <= 0) {
-			if (bc.dsign)
-				break;	/* Must use bigcomp(). */
+			if (bc.dsign) {
+				/* Must use bigcomp(). */
+				req_bigcomp = 1;
+				break;
+				}
 #ifdef Honor_FLT_ROUNDS
 			if (bc.rounding != 1) {
-				if (i < 0)
+				if (i < 0) {
+					req_bigcomp = 1;
 					break;
+					}
 				}
 			else
 #endif
-				{
-				bc.nd = nd;
 				i = -1;	/* Discarded digits make delta smaller. */
-				}
 			}
-#endif
-#ifdef Honor_FLT_ROUNDS
+#endif /*}*/
+#ifdef Honor_FLT_ROUNDS /*{*/
 		if (bc.rounding != 1) {
 			if (i < 0) {
 				/* Error is less than an ulp */
@@ -3048,7 +3145,7 @@ strtod
 						  }
 						}
  apply_adj:
-#ifdef Avoid_Underflow
+#ifdef Avoid_Underflow /*{*/
 					if (bc.scale && (y = word0(&rv) & Exp_mask)
 						<= 2*P*Exp_msk1)
 					  word0(&adj) += (2*P+1)*Exp_msk1 - y;
@@ -3062,7 +3159,7 @@ strtod
 						}
 					else
 #endif /*Sudden_Underflow*/
-#endif /*Avoid_Underflow*/
+#endif /*Avoid_Underflow}*/
 					dval(&rv) += adj.d*ulp(&rv);
 					}
 				break;
@@ -3079,7 +3176,7 @@ strtod
 					adj.d = y;
 					}
 				}
-#ifdef Avoid_Underflow
+#ifdef Avoid_Underflow /*{*/
 			if (bc.scale && (y = word0(&rv) & Exp_mask) <= 2*P*Exp_msk1)
 				word0(&adj) += (2*P+1)*Exp_msk1 - y;
 #else
@@ -3095,7 +3192,7 @@ strtod
 				goto cont;
 				}
 #endif /*Sudden_Underflow*/
-#endif /*Avoid_Underflow*/
+#endif /*Avoid_Underflow}*/
 			adj.d *= ulp(&rv);
 			if (bc.dsign) {
 				if (word0(&rv) == Big0 && word1(&rv) == Big1)
@@ -3106,20 +3203,20 @@ strtod
 				dval(&rv) -= adj.d;
 			goto cont;
 			}
-#endif /*Honor_FLT_ROUNDS*/
+#endif /*}Honor_FLT_ROUNDS*/
 
 		if (i < 0) {
 			/* Error is less than half an ulp -- check for
 			 * special case of mantissa a power of two.
 			 */
 			if (bc.dsign || word1(&rv) || word0(&rv) & Bndry_mask
-#ifdef IEEE_Arith
+#ifdef IEEE_Arith /*{*/
 #ifdef Avoid_Underflow
 			 || (word0(&rv) & Exp_mask) <= (2*P+1)*Exp_msk1
 #else
 			 || (word0(&rv) & Exp_mask) <= Exp_msk1
 #endif
-#endif
+#endif /*}*/
 				) {
 #ifdef SET_INEXACT
 				if (!delta->x[0] && delta->wds <= 1)
@@ -3150,6 +3247,8 @@ strtod
 #endif
 						   0xffffffff)) {
 					/*boundary case -- increment exponent*/
+					if (word0(&rv) == Big0 && word1(&rv) == Big1)
+						goto ovfl;
 					word0(&rv) = (word0(&rv) & Exp_mask)
 						+ Exp_msk1
 #ifdef IBM
@@ -3210,18 +3309,39 @@ strtod
 #ifdef IBM
 				goto cont;
 #else
+#ifndef NO_STRTOD_BIGCOMP
+				if (bc.nd > nd)
+					goto cont;
+#endif
 				break;
 #endif
 				}
 #ifndef ROUND_BIASED
+#ifdef Avoid_Underflow
+			if (Lsb1) {
+				if (!(word0(&rv) & Lsb1))
+					break;
+				}
+			else if (!(word1(&rv) & Lsb))
+				break;
+#else
 			if (!(word1(&rv) & LSB))
 				break;
 #endif
+#endif
 			if (bc.dsign)
+#ifdef Avoid_Underflow
+				dval(&rv) += sulp(&rv, &bc);
+#else
 				dval(&rv) += ulp(&rv);
+#endif
 #ifndef ROUND_BIASED
 			else {
+#ifdef Avoid_Underflow
+				dval(&rv) -= sulp(&rv, &bc);
+#else
 				dval(&rv) -= ulp(&rv);
+#endif
 #ifndef Sudden_Underflow
 				if (!dval(&rv)) {
 					if (bc.nd >nd) {
@@ -3314,9 +3434,22 @@ strtod
 				dval(&aadj2) = aadj1;
 				word0(&aadj2) += (2*P+1)*Exp_msk1 - y;
 				aadj1 = dval(&aadj2);
+				adj.d = aadj1 * ulp(&rv);
+				dval(&rv) += adj.d;
+				if (rv.d == 0.)
+#ifdef NO_STRTOD_BIGCOMP
+					goto undfl;
+#else
+					{
+					req_bigcomp = 1;
+					break;
+					}
+#endif
+				}
+			else {
+				adj.d = aadj1 * ulp(&rv);
+				dval(&rv) += adj.d;
 				}
-			adj.d = aadj1 * ulp(&rv);
-			dval(&rv) += adj.d;
 #else
 #ifdef Sudden_Underflow
 			if ((word0(&rv) & Exp_mask) <= P*Exp_msk1) {
@@ -3399,8 +3532,16 @@ strtod
 	Bfree(bd0);
 	Bfree(delta);
 #ifndef NO_STRTOD_BIGCOMP
-	if (bc.nd > nd)
+	if (req_bigcomp) {
+		bd0 = 0;
+		bc.e0 += nz1;
 		bigcomp(&rv, s0, &bc);
+		y = word0(&rv) & Exp_mask;
+		if (y == Exp_mask)
+			goto ovfl;
+		if (y == 0 && rv.d == 0.)
+			goto undfl;
+		}
 #endif
 #ifdef SET_INEXACT
 	if (bc.inexact) {
@@ -3473,7 +3614,7 @@ rv_alloc(int i)
 #ifdef KR_headers
 nrv_alloc(s, rve, n) char *s, **rve; int n;
 #else
-nrv_alloc(CONST char *s, char **rve, int n)
+nrv_alloc(const char *s, char **rve, int n)
 #endif
 {
 	char *rv, *t;
@@ -3585,7 +3726,7 @@ dtoa
 	*/
 
 	int bbits, b2, b5, be, dig, i, ieps, ilim, ilim0, ilim1,
-		j, j1, k, k0, k_check, leftright, m2, m5, s2, s5,
+		j, j1 = 0, k, k0, k_check, leftright, m2, m5, s2, s5,
 		spec_case, try_quick;
 	Long L;
 #ifndef Sudden_Underflow
@@ -3596,6 +3737,11 @@ dtoa
 	U d2, eps, u;
 	double ds;
 	char *s, *s0;
+#ifndef No_leftright
+#ifdef IEEE_Arith
+	U eps1;
+#endif
+#endif
 #ifdef SET_INEXACT
 	int inexact, oldinexact;
 #endif
@@ -3861,14 +4007,26 @@ dtoa
 			 * generating digits needed.
 			 */
 			dval(&eps) = 0.5/tens[ilim-1] - dval(&eps);
+#ifdef IEEE_Arith
+			if (k0 < 0 && j1 >= 307) {
+				eps1.d = 1.01e256; /* 1.01 allows roundoff in the next few lines */
+				word0(&eps1) -= Exp_msk1 * (Bias+P-1);
+				dval(&eps1) *= tens[j1 & 0xf];
+				for(i = 0, j = (j1-256) >> 4; j; j >>= 1, i++)
+					if (j & 1)
+						dval(&eps1) *= bigtens[i];
+				if (eps.d < eps1.d)
+					eps.d = eps1.d;
+				}
+#endif
 			for(i = 0;;) {
-				L = (long)dval(&u);
+				L = dval(&u);
 				dval(&u) -= L;
-				*s++ = '0' + (char)L;
-				if (dval(&u) < dval(&eps))
-					goto ret1;
+				*s++ = '0' + (int)L;
 				if (1. - dval(&u) < dval(&eps))
 					goto bump_up;
+				if (dval(&u) < dval(&eps))
+					goto ret1;
 				if (++i >= ilim)
 					break;
 				dval(&eps) *= 10.;
@@ -3916,7 +4074,7 @@ dtoa
 				goto no_digits;
 			goto one_digit;
 			}
-		for(i = 1; i <= k + 1; i++, dval(&u) *= 10.) {
+		for(i = 1;; i++, dval(&u) *= 10.) {
 			L = (Long)(dval(&u) / ds);
 			dval(&u) -= L*ds;
 #ifdef Check_FLT_ROUNDS
@@ -3942,7 +4100,12 @@ dtoa
 				  }
 #endif
 				dval(&u) += dval(&u);
-				if (dval(&u) > ds || (dval(&u) == ds && L & 1)) {
+#ifdef ROUND_BIASED
+				if (dval(&u) >= ds)
+#else
+				if (dval(&u) > ds || (dval(&u) == ds && L & 1))
+#endif
+					{
  bump_up:
 					while(*--s == '9')
 						if (s == s0) {
@@ -4027,16 +4190,6 @@ dtoa
 	 * and for all and pass them and a shift to quorem, so it
 	 * can do shifts and ors to compute the numerator for q.
 	 */
-#ifdef Pack_32
-	i = ((s5 ? 32 - hi0bits(S->x[S->wds-1]) : 1) + s2) & 0x1f;
-	if (i)
-		i = 32 - i;
-#define iInc 28
-#else
-	if (i = ((s5 ? 32 - hi0bits(S->x[S->wds-1]) : 1) + s2) & 0xf)
-		i = 16 - i;
-#define iInc 12
-#endif
 	i = dshift(S, s2);
 	b2 += i;
 	m2 += i;
@@ -4129,7 +4282,11 @@ dtoa
 				if (j1 > 0) {
 					b = lshift(b, 1);
 					j1 = cmp(b, S);
+#ifdef ROUND_BIASED
+					if (j1 >= 0 /*)*/
+#else
 					if ((j1 > 0 || (j1 == 0 && dig & 1))
+#endif
 					&& dig++ == '9')
 						goto round_9_up;
 					}
@@ -4190,7 +4347,12 @@ dtoa
 #endif
 	b = lshift(b, 1);
 	j = cmp(b, S);
-	if (j > 0 || (j == 0 && dig & 1)) {
+#ifdef ROUND_BIASED
+	if (j >= 0)
+#else
+	if (j > 0 || (j == 0 && dig & 1))
+#endif
+		{
  roundoff:
 		while(*--s == '9')
 			if (s == s0) {
diff --git a/src/base/threading/platform_thread.h b/src/base/threading/platform_thread.h
index 4c2db8a..0b34cce 100644
--- a/src/base/threading/platform_thread.h
+++ b/src/base/threading/platform_thread.h
@@ -205,6 +205,20 @@ class BASE_EXPORT PlatformThread {
 
   static ThreadPriority GetCurrentThreadPriority();
 
+#if defined(OS_LINUX)
+  // Toggles a specific thread's priority at runtime. This can be used to
+  // change the priority of a thread in a different process and will fail
+  // if the calling process does not have proper permissions. The
+  // SetCurrentThreadPriority() function above is preferred in favor of
+  // security but on platforms where sandboxed processes are not allowed to
+  // change priority this function exists to allow a non-sandboxed process
+  // to change the priority of sandboxed threads for improved performance.
+  // Warning: Don't use this for a main thread because that will change the
+  // whole thread group's (i.e. process) priority.
+  static void SetThreadPriority(PlatformThreadId thread_id,
+                                ThreadPriority priority);
+#endif
+
  private:
   DISALLOW_IMPLICIT_CONSTRUCTORS(PlatformThread);
 };
diff --git a/src/base/threading/platform_thread_linux.cc b/src/base/threading/platform_thread_linux.cc
index 054de87..85a5792 100644
--- a/src/base/threading/platform_thread_linux.cc
+++ b/src/base/threading/platform_thread_linux.cc
@@ -8,8 +8,10 @@
 #include <sched.h>
 #include <stddef.h>
 
+#include "base/files/file_util.h"
 #include "base/lazy_instance.h"
 #include "base/logging.h"
+#include "base/strings/string_number_conversions.h"
 #include "base/threading/platform_thread_internal_posix.h"
 #include "base/threading/thread_id_name_manager.h"
 #if 0
@@ -20,11 +22,47 @@
 #if !defined(OS_NACL)
 #include <pthread.h>
 #include <sys/prctl.h>
+#include <sys/resource.h>
+#include <sys/time.h>
 #include <sys/types.h>
 #include <unistd.h>
 #endif
 
 namespace base {
+namespace {
+#if !defined(OS_NACL)
+const FilePath::CharType kCpusetDirectory[] =
+    FILE_PATH_LITERAL("/sys/fs/cgroup/cpuset/chrome");
+
+FilePath ThreadPriorityToCpusetDirectory(ThreadPriority priority) {
+  FilePath cpuset_filepath(kCpusetDirectory);
+  switch (priority) {
+    case ThreadPriority::NORMAL:
+      return cpuset_filepath;
+    case ThreadPriority::BACKGROUND:
+      return cpuset_filepath.Append(FILE_PATH_LITERAL("non-urgent"));
+    case ThreadPriority::DISPLAY:
+    case ThreadPriority::REALTIME_AUDIO:
+      return cpuset_filepath.Append(FILE_PATH_LITERAL("urgent"));
+  }
+  NOTREACHED();
+  return FilePath();
+}
+
+void SetThreadCpuset(PlatformThreadId thread_id,
+                     const FilePath& cpuset_directory) {
+  // Silently ignore request if cpuset directory doesn't exist.
+  if (!DirectoryExists(cpuset_directory))
+    return;
+  FilePath tasks_filepath = cpuset_directory.Append(FILE_PATH_LITERAL("tasks"));
+  std::string tid = IntToString(thread_id);
+  int bytes_written = WriteFile(tasks_filepath, tid.c_str(), tid.size());
+  if (bytes_written != static_cast<int>(tid.size())) {
+    DVLOG(1) << "Failed to add " << tid << " to " << tasks_filepath.value();
+  }
+}
+#endif
+}  // namespace
 
 namespace internal {
 
@@ -43,6 +81,8 @@ const ThreadPriorityToNiceValuePair kThreadPriorityToNiceValueMap[4] = {
 
 bool SetCurrentThreadPriorityForPlatform(ThreadPriority priority) {
 #if !defined(OS_NACL)
+  FilePath cpuset_directory = ThreadPriorityToCpusetDirectory(priority);
+  SetThreadCpuset(PlatformThread::CurrentId(), cpuset_directory);
   return priority == ThreadPriority::REALTIME_AUDIO &&
          pthread_setschedparam(pthread_self(), SCHED_RR, &kRealTimePrio) == 0;
 #else
@@ -94,6 +134,26 @@ void PlatformThread::SetName(const std::string& name) {
 #endif  //  !defined(OS_NACL)
 }
 
+#if !defined(OS_NACL)
+// static
+void PlatformThread::SetThreadPriority(PlatformThreadId thread_id,
+                                       ThreadPriority priority) {
+  // Changing current main threads' priority is not permitted in favor of
+  // security, this interface is restricted to change only non-main thread
+  // priority.
+  CHECK_NE(thread_id, getpid());
+
+  FilePath cpuset_directory = ThreadPriorityToCpusetDirectory(priority);
+  SetThreadCpuset(thread_id, cpuset_directory);
+
+  const int nice_setting = internal::ThreadPriorityToNiceValue(priority);
+  if (setpriority(PRIO_PROCESS, thread_id, nice_setting)) {
+    DVPLOG(1) << "Failed to set nice value of thread (" << thread_id << ") to "
+              << nice_setting;
+  }
+}
+#endif  //  !defined(OS_NACL)
+
 void InitThreading() {}
 
 void TerminateOnThread() {}
diff --git a/src/base/threading/sequenced_task_runner_handle.cc b/src/base/threading/sequenced_task_runner_handle.cc
index db96a6a..53f3261 100644
--- a/src/base/threading/sequenced_task_runner_handle.cc
+++ b/src/base/threading/sequenced_task_runner_handle.cc
@@ -40,8 +40,10 @@ scoped_refptr<SequencedTaskRunner> SequencedTaskRunnerHandle::Get() {
     SequencedWorkerPool::SequenceToken sequence_token =
         SequencedWorkerPool::GetSequenceTokenForCurrentThread();
     DCHECK(sequence_token.IsValid());
-    DCHECK(pool->IsRunningSequenceOnCurrentThread(sequence_token));
-    return pool->GetSequencedTaskRunner(sequence_token);
+    scoped_refptr<SequencedTaskRunner> sequenced_task_runner(
+        pool->GetSequencedTaskRunner(sequence_token));
+    DCHECK(sequenced_task_runner->RunsTasksOnCurrentThread());
+    return sequenced_task_runner;
   }
 
   // Return the SingleThreadTaskRunner for the current thread otherwise.
diff --git a/src/base/threading/sequenced_worker_pool.cc b/src/base/threading/sequenced_worker_pool.cc
index 1f461c1..b7e93bb 100644
--- a/src/base/threading/sequenced_worker_pool.cc
+++ b/src/base/threading/sequenced_worker_pool.cc
@@ -15,10 +15,10 @@
 #include <vector>
 
 #include "base/atomic_sequence_num.h"
-#include "base/atomicops.h"
 #include "base/callback.h"
 #include "base/compiler_specific.h"
 #include "base/critical_closure.h"
+#include "base/debug/dump_without_crashing.h"
 #include "base/lazy_instance.h"
 #include "base/logging.h"
 #include "base/macros.h"
@@ -30,14 +30,14 @@
 #include "base/task_scheduler/post_task.h"
 #include "base/task_scheduler/task_scheduler.h"
 #include "base/threading/platform_thread.h"
+#include "base/threading/sequenced_task_runner_handle.h"
 #include "base/threading/simple_thread.h"
 #include "base/threading/thread_local.h"
 #include "base/threading/thread_restrictions.h"
-#include "base/threading/thread_task_runner_handle.h"
 #include "base/time/time.h"
-#include "base/trace_event/heap_profiler.h"
 #include "base/trace_event/trace_event.h"
 #include "base/tracked_objects.h"
+#include "base/tracking_info.h"
 #include "build/build_config.h"
 
 #if defined(OS_MACOSX)
@@ -54,27 +54,26 @@ namespace base {
 
 namespace {
 
-// An enum representing the state of all pools. Any given process should only
-// ever transition from NONE_ACTIVE to the active states, transitions between
-// actives states are unexpected. The REDIRECTED_TO_TASK_SCHEDULER transition
-// occurs when RedirectSequencedWorkerPoolsToTaskSchedulerForProcess() is called
-// and the WORKER_CREATED transition occurs when a Worker needs to be created
-// because the first task was posted and the state is still NONE_ACTIVE.
-// |g_all_pools_state| uses relaxed atomic operations to ensure no data race
-// between reads/writes, strict memory ordering isn't required per no other
-// state being inferred from its value. Explicit synchronization (e.g. locks or
-// events) would be overkill (it's fine for other threads to still see
-// NONE_ACTIVE after the first Worker was created -- this is not possible for
-// REDIRECTED_TO_TASK_SCHEDULER per its API requesting to be invoked while no
-// other threads are active).
+// An enum representing the state of all pools. A non-test process should only
+// ever transition from POST_TASK_DISABLED to one of the active states. A test
+// process may transition from one of the active states to POST_TASK_DISABLED
+// when DisableForProcessForTesting() is called.
+//
+// External memory synchronization is required to call a method that reads
+// |g_all_pools_state| after calling a method that modifies it.
+//
 // TODO(gab): Remove this if http://crbug.com/622400 fails (SequencedWorkerPool
 // will be phased out completely otherwise).
-enum AllPoolsState : subtle::Atomic32 {
-  NONE_ACTIVE,
-  WORKER_CREATED,
+enum class AllPoolsState {
+  POST_TASK_DISABLED,
+  USE_WORKER_POOL,
   REDIRECTED_TO_TASK_SCHEDULER,
 };
-subtle::Atomic32 g_all_pools_state = AllPoolsState::NONE_ACTIVE;
+
+// TODO(fdoray): Change the initial state to POST_TASK_DISABLED. It is initially
+// USE_WORKER_POOL to avoid a revert of the CL that adds
+// debug::DumpWithoutCrashing() in case of waterfall failures.
+AllPoolsState g_all_pools_state = AllPoolsState::USE_WORKER_POOL;
 
 struct SequencedTask : public TrackingInfo  {
   SequencedTask()
@@ -118,6 +117,14 @@ struct SequencedTaskLessThan {
   }
 };
 
+// Create a process-wide unique ID to represent this task in trace events. This
+// will be mangled with a Process ID hash to reduce the likelyhood of colliding
+// with MessageLoop pointers on other processes.
+uint64_t GetTaskTraceID(const SequencedTask& task, void* pool) {
+  return (static_cast<uint64_t>(task.trace_id) << 32) |
+         static_cast<uint64_t>(reinterpret_cast<intptr_t>(pool));
+}
+
 // SequencedWorkerPoolTaskRunner ---------------------------------------------
 // A TaskRunner which posts tasks to a SequencedWorkerPool with a
 // fixed ShutdownBehavior.
@@ -168,14 +175,17 @@ bool SequencedWorkerPoolTaskRunner::RunsTasksOnCurrentThread() const {
   return pool_->RunsTasksOnCurrentThread();
 }
 
-// SequencedWorkerPoolSequencedTaskRunner ------------------------------------
+}  // namespace
+
+// SequencedWorkerPool::PoolSequencedTaskRunner ------------------------------
 // A SequencedTaskRunner which posts tasks to a SequencedWorkerPool with a
 // fixed sequence token.
 //
 // Note that this class is RefCountedThreadSafe (inherited from TaskRunner).
-class SequencedWorkerPoolSequencedTaskRunner : public SequencedTaskRunner {
+class SequencedWorkerPool::PoolSequencedTaskRunner
+    : public SequencedTaskRunner {
  public:
-  SequencedWorkerPoolSequencedTaskRunner(
+  PoolSequencedTaskRunner(
       scoped_refptr<SequencedWorkerPool> pool,
       SequencedWorkerPool::SequenceToken token,
       SequencedWorkerPool::WorkerShutdown shutdown_behavior);
@@ -192,7 +202,7 @@ class SequencedWorkerPoolSequencedTaskRunner : public SequencedTaskRunner {
                                   TimeDelta delay) override;
 
  private:
-  ~SequencedWorkerPoolSequencedTaskRunner() override;
+  ~PoolSequencedTaskRunner() override;
 
   const scoped_refptr<SequencedWorkerPool> pool_;
 
@@ -200,25 +210,25 @@ class SequencedWorkerPoolSequencedTaskRunner : public SequencedTaskRunner {
 
   const SequencedWorkerPool::WorkerShutdown shutdown_behavior_;
 
-  DISALLOW_COPY_AND_ASSIGN(SequencedWorkerPoolSequencedTaskRunner);
+  DISALLOW_COPY_AND_ASSIGN(PoolSequencedTaskRunner);
 };
 
-SequencedWorkerPoolSequencedTaskRunner::SequencedWorkerPoolSequencedTaskRunner(
-    scoped_refptr<SequencedWorkerPool> pool,
-    SequencedWorkerPool::SequenceToken token,
-    SequencedWorkerPool::WorkerShutdown shutdown_behavior)
+SequencedWorkerPool::PoolSequencedTaskRunner::
+    PoolSequencedTaskRunner(
+        scoped_refptr<SequencedWorkerPool> pool,
+        SequencedWorkerPool::SequenceToken token,
+        SequencedWorkerPool::WorkerShutdown shutdown_behavior)
     : pool_(std::move(pool)),
       token_(token),
       shutdown_behavior_(shutdown_behavior) {}
 
-SequencedWorkerPoolSequencedTaskRunner::
-~SequencedWorkerPoolSequencedTaskRunner() {
-}
+SequencedWorkerPool::PoolSequencedTaskRunner::
+    ~PoolSequencedTaskRunner() = default;
 
-bool SequencedWorkerPoolSequencedTaskRunner::PostDelayedTask(
-    const tracked_objects::Location& from_here,
-    const Closure& task,
-    TimeDelta delay) {
+bool SequencedWorkerPool::PoolSequencedTaskRunner::
+    PostDelayedTask(const tracked_objects::Location& from_here,
+                    const Closure& task,
+                    TimeDelta delay) {
   if (delay.is_zero()) {
     return pool_->PostSequencedWorkerTaskWithShutdownBehavior(
         token_, from_here, task, shutdown_behavior_);
@@ -226,29 +236,20 @@ bool SequencedWorkerPoolSequencedTaskRunner::PostDelayedTask(
   return pool_->PostDelayedSequencedWorkerTask(token_, from_here, task, delay);
 }
 
-bool SequencedWorkerPoolSequencedTaskRunner::RunsTasksOnCurrentThread() const {
+bool SequencedWorkerPool::PoolSequencedTaskRunner::
+    RunsTasksOnCurrentThread() const {
   return pool_->IsRunningSequenceOnCurrentThread(token_);
 }
 
-bool SequencedWorkerPoolSequencedTaskRunner::PostNonNestableDelayedTask(
-    const tracked_objects::Location& from_here,
-    const Closure& task,
-    TimeDelta delay) {
+bool SequencedWorkerPool::PoolSequencedTaskRunner::
+    PostNonNestableDelayedTask(const tracked_objects::Location& from_here,
+                               const Closure& task,
+                               TimeDelta delay) {
   // There's no way to run nested tasks, so simply forward to
   // PostDelayedTask.
   return PostDelayedTask(from_here, task, delay);
 }
 
-// Create a process-wide unique ID to represent this task in trace events. This
-// will be mangled with a Process ID hash to reduce the likelyhood of colliding
-// with MessageLoop pointers on other processes.
-uint64_t GetTaskTraceID(const SequencedTask& task, void* pool) {
-  return (static_cast<uint64_t>(task.trace_id) << 32) |
-         static_cast<uint64_t>(reinterpret_cast<intptr_t>(pool));
-}
-
-}  // namespace
-
 // Worker ---------------------------------------------------------------------
 
 class SequencedWorkerPool::Worker : public SimpleThread {
@@ -381,8 +382,10 @@ class SequencedWorkerPool::Inner {
   };
 
   // Helper used by PostTask() to complete the work when redirection is on.
+  // Returns true if the task may run at some point in the future and false if
+  // it will definitely not run.
   // Coalesce upon resolution of http://crbug.com/622400.
-  void PostTaskToTaskScheduler(const SequencedTask& sequenced,
+  bool PostTaskToTaskScheduler(const SequencedTask& sequenced,
                                const TimeDelta& delay);
 
   // Returns the TaskScheduler TaskRunner for the specified |sequence_token_id|
@@ -573,8 +576,7 @@ SequencedWorkerPool::Worker::Worker(
       worker_pool_(std::move(worker_pool)),
       task_shutdown_behavior_(BLOCK_SHUTDOWN),
       is_processing_task_(false) {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
   Start();
 }
 
@@ -582,8 +584,7 @@ SequencedWorkerPool::Worker::~Worker() {
 }
 
 void SequencedWorkerPool::Worker::Run() {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
 
 #if defined(OS_WIN)
   win::ScopedCOMInitializer com_initializer;
@@ -643,7 +644,9 @@ SequencedWorkerPool::Inner::Inner(SequencedWorkerPool* worker_pool,
       cleanup_idlers_(0),
       cleanup_cv_(&lock_),
       testing_observer_(observer),
-      task_priority_(task_priority) {}
+      task_priority_(task_priority) {
+  DCHECK_GT(max_threads_, 1U);
+}
 
 SequencedWorkerPool::Inner::~Inner() {
   // You must call Shutdown() before destroying the pool.
@@ -680,6 +683,13 @@ bool SequencedWorkerPool::Inner::PostTask(
     const tracked_objects::Location& from_here,
     const Closure& task,
     TimeDelta delay) {
+  // TODO(fdoray): Uncomment this DCHECK. It is initially commented to avoid a
+  // revert of the CL that adds debug::DumpWithoutCrashing() if it fails on the
+  // waterfall. https://crbug.com/622400
+  // DCHECK_NE(AllPoolsState::POST_TASK_DISABLED, g_all_pools_state);
+  if (g_all_pools_state == AllPoolsState::POST_TASK_DISABLED)
+    debug::DumpWithoutCrashing();
+
   DCHECK(delay.is_zero() || shutdown_behavior == SKIP_ON_SHUTDOWN);
   SequencedTask sequenced(from_here);
   sequenced.sequence_token_id = sequence_token.id_;
@@ -729,9 +739,9 @@ bool SequencedWorkerPool::Inner::PostTask(
     if (optional_token_name)
       sequenced.sequence_token_id = LockedGetNamedTokenID(*optional_token_name);
 
-    if (subtle::NoBarrier_Load(&g_all_pools_state) ==
-        AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
-      PostTaskToTaskScheduler(sequenced, delay);
+    if (g_all_pools_state == AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
+      if (!PostTaskToTaskScheduler(sequenced, delay))
+        return false;
     } else {
       pending_tasks_.insert(sequenced);
 
@@ -742,8 +752,10 @@ bool SequencedWorkerPool::Inner::PostTask(
     }
   }
 
-  if (subtle::NoBarrier_Load(&g_all_pools_state) !=
-      AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
+  // Use != REDIRECTED_TO_TASK_SCHEDULER instead of == USE_WORKER_POOL to ensure
+  // correct behavior if a task is posted to a SequencedWorkerPool before
+  // Enable(WithRedirectionToTaskScheduler)ForProcess() in a non-DCHECK build.
+  if (g_all_pools_state != AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
     // Actually start the additional thread or signal an existing one outside
     // the lock.
     if (create_thread_id)
@@ -757,8 +769,7 @@ bool SequencedWorkerPool::Inner::PostTask(
     AutoLock lock_for_dcheck(lock_);
     // Some variables are exposed in both modes for convenience but only really
     // intended for one of them at runtime, confirm exclusive usage here.
-    if (subtle::NoBarrier_Load(&g_all_pools_state) ==
-        AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
+    if (g_all_pools_state == AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
       DCHECK(pending_tasks_.empty());
       DCHECK_EQ(0, create_thread_id);
     } else {
@@ -770,11 +781,10 @@ bool SequencedWorkerPool::Inner::PostTask(
   return true;
 }
 
-void SequencedWorkerPool::Inner::PostTaskToTaskScheduler(
+bool SequencedWorkerPool::Inner::PostTaskToTaskScheduler(
     const SequencedTask& sequenced,
     const TimeDelta& delay) {
-  DCHECK_EQ(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER, g_all_pools_state);
 
   lock_.AssertAcquired();
 
@@ -798,9 +808,10 @@ void SequencedWorkerPool::Inner::PostTaskToTaskScheduler(
       static_cast<TaskShutdownBehavior>(sequenced.shutdown_behavior);
   const TaskTraits traits = TaskTraits()
                                 .WithFileIO()
+                                .WithWait()
                                 .WithPriority(task_priority_)
                                 .WithShutdownBehavior(task_shutdown_behavior);
-  GetTaskSchedulerTaskRunner(sequenced.sequence_token_id, traits)
+  return GetTaskSchedulerTaskRunner(sequenced.sequence_token_id, traits)
       ->PostDelayedTask(sequenced.posted_from, sequenced.task, delay);
 }
 
@@ -808,8 +819,7 @@ scoped_refptr<TaskRunner>
 SequencedWorkerPool::Inner::GetTaskSchedulerTaskRunner(
     int sequence_token_id,
     const TaskTraits& traits) {
-  DCHECK_EQ(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER, g_all_pools_state);
 
   lock_.AssertAcquired();
 
@@ -836,25 +846,9 @@ SequencedWorkerPool::Inner::GetTaskSchedulerTaskRunner(
   // same shutdown behavior.
 
   if (!task_runner) {
-    ExecutionMode execution_mode =
-        sequence_token_id ? ExecutionMode::SEQUENCED : ExecutionMode::PARALLEL;
-
-    if (max_threads_ == 1U) {
-      // Tasks posted to single-threaded pools can assume thread affinity.
-      execution_mode = ExecutionMode::SINGLE_THREADED;
-
-      // Disallow posting tasks with different sequence tokens to single-
-      // threaded pools since the TaskScheduler can't force different sequences
-      // to run on the same thread.
-      DCHECK_LE(sequenced_task_runner_map_.size(), 1U);
-
-      // Disallow posting tasks without a sequence token to a single-threaded
-      // pool. No users do that currently and we don't want to support new use
-      // cases.
-      DCHECK(sequence_token_id);
-    }
-
-    task_runner = CreateTaskRunnerWithTraits(traits, execution_mode);
+    task_runner = sequence_token_id
+                      ? CreateSequencedTaskRunnerWithTraits(traits)
+                      : CreateTaskRunnerWithTraits(traits);
   }
 
   return task_runner;
@@ -862,12 +856,10 @@ SequencedWorkerPool::Inner::GetTaskSchedulerTaskRunner(
 
 bool SequencedWorkerPool::Inner::RunsTasksOnCurrentThread() const {
   AutoLock lock(lock_);
-  if (subtle::NoBarrier_Load(&g_all_pools_state) ==
-      AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
+  if (g_all_pools_state == AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
     if (!runs_tasks_on_verifier_) {
       runs_tasks_on_verifier_ = CreateTaskRunnerWithTraits(
-          TaskTraits().WithFileIO().WithPriority(task_priority_),
-          ExecutionMode::PARALLEL);
+          TaskTraits().WithFileIO().WithWait().WithPriority(task_priority_));
     }
     return runs_tasks_on_verifier_->RunsTasksOnCurrentThread();
   } else {
@@ -877,13 +869,11 @@ bool SequencedWorkerPool::Inner::RunsTasksOnCurrentThread() const {
 
 bool SequencedWorkerPool::Inner::IsRunningSequenceOnCurrentThread(
     SequenceToken sequence_token) const {
+  DCHECK(sequence_token.IsValid());
+
   AutoLock lock(lock_);
-  if (subtle::NoBarrier_Load(&g_all_pools_state) ==
-      AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
-    // TODO(gab): This currently only verifies that the current thread is a
-    // thread on which a task bound to |sequence_token| *could* run, but it
-    // doesn't verify that the current is *currently running* a task bound to
-    // |sequence_token|.
+
+  if (g_all_pools_state == AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
     const auto sequenced_task_runner_it =
         sequenced_task_runner_map_.find(sequence_token.id_);
     return sequenced_task_runner_it != sequenced_task_runner_map_.end() &&
@@ -891,17 +881,14 @@ bool SequencedWorkerPool::Inner::IsRunningSequenceOnCurrentThread(
   } else {
     ThreadMap::const_iterator found =
         threads_.find(PlatformThread::CurrentId());
-    if (found == threads_.end())
-      return false;
-    return found->second->is_processing_task() &&
+    return found != threads_.end() && found->second->is_processing_task() &&
            sequence_token.Equals(found->second->task_sequence_token());
   }
 }
 
 // See https://code.google.com/p/chromium/issues/detail?id=168415
 void SequencedWorkerPool::Inner::CleanupForTesting() {
-  DCHECK(!RunsTasksOnCurrentThread());
-  base::ThreadRestrictions::ScopedAllowWait allow_wait;
+  DCHECK_NE(g_all_pools_state, AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER);
   AutoLock lock(lock_);
   CHECK_EQ(CLEANUP_DONE, cleanup_state_);
   if (shutdown_called_)
@@ -930,12 +917,11 @@ void SequencedWorkerPool::Inner::Shutdown(
       return;
     shutdown_called_ = true;
 
-    if (subtle::NoBarrier_Load(&g_all_pools_state) !=
-        AllPoolsState::WORKER_CREATED)
-      return;
-
     max_blocking_tasks_after_shutdown_ = max_new_blocking_tasks_after_shutdown;
 
+    if (g_all_pools_state != AllPoolsState::USE_WORKER_POOL)
+      return;
+
     // Tickle the threads. This will wake up a waiting one so it will know that
     // it can exit, which in turn will wake up any other waiting ones.
     SignalHasWork();
@@ -973,8 +959,7 @@ bool SequencedWorkerPool::Inner::IsShutdownInProgress() {
 }
 
 void SequencedWorkerPool::Inner::ThreadLoop(Worker* this_worker) {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
   {
     AutoLock lock(lock_);
     DCHECK(thread_being_created_);
@@ -997,14 +982,11 @@ void SequencedWorkerPool::Inner::ThreadLoop(Worker* this_worker) {
       GetWorkStatus status =
           GetWork(&task, &wait_time, &delete_these_outside_lock);
       if (status == GET_WORK_FOUND) {
-        TRACE_EVENT_WITH_FLOW2(TRACE_DISABLED_BY_DEFAULT("toplevel.flow"),
-            "SequencedWorkerPool::Inner::ThreadLoop",
+        TRACE_TASK_EXECUTION("SequencedWorkerPool::Inner::ThreadLoop", task);
+        TRACE_EVENT_WITH_FLOW0(TRACE_DISABLED_BY_DEFAULT("toplevel.flow"),
+            "SequencedWorkerPool::Inner::PostTask",
             TRACE_ID_MANGLE(GetTaskTraceID(task, static_cast<void*>(this))),
-            TRACE_EVENT_FLAG_FLOW_IN,
-            "src_file", task.posted_from.file_name(),
-            "src_func", task.posted_from.function_name());
-        TRACE_HEAP_PROFILER_API_SCOPED_TASK_EXECUTION task_event(
-            task.posted_from.file_name());
+            TRACE_EVENT_FLAG_FLOW_IN);
         int new_thread_id = WillRunWorkerTask(task);
         {
           AutoUnlock unlock(lock_);
@@ -1109,8 +1091,7 @@ void SequencedWorkerPool::Inner::ThreadLoop(Worker* this_worker) {
 }
 
 void SequencedWorkerPool::Inner::HandleCleanup() {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
 
   lock_.AssertAcquired();
   if (cleanup_state_ == CLEANUP_DONE)
@@ -1177,8 +1158,7 @@ SequencedWorkerPool::Inner::GetWorkStatus SequencedWorkerPool::Inner::GetWork(
     SequencedTask* task,
     TimeDelta* wait_time,
     std::vector<Closure>* delete_these_outside_lock) {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
 
   lock_.AssertAcquired();
 
@@ -1266,8 +1246,7 @@ SequencedWorkerPool::Inner::GetWorkStatus SequencedWorkerPool::Inner::GetWork(
 }
 
 int SequencedWorkerPool::Inner::WillRunWorkerTask(const SequencedTask& task) {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
 
   lock_.AssertAcquired();
 
@@ -1300,8 +1279,7 @@ int SequencedWorkerPool::Inner::WillRunWorkerTask(const SequencedTask& task) {
 }
 
 void SequencedWorkerPool::Inner::DidRunWorkerTask(const SequencedTask& task) {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
 
   lock_.AssertAcquired();
 
@@ -1316,8 +1294,7 @@ void SequencedWorkerPool::Inner::DidRunWorkerTask(const SequencedTask& task) {
 
 bool SequencedWorkerPool::Inner::IsSequenceTokenRunnable(
     int sequence_token_id) const {
-  DCHECK_NE(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_NE(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER, g_all_pools_state);
 
   lock_.AssertAcquired();
   return !sequence_token_id ||
@@ -1326,8 +1303,7 @@ bool SequencedWorkerPool::Inner::IsSequenceTokenRunnable(
 }
 
 int SequencedWorkerPool::Inner::PrepareToStartAdditionalThreadIfHelpful() {
-  DCHECK_NE(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_NE(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER, g_all_pools_state);
 
   lock_.AssertAcquired();
   // How thread creation works:
@@ -1379,27 +1355,18 @@ int SequencedWorkerPool::Inner::PrepareToStartAdditionalThreadIfHelpful() {
 
 void SequencedWorkerPool::Inner::FinishStartingAdditionalThread(
     int thread_number) {
-  DCHECK_NE(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
 
   // Called outside of the lock.
   DCHECK_GT(thread_number, 0);
 
-  if (subtle::NoBarrier_Load(&g_all_pools_state) !=
-      AllPoolsState::WORKER_CREATED) {
-    DCHECK_EQ(AllPoolsState::NONE_ACTIVE,
-              subtle::NoBarrier_Load(&g_all_pools_state));
-    subtle::NoBarrier_Store(&g_all_pools_state, AllPoolsState::WORKER_CREATED);
-  }
-
   // The worker is assigned to the list when the thread actually starts, which
   // will manage the memory of the pointer.
   new Worker(worker_pool_, thread_number, thread_name_prefix_);
 }
 
 void SequencedWorkerPool::Inner::SignalHasWork() {
-  DCHECK_NE(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_NE(AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER, g_all_pools_state);
 
   has_work_cv_.Signal();
   if (testing_observer_) {
@@ -1408,8 +1375,7 @@ void SequencedWorkerPool::Inner::SignalHasWork() {
 }
 
 bool SequencedWorkerPool::Inner::CanShutdown() const {
-  DCHECK_EQ(AllPoolsState::WORKER_CREATED,
-            subtle::NoBarrier_Load(&g_all_pools_state));
+  DCHECK_EQ(AllPoolsState::USE_WORKER_POOL, g_all_pools_state);
   lock_.AssertAcquired();
   // See PrepareToStartAdditionalThreadIfHelpful for how thread creation works.
   return !thread_being_created_ &&
@@ -1447,23 +1413,38 @@ SequencedWorkerPool::GetWorkerPoolForCurrentThread() {
 }
 
 // static
-void SequencedWorkerPool::
-    RedirectSequencedWorkerPoolsToTaskSchedulerForProcess() {
+void SequencedWorkerPool::EnableForProcess() {
+  // TODO(fdoray): Uncomment this line. It is initially commented to avoid a
+  // revert of the CL that adds debug::DumpWithoutCrashing() in case of
+  // waterfall failures.
+  // DCHECK_EQ(AllPoolsState::POST_TASK_DISABLED, g_all_pools_state);
+  g_all_pools_state = AllPoolsState::USE_WORKER_POOL;
+}
+
+// static
+void SequencedWorkerPool::EnableWithRedirectionToTaskSchedulerForProcess() {
+  // TODO(fdoray): Uncomment this line. It is initially commented to avoid a
+  // revert of the CL that adds debug::DumpWithoutCrashing() in case of
+  // waterfall failures.
+  // DCHECK_EQ(AllPoolsState::POST_TASK_DISABLED, g_all_pools_state);
   DCHECK(TaskScheduler::GetInstance());
-  // Hitting this DCHECK indicates that a task was posted to a
-  // SequencedWorkerPool before the TaskScheduler was initialized and
-  // redirected, posting task to SequencedWorkerPools needs to at least be
-  // delayed until after that point.
-  DCHECK_EQ(AllPoolsState::NONE_ACTIVE,
-            subtle::NoBarrier_Load(&g_all_pools_state));
-  subtle::NoBarrier_Store(&g_all_pools_state,
-                          AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER);
+  g_all_pools_state = AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER;
+}
+
+// static
+void SequencedWorkerPool::DisableForProcessForTesting() {
+  g_all_pools_state = AllPoolsState::POST_TASK_DISABLED;
+}
+
+// static
+bool SequencedWorkerPool::IsEnabled() {
+  return g_all_pools_state != AllPoolsState::POST_TASK_DISABLED;
 }
 
 SequencedWorkerPool::SequencedWorkerPool(size_t max_threads,
                                          const std::string& thread_name_prefix,
                                          base::TaskPriority task_priority)
-    : constructor_task_runner_(ThreadTaskRunnerHandle::Get()),
+    : constructor_task_runner_(SequencedTaskRunnerHandle::Get()),
       inner_(new Inner(this,
                        max_threads,
                        thread_name_prefix,
@@ -1474,7 +1455,7 @@ SequencedWorkerPool::SequencedWorkerPool(size_t max_threads,
                                          const std::string& thread_name_prefix,
                                          base::TaskPriority task_priority,
                                          TestingObserver* observer)
-    : constructor_task_runner_(ThreadTaskRunnerHandle::Get()),
+    : constructor_task_runner_(SequencedTaskRunnerHandle::Get()),
       inner_(new Inner(this,
                        max_threads,
                        thread_name_prefix,
@@ -1510,7 +1491,7 @@ scoped_refptr<SequencedTaskRunner> SequencedWorkerPool::GetSequencedTaskRunner(
 scoped_refptr<SequencedTaskRunner>
 SequencedWorkerPool::GetSequencedTaskRunnerWithShutdownBehavior(
     SequenceToken token, WorkerShutdown shutdown_behavior) {
-  return new SequencedWorkerPoolSequencedTaskRunner(
+  return new PoolSequencedTaskRunner(
       this, token, shutdown_behavior);
 }
 
@@ -1593,13 +1574,15 @@ bool SequencedWorkerPool::RunsTasksOnCurrentThread() const {
   return inner_->RunsTasksOnCurrentThread();
 }
 
-bool SequencedWorkerPool::IsRunningSequenceOnCurrentThread(
-    SequenceToken sequence_token) const {
-  return inner_->IsRunningSequenceOnCurrentThread(sequence_token);
-}
-
 void SequencedWorkerPool::FlushForTesting() {
-  inner_->CleanupForTesting();
+  DCHECK(!RunsTasksOnCurrentThread());
+  base::ThreadRestrictions::ScopedAllowWait allow_wait;
+  if (g_all_pools_state == AllPoolsState::REDIRECTED_TO_TASK_SCHEDULER) {
+    // TODO(gab): Remove this if http://crbug.com/622400 fails.
+    TaskScheduler::GetInstance()->FlushForTesting();
+  } else {
+    inner_->CleanupForTesting();
+  }
 }
 
 void SequencedWorkerPool::SignalHasWorkForTesting() {
@@ -1607,7 +1590,7 @@ void SequencedWorkerPool::SignalHasWorkForTesting() {
 }
 
 void SequencedWorkerPool::Shutdown(int max_new_blocking_tasks_after_shutdown) {
-  DCHECK(constructor_task_runner_->BelongsToCurrentThread());
+  DCHECK(constructor_task_runner_->RunsTasksOnCurrentThread());
   inner_->Shutdown(max_new_blocking_tasks_after_shutdown);
 }
 
@@ -1615,4 +1598,9 @@ bool SequencedWorkerPool::IsShutdownInProgress() {
   return inner_->IsShutdownInProgress();
 }
 
+bool SequencedWorkerPool::IsRunningSequenceOnCurrentThread(
+    SequenceToken sequence_token) const {
+  return inner_->IsRunningSequenceOnCurrentThread(sequence_token);
+}
+
 }  // namespace base
diff --git a/src/base/threading/sequenced_worker_pool.h b/src/base/threading/sequenced_worker_pool.h
index 0e916c8..f1070d5 100644
--- a/src/base/threading/sequenced_worker_pool.h
+++ b/src/base/threading/sequenced_worker_pool.h
@@ -13,9 +13,9 @@
 
 #include "base/base_export.h"
 #include "base/callback_forward.h"
+#include "base/compiler_specific.h"
 #include "base/macros.h"
 #include "base/memory/ref_counted.h"
-#include "base/single_thread_task_runner.h"
 #include "base/task_runner.h"
 #include "base/task_scheduler/task_traits.h"
 
@@ -25,12 +25,10 @@ class Location;
 
 namespace base {
 
-class SingleThreadTaskRunner;
+class SequencedTaskRunner;
 
 template <class T> class DeleteHelper;
 
-class SequencedTaskRunner;
-
 // A worker thread pool that enforces ordering between sets of tasks. It also
 // allows you to specify what should happen to your tasks on shutdown.
 //
@@ -61,6 +59,10 @@ class SequencedTaskRunner;
 // These will be executed in an unspecified order. The order of execution
 // between tasks with different sequence tokens is also unspecified.
 //
+// You must call EnableForProcess() or
+// EnableWithRedirectionToTaskSchedulerForProcess() before starting to post
+// tasks to a process' SequencedWorkerPools.
+//
 // This class may be leaked on shutdown to facilitate fast shutdown. The
 // expected usage, however, is to call Shutdown(), which correctly accounts
 // for CONTINUE_ON_SHUTDOWN behavior and is required for BLOCK_SHUTDOWN
@@ -166,32 +168,52 @@ class BASE_EXPORT SequencedWorkerPool : public TaskRunner {
 
   // Returns the SequencedWorkerPool that owns this thread, or null if the
   // current thread is not a SequencedWorkerPool worker thread.
+  //
+  // Always returns nullptr when SequencedWorkerPool is redirected to
+  // TaskScheduler.
+  //
+  // DEPRECATED. Use SequencedTaskRunnerHandle::Get() instead. Consequentially
+  // the only remaining use case is in sequenced_task_runner_handle.cc to
+  // implement that and will soon be removed along with SequencedWorkerPool:
+  // http://crbug.com/622400.
   static scoped_refptr<SequencedWorkerPool> GetWorkerPoolForCurrentThread();
 
   // Returns a unique token that can be used to sequence tasks posted to
   // PostSequencedWorkerTask(). Valid tokens are always nonzero.
   static SequenceToken GetSequenceToken();
 
-  // Invoke this once on the main thread of a process, before any other threads
-  // are created and before any tasks are posted to that process'
-  // SequencedWorkerPools but after TaskScheduler was instantiated, to force all
-  // SequencedWorkerPools in that process to redirect their tasks to the
-  // TaskScheduler. Note: SequencedWorkerPool instances with |max_threads == 1|
-  // will be special cased to send all of their work as
-  // ExecutionMode::SINGLE_THREADED.
+  // Enables posting tasks to this process' SequencedWorkerPools. Cannot be
+  // called if already enabled. This is not thread-safe; proper synchronization
+  // is required to use any SequencedWorkerPool method after calling this.
+  static void EnableForProcess();
+
+  // Same as EnableForProcess(), but tasks are redirected to the registered
+  // TaskScheduler. There must be a registered TaskScheduler when this is
+  // called.
   // TODO(gab): Remove this if http://crbug.com/622400 fails
   // (SequencedWorkerPool will be phased out completely otherwise).
-  static void RedirectSequencedWorkerPoolsToTaskSchedulerForProcess();
+  static void EnableWithRedirectionToTaskSchedulerForProcess();
+
+  // Disables posting tasks to this process' SequencedWorkerPools. Calling this
+  // while there are active SequencedWorkerPools is not supported. This is not
+  // thread-safe; proper synchronization is required to use any
+  // SequencedWorkerPool method after calling this.
+  static void DisableForProcessForTesting();
+
+  // Returns true if posting tasks to this process' SequencedWorkerPool is
+  // enabled (with or without redirection to TaskScheduler).
+  static bool IsEnabled();
 
   // When constructing a SequencedWorkerPool, there must be a
   // ThreadTaskRunnerHandle on the current thread unless you plan to
   // deliberately leak it.
 
-  // Pass the maximum number of threads (they will be lazily created as needed)
-  // and a prefix for the thread name to aid in debugging. |task_priority| will
-  // be used to hint base::TaskScheduler for an experiment in which all
-  // SequencedWorkerPool tasks will be redirected to it in processes where a
-  // base::TaskScheduler was instantiated.
+  // Constructs a SequencedWorkerPool which will lazily create up to
+  // |max_threads| and a prefix for the thread name to aid in debugging.
+  // |max_threads| must be greater than 1. |task_priority| will be used to hint
+  // base::TaskScheduler for an experiment in which all SequencedWorkerPool
+  // tasks will be redirected to it in processes where a base::TaskScheduler was
+  // instantiated.
   SequencedWorkerPool(size_t max_threads,
                       const std::string& thread_name_prefix,
                       base::TaskPriority task_priority);
@@ -214,7 +236,7 @@ class BASE_EXPORT SequencedWorkerPool : public TaskRunner {
   // delay are posted with SKIP_ON_SHUTDOWN behavior and tasks with zero delay
   // are posted with BLOCK_SHUTDOWN behavior.
   scoped_refptr<SequencedTaskRunner> GetSequencedTaskRunner(
-      SequenceToken token);
+      SequenceToken token) WARN_UNUSED_RESULT;
 
   // Returns a SequencedTaskRunner wrapper which posts to this
   // SequencedWorkerPool using the given sequence token. Tasks with nonzero
@@ -222,14 +244,14 @@ class BASE_EXPORT SequencedWorkerPool : public TaskRunner {
   // are posted with the given shutdown behavior.
   scoped_refptr<SequencedTaskRunner> GetSequencedTaskRunnerWithShutdownBehavior(
       SequenceToken token,
-      WorkerShutdown shutdown_behavior);
+      WorkerShutdown shutdown_behavior) WARN_UNUSED_RESULT;
 
   // Returns a TaskRunner wrapper which posts to this SequencedWorkerPool using
   // the given shutdown behavior. Tasks with nonzero delay are posted with
   // SKIP_ON_SHUTDOWN behavior and tasks with zero delay are posted with the
   // given shutdown behavior.
   scoped_refptr<TaskRunner> GetTaskRunnerWithShutdownBehavior(
-      WorkerShutdown shutdown_behavior);
+      WorkerShutdown shutdown_behavior) WARN_UNUSED_RESULT;
 
   // Posts the given task for execution in the worker pool. Tasks posted with
   // this function will execute in an unspecified order on a background thread.
@@ -323,19 +345,21 @@ class BASE_EXPORT SequencedWorkerPool : public TaskRunner {
                        TimeDelta delay) override;
   bool RunsTasksOnCurrentThread() const override;
 
-  // Returns true if the current thread is processing a task with the given
-  // sequence_token.
-  bool IsRunningSequenceOnCurrentThread(SequenceToken sequence_token) const;
-
   // Blocks until all pending tasks are complete. This should only be called in
   // unit tests when you want to validate something that should have happened.
-  // This will not flush delayed tasks; delayed tasks get deleted.
+  // Does not wait for delayed tasks. If redirection to TaskScheduler is
+  // disabled, delayed tasks are deleted. If redirection to TaskScheduler is
+  // enabled, this will wait for all tasks posted to TaskScheduler (not just
+  // tasks posted to this SequencedWorkerPool).
   //
   // Note that calling this will not prevent other threads from posting work to
   // the queue while the calling thread is waiting on Flush(). In this case,
   // Flush will return only when there's no more work in the queue. Normally,
   // this doesn't come up since in a test, all the work is being posted from
   // the main thread.
+  //
+  // TODO(gab): Remove mentions of TaskScheduler in this comment if
+  // http://crbug.com/622400 fails.
   void FlushForTesting();
 
   // Spuriously signal that there is work to be done.
@@ -371,9 +395,14 @@ class BASE_EXPORT SequencedWorkerPool : public TaskRunner {
   friend class DeleteHelper<SequencedWorkerPool>;
 
   class Inner;
+  class PoolSequencedTaskRunner;
   class Worker;
 
-  const scoped_refptr<SingleThreadTaskRunner> constructor_task_runner_;
+  // Returns true if the current thread is processing a task with the given
+  // sequence_token.
+  bool IsRunningSequenceOnCurrentThread(SequenceToken sequence_token) const;
+
+  const scoped_refptr<SequencedTaskRunner> constructor_task_runner_;
 
   // Avoid pulling in too many headers by putting (almost) everything
   // into |inner_|.
diff --git a/src/base/threading/thread.cc b/src/base/threading/thread.cc
index 6181ba6..ec2f98d 100644
--- a/src/base/threading/thread.cc
+++ b/src/base/threading/thread.cc
@@ -17,6 +17,10 @@
 #include "base/threading/thread_restrictions.h"
 #include "build/build_config.h"
 
+#if defined(OS_POSIX) && !defined(OS_NACL)
+#include "base/files/file_descriptor_watcher_posix.h"
+#endif
+
 #if defined(OS_WIN)
 #include "base/win/scoped_com_initializer.h"
 #endif
@@ -144,6 +148,18 @@ bool Thread::WaitUntilThreadStarted() const {
   return true;
 }
 
+void Thread::FlushForTesting() {
+  DCHECK(owning_sequence_checker_.CalledOnValidSequence());
+  if (!message_loop_)
+    return;
+
+  WaitableEvent done(WaitableEvent::ResetPolicy::AUTOMATIC,
+                     WaitableEvent::InitialState::NOT_SIGNALED);
+  task_runner()->PostTask(FROM_HERE,
+                          Bind(&WaitableEvent::Signal, Unretained(&done)));
+  done.Wait();
+}
+
 void Thread::Stop() {
   DCHECK(joinable_);
 
@@ -245,12 +261,7 @@ bool Thread::GetThreadWasQuitProperly() {
 
 void Thread::SetMessageLoop(MessageLoop* message_loop) {
   DCHECK(owning_sequence_checker_.CalledOnValidSequence());
-
-  // TODO(gab): Figure out why some callers pass in a null |message_loop|...
-  // https://crbug.com/629139#c15
-  // DCHECK(message_loop);
-  if (!message_loop)
-    return;
+  DCHECK(message_loop);
 
   // Setting |message_loop_| should suffice for this thread to be considered
   // as "running", until Stop() is invoked.
@@ -283,6 +294,16 @@ void Thread::ThreadMain() {
   message_loop_->BindToCurrentThread();
   message_loop_->SetTimerSlack(message_loop_timer_slack_);
 
+#if defined(OS_POSIX) && !defined(OS_NACL)
+  // Allow threads running a MessageLoopForIO to use FileDescriptorWatcher API.
+  std::unique_ptr<FileDescriptorWatcher> file_descriptor_watcher;
+  if (MessageLoopForIO::IsCurrent()) {
+    DCHECK_EQ(message_loop_, MessageLoopForIO::current());
+    file_descriptor_watcher.reset(
+        new FileDescriptorWatcher(MessageLoopForIO::current()));
+  }
+#endif
+
 #if defined(OS_WIN)
   std::unique_ptr<win::ScopedCOMInitializer> com_initializer;
   if (com_status_ != NONE) {
diff --git a/src/base/threading/thread.h b/src/base/threading/thread.h
index 5bb53f7..f103e3d 100644
--- a/src/base/threading/thread.h
+++ b/src/base/threading/thread.h
@@ -140,6 +140,9 @@ class BASE_EXPORT Thread : PlatformThread::Delegate {
   // carefully for production code.
   bool WaitUntilThreadStarted() const;
 
+  // Blocks until all tasks previously posted to this thread have been executed.
+  void FlushForTesting();
+
   // Signals the thread to exit and returns once the thread has exited. The
   // Thread object is completely reset and may be used as if it were newly
   // constructed (i.e., Start may be called again). Can only be called if
@@ -241,6 +244,10 @@ class BASE_EXPORT Thread : PlatformThread::Delegate {
   // Bind this Thread to an existing MessageLoop instead of starting a new one.
   void SetMessageLoop(MessageLoop* message_loop);
 
+  bool using_external_message_loop() const {
+    return using_external_message_loop_;
+  }
+
  private:
 #if defined(OS_WIN)
   enum ComStatus {
@@ -290,7 +297,9 @@ class BASE_EXPORT Thread : PlatformThread::Delegate {
 
   // True only if |message_loop_| was externally provided by |SetMessageLoop()|
   // in which case this Thread has no underlying |thread_| and should merely
-  // drop |message_loop_| on Stop().
+  // drop |message_loop_| on Stop(). In that event, this remains true after
+  // Stop() was invoked so that subclasses can use this state to build their own
+  // cleanup logic as required.
   bool using_external_message_loop_ = false;
 
   // Stores Options::timer_slack_ until the message loop has been bound to
diff --git a/src/base/threading/thread_local.h b/src/base/threading/thread_local.h
index f40420c..cad9add 100644
--- a/src/base/threading/thread_local.h
+++ b/src/base/threading/thread_local.h
@@ -2,35 +2,34 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-// WARNING: Thread local storage is a bit tricky to get right.  Please make
-// sure that this is really the proper solution for what you're trying to
-// achieve.  Don't prematurely optimize, most likely you can just use a Lock.
+// WARNING: Thread local storage is a bit tricky to get right. Please make sure
+// that this is really the proper solution for what you're trying to achieve.
+// Don't prematurely optimize, most likely you can just use a Lock.
 //
-// These classes implement a wrapper around the platform's TLS storage
-// mechanism.  On construction, they will allocate a TLS slot, and free the
-// TLS slot on destruction.  No memory management (creation or destruction) is
-// handled.  This means for uses of ThreadLocalPointer, you must correctly
-// manage the memory yourself, these classes will not destroy the pointer for
-// you.  There are no at-thread-exit actions taken by these classes.
+// These classes implement a wrapper around ThreadLocalStorage::Slot. On
+// construction, they will allocate a TLS slot, and free the TLS slot on
+// destruction. No memory management (creation or destruction) is handled. This
+// means for uses of ThreadLocalPointer, you must correctly manage the memory
+// yourself, these classes will not destroy the pointer for you. There are no
+// at-thread-exit actions taken by these classes.
 //
-// ThreadLocalPointer<Type> wraps a Type*.  It performs no creation or
-// destruction, so memory management must be handled elsewhere.  The first call
-// to Get() on a thread will return NULL.  You can update the pointer with a
-// call to Set().
+// ThreadLocalPointer<Type> wraps a Type*. It performs no creation or
+// destruction, so memory management must be handled elsewhere. The first call
+// to Get() on a thread will return NULL. You can update the pointer with a call
+// to Set().
 //
-// ThreadLocalBoolean wraps a bool.  It will default to false if it has never
+// ThreadLocalBoolean wraps a bool. It will default to false if it has never
 // been set otherwise with Set().
 //
-// Thread Safety:  An instance of ThreadLocalStorage is completely thread safe
-// once it has been created.  If you want to dynamically create an instance,
-// you must of course properly deal with safety and race conditions.  This
-// means a function-level static initializer is generally inappropiate.
+// Thread Safety: An instance of ThreadLocalStorage is completely thread safe
+// once it has been created. If you want to dynamically create an instance, you
+// must of course properly deal with safety and race conditions. This means a
+// function-level static initializer is generally inappropiate.
 //
-// In Android, the system TLS is limited, the implementation is backed with
-// ThreadLocalStorage.
+// In Android, the system TLS is limited.
 //
 // Example usage:
-//   // My class is logically attached to a single thread.  We cache a pointer
+//   // My class is logically attached to a single thread. We cache a pointer
 //   // on the thread it was created on, so we can implement current().
 //   MyClass::MyClass() {
 //     DCHECK(Singleton<ThreadLocalPointer<MyClass> >::get()->Get() == NULL);
@@ -51,76 +50,42 @@
 #ifndef BASE_THREADING_THREAD_LOCAL_H_
 #define BASE_THREADING_THREAD_LOCAL_H_
 
-#include "base/base_export.h"
 #include "base/macros.h"
 #include "base/threading/thread_local_storage.h"
-#include "build/build_config.h"
-
-#if defined(OS_POSIX)
-#include <pthread.h>
-#endif
 
 namespace base {
-namespace internal {
-
-// Helper functions that abstract the cross-platform APIs.  Do not use directly.
-struct BASE_EXPORT ThreadLocalPlatform {
-#if defined(OS_WIN)
-  typedef unsigned long SlotType;
-#elif defined(OS_ANDROID)
-  typedef ThreadLocalStorage::StaticSlot SlotType;
-#elif defined(OS_POSIX)
-  typedef pthread_key_t SlotType;
-#endif
-
-  static void AllocateSlot(SlotType* slot);
-  static void FreeSlot(SlotType slot);
-  static void* GetValueFromSlot(SlotType slot);
-  static void SetValueInSlot(SlotType slot, void* value);
-};
-
-}  // namespace internal
 
 template <typename Type>
 class ThreadLocalPointer {
  public:
-  ThreadLocalPointer() : slot_() {
-    internal::ThreadLocalPlatform::AllocateSlot(&slot_);
-  }
-
-  ~ThreadLocalPointer() {
-    internal::ThreadLocalPlatform::FreeSlot(slot_);
-  }
+  ThreadLocalPointer() = default;
+  ~ThreadLocalPointer() = default;
 
   Type* Get() {
-    return static_cast<Type*>(
-        internal::ThreadLocalPlatform::GetValueFromSlot(slot_));
+    return static_cast<Type*>(slot_.Get());
   }
 
   void Set(Type* ptr) {
-    internal::ThreadLocalPlatform::SetValueInSlot(
-        slot_, const_cast<void*>(static_cast<const void*>(ptr)));
+    slot_.Set(const_cast<void*>(static_cast<const void*>(ptr)));
   }
 
  private:
-  typedef internal::ThreadLocalPlatform::SlotType SlotType;
-
-  SlotType slot_;
+  ThreadLocalStorage::Slot slot_;
 
   DISALLOW_COPY_AND_ASSIGN(ThreadLocalPointer<Type>);
 };
 
 class ThreadLocalBoolean {
  public:
-  ThreadLocalBoolean() {}
-  ~ThreadLocalBoolean() {}
+  ThreadLocalBoolean() = default;
+  ~ThreadLocalBoolean() = default;
 
   bool Get() {
-    return tlp_.Get() != NULL;
+    return tlp_.Get() != nullptr;
   }
 
   void Set(bool val) {
-    tlp_.Set(val ? this : NULL);
+    tlp_.Set(val ? this : nullptr);
   }
 
  private:
diff --git a/src/base/threading/thread_local_android.cc b/src/base/threading/thread_local_android.cc
deleted file mode 100644
index 813dd78..0000000
--- a/src/base/threading/thread_local_android.cc
+++ /dev/null
@@ -1,31 +0,0 @@
-// Copyright 2014 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "base/threading/thread_local.h"
-
-namespace base {
-namespace internal {
-
-// static
-void ThreadLocalPlatform::AllocateSlot(SlotType* slot) {
-  slot->Initialize(nullptr);
-}
-
-// static
-void ThreadLocalPlatform::FreeSlot(SlotType slot) {
-  slot.Free();
-}
-
-// static
-void* ThreadLocalPlatform::GetValueFromSlot(SlotType slot) {
-  return slot.Get();
-}
-
-// static
-void ThreadLocalPlatform::SetValueInSlot(SlotType slot, void* value) {
-  slot.Set(value);
-}
-
-}  // namespace internal
-}  // namespace base
diff --git a/src/base/threading/thread_local_posix.cc b/src/base/threading/thread_local_posix.cc
deleted file mode 100644
index 8bc46ad..0000000
--- a/src/base/threading/thread_local_posix.cc
+++ /dev/null
@@ -1,43 +0,0 @@
-// Copyright (c) 2011 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "base/threading/thread_local.h"
-
-#include <pthread.h>
-
-#include "base/logging.h"
-#include "build/build_config.h"
-
-#if !defined(OS_ANDROID)
-
-namespace base {
-namespace internal {
-
-// static
-void ThreadLocalPlatform::AllocateSlot(SlotType* slot) {
-  int error = pthread_key_create(slot, NULL);
-  CHECK_EQ(error, 0);
-}
-
-// static
-void ThreadLocalPlatform::FreeSlot(SlotType slot) {
-  int error = pthread_key_delete(slot);
-  DCHECK_EQ(0, error);
-}
-
-// static
-void* ThreadLocalPlatform::GetValueFromSlot(SlotType slot) {
-  return pthread_getspecific(slot);
-}
-
-// static
-void ThreadLocalPlatform::SetValueInSlot(SlotType slot, void* value) {
-  int error = pthread_setspecific(slot, value);
-  DCHECK_EQ(error, 0);
-}
-
-}  // namespace internal
-}  // namespace base
-
-#endif  // !defined(OS_ANDROID)
diff --git a/src/base/threading/thread_local_storage.cc b/src/base/threading/thread_local_storage.cc
index 0ef31f7..15a1d5e 100644
--- a/src/base/threading/thread_local_storage.cc
+++ b/src/base/threading/thread_local_storage.cc
@@ -5,11 +5,59 @@
 #include "base/threading/thread_local_storage.h"
 
 #include "base/atomicops.h"
+#include "base/lazy_instance.h"
 #include "base/logging.h"
+#include "base/synchronization/lock.h"
 #include "build/build_config.h"
 
 using base::internal::PlatformThreadLocalStorage;
 
+// Chrome Thread Local Storage (TLS)
+//
+// This TLS system allows Chrome to use a single OS level TLS slot process-wide,
+// and allows us to control the slot limits instead of being at the mercy of the
+// platform. To do this, Chrome TLS replicates an array commonly found in the OS
+// thread metadata.
+//
+// Overview:
+//
+// OS TLS Slots       Per-Thread                 Per-Process Global
+//     ...
+//     []             Chrome TLS Array           Chrome TLS Metadata
+//     [] ----------> [][][][][ ][][][][]        [][][][][ ][][][][]
+//     []                      |                          |
+//     ...                     V                          V
+//                      Metadata Version           Slot Information
+//                         Your Data!
+//
+// Using a single OS TLS slot, Chrome TLS allocates an array on demand for the
+// lifetime of each thread that requests Chrome TLS data. Each per-thread TLS
+// array matches the length of the per-process global metadata array.
+//
+// A per-process global TLS metadata array tracks information about each item in
+// the per-thread array:
+//   * Status: Tracks if the slot is allocated or free to assign.
+//   * Destructor: An optional destructor to call on thread destruction for that
+//                 specific slot.
+//   * Version: Tracks the current version of the TLS slot. Each TLS slot
+//              allocation is associated with a unique version number.
+//
+//              Most OS TLS APIs guarantee that a newly allocated TLS slot is
+//              initialized to 0 for all threads. The Chrome TLS system provides
+//              this guarantee by tracking the version for each TLS slot here
+//              on each per-thread Chrome TLS array entry. Threads that access
+//              a slot with a mismatched version will receive 0 as their value.
+//              The metadata version is incremented when the client frees a
+//              slot. The per-thread metadata version is updated when a client
+//              writes to the slot. This scheme allows for constant time
+//              invalidation and avoids the need to iterate through each Chrome
+//              TLS array to mark the slot as zero.
+//
+// Just like an OS TLS API, clients of the Chrome TLS are responsible for
+// managing any necessary lifetime of the data in their slots. The only
+// convenience provided is automatic destruction when a thread ends. If a client
+// frees a slot, that client is responsible for destroying the data in the slot.
+
 namespace {
 // In order to make TLS destructors work, we need to keep around a function
 // pointer to the destructor for each slot. We keep this array of pointers in a
@@ -18,37 +66,39 @@ namespace {
 // hold a pointer to a per-thread array (table) of slots that we allocate to
 // Chromium consumers.
 
-// g_native_tls_key is the one native TLS that we use.  It stores our table.
+// g_native_tls_key is the one native TLS that we use. It stores our table.
 base::subtle::Atomic32 g_native_tls_key =
     PlatformThreadLocalStorage::TLS_KEY_OUT_OF_INDEXES;
 
-// g_last_used_tls_key is the high-water-mark of allocated thread local storage.
-// Each allocation is an index into our g_tls_destructors[].  Each such index is
-// assigned to the instance variable slot_ in a ThreadLocalStorage::Slot
-// instance.  We reserve the value slot_ == 0 to indicate that the corresponding
-// instance of ThreadLocalStorage::Slot has been freed (i.e., destructor called,
-// etc.).  This reserved use of 0 is then stated as the initial value of
-// g_last_used_tls_key, so that the first issued index will be 1.
-base::subtle::Atomic32 g_last_used_tls_key = 0;
+// The maximum number of slots in our thread local storage stack.
+constexpr int kThreadLocalStorageSize = 256;
+constexpr int kInvalidSlotValue = -1;
+
+enum TlsStatus {
+  FREE,
+  IN_USE,
+};
+
+struct TlsMetadata {
+  TlsStatus status;
+  base::ThreadLocalStorage::TLSDestructorFunc destructor;
+  uint32_t version;
+};
 
-// The maximum number of 'slots' in our thread local storage stack.
-const int kThreadLocalStorageSize = 256;
+struct TlsVectorEntry {
+  void* data;
+  uint32_t version;
+};
+
+// This LazyInstance isn't needed until after we've constructed the per-thread
+// TLS vector, so it's safe to use.
+base::LazyInstance<base::Lock>::Leaky g_tls_metadata_lock;
+TlsMetadata g_tls_metadata[kThreadLocalStorageSize];
+size_t g_last_assigned_slot = 0;
 
 // The maximum number of times to try to clear slots by calling destructors.
 // Use pthread naming convention for clarity.
-const int kMaxDestructorIterations = kThreadLocalStorageSize;
-
-// An array of destructor function pointers for the slots.  If a slot has a
-// destructor, it will be stored in its corresponding entry in this array.
-// The elements are volatile to ensure that when the compiler reads the value
-// to potentially call the destructor, it does so once, and that value is tested
-// for null-ness and then used. Yes, that would be a weird de-optimization,
-// but I can imagine some register machines where it was just as easy to
-// re-fetch an array element, and I want to be sure a call to free the key
-// (i.e., null out the destructor entry) that happens on a separate thread can't
-// hurt the racy calls to the destructors on another thread.
-volatile base::ThreadLocalStorage::TLSDestructorFunc
-    g_tls_destructors[kThreadLocalStorageSize];
+constexpr int kMaxDestructorIterations = kThreadLocalStorageSize;
 
 // This function is called to initialize our entire Chromium TLS system.
 // It may be called very early, and we need to complete most all of the setup
@@ -56,7 +106,7 @@ volatile base::ThreadLocalStorage::TLSDestructorFunc
 // recursively depend on this initialization.
 // As a result, we use Atomics, and avoid anything (like a singleton) that might
 // require memory allocations.
-void** ConstructTlsVector() {
+TlsVectorEntry* ConstructTlsVector() {
   PlatformThreadLocalStorage::TLSKey key =
       base::subtle::NoBarrier_Load(&g_native_tls_key);
   if (key == PlatformThreadLocalStorage::TLS_KEY_OUT_OF_INDEXES) {
@@ -73,8 +123,8 @@ void** ConstructTlsVector() {
             key != PlatformThreadLocalStorage::TLS_KEY_OUT_OF_INDEXES);
       PlatformThreadLocalStorage::FreeTLS(tmp);
     }
-    // Atomically test-and-set the tls_key.  If the key is
-    // TLS_KEY_OUT_OF_INDEXES, go ahead and set it.  Otherwise, do nothing, as
+    // Atomically test-and-set the tls_key. If the key is
+    // TLS_KEY_OUT_OF_INDEXES, go ahead and set it. Otherwise, do nothing, as
     // another thread already did our dirty work.
     if (PlatformThreadLocalStorage::TLS_KEY_OUT_OF_INDEXES !=
         static_cast<PlatformThreadLocalStorage::TLSKey>(
@@ -90,39 +140,38 @@ void** ConstructTlsVector() {
   }
   CHECK(!PlatformThreadLocalStorage::GetTLSValue(key));
 
-  // Some allocators, such as TCMalloc, make use of thread local storage.
-  // As a result, any attempt to call new (or malloc) will lazily cause such a
-  // system to initialize, which will include registering for a TLS key.  If we
-  // are not careful here, then that request to create a key will call new back,
-  // and we'll have an infinite loop.  We avoid that as follows:
-  // Use a stack allocated vector, so that we don't have dependence on our
-  // allocator until our service is in place.  (i.e., don't even call new until
-  // after we're setup)
-  void* stack_allocated_tls_data[kThreadLocalStorageSize];
+  // Some allocators, such as TCMalloc, make use of thread local storage. As a
+  // result, any attempt to call new (or malloc) will lazily cause such a system
+  // to initialize, which will include registering for a TLS key. If we are not
+  // careful here, then that request to create a key will call new back, and
+  // we'll have an infinite loop. We avoid that as follows: Use a stack
+  // allocated vector, so that we don't have dependence on our allocator until
+  // our service is in place. (i.e., don't even call new until after we're
+  // setup)
+  TlsVectorEntry stack_allocated_tls_data[kThreadLocalStorageSize];
   memset(stack_allocated_tls_data, 0, sizeof(stack_allocated_tls_data));
   // Ensure that any rentrant calls change the temp version.
   PlatformThreadLocalStorage::SetTLSValue(key, stack_allocated_tls_data);
 
   // Allocate an array to store our data.
-  void** tls_data = new void*[kThreadLocalStorageSize];
+  TlsVectorEntry* tls_data = new TlsVectorEntry[kThreadLocalStorageSize];
   memcpy(tls_data, stack_allocated_tls_data, sizeof(stack_allocated_tls_data));
   PlatformThreadLocalStorage::SetTLSValue(key, tls_data);
   return tls_data;
 }
 
-void OnThreadExitInternal(void* value) {
-  DCHECK(value);
-  void** tls_data = static_cast<void**>(value);
-  // Some allocators, such as TCMalloc, use TLS.  As a result, when a thread
+void OnThreadExitInternal(TlsVectorEntry* tls_data) {
+  DCHECK(tls_data);
+  // Some allocators, such as TCMalloc, use TLS. As a result, when a thread
   // terminates, one of the destructor calls we make may be to shut down an
-  // allocator.  We have to be careful that after we've shutdown all of the
-  // known destructors (perchance including an allocator), that we don't call
-  // the allocator and cause it to resurrect itself (with no possibly destructor
-  // call to follow).  We handle this problem as follows:
-  // Switch to using a stack allocated vector, so that we don't have dependence
-  // on our allocator after we have called all g_tls_destructors.  (i.e., don't
-  // even call delete[] after we're done with destructors.)
-  void* stack_allocated_tls_data[kThreadLocalStorageSize];
+  // allocator. We have to be careful that after we've shutdown all of the known
+  // destructors (perchance including an allocator), that we don't call the
+  // allocator and cause it to resurrect itself (with no possibly destructor
+  // call to follow). We handle this problem as follows: Switch to using a stack
+  // allocated vector, so that we don't have dependence on our allocator after
+  // we have called all g_tls_metadata destructors. (i.e., don't even call
+  // delete[] after we're done with destructors.)
+  TlsVectorEntry stack_allocated_tls_data[kThreadLocalStorageSize];
   memcpy(stack_allocated_tls_data, tls_data, sizeof(stack_allocated_tls_data));
   // Ensure that any re-entrant calls change the temp version.
   PlatformThreadLocalStorage::TLSKey key =
@@ -130,32 +179,38 @@ void OnThreadExitInternal(void* value) {
   PlatformThreadLocalStorage::SetTLSValue(key, stack_allocated_tls_data);
   delete[] tls_data;  // Our last dependence on an allocator.
 
+  // Snapshot the TLS Metadata so we don't have to lock on every access.
+  TlsMetadata tls_metadata[kThreadLocalStorageSize];
+  {
+    base::AutoLock auto_lock(g_tls_metadata_lock.Get());
+    memcpy(tls_metadata, g_tls_metadata, sizeof(g_tls_metadata));
+  }
+
   int remaining_attempts = kMaxDestructorIterations;
   bool need_to_scan_destructors = true;
   while (need_to_scan_destructors) {
     need_to_scan_destructors = false;
     // Try to destroy the first-created-slot (which is slot 1) in our last
-    // destructor call.  That user was able to function, and define a slot with
+    // destructor call. That user was able to function, and define a slot with
     // no other services running, so perhaps it is a basic service (like an
-    // allocator) and should also be destroyed last.  If we get the order wrong,
-    // then we'll itterate several more times, so it is really not that
-    // critical (but it might help).
-    base::subtle::Atomic32 last_used_tls_key =
-        base::subtle::NoBarrier_Load(&g_last_used_tls_key);
-    for (int slot = last_used_tls_key; slot > 0; --slot) {
-      void* tls_value = stack_allocated_tls_data[slot];
-      if (tls_value == NULL)
+    // allocator) and should also be destroyed last. If we get the order wrong,
+    // then we'll iterate several more times, so it is really not that critical
+    // (but it might help).
+    for (int slot = 0; slot < kThreadLocalStorageSize ; ++slot) {
+      void* tls_value = stack_allocated_tls_data[slot].data;
+      if (!tls_value || tls_metadata[slot].status == TlsStatus::FREE ||
+          stack_allocated_tls_data[slot].version != tls_metadata[slot].version)
         continue;
 
       base::ThreadLocalStorage::TLSDestructorFunc destructor =
-          g_tls_destructors[slot];
-      if (destructor == NULL)
+          tls_metadata[slot].destructor;
+      if (!destructor)
         continue;
-      stack_allocated_tls_data[slot] = NULL;  // pre-clear the slot.
+      stack_allocated_tls_data[slot].data = nullptr;  // pre-clear the slot.
       destructor(tls_value);
-      // Any destructor might have called a different service, which then set
-      // a different slot to a non-NULL value.  Hence we need to check
-      // the whole vector again.  This is a pthread standard.
+      // Any destructor might have called a different service, which then set a
+      // different slot to a non-null value. Hence we need to check the whole
+      // vector again. This is a pthread standard.
       need_to_scan_destructors = true;
     }
     if (--remaining_attempts <= 0) {
@@ -165,7 +220,7 @@ void OnThreadExitInternal(void* value) {
   }
 
   // Remove our stack allocated vector.
-  PlatformThreadLocalStorage::SetTLSValue(key, NULL);
+  PlatformThreadLocalStorage::SetTLSValue(key, nullptr);
 }
 
 }  // namespace
@@ -184,11 +239,11 @@ void PlatformThreadLocalStorage::OnThreadExit() {
   // Maybe we have never initialized TLS for this thread.
   if (!tls_data)
     return;
-  OnThreadExitInternal(tls_data);
+  OnThreadExitInternal(static_cast<TlsVectorEntry*>(tls_data));
 }
 #elif defined(OS_POSIX)
 void PlatformThreadLocalStorage::OnThreadExit(void* value) {
-  OnThreadExitInternal(value);
+  OnThreadExitInternal(static_cast<TlsVectorEntry*>(value));
 }
 #endif  // defined(OS_WIN)
 
@@ -198,49 +253,77 @@ void ThreadLocalStorage::StaticSlot::Initialize(TLSDestructorFunc destructor) {
   PlatformThreadLocalStorage::TLSKey key =
       base::subtle::NoBarrier_Load(&g_native_tls_key);
   if (key == PlatformThreadLocalStorage::TLS_KEY_OUT_OF_INDEXES ||
-      !PlatformThreadLocalStorage::GetTLSValue(key))
+      !PlatformThreadLocalStorage::GetTLSValue(key)) {
     ConstructTlsVector();
+  }
 
   // Grab a new slot.
-  slot_ = base::subtle::NoBarrier_AtomicIncrement(&g_last_used_tls_key, 1);
-  DCHECK_GT(slot_, 0);
+  slot_ = kInvalidSlotValue;
+  version_ = 0;
+  {
+    base::AutoLock auto_lock(g_tls_metadata_lock.Get());
+    for (int i = 0; i < kThreadLocalStorageSize; ++i) {
+      // Tracking the last assigned slot is an attempt to find the next
+      // available slot within one iteration. Under normal usage, slots remain
+      // in use for the lifetime of the process (otherwise before we reclaimed
+      // slots, we would have run out of slots). This makes it highly likely the
+      // next slot is going to be a free slot.
+      size_t slot_candidate =
+          (g_last_assigned_slot + 1 + i) % kThreadLocalStorageSize;
+      if (g_tls_metadata[slot_candidate].status == TlsStatus::FREE) {
+        g_tls_metadata[slot_candidate].status = TlsStatus::IN_USE;
+        g_tls_metadata[slot_candidate].destructor = destructor;
+        g_last_assigned_slot = slot_candidate;
+        slot_ = slot_candidate;
+        version_ = g_tls_metadata[slot_candidate].version;
+        break;
+      }
+    }
+  }
+  CHECK_NE(slot_, kInvalidSlotValue);
   CHECK_LT(slot_, kThreadLocalStorageSize);
 
   // Setup our destructor.
-  g_tls_destructors[slot_] = destructor;
   base::subtle::Release_Store(&initialized_, 1);
 }
 
 void ThreadLocalStorage::StaticSlot::Free() {
-  // At this time, we don't reclaim old indices for TLS slots.
-  // So all we need to do is wipe the destructor.
-  DCHECK_GT(slot_, 0);
+  DCHECK_NE(slot_, kInvalidSlotValue);
   DCHECK_LT(slot_, kThreadLocalStorageSize);
-  g_tls_destructors[slot_] = NULL;
-  slot_ = 0;
+  {
+    base::AutoLock auto_lock(g_tls_metadata_lock.Get());
+    g_tls_metadata[slot_].status = TlsStatus::FREE;
+    g_tls_metadata[slot_].destructor = nullptr;
+    ++(g_tls_metadata[slot_].version);
+  }
+  slot_ = kInvalidSlotValue;
   base::subtle::Release_Store(&initialized_, 0);
 }
 
 void* ThreadLocalStorage::StaticSlot::Get() const {
-  void** tls_data = static_cast<void**>(
+  TlsVectorEntry* tls_data = static_cast<TlsVectorEntry*>(
       PlatformThreadLocalStorage::GetTLSValue(
           base::subtle::NoBarrier_Load(&g_native_tls_key)));
   if (!tls_data)
     tls_data = ConstructTlsVector();
-  DCHECK_GT(slot_, 0);
+  DCHECK_NE(slot_, kInvalidSlotValue);
   DCHECK_LT(slot_, kThreadLocalStorageSize);
-  return tls_data[slot_];
+  // Version mismatches means this slot was previously freed.
+  if (tls_data[slot_].version != version_)
+    return nullptr;
+  return tls_data[slot_].data;
 }
 
 void ThreadLocalStorage::StaticSlot::Set(void* value) {
-  void** tls_data = static_cast<void**>(
+  TlsVectorEntry* tls_data = static_cast<TlsVectorEntry*>(
       PlatformThreadLocalStorage::GetTLSValue(
           base::subtle::NoBarrier_Load(&g_native_tls_key)));
   if (!tls_data)
     tls_data = ConstructTlsVector();
-  DCHECK_GT(slot_, 0);
+  DCHECK_NE(slot_, kInvalidSlotValue);
   DCHECK_LT(slot_, kThreadLocalStorageSize);
-  tls_data[slot_] = value;
+  tls_data[slot_].data = value;
+  tls_data[slot_].version = version_;
 }
 
 ThreadLocalStorage::Slot::Slot(TLSDestructorFunc destructor) {
diff --git a/src/base/threading/thread_local_storage.h b/src/base/threading/thread_local_storage.h
index bc956a7..fd2a789 100644
--- a/src/base/threading/thread_local_storage.h
+++ b/src/base/threading/thread_local_storage.h
@@ -5,6 +5,8 @@
 #ifndef BASE_THREADING_THREAD_LOCAL_STORAGE_H_
 #define BASE_THREADING_THREAD_LOCAL_STORAGE_H_
 
+#include <stdint.h>
+
 #include "base/atomicops.h"
 #include "base/base_export.h"
 #include "base/macros.h"
@@ -20,9 +22,12 @@ namespace base {
 
 namespace internal {
 
-// WARNING: You should *NOT* be using this class directly.
-// PlatformThreadLocalStorage is low-level abstraction to the OS's TLS
-// interface, you should instead be using ThreadLocalStorage::StaticSlot/Slot.
+// WARNING: You should *NOT* use this class directly.
+// PlatformThreadLocalStorage is a low-level abstraction of the OS's TLS
+// interface. Instead, you should use one of the following:
+// * ThreadLocalBoolean (from thread_local.h) for booleans.
+// * ThreadLocalPointer (from thread_local.h) for pointers.
+// * ThreadLocalStorage::StaticSlot/Slot for more direct control of the slot.
 class BASE_EXPORT PlatformThreadLocalStorage {
  public:
 
@@ -123,6 +128,7 @@ class BASE_EXPORT ThreadLocalStorage {
     // The internals of this struct should be considered private.
     base::subtle::Atomic32 initialized_;
     int slot_;
+    uint32_t version_;
   };
 
   // A convenience wrapper around StaticSlot with a constructor. Can be used
diff --git a/src/base/threading/thread_restrictions.h b/src/base/threading/thread_restrictions.h
index b451ab1..f0918cd 100644
--- a/src/base/threading/thread_restrictions.h
+++ b/src/base/threading/thread_restrictions.h
@@ -54,9 +54,6 @@ namespace gpu {
 class GpuChannelHost;
 }
 namespace mojo {
-namespace common {
-class MessagePumpMojo;
-}
 class SyncCallRestrictions;
 }
 namespace ui {
@@ -89,6 +86,10 @@ namespace android {
 class JavaHandlerThread;
 }
 
+namespace internal {
+class TaskTracker;
+}
+
 class SequencedWorkerPool;
 class SimpleThread;
 class Thread;
@@ -134,20 +135,6 @@ class BASE_EXPORT ThreadRestrictions {
     DISALLOW_COPY_AND_ASSIGN(ScopedAllowIO);
   };
 
-  // Constructing a ScopedAllowSingleton temporarily allows accessing for the
-  // current thread.  Doing this is almost always incorrect.
-  class BASE_EXPORT ScopedAllowSingleton {
-   public:
-    ScopedAllowSingleton() { previous_value_ = SetSingletonAllowed(true); }
-    ~ScopedAllowSingleton() { SetSingletonAllowed(previous_value_); }
-   private:
-    // Whether singleton use is allowed when the ScopedAllowSingleton was
-    // constructed.
-    bool previous_value_;
-
-    DISALLOW_COPY_AND_ASSIGN(ScopedAllowSingleton);
-  };
-
 #if DCHECK_IS_ON()
   // Set whether the current thread to make IO calls.
   // Threads start out in the *allowed* state.
@@ -195,6 +182,7 @@ class BASE_EXPORT ThreadRestrictions {
   friend class content::ScopedAllowWaitForAndroidLayoutTests;
   friend class content::ScopedAllowWaitForDebugURL;
   friend class ::HistogramSynchronizer;
+  friend class internal::TaskTracker;
   friend class ::ScopedAllowWaitForLegacyWebViewApi;
   friend class cc::CompletionEvent;
   friend class cc::SingleThreadTaskGraphRunner;
@@ -208,7 +196,6 @@ class BASE_EXPORT ThreadRestrictions {
   friend class ThreadTestHelper;
   friend class PlatformThread;
   friend class android::JavaHandlerThread;
-  friend class mojo::common::MessagePumpMojo;
   friend class mojo::SyncCallRestrictions;
   friend class ui::CommandBufferClientImpl;
   friend class ui::CommandBufferLocal;
diff --git a/src/base/threading/worker_pool.h b/src/base/threading/worker_pool.h
index a52a414..1f1b818 100644
--- a/src/base/threading/worker_pool.h
+++ b/src/base/threading/worker_pool.h
@@ -9,8 +9,6 @@
 #include "base/callback_forward.h"
 #include "base/memory/ref_counted.h"
 
-class Task;
-
 namespace tracked_objects {
 class Location;
 }  // namespace tracked_objects
diff --git a/src/base/threading/worker_pool_posix.cc b/src/base/threading/worker_pool_posix.cc
index b0a2b87..afa9a50 100644
--- a/src/base/threading/worker_pool_posix.cc
+++ b/src/base/threading/worker_pool_posix.cc
@@ -33,7 +33,10 @@ const int kIdleSecondsBeforeExit = 10 * 60;
 class WorkerPoolImpl {
  public:
   WorkerPoolImpl();
-  ~WorkerPoolImpl();
+
+  // WorkerPoolImpl is only instantiated as a leaky LazyInstance, so the
+  // destructor is never called.
+  ~WorkerPoolImpl() = delete;
 
   void PostTask(const tracked_objects::Location& from_here,
                 const base::Closure& task,
@@ -47,17 +50,13 @@ WorkerPoolImpl::WorkerPoolImpl()
     : pool_(new base::PosixDynamicThreadPool("WorkerPool",
                                              kIdleSecondsBeforeExit)) {}
 
-WorkerPoolImpl::~WorkerPoolImpl() {
-  pool_->Terminate();
-}
-
 void WorkerPoolImpl::PostTask(const tracked_objects::Location& from_here,
                               const base::Closure& task,
                               bool task_is_slow) {
   pool_->PostTask(from_here, task);
 }
 
-base::LazyInstance<WorkerPoolImpl> g_lazy_worker_pool =
+base::LazyInstance<WorkerPoolImpl>::Leaky g_lazy_worker_pool =
     LAZY_INSTANCE_INITIALIZER;
 
 class WorkerThread : public PlatformThread::Delegate {
@@ -90,7 +89,7 @@ void WorkerThread::ThreadMain() {
 
     tracked_objects::TaskStopwatch stopwatch;
     stopwatch.Start();
-    pending_task.task.Run();
+    std::move(pending_task.task).Run();
     stopwatch.Stop();
 
     tracked_objects::ThreadData::TallyRunOnWorkerThreadIfTracking(
@@ -121,23 +120,13 @@ PosixDynamicThreadPool::PosixDynamicThreadPool(const std::string& name_prefix,
     : name_prefix_(name_prefix),
       idle_seconds_before_exit_(idle_seconds_before_exit),
       pending_tasks_available_cv_(&lock_),
-      num_idle_threads_(0),
-      terminated_(false) {}
+      num_idle_threads_(0) {}
 
 PosixDynamicThreadPool::~PosixDynamicThreadPool() {
   while (!pending_tasks_.empty())
     pending_tasks_.pop();
 }
 
-void PosixDynamicThreadPool::Terminate() {
-  {
-    AutoLock locked(lock_);
-    DCHECK(!terminated_) << "Thread pool is already terminated.";
-    terminated_ = true;
-  }
-  pending_tasks_available_cv_.Broadcast();
-}
-
 void PosixDynamicThreadPool::PostTask(
     const tracked_objects::Location& from_here,
     const base::Closure& task) {
@@ -147,8 +136,6 @@ void PosixDynamicThreadPool::PostTask(
 
 void PosixDynamicThreadPool::AddTask(PendingTask* pending_task) {
   AutoLock locked(lock_);
-  DCHECK(!terminated_)
-      << "This thread pool is already terminated.  Do not post new tasks.";
 
   pending_tasks_.push(std::move(*pending_task));
 
@@ -166,9 +153,6 @@ void PosixDynamicThreadPool::AddTask(PendingTask* pending_task) {
 PendingTask PosixDynamicThreadPool::WaitForTask() {
   AutoLock locked(lock_);
 
-  if (terminated_)
-    return PendingTask(FROM_HERE, base::Closure());
-
   if (pending_tasks_.empty()) {  // No work available, wait for work.
     num_idle_threads_++;
     if (num_idle_threads_cv_.get())
diff --git a/src/base/threading/worker_pool_posix.h b/src/base/threading/worker_pool_posix.h
index 628e2b6..d65ae8f 100644
--- a/src/base/threading/worker_pool_posix.h
+++ b/src/base/threading/worker_pool_posix.h
@@ -38,8 +38,6 @@
 #include "base/threading/platform_thread.h"
 #include "base/tracked_objects.h"
 
-class Task;
-
 namespace base {
 
 class BASE_EXPORT PosixDynamicThreadPool
@@ -52,10 +50,6 @@ class BASE_EXPORT PosixDynamicThreadPool
   PosixDynamicThreadPool(const std::string& name_prefix,
                          int idle_seconds_before_exit);
 
-  // Indicates that the thread pool is going away.  Stops handing out tasks to
-  // worker threads.  Wakes up all the idle threads to let them exit.
-  void Terminate();
-
   // Adds |task| to the thread pool.
   void PostTask(const tracked_objects::Location& from_here,
                 const Closure& task);
@@ -85,7 +79,6 @@ class BASE_EXPORT PosixDynamicThreadPool
   ConditionVariable pending_tasks_available_cv_;
   int num_idle_threads_;
   TaskQueue pending_tasks_;
-  bool terminated_;
   // Only used for tests to ensure correct thread ordering.  It will always be
   // NULL in non-test code.
   std::unique_ptr<ConditionVariable> num_idle_threads_cv_;
diff --git a/src/base/time/time.cc b/src/base/time/time.cc
index 3670f55..df3942c 100644
--- a/src/base/time/time.cc
+++ b/src/base/time/time.cc
@@ -104,33 +104,29 @@ namespace time_internal {
 int64_t SaturatedAdd(TimeDelta delta, int64_t value) {
   CheckedNumeric<int64_t> rv(delta.delta_);
   rv += value;
-  return FromCheckedNumeric(rv);
+  if (rv.IsValid())
+    return rv.ValueOrDie();
+  // Positive RHS overflows. Negative RHS underflows.
+  if (value < 0)
+    return -std::numeric_limits<int64_t>::max();
+  return std::numeric_limits<int64_t>::max();
 }
 
 int64_t SaturatedSub(TimeDelta delta, int64_t value) {
   CheckedNumeric<int64_t> rv(delta.delta_);
   rv -= value;
-  return FromCheckedNumeric(rv);
-}
-
-int64_t FromCheckedNumeric(const CheckedNumeric<int64_t> value) {
-  if (value.IsValid())
-    return value.ValueUnsafe();
-
-  // We could return max/min but we don't really expose what the maximum delta
-  // is. Instead, return max/(-max), which is something that clients can reason
-  // about.
-  // TODO(rvargas) crbug.com/332611: don't use internal values.
-  int64_t limit = std::numeric_limits<int64_t>::max();
-  if (value.validity() == internal::RANGE_UNDERFLOW)
-    limit = -limit;
-  return value.ValueOrDefault(limit);
+  if (rv.IsValid())
+    return rv.ValueOrDie();
+  // Negative RHS overflows. Positive RHS underflows.
+  if (value < 0)
+    return std::numeric_limits<int64_t>::max();
+  return -std::numeric_limits<int64_t>::max();
 }
 
 }  // namespace time_internal
 
 std::ostream& operator<<(std::ostream& os, TimeDelta time_delta) {
-  return os << time_delta.InSecondsF() << "s";
+  return os << time_delta.InSecondsF() << " s";
 }
 
 // Time -----------------------------------------------------------------------
@@ -207,6 +203,11 @@ double Time::ToJsTime() const {
           kMicrosecondsPerMillisecond);
 }
 
+Time Time::FromJavaTime(int64_t ms_since_epoch) {
+  return base::Time::UnixEpoch() +
+         base::TimeDelta::FromMilliseconds(ms_since_epoch);
+}
+
 int64_t Time::ToJavaTime() const {
   if (is_null()) {
     // Preserve 0 so the invalid result doesn't depend on the platform.
diff --git a/src/base/time/time.h b/src/base/time/time.h
index b09cd9e..ece4fe8 100644
--- a/src/base/time/time.h
+++ b/src/base/time/time.h
@@ -21,9 +21,11 @@
 // ThreadTicks will "stand still" whenever the thread has been de-scheduled by
 // the operating system.
 //
-// All time classes are copyable, assignable, and occupy 64-bits per
-// instance. Thus, they can be efficiently passed by-value (as opposed to
-// by-reference).
+// All time classes are copyable, assignable, and occupy 64-bits per instance.
+// As a result, prefer passing them by value:
+//   void MyFunction(TimeDelta arg);
+// If circumstances require, you may also pass by const reference:
+//   void MyFunction(const TimeDelta& arg);  // Not preferred.
 //
 // Definitions of operator<< are provided to make these types work with
 // DCHECK_EQ() and other log macros. For human-readable formatting, see
@@ -57,6 +59,7 @@
 
 #include "base/base_export.h"
 #include "base/compiler_specific.h"
+#include "base/logging.h"
 #include "base/numerics/safe_math.h"
 #include "build/build_config.h"
 
@@ -93,10 +96,6 @@ namespace time_internal {
 BASE_EXPORT int64_t SaturatedAdd(TimeDelta delta, int64_t value);
 BASE_EXPORT int64_t SaturatedSub(TimeDelta delta, int64_t value);
 
-// Clamp |value| on overflow and underflow conditions. The int64_t argument and
-// return value are in terms of a microsecond timebase.
-BASE_EXPORT int64_t FromCheckedNumeric(const CheckedNumeric<int64_t> value);
-
 }  // namespace time_internal
 
 // TimeDelta ------------------------------------------------------------------
@@ -115,6 +114,9 @@ class BASE_EXPORT TimeDelta {
   static constexpr TimeDelta FromSecondsD(double secs);
   static constexpr TimeDelta FromMillisecondsD(double ms);
   static constexpr TimeDelta FromMicroseconds(int64_t us);
+#if defined(OS_POSIX)
+  static TimeDelta FromTimeSpec(const timespec& ts);
+#endif
 #if defined(OS_WIN)
   static TimeDelta FromQPCValue(LONGLONG qpc_value);
 #endif
@@ -200,13 +202,24 @@ class BASE_EXPORT TimeDelta {
   TimeDelta operator*(T a) const {
     CheckedNumeric<int64_t> rv(delta_);
     rv *= a;
-    return TimeDelta(time_internal::FromCheckedNumeric(rv));
+    if (rv.IsValid())
+      return TimeDelta(rv.ValueOrDie());
+    // Matched sign overflows. Mismatched sign underflows.
+    if ((delta_ < 0) ^ (a < 0))
+      return TimeDelta(-std::numeric_limits<int64_t>::max());
+    return TimeDelta(std::numeric_limits<int64_t>::max());
   }
   template<typename T>
   TimeDelta operator/(T a) const {
     CheckedNumeric<int64_t> rv(delta_);
     rv /= a;
-    return TimeDelta(time_internal::FromCheckedNumeric(rv));
+    if (rv.IsValid())
+      return TimeDelta(rv.ValueOrDie());
+    // Matched sign overflows. Mismatched sign underflows.
+    // Special case to catch divide by zero.
+    if ((delta_ < 0) ^ (a <= 0))
+      return TimeDelta(-std::numeric_limits<int64_t>::max());
+    return TimeDelta(std::numeric_limits<int64_t>::max());
   }
   template<typename T>
   TimeDelta& operator*=(T a) {
@@ -457,8 +470,6 @@ class BASE_EXPORT Time : public time_internal::TimeBase<Time> {
   static Time NowFromSystemTime();
 
   // Converts to/from time_t in UTC and a Time class.
-  // TODO(brettw) this should be removed once everybody starts using the |Time|
-  // class.
   static Time FromTimeT(time_t tt);
   time_t ToTimeT() const;
 
@@ -484,8 +495,9 @@ class BASE_EXPORT Time : public time_internal::TimeBase<Time> {
   static Time FromJsTime(double ms_since_epoch);
   double ToJsTime() const;
 
-  // Converts to Java convention for times, a number of
+  // Converts to/from Java convention for times, a number of
   // milliseconds since the epoch.
+  static Time FromJavaTime(int64_t ms_since_epoch);
   int64_t ToJavaTime() const;
 
 #if defined(OS_POSIX)
@@ -542,7 +554,7 @@ class BASE_EXPORT Time : public time_internal::TimeBase<Time> {
 
   // Converts an exploded structure representing either the local time or UTC
   // into a Time class. Returns false on a failure when, for example, a day of
-  // month is set to 31 on a 28-30 day month.
+  // month is set to 31 on a 28-30 day month. Returns Time(0) on overflow.
   static bool FromUTCExploded(const Exploded& exploded,
                               Time* time) WARN_UNUSED_RESULT {
     return FromExploded(false, exploded, time);
@@ -732,6 +744,10 @@ class BASE_EXPORT TimeTicks : public time_internal::TimeBase<TimeTicks> {
   static TimeTicks FromQPCValue(LONGLONG qpc_value);
 #endif
 
+#if defined(OS_MACOSX) && !defined(OS_IOS)
+  static TimeTicks FromMachAbsoluteTime(uint64_t mach_absolute_time);
+#endif  // defined(OS_MACOSX) && !defined(OS_IOS)
+
   // Get an estimate of the TimeTick value at the time of the UnixEpoch. Because
   // Time and TimeTicks respond differently to user-set time and NTP
   // adjustments, this number is only an estimate. Nevertheless, this can be
diff --git a/src/base/time/time_mac.cc b/src/base/time/time_mac.cc
index 8f58916..c75423d 100644
--- a/src/base/time/time_mac.cc
+++ b/src/base/time/time_mac.cc
@@ -25,22 +25,8 @@
 
 namespace {
 
-int64_t ComputeCurrentTicks() {
-#if defined(OS_IOS)
-  // On iOS mach_absolute_time stops while the device is sleeping. Instead use
-  // now - KERN_BOOTTIME to get a time difference that is not impacted by clock
-  // changes. KERN_BOOTTIME will be updated by the system whenever the system
-  // clock change.
-  struct timeval boottime;
-  int mib[2] = {CTL_KERN, KERN_BOOTTIME};
-  size_t size = sizeof(boottime);
-  int kr = sysctl(mib, arraysize(mib), &boottime, &size, nullptr, 0);
-  DCHECK_EQ(KERN_SUCCESS, kr);
-  base::TimeDelta time_difference = base::Time::Now() -
-      (base::Time::FromTimeT(boottime.tv_sec) +
-       base::TimeDelta::FromMicroseconds(boottime.tv_usec));
-  return time_difference.InMicroseconds();
-#else
+#if defined(OS_MACOSX) && !defined(OS_IOS)
+int64_t MachAbsoluteTimeToTicks(uint64_t mach_absolute_time) {
   static mach_timebase_info_data_t timebase_info;
   if (timebase_info.denom == 0) {
     // Zero-initialization of statics guarantees that denom will be 0 before
@@ -52,14 +38,10 @@ int64_t ComputeCurrentTicks() {
     MACH_DCHECK(kr == KERN_SUCCESS, kr) << "mach_timebase_info";
   }
 
-  // mach_absolute_time is it when it comes to ticks on the Mac.  Other calls
-  // with less precision (such as TickCount) just call through to
-  // mach_absolute_time.
-
   // timebase_info converts absolute time tick units into nanoseconds.  Convert
   // to microseconds up front to stave off overflows.
-  base::CheckedNumeric<uint64_t> result(
-      mach_absolute_time() / base::Time::kNanosecondsPerMicrosecond);
+  base::CheckedNumeric<uint64_t> result(mach_absolute_time /
+                                        base::Time::kNanosecondsPerMicrosecond);
   result *= timebase_info.numer;
   result /= timebase_info.denom;
 
@@ -67,6 +49,29 @@ int64_t ComputeCurrentTicks() {
   // With numer and denom = 1 (the expected case), the 64-bit absolute time
   // reported in nanoseconds is enough to last nearly 585 years.
   return base::checked_cast<int64_t>(result.ValueOrDie());
+}
+#endif  // defined(OS_MACOSX) && !defined(OS_IOS)
+
+int64_t ComputeCurrentTicks() {
+#if defined(OS_IOS)
+  // On iOS mach_absolute_time stops while the device is sleeping. Instead use
+  // now - KERN_BOOTTIME to get a time difference that is not impacted by clock
+  // changes. KERN_BOOTTIME will be updated by the system whenever the system
+  // clock change.
+  struct timeval boottime;
+  int mib[2] = {CTL_KERN, KERN_BOOTTIME};
+  size_t size = sizeof(boottime);
+  int kr = sysctl(mib, arraysize(mib), &boottime, &size, nullptr, 0);
+  DCHECK_EQ(KERN_SUCCESS, kr);
+  base::TimeDelta time_difference =
+      base::Time::Now() - (base::Time::FromTimeT(boottime.tv_sec) +
+                           base::TimeDelta::FromMicroseconds(boottime.tv_usec));
+  return time_difference.InMicroseconds();
+#else
+  // mach_absolute_time is it when it comes to ticks on the Mac.  Other calls
+  // with less precision (such as TickCount) just call through to
+  // mach_absolute_time.
+  return MachAbsoluteTimeToTicks(mach_absolute_time());
 #endif  // defined(OS_IOS)
 }
 
@@ -185,9 +190,18 @@ bool Time::FromExploded(bool is_local, const Exploded& exploded, Time* time) {
       exploded.millisecond);
   CFAbsoluteTime seconds = absolute_time + kCFAbsoluteTimeIntervalSince1970;
 
-  base::Time converted_time =
-      Time(static_cast<int64_t>(seconds * kMicrosecondsPerSecond) +
-           kWindowsEpochDeltaMicroseconds);
+  // CFAbsolutTime is typedef of double. Convert seconds to
+  // microseconds and then cast to int64. If
+  // it cannot be suited to int64, then fail to avoid overflows.
+  double microseconds =
+      (seconds * kMicrosecondsPerSecond) + kWindowsEpochDeltaMicroseconds;
+  if (microseconds > std::numeric_limits<int64_t>::max() ||
+      microseconds < std::numeric_limits<int64_t>::min()) {
+    *time = Time(0);
+    return false;
+  }
+
+  base::Time converted_time = Time(static_cast<int64_t>(microseconds));
 
   // If |exploded.day_of_month| is set to 31
   // on a 28-30 day month, it will return the first day of the next month.
@@ -263,6 +277,13 @@ bool TimeTicks::IsConsistentAcrossProcesses() {
   return true;
 }
 
+#if defined(OS_MACOSX) && !defined(OS_IOS)
+// static
+TimeTicks TimeTicks::FromMachAbsoluteTime(uint64_t mach_absolute_time) {
+  return TimeTicks(MachAbsoluteTimeToTicks(mach_absolute_time));
+}
+#endif  // defined(OS_MACOSX) && !defined(OS_IOS)
+
 // static
 TimeTicks::Clock TimeTicks::GetClock() {
 #if defined(OS_IOS)
diff --git a/src/base/time/time_posix.cc b/src/base/time/time_posix.cc
index 0897f9c..963c15b 100644
--- a/src/base/time/time_posix.cc
+++ b/src/base/time/time_posix.cc
@@ -16,6 +16,7 @@
 #include <ostream>
 
 #include "base/logging.h"
+#include "base/numerics/safe_math.h"
 #include "build/build_config.h"
 
 #if defined(OS_ANDROID)
@@ -80,10 +81,19 @@ void SysTimeToTimeStruct(SysTime t, struct tm* timestruct, bool is_local) {
 #endif  // OS_ANDROID
 
 int64_t ConvertTimespecToMicros(const struct timespec& ts) {
-  base::CheckedNumeric<int64_t> result(ts.tv_sec);
-  result *= base::Time::kMicrosecondsPerSecond;
-  result += (ts.tv_nsec / base::Time::kNanosecondsPerMicrosecond);
-  return result.ValueOrDie();
+  // On 32-bit systems, the calculation cannot overflow int64_t.
+  // 2**32 * 1000000 + 2**64 / 1000 < 2**63
+  if (sizeof(ts.tv_sec) <= 4 && sizeof(ts.tv_nsec) <= 8) {
+    int64_t result = ts.tv_sec;
+    result *= base::Time::kMicrosecondsPerSecond;
+    result += (ts.tv_nsec / base::Time::kNanosecondsPerMicrosecond);
+    return result;
+  } else {
+    base::CheckedNumeric<int64_t> result(ts.tv_sec);
+    result *= base::Time::kMicrosecondsPerSecond;
+    result += (ts.tv_nsec / base::Time::kNanosecondsPerMicrosecond);
+    return result.ValueOrDie();
+  }
 }
 
 // Helper function to get results from clock_gettime() and convert to a
@@ -110,6 +120,12 @@ int64_t ClockNow(clockid_t clk_id) {
 
 namespace base {
 
+// static
+TimeDelta TimeDelta::FromTimeSpec(const timespec& ts) {
+  return TimeDelta(ts.tv_sec * Time::kMicrosecondsPerSecond +
+                   ts.tv_nsec / Time::kNanosecondsPerMicrosecond);
+}
+
 struct timespec TimeDelta::ToTimeSpec() const {
   int64_t microseconds = InMicroseconds();
   time_t seconds = 0;
@@ -212,22 +228,30 @@ void Time::Explode(bool is_local, Exploded* exploded) const {
 
 // static
 bool Time::FromExploded(bool is_local, const Exploded& exploded, Time* time) {
+  CheckedNumeric<int> month = exploded.month;
+  month--;
+  CheckedNumeric<int> year = exploded.year;
+  year -= 1900;
+  if (!month.IsValid() || !year.IsValid()) {
+    *time = Time(0);
+    return false;
+  }
+
   struct tm timestruct;
-  timestruct.tm_sec    = exploded.second;
-  timestruct.tm_min    = exploded.minute;
-  timestruct.tm_hour   = exploded.hour;
-  timestruct.tm_mday   = exploded.day_of_month;
-  timestruct.tm_mon    = exploded.month - 1;
-  timestruct.tm_year   = exploded.year - 1900;
-  timestruct.tm_wday   = exploded.day_of_week;  // mktime/timegm ignore this
-  timestruct.tm_yday   = 0;     // mktime/timegm ignore this
-  timestruct.tm_isdst  = -1;    // attempt to figure it out
+  timestruct.tm_sec = exploded.second;
+  timestruct.tm_min = exploded.minute;
+  timestruct.tm_hour = exploded.hour;
+  timestruct.tm_mday = exploded.day_of_month;
+  timestruct.tm_mon = month.ValueOrDie();
+  timestruct.tm_year = year.ValueOrDie();
+  timestruct.tm_wday = exploded.day_of_week;  // mktime/timegm ignore this
+  timestruct.tm_yday = 0;                     // mktime/timegm ignore this
+  timestruct.tm_isdst = -1;                   // attempt to figure it out
 #if !defined(OS_NACL) && !defined(OS_SOLARIS)
-  timestruct.tm_gmtoff = 0;     // not a POSIX field, so mktime/timegm ignore
-  timestruct.tm_zone   = NULL;  // not a POSIX field, so mktime/timegm ignore
+  timestruct.tm_gmtoff = 0;   // not a POSIX field, so mktime/timegm ignore
+  timestruct.tm_zone = NULL;  // not a POSIX field, so mktime/timegm ignore
 #endif
 
-  int64_t milliseconds;
   SysTime seconds;
 
   // Certain exploded dates do not really exist due to daylight saving times,
@@ -265,6 +289,7 @@ bool Time::FromExploded(bool is_local, const Exploded& exploded, Time* time) {
   // return is the best that can be done here.  It's not ideal, but it's better
   // than failing here or ignoring the overflow case and treating each time
   // overflow as one second prior to the epoch.
+  int64_t milliseconds = 0;
   if (seconds == -1 &&
       (exploded.year < 1969 || exploded.year > 1970)) {
     // If exploded.year is 1969 or 1970, take -1 as correct, with the
@@ -297,13 +322,25 @@ bool Time::FromExploded(bool is_local, const Exploded& exploded, Time* time) {
       milliseconds += (kMillisecondsPerSecond - 1);
     }
   } else {
-    milliseconds = seconds * kMillisecondsPerSecond + exploded.millisecond;
+    base::CheckedNumeric<int64_t> checked_millis = seconds;
+    checked_millis *= kMillisecondsPerSecond;
+    checked_millis += exploded.millisecond;
+    if (!checked_millis.IsValid()) {
+      *time = base::Time(0);
+      return false;
+    }
+    milliseconds = checked_millis.ValueOrDie();
   }
 
-  // Adjust from Unix (1970) to Windows (1601) epoch.
-  base::Time converted_time =
-      Time((milliseconds * kMicrosecondsPerMillisecond) +
-           kWindowsEpochDeltaMicroseconds);
+  // Adjust from Unix (1970) to Windows (1601) epoch avoiding overflows.
+  base::CheckedNumeric<int64_t> checked_microseconds_win_epoch = milliseconds;
+  checked_microseconds_win_epoch *= kMicrosecondsPerMillisecond;
+  checked_microseconds_win_epoch += kWindowsEpochDeltaMicroseconds;
+  if (!checked_microseconds_win_epoch.IsValid()) {
+    *time = base::Time(0);
+    return false;
+  }
+  base::Time converted_time(checked_microseconds_win_epoch.ValueOrDie());
 
   // If |exploded.day_of_month| is set to 31 on a 28-30 day month, it will
   // return the first day of the next month. Thus round-trip the time and
diff --git a/src/base/timer/timer.cc b/src/base/timer/timer.cc
index e554905..6ec18f1 100644
--- a/src/base/timer/timer.cc
+++ b/src/base/timer/timer.cc
@@ -6,11 +6,15 @@
 
 #include <stddef.h>
 
+#include <utility>
+
 #include "base/logging.h"
+#include "base/memory/ptr_util.h"
 #include "base/memory/ref_counted.h"
 #include "base/single_thread_task_runner.h"
 #include "base/threading/platform_thread.h"
 #include "base/threading/thread_task_runner_handle.h"
+#include "base/time/tick_clock.h"
 
 namespace base {
 
@@ -60,26 +64,36 @@ class BaseTimerTaskInternal {
 };
 
 Timer::Timer(bool retain_user_task, bool is_repeating)
-    : scheduled_task_(NULL),
+    : Timer(retain_user_task, is_repeating, nullptr) {}
+
+Timer::Timer(bool retain_user_task, bool is_repeating, TickClock* tick_clock)
+    : scheduled_task_(nullptr),
       thread_id_(0),
       is_repeating_(is_repeating),
       retain_user_task_(retain_user_task),
-      is_running_(false) {
-}
+      tick_clock_(tick_clock),
+      is_running_(false) {}
 
 Timer::Timer(const tracked_objects::Location& posted_from,
              TimeDelta delay,
              const base::Closure& user_task,
              bool is_repeating)
-    : scheduled_task_(NULL),
+    : Timer(posted_from, delay, user_task, is_repeating, nullptr) {}
+
+Timer::Timer(const tracked_objects::Location& posted_from,
+             TimeDelta delay,
+             const base::Closure& user_task,
+             bool is_repeating,
+             TickClock* tick_clock)
+    : scheduled_task_(nullptr),
       posted_from_(posted_from),
       delay_(delay),
       user_task_(user_task),
       thread_id_(0),
       is_repeating_(is_repeating),
       retain_user_task_(true),
-      is_running_(false) {
-}
+      tick_clock_(tick_clock),
+      is_running_(false) {}
 
 Timer::~Timer() {
   StopAndAbandon();
@@ -123,7 +137,7 @@ void Timer::Reset() {
 
   // Set the new desired_run_time_.
   if (delay_ > TimeDelta::FromMicroseconds(0))
-    desired_run_time_ = TimeTicks::Now() + delay_;
+    desired_run_time_ = Now() + delay_;
   else
     desired_run_time_ = TimeTicks();
 
@@ -139,6 +153,10 @@ void Timer::Reset() {
   PostNewScheduledTask(delay_);
 }
 
+TimeTicks Timer::Now() const {
+  return tick_clock_ ? tick_clock_->NowTicks() : TimeTicks::Now();
+}
+
 void Timer::SetTaskInfo(const tracked_objects::Location& posted_from,
                         TimeDelta delay,
                         const base::Closure& user_task) {
@@ -155,7 +173,7 @@ void Timer::PostNewScheduledTask(TimeDelta delay) {
     GetTaskRunner()->PostDelayedTask(posted_from_,
         base::Bind(&BaseTimerTaskInternal::Run, base::Owned(scheduled_task_)),
         delay);
-    scheduled_run_time_ = desired_run_time_ = TimeTicks::Now() + delay;
+    scheduled_run_time_ = desired_run_time_ = Now() + delay;
   } else {
     GetTaskRunner()->PostTask(posted_from_,
         base::Bind(&BaseTimerTaskInternal::Run, base::Owned(scheduled_task_)));
@@ -163,10 +181,8 @@ void Timer::PostNewScheduledTask(TimeDelta delay) {
   }
   // Remember the thread ID that posts the first task -- this will be verified
   // later when the task is abandoned to detect misuse from multiple threads.
-  if (!thread_id_) {
-    DCHECK(GetTaskRunner()->BelongsToCurrentThread());
+  if (!thread_id_)
     thread_id_ = static_cast<int>(PlatformThread::CurrentId());
-  }
 }
 
 scoped_refptr<SingleThreadTaskRunner> Timer::GetTaskRunner() {
@@ -189,9 +205,9 @@ void Timer::RunScheduledTask() {
 
   // First check if we need to delay the task because of a new target time.
   if (desired_run_time_ > scheduled_run_time_) {
-    // TimeTicks::Now() can be expensive, so only call it if we know the user
-    // has changed the desired_run_time_.
-    TimeTicks now = TimeTicks::Now();
+    // Now() can be expensive, so only call it if we know the user has changed
+    // the desired_run_time_.
+    TimeTicks now = Now();
     // Task runner may have called us late anyway, so only post a continuation
     // task if the desired_run_time_ is in the future.
     if (desired_run_time_ > now) {
diff --git a/src/base/timer/timer.h b/src/base/timer/timer.h
index 661829b..50aedbd 100644
--- a/src/base/timer/timer.h
+++ b/src/base/timer/timer.h
@@ -49,6 +49,8 @@
 // because they're flaky on the buildbot, but when you run them locally you
 // should be able to tell the difference.
 
+#include <memory>
+
 #include "base/base_export.h"
 #include "base/bind.h"
 #include "base/bind_helpers.h"
@@ -61,6 +63,7 @@ namespace base {
 
 class BaseTimerTaskInternal;
 class SingleThreadTaskRunner;
+class TickClock;
 
 //-----------------------------------------------------------------------------
 // This class wraps MessageLoop::PostDelayedTask to manage delayed and repeating
@@ -71,14 +74,23 @@ class BASE_EXPORT Timer {
  public:
   // Construct a timer in repeating or one-shot mode. Start or SetTaskInfo must
   // be called later to set task info. |retain_user_task| determines whether the
-  // user_task is retained or reset when it runs or stops.
+  // user_task is retained or reset when it runs or stops. If |tick_clock| is
+  // provided, it is used instead of TimeTicks::Now() to get TimeTicks when
+  // scheduling tasks.
   Timer(bool retain_user_task, bool is_repeating);
+  Timer(bool retain_user_task, bool is_repeating, TickClock* tick_clock);
 
-  // Construct a timer with retained task info.
+  // Construct a timer with retained task info. If |tick_clock| is provided, it
+  // is used instead of TimeTicks::Now() to get TimeTicks when scheduling tasks.
   Timer(const tracked_objects::Location& posted_from,
         TimeDelta delay,
         const base::Closure& user_task,
         bool is_repeating);
+  Timer(const tracked_objects::Location& posted_from,
+        TimeDelta delay,
+        const base::Closure& user_task,
+        bool is_repeating,
+        TickClock* tick_clock);
 
   virtual ~Timer();
 
@@ -111,6 +123,9 @@ class BASE_EXPORT Timer {
   const TimeTicks& desired_run_time() const { return desired_run_time_; }
 
  protected:
+  // Returns the current tick count.
+  TimeTicks Now() const;
+
   // Used to initiate a new delayed task.  This has the side-effect of disabling
   // scheduled_task_ if it is non-null.
   void SetTaskInfo(const tracked_objects::Location& posted_from,
@@ -191,6 +206,9 @@ class BASE_EXPORT Timer {
   // If true, hold on to the user_task_ closure object for reuse.
   const bool retain_user_task_;
 
+  // The tick clock used to calculate the run time for scheduled tasks.
+  TickClock* const tick_clock_;
+
   // If true, user_task_ is scheduled to run sometime in the future.
   bool is_running_;
 
@@ -210,8 +228,8 @@ class BaseTimerMethodPointer : public Timer {
   using Timer::Start;
 
   enum RepeatMode { ONE_SHOT, REPEATING };
-  BaseTimerMethodPointer(RepeatMode mode)
-      : Timer(mode == REPEATING, mode == REPEATING) {}
+  BaseTimerMethodPointer(RepeatMode mode, TickClock* tick_clock)
+      : Timer(mode == REPEATING, mode == REPEATING, tick_clock) {}
 
   // Start the timer to run at the given |delay| from now. If the timer is
   // already running, it will be replaced to call a task formed from
@@ -230,14 +248,18 @@ class BaseTimerMethodPointer : public Timer {
 // A simple, one-shot timer.  See usage notes at the top of the file.
 class OneShotTimer : public BaseTimerMethodPointer {
  public:
-  OneShotTimer() : BaseTimerMethodPointer(ONE_SHOT) {}
+  OneShotTimer() : OneShotTimer(nullptr) {}
+  explicit OneShotTimer(TickClock* tick_clock)
+      : BaseTimerMethodPointer(ONE_SHOT, tick_clock) {}
 };
 
 //-----------------------------------------------------------------------------
 // A simple, repeating timer.  See usage notes at the top of the file.
 class RepeatingTimer : public BaseTimerMethodPointer {
  public:
-  RepeatingTimer() : BaseTimerMethodPointer(REPEATING) {}
+  RepeatingTimer() : RepeatingTimer(nullptr) {}
+  explicit RepeatingTimer(TickClock* tick_clock)
+      : BaseTimerMethodPointer(REPEATING, tick_clock) {}
 };
 
 //-----------------------------------------------------------------------------
@@ -258,10 +280,19 @@ class DelayTimer : protected Timer {
              TimeDelta delay,
              Receiver* receiver,
              void (Receiver::*method)())
+      : DelayTimer(posted_from, delay, receiver, method, nullptr) {}
+
+  template <class Receiver>
+  DelayTimer(const tracked_objects::Location& posted_from,
+             TimeDelta delay,
+             Receiver* receiver,
+             void (Receiver::*method)(),
+             TickClock* tick_clock)
       : Timer(posted_from,
               delay,
               base::Bind(method, base::Unretained(receiver)),
-              false) {}
+              false,
+              tick_clock) {}
 
   void Reset() override;
 };
diff --git a/src/base/trace_event/common/trace_event_common.h b/src/base/trace_event/common/trace_event_common.h
index 21ac61e..e87665b 100644
--- a/src/base/trace_event/common/trace_event_common.h
+++ b/src/base/trace_event/common/trace_event_common.h
@@ -223,49 +223,6 @@
                                             flow_flags, arg1_name, arg1_val, \
                                             arg2_name, arg2_val)
 
-// UNSHIPPED_TRACE_EVENT* are like TRACE_EVENT* except that they are not
-// included in official builds.
-
-#if OFFICIAL_BUILD
-#undef TRACING_IS_OFFICIAL_BUILD
-#define TRACING_IS_OFFICIAL_BUILD 1
-#elif !defined(TRACING_IS_OFFICIAL_BUILD)
-#define TRACING_IS_OFFICIAL_BUILD 0
-#endif
-
-#if TRACING_IS_OFFICIAL_BUILD
-#define UNSHIPPED_TRACE_EVENT0(category_group, name) (void)0
-#define UNSHIPPED_TRACE_EVENT1(category_group, name, arg1_name, arg1_val) \
-  (void)0
-#define UNSHIPPED_TRACE_EVENT2(category_group, name, arg1_name, arg1_val, \
-                               arg2_name, arg2_val)                       \
-  (void)0
-#define UNSHIPPED_TRACE_EVENT_INSTANT0(category_group, name, scope) (void)0
-#define UNSHIPPED_TRACE_EVENT_INSTANT1(category_group, name, scope, arg1_name, \
-                                       arg1_val)                               \
-  (void)0
-#define UNSHIPPED_TRACE_EVENT_INSTANT2(category_group, name, scope, arg1_name, \
-                                       arg1_val, arg2_name, arg2_val)          \
-  (void)0
-#else
-#define UNSHIPPED_TRACE_EVENT0(category_group, name) \
-  TRACE_EVENT0(category_group, name)
-#define UNSHIPPED_TRACE_EVENT1(category_group, name, arg1_name, arg1_val) \
-  TRACE_EVENT1(category_group, name, arg1_name, arg1_val)
-#define UNSHIPPED_TRACE_EVENT2(category_group, name, arg1_name, arg1_val, \
-                               arg2_name, arg2_val)                       \
-  TRACE_EVENT2(category_group, name, arg1_name, arg1_val, arg2_name, arg2_val)
-#define UNSHIPPED_TRACE_EVENT_INSTANT0(category_group, name, scope) \
-  TRACE_EVENT_INSTANT0(category_group, name, scope)
-#define UNSHIPPED_TRACE_EVENT_INSTANT1(category_group, name, scope, arg1_name, \
-                                       arg1_val)                               \
-  TRACE_EVENT_INSTANT1(category_group, name, scope, arg1_name, arg1_val)
-#define UNSHIPPED_TRACE_EVENT_INSTANT2(category_group, name, scope, arg1_name, \
-                                       arg1_val, arg2_name, arg2_val)          \
-  TRACE_EVENT_INSTANT2(category_group, name, scope, arg1_name, arg1_val,       \
-                       arg2_name, arg2_val)
-#endif
-
 // Records a single event called "name" immediately, with 0, 1 or 2
 // associated arguments. If the category is not enabled, then this
 // does nothing.
@@ -297,20 +254,10 @@
 
 #define TRACE_EVENT_INSTANT_WITH_TIMESTAMP0(category_group, name, scope, \
                                             timestamp)                   \
-  INTERNAL_TRACE_EVENT_ADD_WITH_ID_TID_AND_TIMESTAMP(                    \
-      TRACE_EVENT_PHASE_INSTANT, category_group, name, 0, 0, timestamp,  \
+  INTERNAL_TRACE_EVENT_ADD_WITH_TIMESTAMP(                               \
+      TRACE_EVENT_PHASE_INSTANT, category_group, name, timestamp,        \
       TRACE_EVENT_FLAG_NONE | scope)
 
-// Syntactic sugars for the sampling tracing in the main thread.
-#define TRACE_EVENT_SCOPED_SAMPLING_STATE(category, name) \
-  TRACE_EVENT_SCOPED_SAMPLING_STATE_FOR_BUCKET(0, category, name)
-#define TRACE_EVENT_GET_SAMPLING_STATE() \
-  TRACE_EVENT_GET_SAMPLING_STATE_FOR_BUCKET(0)
-#define TRACE_EVENT_SET_SAMPLING_STATE(category, name) \
-  TRACE_EVENT_SET_SAMPLING_STATE_FOR_BUCKET(0, category, name)
-#define TRACE_EVENT_SET_NONCONST_SAMPLING_STATE(categoryAndName) \
-  TRACE_EVENT_SET_NONCONST_SAMPLING_STATE_FOR_BUCKET(0, categoryAndName)
-
 // Records a single BEGIN event called "name" immediately, with 0, 1 or 2
 // associated arguments. If the category is not enabled, then this
 // does nothing.
@@ -395,10 +342,15 @@
                            TRACE_EVENT_FLAG_COPY, arg1_name, arg1_val,   \
                            arg2_name, arg2_val)
 
+#define TRACE_EVENT_MARK_WITH_TIMESTAMP0(category_group, name, timestamp) \
+  INTERNAL_TRACE_EVENT_ADD_WITH_TIMESTAMP(                                \
+      TRACE_EVENT_PHASE_MARK, category_group, name, timestamp,            \
+      TRACE_EVENT_FLAG_NONE)
+
 #define TRACE_EVENT_MARK_WITH_TIMESTAMP1(category_group, name, timestamp, \
                                          arg1_name, arg1_val)             \
-  INTERNAL_TRACE_EVENT_ADD_WITH_ID_TID_AND_TIMESTAMP(                     \
-      TRACE_EVENT_PHASE_MARK, category_group, name, 0, 0, timestamp,      \
+  INTERNAL_TRACE_EVENT_ADD_WITH_TIMESTAMP(                                \
+      TRACE_EVENT_PHASE_MARK, category_group, name, timestamp,            \
       TRACE_EVENT_FLAG_NONE, arg1_name, arg1_val)
 
 #define TRACE_EVENT_COPY_MARK(category_group, name)                      \
@@ -406,8 +358,8 @@
                            TRACE_EVENT_FLAG_COPY)
 
 #define TRACE_EVENT_COPY_MARK_WITH_TIMESTAMP(category_group, name, timestamp) \
-  INTERNAL_TRACE_EVENT_ADD_WITH_ID_TID_AND_TIMESTAMP(                         \
-      TRACE_EVENT_PHASE_MARK, category_group, name, 0, 0, timestamp,          \
+  INTERNAL_TRACE_EVENT_ADD_WITH_TIMESTAMP(                                    \
+      TRACE_EVENT_PHASE_MARK, category_group, name, timestamp,                \
       TRACE_EVENT_FLAG_COPY)
 
 // Similar to TRACE_EVENT_ENDx but with a custom |at| timestamp provided.
@@ -544,6 +496,12 @@
       TRACE_EVENT_PHASE_SAMPLE, category_group, name, 0, thread_id, timestamp, \
       TRACE_EVENT_FLAG_NONE, arg1_name, arg1_val, arg2_name, arg2_val)
 
+#define TRACE_EVENT_SAMPLE_WITH_ID1(category_group, name, id, arg1_name,       \
+                                    arg1_val)                                  \
+  INTERNAL_TRACE_EVENT_ADD_WITH_ID(TRACE_EVENT_PHASE_SAMPLE, category_group,   \
+                                   name, id, TRACE_EVENT_FLAG_NONE, arg1_name, \
+                                   arg1_val)
+
 // ASYNC_STEP_* APIs should be only used by legacy code. New code should
 // consider using NESTABLE_ASYNC_* APIs to describe substeps within an async
 // event.
@@ -952,59 +910,58 @@
 #define TRACE_EVENT_CLOCK_SYNC_ISSUER(sync_id, issue_ts, issue_end_ts)         \
   INTERNAL_TRACE_EVENT_ADD_WITH_TIMESTAMP(                                     \
       TRACE_EVENT_PHASE_CLOCK_SYNC, "__metadata", "clock_sync",                \
-      issue_end_ts.ToInternalValue(), TRACE_EVENT_FLAG_NONE,                   \
-      "sync_id", sync_id, "issue_ts", issue_ts.ToInternalValue())
+      issue_end_ts, TRACE_EVENT_FLAG_NONE,                                     \
+      "sync_id", sync_id, "issue_ts", issue_ts)
 
 // Macros to track the life time and value of arbitrary client objects.
 // See also TraceTrackableObject.
 #define TRACE_EVENT_OBJECT_CREATED_WITH_ID(category_group, name, id) \
   INTERNAL_TRACE_EVENT_ADD_WITH_ID(                                  \
-      TRACE_EVENT_PHASE_CREATE_OBJECT, category_group, name,         \
-      TRACE_ID_DONT_MANGLE(id), TRACE_EVENT_FLAG_NONE)
+      TRACE_EVENT_PHASE_CREATE_OBJECT, category_group, name, id,     \
+      TRACE_EVENT_FLAG_NONE)
 
 #define TRACE_EVENT_OBJECT_SNAPSHOT_WITH_ID(category_group, name, id, \
                                             snapshot)                 \
   INTERNAL_TRACE_EVENT_ADD_WITH_ID(                                   \
       TRACE_EVENT_PHASE_SNAPSHOT_OBJECT, category_group, name,        \
-      TRACE_ID_DONT_MANGLE(id), TRACE_EVENT_FLAG_NONE, "snapshot", snapshot)
+      id, TRACE_EVENT_FLAG_NONE, "snapshot", snapshot)
 
-#define TRACE_EVENT_OBJECT_SNAPSHOT_WITH_ID_AND_TIMESTAMP(                    \
-    category_group, name, id, timestamp, snapshot)                            \
-  INTERNAL_TRACE_EVENT_ADD_WITH_ID_TID_AND_TIMESTAMP(                         \
-      TRACE_EVENT_PHASE_SNAPSHOT_OBJECT, category_group, name,                \
-      TRACE_ID_DONT_MANGLE(id), TRACE_EVENT_API_CURRENT_THREAD_ID, timestamp, \
-      TRACE_EVENT_FLAG_NONE, "snapshot", snapshot)
+#define TRACE_EVENT_OBJECT_SNAPSHOT_WITH_ID_AND_TIMESTAMP(                     \
+    category_group, name, id, timestamp, snapshot)                             \
+  INTERNAL_TRACE_EVENT_ADD_WITH_ID_TID_AND_TIMESTAMP(                          \
+      TRACE_EVENT_PHASE_SNAPSHOT_OBJECT, category_group, name,                 \
+      id, TRACE_EVENT_API_CURRENT_THREAD_ID, timestamp, TRACE_EVENT_FLAG_NONE, \
+      "snapshot", snapshot)
 
 #define TRACE_EVENT_OBJECT_DELETED_WITH_ID(category_group, name, id) \
   INTERNAL_TRACE_EVENT_ADD_WITH_ID(                                  \
-      TRACE_EVENT_PHASE_DELETE_OBJECT, category_group, name,         \
-      TRACE_ID_DONT_MANGLE(id), TRACE_EVENT_FLAG_NONE)
+      TRACE_EVENT_PHASE_DELETE_OBJECT, category_group, name, id,     \
+      TRACE_EVENT_FLAG_NONE)
 
 // Records entering and leaving trace event contexts. |category_group| and
 // |name| specify the context category and type. |context| is a
 // snapshotted context object id.
-#define TRACE_EVENT_ENTER_CONTEXT(category_group, name, context) \
-  INTERNAL_TRACE_EVENT_ADD_WITH_ID(                              \
-      TRACE_EVENT_PHASE_ENTER_CONTEXT, category_group, name,     \
-      TRACE_ID_DONT_MANGLE(context), TRACE_EVENT_FLAG_NONE)
-#define TRACE_EVENT_LEAVE_CONTEXT(category_group, name, context) \
-  INTERNAL_TRACE_EVENT_ADD_WITH_ID(                              \
-      TRACE_EVENT_PHASE_LEAVE_CONTEXT, category_group, name,     \
-      TRACE_ID_DONT_MANGLE(context), TRACE_EVENT_FLAG_NONE)
+#define TRACE_EVENT_ENTER_CONTEXT(category_group, name, context)      \
+  INTERNAL_TRACE_EVENT_ADD_WITH_ID(                                   \
+      TRACE_EVENT_PHASE_ENTER_CONTEXT, category_group, name, context, \
+      TRACE_EVENT_FLAG_NONE)
+#define TRACE_EVENT_LEAVE_CONTEXT(category_group, name, context)      \
+  INTERNAL_TRACE_EVENT_ADD_WITH_ID(                                   \
+      TRACE_EVENT_PHASE_LEAVE_CONTEXT, category_group, name, context, \
+      TRACE_EVENT_FLAG_NONE)
 #define TRACE_EVENT_SCOPED_CONTEXT(category_group, name, context) \
-  INTERNAL_TRACE_EVENT_SCOPED_CONTEXT(category_group, name,       \
-                                      TRACE_ID_DONT_MANGLE(context))
+  INTERNAL_TRACE_EVENT_SCOPED_CONTEXT(category_group, name, context)
 
 // Macro to specify that two trace IDs are identical. For example,
-// TRACE_BIND_IDS(
+// TRACE_LINK_IDS(
 //     "category", "name",
 //     TRACE_ID_WITH_SCOPE("net::URLRequest", 0x1000),
 //     TRACE_ID_WITH_SCOPE("blink::ResourceFetcher::FetchRequest", 0x2000))
 // tells the trace consumer that events with ID ("net::URLRequest", 0x1000) from
 // the current process have the same ID as events with ID
 // ("blink::ResourceFetcher::FetchRequest", 0x2000).
-#define TRACE_BIND_IDS(category_group, name, id, bind_id) \
-  INTERNAL_TRACE_EVENT_ADD_BIND_IDS(category_group, name, id, bind_id);
+#define TRACE_LINK_IDS(category_group, name, id, linked_id) \
+  INTERNAL_TRACE_EVENT_ADD_LINK_IDS(category_group, name, id, linked_id);
 
 // Macro to efficiently determine if a given category group is enabled.
 #define TRACE_EVENT_CATEGORY_GROUP_ENABLED(category_group, ret)             \
@@ -1071,12 +1028,13 @@
 #define TRACE_EVENT_PHASE_CLOCK_SYNC ('c')
 #define TRACE_EVENT_PHASE_ENTER_CONTEXT ('(')
 #define TRACE_EVENT_PHASE_LEAVE_CONTEXT (')')
-#define TRACE_EVENT_PHASE_BIND_IDS ('=')
+#define TRACE_EVENT_PHASE_LINK_IDS ('=')
 
 // Flags for changing the behavior of TRACE_EVENT_API_ADD_TRACE_EVENT.
 #define TRACE_EVENT_FLAG_NONE (static_cast<unsigned int>(0))
 #define TRACE_EVENT_FLAG_COPY (static_cast<unsigned int>(1 << 0))
 #define TRACE_EVENT_FLAG_HAS_ID (static_cast<unsigned int>(1 << 1))
+// TODO(crbug.com/639003): Free this bit after ID mangling is deprecated.
 #define TRACE_EVENT_FLAG_MANGLE_ID (static_cast<unsigned int>(1 << 2))
 #define TRACE_EVENT_FLAG_SCOPE_OFFSET (static_cast<unsigned int>(1 << 3))
 #define TRACE_EVENT_FLAG_SCOPE_EXTRA (static_cast<unsigned int>(1 << 4))
@@ -1087,6 +1045,8 @@
 #define TRACE_EVENT_FLAG_FLOW_OUT (static_cast<unsigned int>(1 << 9))
 #define TRACE_EVENT_FLAG_HAS_CONTEXT_ID (static_cast<unsigned int>(1 << 10))
 #define TRACE_EVENT_FLAG_HAS_PROCESS_ID (static_cast<unsigned int>(1 << 11))
+#define TRACE_EVENT_FLAG_HAS_LOCAL_ID (static_cast<unsigned int>(1 << 12))
+#define TRACE_EVENT_FLAG_HAS_GLOBAL_ID (static_cast<unsigned int>(1 << 13))
 
 #define TRACE_EVENT_FLAG_SCOPE_MASK                          \
   (static_cast<unsigned int>(TRACE_EVENT_FLAG_SCOPE_OFFSET | \
diff --git a/src/base/trace_event/heap_profiler_allocation_context_tracker.cc b/src/base/trace_event/heap_profiler_allocation_context_tracker.cc
index cbece2b..f3a03fe 100644
--- a/src/base/trace_event/heap_profiler_allocation_context_tracker.cc
+++ b/src/base/trace_event/heap_profiler_allocation_context_tracker.cc
@@ -129,7 +129,9 @@ void AllocationContextTracker::PopPseudoStackFrame(
   // hit if some TRACE_EVENT macro is unbalanced (a TRACE_EVENT_END* call
   // without a corresponding TRACE_EVENT_BEGIN).
   DCHECK(stack_frame == pseudo_stack_.back())
-      << "Encountered an unmatched TRACE_EVENT_END";
+      << "Encountered an unmatched TRACE_EVENT_END: "
+      << stack_frame.trace_event_name
+      << " vs event in stack: " << pseudo_stack_.back().trace_event_name;
 
   pseudo_stack_.pop_back();
 }
diff --git a/src/base/trace_event/heap_profiler_stack_frame_deduplicator.cc b/src/base/trace_event/heap_profiler_stack_frame_deduplicator.cc
index 49a2350..fc5da0d 100644
--- a/src/base/trace_event/heap_profiler_stack_frame_deduplicator.cc
+++ b/src/base/trace_event/heap_profiler_stack_frame_deduplicator.cc
@@ -11,6 +11,7 @@
 #include <utility>
 
 #include "base/strings/stringprintf.h"
+#include "base/trace_event/memory_usage_estimator.h"
 #include "base/trace_event/trace_event_argument.h"
 #include "base/trace_event/trace_event_memory_overhead.h"
 
@@ -23,6 +24,10 @@ StackFrameDeduplicator::FrameNode::FrameNode(StackFrame frame,
 StackFrameDeduplicator::FrameNode::FrameNode(const FrameNode& other) = default;
 StackFrameDeduplicator::FrameNode::~FrameNode() {}
 
+size_t StackFrameDeduplicator::FrameNode::EstimateMemoryUsage() const {
+  return base::trace_event::EstimateMemoryUsage(children);
+}
+
 StackFrameDeduplicator::StackFrameDeduplicator() {}
 StackFrameDeduplicator::~StackFrameDeduplicator() {}
 
@@ -116,19 +121,10 @@ void StackFrameDeduplicator::AppendAsTraceFormat(std::string* out) const {
 
 void StackFrameDeduplicator::EstimateTraceMemoryOverhead(
     TraceEventMemoryOverhead* overhead) {
-  // The sizes here are only estimates; they fail to take into account the
-  // overhead of the tree nodes for the map, but as an estimate this should be
-  // fine.
-  size_t maps_size = roots_.size() * sizeof(std::pair<StackFrame, int>);
-  size_t frames_allocated = frames_.capacity() * sizeof(FrameNode);
-  size_t frames_resident = frames_.size() * sizeof(FrameNode);
-
-  for (const FrameNode& node : frames_)
-    maps_size += node.children.size() * sizeof(std::pair<StackFrame, int>);
-
+  size_t memory_usage =
+      EstimateMemoryUsage(frames_) + EstimateMemoryUsage(roots_);
   overhead->Add("StackFrameDeduplicator",
-                sizeof(StackFrameDeduplicator) + maps_size + frames_allocated,
-                sizeof(StackFrameDeduplicator) + maps_size + frames_resident);
+                sizeof(StackFrameDeduplicator) + memory_usage);
 }
 
 }  // namespace trace_event
diff --git a/src/base/trace_event/heap_profiler_stack_frame_deduplicator.h b/src/base/trace_event/heap_profiler_stack_frame_deduplicator.h
index 4932534..66d430f 100644
--- a/src/base/trace_event/heap_profiler_stack_frame_deduplicator.h
+++ b/src/base/trace_event/heap_profiler_stack_frame_deduplicator.h
@@ -34,6 +34,8 @@ class BASE_EXPORT StackFrameDeduplicator : public ConvertableToTraceFormat {
     FrameNode(const FrameNode& other);
     ~FrameNode();
 
+    size_t EstimateMemoryUsage() const;
+
     StackFrame frame;
 
     // The index of the parent stack frame in |frames_|, or -1 if there is no
diff --git a/src/base/trace_event/heap_profiler_type_name_deduplicator.cc b/src/base/trace_event/heap_profiler_type_name_deduplicator.cc
index 9d56ce7..a6dab51 100644
--- a/src/base/trace_event/heap_profiler_type_name_deduplicator.cc
+++ b/src/base/trace_event/heap_profiler_type_name_deduplicator.cc
@@ -12,6 +12,7 @@
 #include "base/json/string_escape.h"
 #include "base/strings/string_split.h"
 #include "base/strings/stringprintf.h"
+#include "base/trace_event/memory_usage_estimator.h"
 #include "base/trace_event/trace_event.h"
 #include "base/trace_event/trace_event_memory_overhead.h"
 
@@ -105,12 +106,9 @@ void TypeNameDeduplicator::AppendAsTraceFormat(std::string* out) const {
 
 void TypeNameDeduplicator::EstimateTraceMemoryOverhead(
     TraceEventMemoryOverhead* overhead) {
-  // The size here is only an estimate; it fails to take into account the size
-  // of the tree nodes for the map, but as an estimate this should be fine.
-  size_t map_size = type_ids_.size() * sizeof(std::pair<const char*, int>);
-
+  size_t memory_usage = EstimateMemoryUsage(type_ids_);
   overhead->Add("TypeNameDeduplicator",
-                sizeof(TypeNameDeduplicator) + map_size);
+                sizeof(TypeNameDeduplicator) + memory_usage);
 }
 
 }  // namespace trace_event
diff --git a/src/base/trace_event/malloc_dump_provider.cc b/src/base/trace_event/malloc_dump_provider.cc
index 26eb923..c09470b 100644
--- a/src/base/trace_event/malloc_dump_provider.cc
+++ b/src/base/trace_event/malloc_dump_provider.cc
@@ -96,81 +96,37 @@ AllocatorDispatch g_allocator_hooks = {
 #if defined(OS_WIN)
 // A structure containing some information about a given heap.
 struct WinHeapInfo {
-  HANDLE heap_id;
   size_t committed_size;
   size_t uncommitted_size;
   size_t allocated_size;
   size_t block_count;
 };
 
-bool GetHeapInformation(WinHeapInfo* heap_info,
-                        const std::set<void*>& block_to_skip) {
-  CHECK(::HeapLock(heap_info->heap_id) == TRUE);
-  PROCESS_HEAP_ENTRY heap_entry;
-  heap_entry.lpData = nullptr;
-  // Walk over all the entries in this heap.
-  while (::HeapWalk(heap_info->heap_id, &heap_entry) != FALSE) {
-    if (block_to_skip.count(heap_entry.lpData) == 1)
-      continue;
-    if ((heap_entry.wFlags & PROCESS_HEAP_ENTRY_BUSY) != 0) {
-      heap_info->allocated_size += heap_entry.cbData;
-      heap_info->block_count++;
-    } else if ((heap_entry.wFlags & PROCESS_HEAP_REGION) != 0) {
-      heap_info->committed_size += heap_entry.Region.dwCommittedSize;
-      heap_info->uncommitted_size += heap_entry.Region.dwUnCommittedSize;
-    }
-  }
-  CHECK(::HeapUnlock(heap_info->heap_id) == TRUE);
-  return true;
-}
-
-void WinHeapMemoryDumpImpl(WinHeapInfo* all_heap_info) {
-// This method might be flaky for 2 reasons:
-//   - GetProcessHeaps is racy by design. It returns a snapshot of the
-//     available heaps, but there's no guarantee that that snapshot remains
-//     valid. If a heap disappears between GetProcessHeaps() and HeapWalk()
-//     then chaos should be assumed. This flakyness is acceptable for tracing.
-//   - The MSDN page for HeapLock says: "If the HeapLock function is called on
-//     a heap created with the HEAP_NO_SERIALIZATION flag, the results are
-//     undefined."
-//   - Note that multiple heaps occur on Windows primarily because system and
-//     3rd party DLLs will each create their own private heap. It's possible to
-//     retrieve the heap the CRT allocates from and report specifically on that
-//     heap. It's interesting to report all heaps, as e.g. loading or invoking
-//     on a Windows API may consume memory from a private heap.
+// NOTE: crbug.com/665516
+// Unfortunately, there is no safe way to collect information from secondary
+// heaps due to limitations and racy nature of this piece of WinAPI.
+void WinHeapMemoryDumpImpl(WinHeapInfo* crt_heap_info) {
 #if defined(SYZYASAN)
   if (base::debug::IsBinaryInstrumented())
     return;
 #endif
 
-  // Retrieves the number of heaps in the current process.
-  DWORD number_of_heaps = ::GetProcessHeaps(0, NULL);
-
-  // Try to retrieve a handle to all the heaps owned by this process. Returns
-  // false if the number of heaps has changed.
-  //
-  // This is inherently racy as is, but it's not something that we observe a lot
-  // in Chrome, the heaps tend to be created at startup only.
-  std::unique_ptr<HANDLE[]> all_heaps(new HANDLE[number_of_heaps]);
-  if (::GetProcessHeaps(number_of_heaps, all_heaps.get()) != number_of_heaps)
-    return;
-
-  // Skip the pointer to the heap array to avoid accounting the memory used by
-  // this dump provider.
-  std::set<void*> block_to_skip;
-  block_to_skip.insert(all_heaps.get());
-
-  // Retrieves some metrics about each heap.
-  for (size_t i = 0; i < number_of_heaps; ++i) {
-    WinHeapInfo heap_info = {0};
-    heap_info.heap_id = all_heaps[i];
-    GetHeapInformation(&heap_info, block_to_skip);
-
-    all_heap_info->allocated_size += heap_info.allocated_size;
-    all_heap_info->committed_size += heap_info.committed_size;
-    all_heap_info->uncommitted_size += heap_info.uncommitted_size;
-    all_heap_info->block_count += heap_info.block_count;
+  // Iterate through whichever heap our CRT is using.
+  HANDLE crt_heap = reinterpret_cast<HANDLE>(_get_heap_handle());
+  ::HeapLock(crt_heap);
+  PROCESS_HEAP_ENTRY heap_entry;
+  heap_entry.lpData = nullptr;
+  // Walk over all the entries in the main heap.
+  while (::HeapWalk(crt_heap, &heap_entry) != FALSE) {
+    if ((heap_entry.wFlags & PROCESS_HEAP_ENTRY_BUSY) != 0) {
+      crt_heap_info->allocated_size += heap_entry.cbData;
+      crt_heap_info->block_count++;
+    } else if ((heap_entry.wFlags & PROCESS_HEAP_REGION) != 0) {
+      crt_heap_info->committed_size += heap_entry.Region.dwCommittedSize;
+      crt_heap_info->uncommitted_size += heap_entry.Region.dwUnCommittedSize;
+    }
   }
+  CHECK(::HeapUnlock(crt_heap) == TRUE);
 }
 #endif  // defined(OS_WIN)
 }  // namespace
@@ -220,17 +176,17 @@ bool MallocDumpProvider::OnMemoryDump(const MemoryDumpArgs& args,
   // See crrev.com/1531463004 for detailed explanation.
   resident_size = stats.max_size_in_use;
 #elif defined(OS_WIN)
-  WinHeapInfo all_heap_info = {};
-  WinHeapMemoryDumpImpl(&all_heap_info);
+  WinHeapInfo main_heap_info = {};
+  WinHeapMemoryDumpImpl(&main_heap_info);
   total_virtual_size =
-      all_heap_info.committed_size + all_heap_info.uncommitted_size;
+      main_heap_info.committed_size + main_heap_info.uncommitted_size;
   // Resident size is approximated with committed heap size. Note that it is
   // possible to do this with better accuracy on windows by intersecting the
   // working set with the virtual memory ranges occuipied by the heap. It's not
   // clear that this is worth it, as it's fairly expensive to do.
-  resident_size = all_heap_info.committed_size;
-  allocated_objects_size = all_heap_info.allocated_size;
-  allocated_objects_count = all_heap_info.block_count;
+  resident_size = main_heap_info.committed_size;
+  allocated_objects_size = main_heap_info.allocated_size;
+  allocated_objects_count = main_heap_info.block_count;
 #else
   struct mallinfo info = mallinfo();
   DCHECK_GE(info.arena + info.hblkhd, info.uordblks);
diff --git a/src/base/trace_event/memory_allocator_dump.h b/src/base/trace_event/memory_allocator_dump.h
index 7d10236..2e6b08a 100644
--- a/src/base/trace_event/memory_allocator_dump.h
+++ b/src/base/trace_event/memory_allocator_dump.h
@@ -19,7 +19,6 @@
 namespace base {
 namespace trace_event {
 
-class MemoryDumpManager;
 class ProcessMemoryDump;
 class TracedValue;
 
diff --git a/src/base/trace_event/memory_dump_manager.cc b/src/base/trace_event/memory_dump_manager.cc
index 9719a6c..28d5d56 100644
--- a/src/base/trace_event/memory_dump_manager.cc
+++ b/src/base/trace_event/memory_dump_manager.cc
@@ -201,10 +201,33 @@ void MemoryDumpManager::Initialize(MemoryDumpManagerDelegate* delegate,
                        nullptr);
 #endif
 
+  TRACE_EVENT_WARMUP_CATEGORY(kTraceCategory);
+
+  // TODO(ssid): This should be done in EnableHeapProfiling so that we capture
+  // more allocations (crbug.com/625170).
+  if (AllocationContextTracker::capture_mode() ==
+          AllocationContextTracker::CaptureMode::PSEUDO_STACK &&
+      !(TraceLog::GetInstance()->enabled_modes() & TraceLog::FILTERING_MODE)) {
+    // Create trace config with heap profiling filter.
+    TraceConfig::EventFilterConfig heap_profiler_filter_config(
+        TraceLog::TraceEventFilter::kHeapProfilerPredicate);
+    heap_profiler_filter_config.AddIncludedCategory("*");
+    heap_profiler_filter_config.AddIncludedCategory(
+        MemoryDumpManager::kTraceCategory);
+    TraceConfig::EventFilters filters;
+    filters.push_back(heap_profiler_filter_config);
+    TraceConfig filtering_trace_config;
+    filtering_trace_config.SetEventFilters(filters);
+
+    TraceLog::GetInstance()->SetEnabled(filtering_trace_config,
+                                        TraceLog::FILTERING_MODE);
+  }
+
   // If tracing was enabled before initializing MemoryDumpManager, we missed the
   // OnTraceLogEnabled() event. Synthetize it so we can late-join the party.
+  // IsEnabled is called before adding observer to avoid calling
+  // OnTraceLogEnabled twice.
   bool is_tracing_already_enabled = TraceLog::GetInstance()->IsEnabled();
-  TRACE_EVENT0(kTraceCategory, "init");  // Add to trace-viewer category list.
   TraceLog::GetInstance()->AddEnabledStateObserver(this);
   if (is_tracing_already_enabled)
     OnTraceLogEnabled();
diff --git a/src/base/trace_event/memory_infra_background_whitelist.cc b/src/base/trace_event/memory_infra_background_whitelist.cc
index aed187f..c8ba4ed 100644
--- a/src/base/trace_event/memory_infra_background_whitelist.cc
+++ b/src/base/trace_event/memory_infra_background_whitelist.cc
@@ -17,20 +17,24 @@ namespace {
 // providers can be added here only if the background mode dump has very
 // less performance and memory overhead.
 const char* const kDumpProviderWhitelist[] = {
+    "android::ResourceManagerImpl",
     "BlinkGC",
     "ChildDiscardableSharedMemoryManager",
     "DOMStorage",
     "HostDiscardableSharedMemoryManager",
     "IndexedDBBackingStore",
     "JavaHeap",
+    "LevelDB",
     "LeveldbValueStore",
     "Malloc",
+    "MemoryCache",
     "PartitionAlloc",
     "ProcessMemoryMetrics",
     "Skia",
     "Sql",
     "V8Isolate",
     "WinHeap",
+    "SyncDirectory",
     nullptr  // End of list marker.
 };
 
@@ -46,6 +50,13 @@ const char* const kAllocatorDumpNameWhitelist[] = {
     "java_heap",
     "java_heap/allocated_objects",
     "leveldb/index_db/0x?",
+    "leveldb/leveldb_proto/0x?",
+    "leveldb/leveldb_proto/BudgetManager/0x?",
+    "leveldb/leveldb_proto/DomDistillerStore/0x?",
+    "leveldb/leveldb_proto/GCMKeyStore/0x?",
+    "leveldb/leveldb_proto/ImageManager/0x?",
+    "leveldb/leveldb_proto/NTPSnippetImages/0x?",
+    "leveldb/leveldb_proto/NTPSnippets/0x?",
     "leveldb/value_store/Extensions.Database.Open.Settings/0x?",
     "leveldb/value_store/Extensions.Database.Open.Rules/0x?",
     "leveldb/value_store/Extensions.Database.Open.State/0x?",
@@ -55,6 +66,12 @@ const char* const kAllocatorDumpNameWhitelist[] = {
     "malloc",
     "malloc/allocated_objects",
     "malloc/metadata_fragmentation_caches",
+    "web_cache/Image_resources",
+    "web_cache/CSS stylesheet_resources",
+    "web_cache/Script_resources",
+    "web_cache/XSL stylesheet_resources",
+    "web_cache/Font_resources",
+    "web_cache/Other_resources",
     "partition_alloc/allocated_objects",
     "partition_alloc/partitions",
     "partition_alloc/partitions/buffer",
@@ -63,6 +80,7 @@ const char* const kAllocatorDumpNameWhitelist[] = {
     "skia/sk_glyph_cache",
     "skia/sk_resource_cache",
     "sqlite",
+    "ui/resource_manager_0x?",
     "v8/isolate_0x?/heap_spaces",
     "v8/isolate_0x?/heap_spaces/code_space",
     "v8/isolate_0x?/heap_spaces/large_object_space",
@@ -74,6 +92,8 @@ const char* const kAllocatorDumpNameWhitelist[] = {
     "v8/isolate_0x?/zapped_for_debug",
     "winheap",
     "winheap/allocated_objects",
+    "sync/0x?/kernel",
+    "sync/0x?/store",
     nullptr  // End of list marker.
 };
 
diff --git a/src/base/trace_event/process_memory_dump.cc b/src/base/trace_event/process_memory_dump.cc
index 0714211..63d1340 100644
--- a/src/base/trace_event/process_memory_dump.cc
+++ b/src/base/trace_event/process_memory_dump.cc
@@ -18,7 +18,7 @@
 #include "build/build_config.h"
 
 #if defined(OS_IOS)
-#include <sys/sysctl.h>
+#include <mach/vm_page_size.h>
 #endif
 
 #if defined(OS_POSIX)
@@ -57,19 +57,13 @@ bool ProcessMemoryDump::is_black_hole_non_fatal_for_testing_ = false;
 size_t ProcessMemoryDump::GetSystemPageSize() {
 #if defined(OS_IOS)
   // On iOS, getpagesize() returns the user page sizes, but for allocating
-  // arrays for mincore(), kernel page sizes is needed. sysctlbyname() should
-  // be used for this. Refer to crbug.com/542671 and Apple rdar://23651782
-  int pagesize;
-  size_t pagesize_len;
-  int status = sysctlbyname("vm.pagesize", NULL, &pagesize_len, nullptr, 0);
-  if (!status && pagesize_len == sizeof(pagesize)) {
-    if (!sysctlbyname("vm.pagesize", &pagesize, &pagesize_len, nullptr, 0))
-      return pagesize;
-  }
-  LOG(ERROR) << "sysctlbyname(\"vm.pagesize\") failed.";
-  // Falls back to getpagesize() although it may be wrong in certain cases.
-#endif  // defined(OS_IOS)
+  // arrays for mincore(), kernel page sizes is needed. Use vm_kernel_page_size
+  // as recommended by Apple, https://forums.developer.apple.com/thread/47532/.
+  // Refer to http://crbug.com/542671 and Apple rdar://23651782
+  return vm_kernel_page_size;
+#else
   return base::GetPageSize();
+#endif  // defined(OS_IOS)
 }
 
 // static
diff --git a/src/base/trace_event/process_memory_dump.h b/src/base/trace_event/process_memory_dump.h
index d020c7d..6f8d167 100644
--- a/src/base/trace_event/process_memory_dump.h
+++ b/src/base/trace_event/process_memory_dump.h
@@ -31,7 +31,6 @@
 namespace base {
 namespace trace_event {
 
-class MemoryDumpManager;
 class MemoryDumpSessionState;
 class TracedValue;
 
diff --git a/src/base/trace_event/trace_config.cc b/src/base/trace_event/trace_config.cc
index 96c4dc7..9a17adb 100644
--- a/src/base/trace_event/trace_config.cc
+++ b/src/base/trace_event/trace_config.cc
@@ -30,13 +30,11 @@ const char kRecordUntilFull[] = "record-until-full";
 const char kRecordContinuously[] = "record-continuously";
 const char kRecordAsMuchAsPossible[] = "record-as-much-as-possible";
 const char kTraceToConsole[] = "trace-to-console";
-const char kEnableSampling[] = "enable-sampling";
 const char kEnableSystrace[] = "enable-systrace";
 const char kEnableArgumentFilter[] = "enable-argument-filter";
 
 // String parameters that can be used to parse the trace config string.
 const char kRecordModeParam[] = "record_mode";
-const char kEnableSamplingParam[] = "enable_sampling";
 const char kEnableSystraceParam[] = "enable_systrace";
 const char kEnableArgumentFilterParam[] = "enable_argument_filter";
 const char kIncludedCategoriesParam[] = "included_categories";
@@ -121,6 +119,17 @@ void TraceConfig::MemoryDumpConfig::Clear() {
   heap_profiler_options.Clear();
 }
 
+void TraceConfig::MemoryDumpConfig::Merge(
+    const TraceConfig::MemoryDumpConfig& config) {
+  triggers.insert(triggers.end(), config.triggers.begin(),
+                  config.triggers.end());
+  allowed_dump_modes.insert(config.allowed_dump_modes.begin(),
+                            config.allowed_dump_modes.end());
+  heap_profiler_options.breakdown_threshold_bytes =
+      std::min(heap_profiler_options.breakdown_threshold_bytes,
+               config.heap_profiler_options.breakdown_threshold_bytes);
+}
+
 TraceConfig::EventFilterConfig::EventFilterConfig(
     const std::string& predicate_name)
     : predicate_name_(predicate_name) {}
@@ -228,7 +237,6 @@ TraceConfig::TraceConfig(StringPiece config_string) {
 
 TraceConfig::TraceConfig(const TraceConfig& tc)
     : record_mode_(tc.record_mode_),
-      enable_sampling_(tc.enable_sampling_),
       enable_systrace_(tc.enable_systrace_),
       enable_argument_filter_(tc.enable_argument_filter_),
       memory_dump_config_(tc.memory_dump_config_),
@@ -246,7 +254,6 @@ TraceConfig& TraceConfig::operator=(const TraceConfig& rhs) {
     return *this;
 
   record_mode_ = rhs.record_mode_;
-  enable_sampling_ = rhs.enable_sampling_;
   enable_systrace_ = rhs.enable_systrace_;
   enable_argument_filter_ = rhs.enable_argument_filter_;
   memory_dump_config_ = rhs.memory_dump_config_;
@@ -342,7 +349,6 @@ bool TraceConfig::IsCategoryGroupEnabled(
 
 void TraceConfig::Merge(const TraceConfig& config) {
   if (record_mode_ != config.record_mode_
-      || enable_sampling_ != config.enable_sampling_
       || enable_systrace_ != config.enable_systrace_
       || enable_argument_filter_ != config.enable_argument_filter_) {
     DLOG(ERROR) << "Attempting to merge trace config with a different "
@@ -360,9 +366,7 @@ void TraceConfig::Merge(const TraceConfig& config) {
     included_categories_.clear();
   }
 
-  memory_dump_config_.triggers.insert(memory_dump_config_.triggers.end(),
-                             config.memory_dump_config_.triggers.begin(),
-                             config.memory_dump_config_.triggers.end());
+  memory_dump_config_.Merge(config.memory_dump_config_);
 
   disabled_categories_.insert(disabled_categories_.end(),
                               config.disabled_categories_.begin(),
@@ -373,11 +377,12 @@ void TraceConfig::Merge(const TraceConfig& config) {
   synthetic_delays_.insert(synthetic_delays_.end(),
                            config.synthetic_delays_.begin(),
                            config.synthetic_delays_.end());
+  event_filters_.insert(event_filters_.end(), config.event_filters().begin(),
+                        config.event_filters().end());
 }
 
 void TraceConfig::Clear() {
   record_mode_ = RECORD_UNTIL_FULL;
-  enable_sampling_ = false;
   enable_systrace_ = false;
   enable_argument_filter_ = false;
   included_categories_.clear();
@@ -390,7 +395,6 @@ void TraceConfig::Clear() {
 
 void TraceConfig::InitializeDefault() {
   record_mode_ = RECORD_UNTIL_FULL;
-  enable_sampling_ = false;
   enable_systrace_ = false;
   enable_argument_filter_ = false;
 }
@@ -411,7 +415,6 @@ void TraceConfig::InitializeFromConfigDict(const DictionaryValue& dict) {
   }
 
   bool val;
-  enable_sampling_ = dict.GetBoolean(kEnableSamplingParam, &val) ? val : false;
   enable_systrace_ = dict.GetBoolean(kEnableSystraceParam, &val) ? val : false;
   enable_argument_filter_ =
       dict.GetBoolean(kEnableArgumentFilterParam, &val) ? val : false;
@@ -424,6 +427,10 @@ void TraceConfig::InitializeFromConfigDict(const DictionaryValue& dict) {
   if (dict.GetList(kSyntheticDelaysParam, &category_list))
     SetSyntheticDelaysFromList(*category_list);
 
+  const base::ListValue* category_event_filters = nullptr;
+  if (dict.GetList(kEventFiltersParam, &category_event_filters))
+    SetEventFiltersFromConfigList(*category_event_filters);
+
   if (IsCategoryEnabled(MemoryDumpManager::kTraceCategory)) {
     // If dump triggers not set, the client is using the legacy with just
     // category enabled. So, use the default periodic dump config.
@@ -433,10 +440,6 @@ void TraceConfig::InitializeFromConfigDict(const DictionaryValue& dict) {
     else
       SetDefaultMemoryDumpConfig();
   }
-
-  const base::ListValue* category_event_filters = nullptr;
-  if (dict.GetList(kEventFiltersParam, &category_event_filters))
-    SetEventFilters(*category_event_filters);
 }
 
 void TraceConfig::InitializeFromConfigString(StringPiece config_string) {
@@ -482,7 +485,6 @@ void TraceConfig::InitializeFromStrings(StringPiece category_filter_string,
   }
 
   record_mode_ = RECORD_UNTIL_FULL;
-  enable_sampling_ = false;
   enable_systrace_ = false;
   enable_argument_filter_ = false;
   if (!trace_options_string.empty()) {
@@ -497,8 +499,6 @@ void TraceConfig::InitializeFromStrings(StringPiece category_filter_string,
         record_mode_ = ECHO_TO_CONSOLE;
       } else if (token == kRecordAsMuchAsPossible) {
         record_mode_ = RECORD_AS_MUCH_AS_POSSIBLE;
-      } else if (token == kEnableSampling) {
-        enable_sampling_ = true;
       } else if (token == kEnableSystrace) {
         enable_systrace_ = true;
       } else if (token == kEnableArgumentFilter) {
@@ -629,25 +629,9 @@ void TraceConfig::SetDefaultMemoryDumpConfig() {
   memory_dump_config_.triggers.push_back(kDefaultHeavyMemoryDumpTrigger);
   memory_dump_config_.triggers.push_back(kDefaultLightMemoryDumpTrigger);
   memory_dump_config_.allowed_dump_modes = GetDefaultAllowedMemoryDumpModes();
-
-  if (AllocationContextTracker::capture_mode() ==
-      AllocationContextTracker::CaptureMode::PSEUDO_STACK) {
-    for (const auto& filter : event_filters_) {
-      if (filter.predicate_name() ==
-          TraceLog::TraceEventFilter::kHeapProfilerPredicate)
-        return;
-    }
-    // Adds a filter predicate to filter all categories for the heap profiler.
-    // Note that the heap profiler predicate does not filter-out any events.
-    EventFilterConfig heap_profiler_config(
-        TraceLog::TraceEventFilter::kHeapProfilerPredicate);
-    heap_profiler_config.AddIncludedCategory("*");
-    heap_profiler_config.AddIncludedCategory(MemoryDumpManager::kTraceCategory);
-    event_filters_.push_back(heap_profiler_config);
-  }
 }
 
-void TraceConfig::SetEventFilters(
+void TraceConfig::SetEventFiltersFromConfigList(
     const base::ListValue& category_event_filters) {
   event_filters_.clear();
 
@@ -710,7 +694,6 @@ std::unique_ptr<DictionaryValue> TraceConfig::ToDict() const {
       NOTREACHED();
   }
 
-  dict->SetBoolean(kEnableSamplingParam, enable_sampling_);
   dict->SetBoolean(kEnableSystraceParam, enable_systrace_);
   dict->SetBoolean(kEnableArgumentFilterParam, enable_argument_filter_);
 
@@ -810,8 +793,6 @@ std::string TraceConfig::ToTraceOptionsString() const {
     default:
       NOTREACHED();
   }
-  if (enable_sampling_)
-    ret = ret + "," + kEnableSampling;
   if (enable_systrace_)
     ret = ret + "," + kEnableSystrace;
   if (enable_argument_filter_)
diff --git a/src/base/trace_event/trace_config.h b/src/base/trace_event/trace_config.h
index a5f8315..c10ed47 100644
--- a/src/base/trace_event/trace_config.h
+++ b/src/base/trace_event/trace_config.h
@@ -71,6 +71,8 @@ class BASE_EXPORT TraceConfig {
     // Reset the values in the config.
     void Clear();
 
+    void Merge(const MemoryDumpConfig& config);
+
     // Set of memory dump modes allowed for the tracing session. The explicitly
     // triggered dumps will be successful only if the dump mode is allowed in
     // the config.
@@ -125,22 +127,22 @@ class BASE_EXPORT TraceConfig {
   //
   // |trace_options_string| is a comma-delimited list of trace options.
   // Possible options are: "record-until-full", "record-continuously",
-  // "record-as-much-as-possible", "trace-to-console", "enable-sampling",
-  // "enable-systrace" and "enable-argument-filter".
+  // "record-as-much-as-possible", "trace-to-console", "enable-systrace" and
+  // "enable-argument-filter".
   // The first 4 options are trace recoding modes and hence
   // mutually exclusive. If more than one trace recording modes appear in the
   // options_string, the last one takes precedence. If none of the trace
   // recording mode is specified, recording mode is RECORD_UNTIL_FULL.
   //
   // The trace option will first be reset to the default option
-  // (record_mode set to RECORD_UNTIL_FULL, enable_sampling, enable_systrace,
-  // and enable_argument_filter set to false) before options parsed from
+  // (record_mode set to RECORD_UNTIL_FULL, enable_systrace and
+  // enable_argument_filter set to false) before options parsed from
   // |trace_options_string| are applied on it. If |trace_options_string| is
   // invalid, the final state of trace options is undefined.
   //
   // Example: TraceConfig("test_MyTest*", "record-until-full");
   // Example: TraceConfig("test_MyTest*,test_OtherStuff",
-  //                      "record-continuously, enable-sampling");
+  //                      "record-continuously");
   // Example: TraceConfig("-excluded_category1,-excluded_category2",
   //                      "record-until-full, trace-to-console");
   //          would set ECHO_TO_CONSOLE as the recording mode.
@@ -170,7 +172,6 @@ class BASE_EXPORT TraceConfig {
   // Example:
   //   {
   //     "record_mode": "record-continuously",
-  //     "enable_sampling": true,
   //     "enable_systrace": true,
   //     "enable_argument_filter": true,
   //     "included_categories": ["included",
@@ -206,12 +207,10 @@ class BASE_EXPORT TraceConfig {
   const StringList& GetSyntheticDelayValues() const;
 
   TraceRecordMode GetTraceRecordMode() const { return record_mode_; }
-  bool IsSamplingEnabled() const { return enable_sampling_; }
   bool IsSystraceEnabled() const { return enable_systrace_; }
   bool IsArgumentFilterEnabled() const { return enable_argument_filter_; }
 
   void SetTraceRecordMode(TraceRecordMode mode) { record_mode_ = mode; }
-  void EnableSampling() { enable_sampling_ = true; }
   void EnableSystrace() { enable_systrace_ = true; }
   void EnableArgumentFilter() { enable_argument_filter_ = true; }
 
@@ -243,6 +242,9 @@ class BASE_EXPORT TraceConfig {
   }
 
   const EventFilters& event_filters() const { return event_filters_; }
+  void SetEventFilters(const EventFilters& filter_configs) {
+    event_filters_ = filter_configs;
+  }
 
  private:
   FRIEND_TEST_ALL_PREFIXES(TraceConfigTest, TraceConfigFromValidLegacyFormat);
@@ -284,7 +286,7 @@ class BASE_EXPORT TraceConfig {
       const DictionaryValue& memory_dump_config);
   void SetDefaultMemoryDumpConfig();
 
-  void SetEventFilters(const base::ListValue& event_filters);
+  void SetEventFiltersFromConfigList(const base::ListValue& event_filters);
   std::unique_ptr<DictionaryValue> ToDict() const;
 
   std::string ToTraceOptionsString() const;
@@ -306,7 +308,6 @@ class BASE_EXPORT TraceConfig {
   bool HasIncludedPatterns() const;
 
   TraceRecordMode record_mode_;
-  bool enable_sampling_ : 1;
   bool enable_systrace_ : 1;
   bool enable_argument_filter_ : 1;
 
diff --git a/src/base/trace_event/trace_event.h b/src/base/trace_event/trace_event.h
index ffc5763..0299ddd 100644
--- a/src/base/trace_event/trace_event.h
+++ b/src/base/trace_event/trace_event.h
@@ -19,6 +19,7 @@
 #include "base/time/time.h"
 #include "base/trace_event/common/trace_event_common.h"
 #include "base/trace_event/heap_profiler.h"
+#include "base/trace_event/trace_category.h"
 #include "base/trace_event/trace_event_system_stats_monitor.h"
 #include "base/trace_event/trace_log.h"
 #include "build/build_config.h"
@@ -28,13 +29,16 @@
 #define TRACE_STR_COPY(str) \
     trace_event_internal::TraceStringWithCopy(str)
 
-// By default, uint64_t ID argument values are not mangled with the Process ID
-// in TRACE_EVENT_ASYNC macros. Use this macro to force Process ID mangling.
+// DEPRECATED: do not use: Consider using TRACE_ID_{GLOBAL, LOCAL} macros,
+// instead. By default, uint64_t ID argument values are not mangled with the
+// Process ID in TRACE_EVENT_ASYNC macros. Use this macro to force Process ID
+// mangling.
 #define TRACE_ID_MANGLE(id) \
     trace_event_internal::TraceID::ForceMangle(id)
 
-// By default, pointers are mangled with the Process ID in TRACE_EVENT_ASYNC
-// macros. Use this macro to prevent Process ID mangling.
+// DEPRECATED: do not use: Consider using TRACE_ID_{GLOBAL, LOCAL} macros,
+// instead. By default, pointers are mangled with the Process ID in
+// TRACE_EVENT_ASYNC macros. Use this macro to prevent Process ID mangling.
 #define TRACE_ID_DONT_MANGLE(id) \
     trace_event_internal::TraceID::DontMangle(id)
 
@@ -43,46 +47,22 @@
 #define TRACE_ID_WITH_SCOPE(scope, id) \
     trace_event_internal::TraceID::WithScope(scope, id)
 
-// Sets the current sample state to the given category and name (both must be
-// constant strings). These states are intended for a sampling profiler.
-// Implementation note: we store category and name together because we don't
-// want the inconsistency/expense of storing two pointers.
-// |thread_bucket| is [0..2] and is used to statically isolate samples in one
-// thread from others.
-#define TRACE_EVENT_SET_SAMPLING_STATE_FOR_BUCKET( \
-    bucket_number, category, name)                 \
-        trace_event_internal::                     \
-        TraceEventSamplingStateScope<bucket_number>::Set(category "\0" name)
-
-// Returns a current sampling state of the given bucket.
-#define TRACE_EVENT_GET_SAMPLING_STATE_FOR_BUCKET(bucket_number) \
-    trace_event_internal::TraceEventSamplingStateScope<bucket_number>::Current()
-
-// Creates a scope of a sampling state of the given bucket.
-//
-// {  // The sampling state is set within this scope.
-//    TRACE_EVENT_SAMPLING_STATE_SCOPE_FOR_BUCKET(0, "category", "name");
-//    ...;
-// }
-#define TRACE_EVENT_SCOPED_SAMPLING_STATE_FOR_BUCKET(                   \
-    bucket_number, category, name)                                      \
-    trace_event_internal::TraceEventSamplingStateScope<bucket_number>   \
-        traceEventSamplingScope(category "\0" name);
+#define TRACE_ID_GLOBAL(id) trace_event_internal::TraceID::GlobalId(id)
+#define TRACE_ID_LOCAL(id) trace_event_internal::TraceID::LocalId(id)
 
 #define TRACE_EVENT_API_CURRENT_THREAD_ID \
   static_cast<int>(base::PlatformThread::CurrentId())
 
 #define INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE() \
   UNLIKELY(*INTERNAL_TRACE_EVENT_UID(category_group_enabled) &           \
-           (base::trace_event::TraceLog::ENABLED_FOR_RECORDING |         \
-            base::trace_event::TraceLog::ENABLED_FOR_EVENT_CALLBACK |    \
-            base::trace_event::TraceLog::ENABLED_FOR_ETW_EXPORT |        \
-            base::trace_event::TraceLog::ENABLED_FOR_FILTERING))
+           (base::trace_event::TraceCategory::ENABLED_FOR_RECORDING |         \
+            base::trace_event::TraceCategory::ENABLED_FOR_ETW_EXPORT |        \
+            base::trace_event::TraceCategory::ENABLED_FOR_FILTERING))
 
 #define INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_FILTERING_MODE( \
     category_group_enabled)                                             \
   UNLIKELY(category_group_enabled&                                      \
-               base::trace_event::TraceLog::ENABLED_FOR_FILTERING)
+               base::trace_event::TraceCategory::ENABLED_FOR_FILTERING)
 
 ////////////////////////////////////////////////////////////////////////////////
 // Implementation specific tracing API definitions.
@@ -218,13 +198,6 @@
 // Defines visibility for classes in trace_event.h
 #define TRACE_EVENT_API_CLASS_EXPORT BASE_EXPORT
 
-// The thread buckets for the sampling profiler.
-TRACE_EVENT_API_CLASS_EXPORT extern \
-    TRACE_EVENT_API_ATOMIC_WORD g_trace_state[3];
-
-#define TRACE_EVENT_API_THREAD_BUCKET(thread_bucket)                           \
-    g_trace_state[thread_bucket]
-
 ////////////////////////////////////////////////////////////////////////////////
 
 // Implementation detail: trace event macros create temporary variables
@@ -292,38 +265,38 @@ TRACE_EVENT_API_CLASS_EXPORT extern \
           INTERNAL_TRACE_EVENT_UID(category_group_enabled), name, h); \
     }
 
-#define INTERNAL_TRACE_EVENT_ADD_SCOPED_WITH_FLOW( \
-    category_group, name, bind_id, flow_flags, ...) \
-  INTERNAL_TRACE_EVENT_GET_CATEGORY_INFO(category_group); \
-  trace_event_internal::ScopedTracer INTERNAL_TRACE_EVENT_UID(tracer); \
-  if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE()) { \
-    unsigned int trace_event_flags = flow_flags; \
-    trace_event_internal::TraceID trace_event_bind_id(bind_id, \
-                                                      &trace_event_flags); \
-    base::trace_event::TraceEventHandle h = \
-        trace_event_internal::AddTraceEvent( \
-            TRACE_EVENT_PHASE_COMPLETE, \
-            INTERNAL_TRACE_EVENT_UID(category_group_enabled), name, \
+#define INTERNAL_TRACE_EVENT_ADD_SCOPED_WITH_FLOW(                           \
+    category_group, name, bind_id, flow_flags, ...)                          \
+  INTERNAL_TRACE_EVENT_GET_CATEGORY_INFO(category_group);                    \
+  trace_event_internal::ScopedTracer INTERNAL_TRACE_EVENT_UID(tracer);       \
+  if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE()) {    \
+    trace_event_internal::TraceID trace_event_bind_id((bind_id));            \
+    unsigned int trace_event_flags = flow_flags |                            \
+                                     trace_event_bind_id.id_flags();         \
+    base::trace_event::TraceEventHandle h =                                  \
+        trace_event_internal::AddTraceEvent(                                 \
+            TRACE_EVENT_PHASE_COMPLETE,                                      \
+            INTERNAL_TRACE_EVENT_UID(category_group_enabled), name,          \
             trace_event_internal::kGlobalScope, trace_event_internal::kNoId, \
             trace_event_flags, trace_event_bind_id.raw_id(), ##__VA_ARGS__); \
-    INTERNAL_TRACE_EVENT_UID(tracer).Initialize( \
-        INTERNAL_TRACE_EVENT_UID(category_group_enabled), name, h); \
+    INTERNAL_TRACE_EVENT_UID(tracer).Initialize(                             \
+        INTERNAL_TRACE_EVENT_UID(category_group_enabled), name, h);          \
   }
 
 // Implementation detail: internal macro to create static category and add
 // event if the category is enabled.
-#define INTERNAL_TRACE_EVENT_ADD_WITH_ID(phase, category_group, name, id, \
-                                         flags, ...) \
-    do { \
-      INTERNAL_TRACE_EVENT_GET_CATEGORY_INFO(category_group); \
-      if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE()) { \
-        unsigned int trace_event_flags = flags | TRACE_EVENT_FLAG_HAS_ID; \
-        trace_event_internal::TraceID trace_event_trace_id( \
-            id, &trace_event_flags); \
-        trace_event_internal::AddTraceEvent( \
-            phase, INTERNAL_TRACE_EVENT_UID(category_group_enabled), \
+#define INTERNAL_TRACE_EVENT_ADD_WITH_ID(phase, category_group, name, id,      \
+                                         flags, ...)                           \
+    do {                                                                       \
+      INTERNAL_TRACE_EVENT_GET_CATEGORY_INFO(category_group);                  \
+      if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE()) {  \
+        trace_event_internal::TraceID trace_event_trace_id((id));              \
+        unsigned int trace_event_flags = flags |                               \
+                                         trace_event_trace_id.id_flags();      \
+        trace_event_internal::AddTraceEvent(                                   \
+            phase, INTERNAL_TRACE_EVENT_UID(category_group_enabled),           \
             name, trace_event_trace_id.scope(), trace_event_trace_id.raw_id(), \
-            trace_event_flags, trace_event_internal::kNoId, ##__VA_ARGS__); \
+            trace_event_flags, trace_event_internal::kNoId, ##__VA_ARGS__);    \
       } \
     } while (0)
 
@@ -338,53 +311,44 @@ TRACE_EVENT_API_CLASS_EXPORT extern \
           phase, INTERNAL_TRACE_EVENT_UID(category_group_enabled), name,     \
           trace_event_internal::kGlobalScope, trace_event_internal::kNoId,   \
           TRACE_EVENT_API_CURRENT_THREAD_ID,                                 \
-          base::TimeTicks::FromInternalValue(timestamp),                     \
-          flags | TRACE_EVENT_FLAG_EXPLICIT_TIMESTAMP,                       \
+          timestamp, flags | TRACE_EVENT_FLAG_EXPLICIT_TIMESTAMP,            \
           trace_event_internal::kNoId, ##__VA_ARGS__);                       \
     }                                                                        \
   } while (0)
 
 // Implementation detail: internal macro to create static category and add
 // event if the category is enabled.
-#define INTERNAL_TRACE_EVENT_ADD_WITH_ID_TID_AND_TIMESTAMP(                   \
-    phase, category_group, name, id, thread_id, timestamp, flags, ...)        \
-  do {                                                                        \
-    INTERNAL_TRACE_EVENT_GET_CATEGORY_INFO(category_group);                   \
-    if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE()) {   \
-      unsigned int trace_event_flags = flags | TRACE_EVENT_FLAG_HAS_ID;       \
-      trace_event_internal::TraceID trace_event_trace_id(id,                  \
-                                                         &trace_event_flags); \
-      trace_event_internal::AddTraceEventWithThreadIdAndTimestamp(            \
-          phase, INTERNAL_TRACE_EVENT_UID(category_group_enabled), name,      \
-          trace_event_trace_id.scope(), trace_event_trace_id.raw_id(),        \
-          thread_id, base::TimeTicks::FromInternalValue(timestamp),           \
-          trace_event_flags | TRACE_EVENT_FLAG_EXPLICIT_TIMESTAMP,            \
-          trace_event_internal::kNoId, ##__VA_ARGS__);                        \
-    }                                                                         \
+#define INTERNAL_TRACE_EVENT_ADD_WITH_ID_TID_AND_TIMESTAMP(                 \
+    phase, category_group, name, id, thread_id, timestamp, flags, ...)      \
+  do {                                                                      \
+    INTERNAL_TRACE_EVENT_GET_CATEGORY_INFO(category_group);                 \
+    if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE()) { \
+      trace_event_internal::TraceID trace_event_trace_id((id));             \
+      unsigned int trace_event_flags = flags |                              \
+                                       trace_event_trace_id.id_flags();     \
+      trace_event_internal::AddTraceEventWithThreadIdAndTimestamp(          \
+          phase, INTERNAL_TRACE_EVENT_UID(category_group_enabled), name,    \
+          trace_event_trace_id.scope(), trace_event_trace_id.raw_id(),      \
+          thread_id, timestamp,                                             \
+          trace_event_flags | TRACE_EVENT_FLAG_EXPLICIT_TIMESTAMP,          \
+          trace_event_internal::kNoId, ##__VA_ARGS__);                      \
+    }                                                                       \
   } while (0)
 
-// The trace ID and bind ID will never be mangled by this macro.
-#define INTERNAL_TRACE_EVENT_ADD_BIND_IDS(category_group, name, id, bind_id,  \
-                                          ...)                                \
+// The linked ID will not be mangled.
+#define INTERNAL_TRACE_EVENT_ADD_LINK_IDS(category_group, name, id1, id2)     \
     do {                                                                      \
       INTERNAL_TRACE_EVENT_GET_CATEGORY_INFO(category_group);                 \
       if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_RECORDING_MODE()) { \
-        trace_event_internal::TraceID::DontMangle source_id(id);              \
-        trace_event_internal::TraceID::DontMangle target_id(bind_id);         \
-        if (target_id.scope() == trace_event_internal::kGlobalScope) {        \
-          trace_event_internal::AddTraceEvent(                                \
-              TRACE_EVENT_PHASE_BIND_IDS,                                     \
-              INTERNAL_TRACE_EVENT_UID(category_group_enabled),               \
-              name, source_id.scope(), source_id.raw_id(),                    \
-              TRACE_EVENT_FLAG_HAS_ID, target_id.raw_id(), ##__VA_ARGS__);    \
-        } else {                                                              \
-          trace_event_internal::AddTraceEvent(                                \
-              TRACE_EVENT_PHASE_BIND_IDS,                                     \
-              INTERNAL_TRACE_EVENT_UID(category_group_enabled),               \
-              name, source_id.scope(), source_id.raw_id(),                    \
-              TRACE_EVENT_FLAG_HAS_ID, target_id.raw_id(),                    \
-              "bind_scope", target_id.scope(), ##__VA_ARGS__);                \
-        }                                                                     \
+        trace_event_internal::TraceID source_id((id1));                       \
+        unsigned int source_flags = source_id.id_flags();                     \
+        trace_event_internal::TraceID target_id((id2));                       \
+        trace_event_internal::AddTraceEvent(                                  \
+            TRACE_EVENT_PHASE_LINK_IDS,                                       \
+            INTERNAL_TRACE_EVENT_UID(category_group_enabled),                 \
+            name, source_id.scope(), source_id.raw_id(), source_flags,        \
+            trace_event_internal::kNoId,                                      \
+            "linked_id", target_id.AsConvertableToTraceFormat());             \
       }                                                                       \
     } while (0)
 
@@ -420,7 +384,7 @@ TRACE_EVENT_API_CLASS_EXPORT extern \
     void operator=(const INTERNAL_TRACE_EVENT_UID(ScopedContext)&) {};     \
   };                                                                       \
   INTERNAL_TRACE_EVENT_UID(ScopedContext)                                  \
-  INTERNAL_TRACE_EVENT_UID(scoped_context)(context.raw_id());
+  INTERNAL_TRACE_EVENT_UID(scoped_context)(context);
 
 // Implementation detail: internal macro to trace a task execution with the
 // location where it was posted from.
@@ -442,19 +406,48 @@ const unsigned long long kNoId = 0;
 // TraceID encapsulates an ID that can either be an integer or pointer. Pointers
 // are by default mangled with the Process ID so that they are unlikely to
 // collide when the same pointer is used on different processes.
-class TraceID {
+class BASE_EXPORT TraceID {
  public:
+  // Can be combined with WithScope.
+  class LocalId {
+   public:
+    explicit LocalId(unsigned long long raw_id) : raw_id_(raw_id) {}
+    unsigned long long raw_id() const { return raw_id_; }
+   private:
+    unsigned long long raw_id_;
+  };
+
+  // Can be combined with WithScope.
+  class GlobalId {
+   public:
+    explicit GlobalId(unsigned long long raw_id) : raw_id_(raw_id) {}
+    unsigned long long raw_id() const { return raw_id_; }
+   private:
+    unsigned long long raw_id_;
+  };
+
   class WithScope {
    public:
     WithScope(const char* scope, unsigned long long raw_id)
         : scope_(scope), raw_id_(raw_id) {}
+    WithScope(const char* scope, LocalId local_id)
+        : scope_(scope), raw_id_(local_id.raw_id()) {
+      id_flags_ = TRACE_EVENT_FLAG_HAS_LOCAL_ID;
+    }
+    WithScope(const char* scope, GlobalId global_id)
+        : scope_(scope), raw_id_(global_id.raw_id()) {
+      id_flags_ = TRACE_EVENT_FLAG_HAS_GLOBAL_ID;
+    }
     unsigned long long raw_id() const { return raw_id_; }
     const char* scope() const { return scope_; }
+    unsigned int id_flags() const { return id_flags_; }
    private:
     const char* scope_ = nullptr;
     unsigned long long raw_id_;
+    unsigned int id_flags_ = TRACE_EVENT_FLAG_HAS_ID;
   };
 
+  // DEPRECATED: consider using LocalId or GlobalId, instead.
   class DontMangle {
    public:
     explicit DontMangle(const void* raw_id)
@@ -475,15 +468,12 @@ class TraceID {
         : raw_id_(static_cast<unsigned long long>(raw_id)) {}
     explicit DontMangle(signed char raw_id)
         : raw_id_(static_cast<unsigned long long>(raw_id)) {}
-    explicit DontMangle(WithScope scoped_id)
-        : scope_(scoped_id.scope()), raw_id_(scoped_id.raw_id()) {}
-    const char* scope() const { return scope_; }
     unsigned long long raw_id() const { return raw_id_; }
    private:
-    const char* scope_ = nullptr;
     unsigned long long raw_id_;
   };
 
+  // DEPRECATED: consider using LocalId or GlobalId, instead.
   class ForceMangle {
    public:
     explicit ForceMangle(unsigned long long raw_id) : raw_id_(raw_id) {}
@@ -505,51 +495,50 @@ class TraceID {
    private:
     unsigned long long raw_id_;
   };
-  TraceID(const void* raw_id, unsigned int* flags)
-      : raw_id_(static_cast<unsigned long long>(
-                reinterpret_cast<uintptr_t>(raw_id))) {
-    *flags |= TRACE_EVENT_FLAG_MANGLE_ID;
-  }
-  TraceID(ForceMangle raw_id, unsigned int* flags) : raw_id_(raw_id.raw_id()) {
-    *flags |= TRACE_EVENT_FLAG_MANGLE_ID;
-  }
-  TraceID(DontMangle maybe_scoped_id, unsigned int* flags)
-      : scope_(maybe_scoped_id.scope()), raw_id_(maybe_scoped_id.raw_id()) {
-  }
-  TraceID(unsigned long long raw_id, unsigned int* flags) : raw_id_(raw_id) {
-    (void)flags;
-  }
-  TraceID(unsigned long raw_id, unsigned int* flags) : raw_id_(raw_id) {
-    (void)flags;
+
+  TraceID(const void* raw_id) : raw_id_(static_cast<unsigned long long>(
+                                        reinterpret_cast<uintptr_t>(raw_id))) {
+    id_flags_ = TRACE_EVENT_FLAG_HAS_ID | TRACE_EVENT_FLAG_MANGLE_ID;
   }
-  TraceID(unsigned int raw_id, unsigned int* flags) : raw_id_(raw_id) {
-    (void)flags;
+  TraceID(ForceMangle raw_id) : raw_id_(raw_id.raw_id()) {
+    id_flags_ = TRACE_EVENT_FLAG_HAS_ID | TRACE_EVENT_FLAG_MANGLE_ID;
   }
-  TraceID(unsigned short raw_id, unsigned int* flags) : raw_id_(raw_id) {
-    (void)flags;
+  TraceID(DontMangle raw_id) : raw_id_(raw_id.raw_id()) {}
+  TraceID(unsigned long long raw_id) : raw_id_(raw_id) {}
+  TraceID(unsigned long raw_id) : raw_id_(raw_id) {}
+  TraceID(unsigned int raw_id) : raw_id_(raw_id) {}
+  TraceID(unsigned short raw_id) : raw_id_(raw_id) {}
+  TraceID(unsigned char raw_id) : raw_id_(raw_id) {}
+  TraceID(long long raw_id)
+      : raw_id_(static_cast<unsigned long long>(raw_id)) {}
+  TraceID(long raw_id)
+      : raw_id_(static_cast<unsigned long long>(raw_id)) {}
+  TraceID(int raw_id)
+      : raw_id_(static_cast<unsigned long long>(raw_id)) {}
+  TraceID(short raw_id)
+      : raw_id_(static_cast<unsigned long long>(raw_id)) {}
+  TraceID(signed char raw_id)
+      : raw_id_(static_cast<unsigned long long>(raw_id)) {}
+  TraceID(LocalId raw_id) : raw_id_(raw_id.raw_id()) {
+    id_flags_ = TRACE_EVENT_FLAG_HAS_LOCAL_ID;
   }
-  TraceID(unsigned char raw_id, unsigned int* flags) : raw_id_(raw_id) {
-    (void)flags;
+  TraceID(GlobalId raw_id) : raw_id_(raw_id.raw_id()) {
+    id_flags_ = TRACE_EVENT_FLAG_HAS_GLOBAL_ID;
   }
-  TraceID(long long raw_id, unsigned int* flags)
-      : raw_id_(static_cast<unsigned long long>(raw_id)) { (void)flags; }
-  TraceID(long raw_id, unsigned int* flags)
-      : raw_id_(static_cast<unsigned long long>(raw_id)) { (void)flags; }
-  TraceID(int raw_id, unsigned int* flags)
-      : raw_id_(static_cast<unsigned long long>(raw_id)) { (void)flags; }
-  TraceID(short raw_id, unsigned int* flags)
-      : raw_id_(static_cast<unsigned long long>(raw_id)) { (void)flags; }
-  TraceID(signed char raw_id, unsigned int* flags)
-      : raw_id_(static_cast<unsigned long long>(raw_id)) { (void)flags; }
-  TraceID(WithScope scoped_id, unsigned int* flags)
-      : scope_(scoped_id.scope()), raw_id_(scoped_id.raw_id()) {}
+  TraceID(WithScope scoped_id) : scope_(scoped_id.scope()),
+      raw_id_(scoped_id.raw_id()), id_flags_(scoped_id.id_flags()) {}
 
   unsigned long long raw_id() const { return raw_id_; }
   const char* scope() const { return scope_; }
+  unsigned int id_flags() const { return id_flags_; }
+
+  std::unique_ptr<base::trace_event::ConvertableToTraceFormat>
+  AsConvertableToTraceFormat() const;
 
  private:
   const char* scope_ = nullptr;
   unsigned long long raw_id_;
+  unsigned int id_flags_ = TRACE_EVENT_FLAG_HAS_ID;
 };
 
 // Simple union to store various types as unsigned long long.
@@ -1016,11 +1005,6 @@ class TRACE_EVENT_API_CLASS_EXPORT ScopedTracer {
     if (p_data_ && *data_.category_group_enabled) {
       TRACE_EVENT_API_UPDATE_TRACE_EVENT_DURATION(
           data_.category_group_enabled, data_.name, data_.event_handle);
-      if (INTERNAL_TRACE_EVENT_CATEGORY_GROUP_ENABLED_FOR_FILTERING_MODE(
-              *data_.category_group_enabled)) {
-        TRACE_EVENT_API_END_FILTERED_EVENT(data_.category_group_enabled,
-                                           data_.name, data_.event_handle);
-      }
     }
   }
 
@@ -1069,37 +1053,6 @@ class TRACE_EVENT_API_CLASS_EXPORT ScopedTraceBinaryEfficient {
     trace_event_internal::ScopedTraceBinaryEfficient \
         INTERNAL_TRACE_EVENT_UID(scoped_trace)(category_group, name);
 
-// TraceEventSamplingStateScope records the current sampling state
-// and sets a new sampling state. When the scope exists, it restores
-// the sampling state having recorded.
-template<size_t BucketNumber>
-class TraceEventSamplingStateScope {
- public:
-  TraceEventSamplingStateScope(const char* category_and_name) {
-    previous_state_ = TraceEventSamplingStateScope<BucketNumber>::Current();
-    TraceEventSamplingStateScope<BucketNumber>::Set(category_and_name);
-  }
-
-  ~TraceEventSamplingStateScope() {
-    TraceEventSamplingStateScope<BucketNumber>::Set(previous_state_);
-  }
-
-  static inline const char* Current() {
-    return reinterpret_cast<const char*>(TRACE_EVENT_API_ATOMIC_LOAD(
-      g_trace_state[BucketNumber]));
-  }
-
-  static inline void Set(const char* category_and_name) {
-    TRACE_EVENT_API_ATOMIC_STORE(
-      g_trace_state[BucketNumber],
-      reinterpret_cast<TRACE_EVENT_API_ATOMIC_WORD>(
-        const_cast<char*>(category_and_name)));
-  }
-
- private:
-  const char* previous_state_;
-};
-
 }  // namespace trace_event_internal
 
 namespace base {
diff --git a/src/base/trace_event/trace_event_argument.cc b/src/base/trace_event/trace_event_argument.cc
index 336d964..da33c6d 100644
--- a/src/base/trace_event/trace_event_argument.cc
+++ b/src/base/trace_event/trace_event_argument.cc
@@ -244,36 +244,36 @@ void TracedValue::SetBaseValueWithCopiedName(base::StringPiece name,
                                              const base::Value& value) {
   DCHECK_CURRENT_CONTAINER_IS(kStackTypeDict);
   switch (value.GetType()) {
-    case base::Value::TYPE_NULL:
-    case base::Value::TYPE_BINARY:
+    case base::Value::Type::NONE:
+    case base::Value::Type::BINARY:
       NOTREACHED();
       break;
 
-    case base::Value::TYPE_BOOLEAN: {
+    case base::Value::Type::BOOLEAN: {
       bool bool_value;
       value.GetAsBoolean(&bool_value);
       SetBooleanWithCopiedName(name, bool_value);
     } break;
 
-    case base::Value::TYPE_INTEGER: {
+    case base::Value::Type::INTEGER: {
       int int_value;
       value.GetAsInteger(&int_value);
       SetIntegerWithCopiedName(name, int_value);
     } break;
 
-    case base::Value::TYPE_DOUBLE: {
+    case base::Value::Type::DOUBLE: {
       double double_value;
       value.GetAsDouble(&double_value);
       SetDoubleWithCopiedName(name, double_value);
     } break;
 
-    case base::Value::TYPE_STRING: {
+    case base::Value::Type::STRING: {
       const StringValue* string_value;
       value.GetAsString(&string_value);
       SetStringWithCopiedName(name, string_value->GetString());
     } break;
 
-    case base::Value::TYPE_DICTIONARY: {
+    case base::Value::Type::DICTIONARY: {
       const DictionaryValue* dict_value;
       value.GetAsDictionary(&dict_value);
       BeginDictionaryWithCopiedName(name);
@@ -284,7 +284,7 @@ void TracedValue::SetBaseValueWithCopiedName(base::StringPiece name,
       EndDictionary();
     } break;
 
-    case base::Value::TYPE_LIST: {
+    case base::Value::Type::LIST: {
       const ListValue* list_value;
       value.GetAsList(&list_value);
       BeginArrayWithCopiedName(name);
@@ -298,36 +298,36 @@ void TracedValue::SetBaseValueWithCopiedName(base::StringPiece name,
 void TracedValue::AppendBaseValue(const base::Value& value) {
   DCHECK_CURRENT_CONTAINER_IS(kStackTypeArray);
   switch (value.GetType()) {
-    case base::Value::TYPE_NULL:
-    case base::Value::TYPE_BINARY:
+    case base::Value::Type::NONE:
+    case base::Value::Type::BINARY:
       NOTREACHED();
       break;
 
-    case base::Value::TYPE_BOOLEAN: {
+    case base::Value::Type::BOOLEAN: {
       bool bool_value;
       value.GetAsBoolean(&bool_value);
       AppendBoolean(bool_value);
     } break;
 
-    case base::Value::TYPE_INTEGER: {
+    case base::Value::Type::INTEGER: {
       int int_value;
       value.GetAsInteger(&int_value);
       AppendInteger(int_value);
     } break;
 
-    case base::Value::TYPE_DOUBLE: {
+    case base::Value::Type::DOUBLE: {
       double double_value;
       value.GetAsDouble(&double_value);
       AppendDouble(double_value);
     } break;
 
-    case base::Value::TYPE_STRING: {
+    case base::Value::Type::STRING: {
       const StringValue* string_value;
       value.GetAsString(&string_value);
       AppendString(string_value->GetString());
     } break;
 
-    case base::Value::TYPE_DICTIONARY: {
+    case base::Value::Type::DICTIONARY: {
       const DictionaryValue* dict_value;
       value.GetAsDictionary(&dict_value);
       BeginDictionary();
@@ -338,7 +338,7 @@ void TracedValue::AppendBaseValue(const base::Value& value) {
       EndDictionary();
     } break;
 
-    case base::Value::TYPE_LIST: {
+    case base::Value::Type::LIST: {
       const ListValue* list_value;
       value.GetAsList(&list_value);
       BeginArray();
diff --git a/src/base/trace_event/trace_event_impl.cc b/src/base/trace_event/trace_event_impl.cc
index 510cc2f..f9792d0 100644
--- a/src/base/trace_event/trace_event_impl.cc
+++ b/src/base/trace_event/trace_event_impl.cc
@@ -8,6 +8,7 @@
 
 #include "base/format_macros.h"
 #include "base/json/string_escape.h"
+#include "base/memory/ptr_util.h"
 #include "base/process/process_handle.h"
 #include "base/stl_util.h"
 #include "base/strings/string_number_conversions.h"
@@ -15,6 +16,7 @@
 #include "base/strings/stringprintf.h"
 #include "base/strings/utf_string_conversions.h"
 #include "base/trace_event/trace_event.h"
+#include "base/trace_event/trace_event_argument.h"
 #include "base/trace_event/trace_log.h"
 
 namespace base {
@@ -358,18 +360,40 @@ void TraceEvent::AppendAsJSON(
 
   // If id_ is set, print it out as a hex string so we don't loose any
   // bits (it might be a 64-bit pointer).
-  if (flags_ & TRACE_EVENT_FLAG_HAS_ID) {
+  unsigned int id_flags_ = flags_ & (TRACE_EVENT_FLAG_HAS_ID |
+                                     TRACE_EVENT_FLAG_HAS_LOCAL_ID |
+                                     TRACE_EVENT_FLAG_HAS_GLOBAL_ID);
+  if (id_flags_) {
     if (scope_ != trace_event_internal::kGlobalScope)
       StringAppendF(out, ",\"scope\":\"%s\"", scope_);
-    StringAppendF(out, ",\"id\":\"0x%" PRIx64 "\"", static_cast<uint64_t>(id_));
+
+    switch (id_flags_) {
+      case TRACE_EVENT_FLAG_HAS_ID:
+        StringAppendF(out, ",\"id\":\"0x%" PRIx64 "\"",
+                      static_cast<uint64_t>(id_));
+        break;
+
+      case TRACE_EVENT_FLAG_HAS_LOCAL_ID:
+        StringAppendF(out, ",\"id2\":{\"local\":\"0x%" PRIx64 "\"}",
+                      static_cast<uint64_t>(id_));
+        break;
+
+      case TRACE_EVENT_FLAG_HAS_GLOBAL_ID:
+        StringAppendF(out, ",\"id2\":{\"global\":\"0x%" PRIx64 "\"}",
+                      static_cast<uint64_t>(id_));
+        break;
+
+      default:
+        NOTREACHED() << "More than one of the ID flags are set";
+        break;
+    }
   }
 
   if (flags_ & TRACE_EVENT_FLAG_BIND_TO_ENCLOSING)
     StringAppendF(out, ",\"bp\":\"e\"");
 
   if ((flags_ & TRACE_EVENT_FLAG_FLOW_OUT) ||
-      (flags_ & TRACE_EVENT_FLAG_FLOW_IN) ||
-      phase_ == TRACE_EVENT_PHASE_BIND_IDS) {
+      (flags_ & TRACE_EVENT_FLAG_FLOW_IN)) {
     StringAppendF(out, ",\"bind_id\":\"0x%" PRIx64 "\"",
                   static_cast<uint64_t>(bind_id_));
   }
@@ -425,3 +449,40 @@ void TraceEvent::AppendPrettyPrinted(std::ostringstream* out) const {
 
 }  // namespace trace_event
 }  // namespace base
+
+namespace trace_event_internal {
+
+std::unique_ptr<base::trace_event::ConvertableToTraceFormat>
+TraceID::AsConvertableToTraceFormat() const {
+  auto value = base::MakeUnique<base::trace_event::TracedValue>();
+
+  if (scope_ != kGlobalScope)
+    value->SetString("scope", scope_);
+  switch (id_flags_) {
+    case TRACE_EVENT_FLAG_HAS_ID:
+      value->SetString(
+          "id",
+          base::StringPrintf("0x%" PRIx64, static_cast<uint64_t>(raw_id_)));
+      break;
+    case TRACE_EVENT_FLAG_HAS_GLOBAL_ID:
+      value->BeginDictionary("id2");
+      value->SetString(
+          "global",
+          base::StringPrintf("0x%" PRIx64, static_cast<uint64_t>(raw_id_)));
+      value->EndDictionary();
+      break;
+    case TRACE_EVENT_FLAG_HAS_LOCAL_ID:
+      value->BeginDictionary("id2");
+      value->SetString(
+          "local",
+          base::StringPrintf("0x%" PRIx64, static_cast<uint64_t>(raw_id_)));
+      value->EndDictionary();
+      break;
+    default:
+      NOTREACHED() << "Unrecognized ID flag";
+  }
+
+  return std::move(value);
+}
+
+}  // namespace trace_event_internal
diff --git a/src/base/trace_event/trace_event_impl.h b/src/base/trace_event/trace_event_impl.h
index 4382217..5eef702 100644
--- a/src/base/trace_event/trace_event_impl.h
+++ b/src/base/trace_event/trace_event_impl.h
@@ -23,16 +23,11 @@
 #include "base/strings/string_util.h"
 #include "base/synchronization/condition_variable.h"
 #include "base/synchronization/lock.h"
-#include "base/threading/thread.h"
 #include "base/threading/thread_local.h"
 #include "base/trace_event/trace_event_memory_overhead.h"
 #include "build/build_config.h"
 
 namespace base {
-
-class WaitableEvent;
-class MessageLoop;
-
 namespace trace_event {
 
 typedef base::Callback<bool(const char* arg_name)> ArgumentNameFilterPredicate;
diff --git a/src/base/trace_event/trace_event_memory_overhead.cc b/src/base/trace_event/trace_event_memory_overhead.cc
index 23579cb..48a0d29 100644
--- a/src/base/trace_event/trace_event_memory_overhead.cc
+++ b/src/base/trace_event/trace_event_memory_overhead.cc
@@ -69,27 +69,27 @@ void TraceEventMemoryOverhead::AddRefCountedString(
 
 void TraceEventMemoryOverhead::AddValue(const Value& value) {
   switch (value.GetType()) {
-    case Value::TYPE_NULL:
-    case Value::TYPE_BOOLEAN:
-    case Value::TYPE_INTEGER:
-    case Value::TYPE_DOUBLE:
+    case Value::Type::NONE:
+    case Value::Type::BOOLEAN:
+    case Value::Type::INTEGER:
+    case Value::Type::DOUBLE:
       Add("FundamentalValue", sizeof(Value));
       break;
 
-    case Value::TYPE_STRING: {
+    case Value::Type::STRING: {
       const StringValue* string_value = nullptr;
       value.GetAsString(&string_value);
       Add("StringValue", sizeof(StringValue));
       AddString(string_value->GetString());
     } break;
 
-    case Value::TYPE_BINARY: {
+    case Value::Type::BINARY: {
       const BinaryValue* binary_value = nullptr;
       value.GetAsBinary(&binary_value);
       Add("BinaryValue", sizeof(BinaryValue) + binary_value->GetSize());
     } break;
 
-    case Value::TYPE_DICTIONARY: {
+    case Value::Type::DICTIONARY: {
       const DictionaryValue* dictionary_value = nullptr;
       value.GetAsDictionary(&dictionary_value);
       Add("DictionaryValue", sizeof(DictionaryValue));
@@ -100,7 +100,7 @@ void TraceEventMemoryOverhead::AddValue(const Value& value) {
       }
     } break;
 
-    case Value::TYPE_LIST: {
+    case Value::Type::LIST: {
       const ListValue* list_value = nullptr;
       value.GetAsList(&list_value);
       Add("ListValue", sizeof(ListValue));
diff --git a/src/base/trace_event/trace_event_synthetic_delay.h b/src/base/trace_event/trace_event_synthetic_delay.h
index 59e2842..e86f9ee 100644
--- a/src/base/trace_event/trace_event_synthetic_delay.h
+++ b/src/base/trace_event/trace_event_synthetic_delay.h
@@ -62,9 +62,6 @@
     trace_event_internal::GetOrCreateDelay(name, &impl_ptr)->End();   \
   } while (false)
 
-template <typename Type>
-struct DefaultSingletonTraits;
-
 namespace base {
 namespace trace_event {
 
diff --git a/src/base/trace_event/trace_log.cc b/src/base/trace_event/trace_log.cc
index 1a9af14..4b21437 100644
--- a/src/base/trace_event/trace_log.cc
+++ b/src/base/trace_event/trace_log.cc
@@ -19,18 +19,19 @@
 #include "base/memory/ptr_util.h"
 #include "base/memory/ref_counted_memory.h"
 #include "base/memory/singleton.h"
+#include "base/message_loop/message_loop.h"
 #include "base/process/process_metrics.h"
 #include "base/stl_util.h"
 #include "base/strings/string_split.h"
 #include "base/strings/string_tokenizer.h"
 #include "base/strings/stringprintf.h"
 #include "base/sys_info.h"
-#include "base/third_party/dynamic_annotations/dynamic_annotations.h"
 #include "base/threading/platform_thread.h"
 #include "base/threading/thread_id_name_manager.h"
 #include "base/threading/thread_task_runner_handle.h"
 #include "base/threading/worker_pool.h"
 #include "base/time/time.h"
+#include "base/trace_event/category_registry.h"
 #include "base/trace_event/heap_profiler.h"
 #include "base/trace_event/heap_profiler_allocation_context_tracker.h"
 #include "base/trace_event/memory_dump_manager.h"
@@ -39,16 +40,12 @@
 #include "base/trace_event/trace_buffer.h"
 #include "base/trace_event/trace_event.h"
 #include "base/trace_event/trace_event_synthetic_delay.h"
-#include "base/trace_event/trace_sampling_thread.h"
 #include "build/build_config.h"
 
 #if defined(OS_WIN)
 #include "base/trace_event/trace_event_etw_export_win.h"
 #endif
 
-// The thread buckets for the sampling profiler.
-BASE_EXPORT TRACE_EVENT_API_ATOMIC_WORD g_trace_state[3];
-
 namespace base {
 namespace internal {
 
@@ -87,24 +84,13 @@ const size_t kEchoToConsoleTraceEventBufferChunks = 256;
 const size_t kTraceEventBufferSizeInBytes = 100 * 1024;
 const int kThreadFlushTimeoutMs = 3000;
 
-#define MAX_CATEGORY_GROUPS 200
-
-// Parallel arrays g_category_groups and g_category_group_enabled are separate
-// so that a pointer to a member of g_category_group_enabled can be easily
-// converted to an index into g_category_groups. This allows macros to deal
-// only with char enabled pointers from g_category_group_enabled, and we can
-// convert internally to determine the category name from the char enabled
-// pointer.
-const char* g_category_groups[MAX_CATEGORY_GROUPS] = {
-    "toplevel",
-    "tracing already shutdown",
-    "tracing categories exhausted; must increase MAX_CATEGORY_GROUPS",
-    "__metadata"};
+const char kEventNameWhitelist[] = "event_name_whitelist";
 
-// The enabled flag is char instead of bool so that the API can be used from C.
-unsigned char g_category_group_enabled[MAX_CATEGORY_GROUPS] = {0};
+#define MAX_TRACE_EVENT_FILTERS 32
 
-const char kEventNameWhitelist[] = "event_name_whitelist";
+// List of TraceEventFilter objects from the most recent tracing session.
+base::LazyInstance<std::vector<std::unique_ptr<TraceLog::TraceEventFilter>>>::
+    Leaky g_category_group_filters = LAZY_INSTANCE_INITIALIZER;
 
 class EventNameFilter : public TraceLog::TraceEventFilter {
  public:
@@ -129,10 +115,6 @@ class EventNameFilter : public TraceLog::TraceEventFilter {
   std::unordered_set<std::string> whitelist_;
 };
 
-base::LazyInstance<
-    std::list<std::unique_ptr<TraceLog::TraceEventFilter>>>::Leaky
-    g_category_group_filter[MAX_CATEGORY_GROUPS] = {LAZY_INSTANCE_INITIALIZER};
-
 // This filter is used to record trace events as pseudo stack for the heap
 // profiler. It does not filter-out any events from the trace, ie. the behavior
 // of trace events being added to TraceLog remains same: the events are added
@@ -179,14 +161,6 @@ class HeapProfilerFilter : public TraceLog::TraceEventFilter {
 TraceLog::TraceEventFilterConstructorForTesting
     g_trace_event_filter_constructor_for_testing = nullptr;
 
-// Indexes here have to match the g_category_groups array indexes above.
-const int kCategoryAlreadyShutdown = 1;
-const int kCategoryCategoriesExhausted = 2;
-const int kCategoryMetadata = 3;
-const int kNumBuiltinCategories = 4;
-// Skip default categories.
-base::subtle::AtomicWord g_category_index = kNumBuiltinCategories;
-
 // The name of the current thread. This is used to decide if the current
 // thread name has changed. We combine all the seen thread names into the
 // output name for the thread.
@@ -215,7 +189,7 @@ void InitializeMetadataEvent(TraceEvent* trace_event,
       TimeTicks(),
       ThreadTicks(),
       TRACE_EVENT_PHASE_METADATA,
-      &g_category_group_enabled[kCategoryMetadata],
+      CategoryRegistry::kCategoryMetadata->state_ptr(),
       metadata_name,
       trace_event_internal::kGlobalScope,  // scope
       trace_event_internal::kNoId,  // id
@@ -257,20 +231,19 @@ void MakeHandle(uint32_t chunk_seq,
   handle->event_index = static_cast<uint16_t>(event_index);
 }
 
-uintptr_t GetCategoryIndex(const unsigned char* category_group_enabled) {
-  // Calculate the index of the category group by finding
-  // category_group_enabled in g_category_group_enabled array.
-  uintptr_t category_begin =
-      reinterpret_cast<uintptr_t>(g_category_group_enabled);
-  uintptr_t category_ptr = reinterpret_cast<uintptr_t>(category_group_enabled);
-  DCHECK(category_ptr >= category_begin);
-  DCHECK(category_ptr < reinterpret_cast<uintptr_t>(g_category_group_enabled +
-                                                    MAX_CATEGORY_GROUPS))
-      << "out of bounds category pointer";
-  uintptr_t category_index =
-      (category_ptr - category_begin) / sizeof(g_category_group_enabled[0]);
-
-  return category_index;
+template <typename Function>
+void ForEachCategoryGroupFilter(const unsigned char* category_group_enabled,
+                                Function filter_fn) {
+  const TraceCategory* category =
+      CategoryRegistry::GetCategoryByStatePtr(category_group_enabled);
+  uint32_t filter_bitmap = category->enabled_filters();
+  int index = 0;
+  while (filter_bitmap) {
+    if (filter_bitmap & 1 && g_category_group_filters.Get()[index])
+      filter_fn(g_category_group_filters.Get()[index].get());
+    filter_bitmap = filter_bitmap >> 1;
+    index++;
+  }
 }
 
 }  // namespace
@@ -446,33 +419,19 @@ TraceLog* TraceLog::GetInstance() {
 }
 
 TraceLog::TraceLog()
-    : mode_(DISABLED),
+    : enabled_modes_(0),
       num_traces_recorded_(0),
-      event_callback_(0),
       dispatching_to_observer_list_(false),
       process_sort_index_(0),
       process_id_hash_(0),
       process_id_(0),
-      watch_category_(0),
       trace_options_(kInternalRecordUntilFull),
-      sampling_thread_handle_(0),
       trace_config_(TraceConfig()),
-      event_callback_trace_config_(TraceConfig()),
       thread_shared_chunk_index_(0),
       generation_(0),
       use_worker_thread_(false) {
-  // Trace is enabled or disabled on one thread while other threads are
-  // accessing the enabled flag. We don't care whether edge-case events are
-  // traced or not, so we allow races on the enabled flag to keep the trace
-  // macros fast.
-  // TODO(jbates): ANNOTATE_BENIGN_RACE_SIZED crashes windows TSAN bots:
-  // ANNOTATE_BENIGN_RACE_SIZED(g_category_group_enabled,
-  //                            sizeof(g_category_group_enabled),
-  //                           "trace_event category enabled");
-  for (int i = 0; i < MAX_CATEGORY_GROUPS; ++i) {
-    ANNOTATE_BENIGN_RACE(&g_category_group_enabled[i],
-                         "trace_event category enabled");
-  }
+  CategoryRegistry::Initialize();
+
 #if defined(OS_NACL)  // NaCl shouldn't expose the process id.
   SetProcessID(0);
 #else
@@ -531,84 +490,109 @@ const unsigned char* TraceLog::GetCategoryGroupEnabled(
     const char* category_group) {
   TraceLog* tracelog = GetInstance();
   if (!tracelog) {
-    DCHECK(!g_category_group_enabled[kCategoryAlreadyShutdown]);
-    return &g_category_group_enabled[kCategoryAlreadyShutdown];
+    DCHECK(!CategoryRegistry::kCategoryAlreadyShutdown->is_enabled());
+    return CategoryRegistry::kCategoryAlreadyShutdown->state_ptr();
+  }
+  TraceCategory* category = CategoryRegistry::GetCategoryByName(category_group);
+  if (!category) {
+    // Slow path: in the case of a new category we have to repeat the check
+    // holding the lock, as multiple threads might have reached this point
+    // at the same time.
+    auto category_initializer = [](TraceCategory* category) {
+      TraceLog::GetInstance()->UpdateCategoryState(category);
+    };
+    AutoLock lock(tracelog->lock_);
+    CategoryRegistry::GetOrCreateCategoryLocked(
+        category_group, category_initializer, &category);
   }
-  return tracelog->GetCategoryGroupEnabledInternal(category_group);
+  DCHECK(category->state_ptr());
+  return category->state_ptr();
 }
 
 const char* TraceLog::GetCategoryGroupName(
     const unsigned char* category_group_enabled) {
-  return g_category_groups[GetCategoryIndex(category_group_enabled)];
-}
-
-std::list<std::unique_ptr<TraceLog::TraceEventFilter>>* GetCategoryGroupFilter(
-    const unsigned char* category_group_enabled) {
-  return g_category_group_filter[GetCategoryIndex(category_group_enabled)]
-      .Pointer();
+  return CategoryRegistry::GetCategoryByStatePtr(category_group_enabled)
+      ->name();
 }
 
-void TraceLog::UpdateCategoryGroupEnabledFlag(size_t category_index) {
-  unsigned char enabled_flag = 0;
-  const char* category_group = g_category_groups[category_index];
-  if (mode_ == RECORDING_MODE &&
-      trace_config_.IsCategoryGroupEnabled(category_group)) {
-    enabled_flag |= ENABLED_FOR_RECORDING;
+void TraceLog::UpdateCategoryState(TraceCategory* category) {
+  DCHECK(category->is_valid());
+  unsigned char state_flags = 0;
+  if (enabled_modes_ & RECORDING_MODE &&
+      trace_config_.IsCategoryGroupEnabled(category->name())) {
+    state_flags |= TraceCategory::ENABLED_FOR_RECORDING;
   }
 
-  if (event_callback_ &&
-      event_callback_trace_config_.IsCategoryGroupEnabled(category_group)) {
-    enabled_flag |= ENABLED_FOR_EVENT_CALLBACK;
+  // TODO(primiano): this is a temporary workaround for catapult:#2341,
+  // to guarantee that metadata events are always added even if the category
+  // filter is "-*". See crbug.com/618054 for more details and long-term fix.
+  if (enabled_modes_ & RECORDING_MODE &&
+      category == CategoryRegistry::kCategoryMetadata) {
+    state_flags |= TraceCategory::ENABLED_FOR_RECORDING;
   }
 
 #if defined(OS_WIN)
   if (base::trace_event::TraceEventETWExport::IsCategoryGroupEnabled(
-          category_group)) {
-    enabled_flag |= ENABLED_FOR_ETW_EXPORT;
+          category->name())) {
+    state_flags |= TraceCategory::ENABLED_FOR_ETW_EXPORT;
   }
 #endif
 
-  // TODO(primiano): this is a temporary workaround for catapult:#2341,
-  // to guarantee that metadata events are always added even if the category
-  // filter is "-*". See crbug.com/618054 for more details and long-term fix.
-  if (mode_ == RECORDING_MODE && !strcmp(category_group, "__metadata"))
-    enabled_flag |= ENABLED_FOR_RECORDING;
-
-  // Having a filter is an exceptional case, so we avoid
-  // the LazyInstance creation in the common case.
-  if (!(g_category_group_filter[category_index] == nullptr))
-    g_category_group_filter[category_index].Get().clear();
-
-  for (const auto& event_filter : trace_config_.event_filters()) {
-    if (event_filter.IsCategoryGroupEnabled(category_group)) {
-      std::unique_ptr<TraceEventFilter> new_filter;
-
-      if (event_filter.predicate_name() ==
-          TraceEventFilter::kEventWhitelistPredicate) {
-        new_filter = MakeUnique<EventNameFilter>(event_filter.filter_args());
-      } else if (event_filter.predicate_name() ==
-                 TraceEventFilter::kHeapProfilerPredicate) {
-        new_filter = MakeUnique<HeapProfilerFilter>();
-      } else if (event_filter.predicate_name() == "testing_predicate") {
-        CHECK(g_trace_event_filter_constructor_for_testing);
-        new_filter = g_trace_event_filter_constructor_for_testing();
-      }
-
-      if (new_filter) {
-        g_category_group_filter[category_index].Get().push_back(
-            std::move(new_filter));
-        enabled_flag |= ENABLED_FOR_FILTERING;
-      }
+  uint32_t enabled_filters_bitmap = 0;
+  int index = 0;
+  for (const auto& event_filter : enabled_event_filters_) {
+    if (event_filter.IsCategoryGroupEnabled(category->name())) {
+      state_flags |= TraceCategory::ENABLED_FOR_FILTERING;
+      DCHECK(g_category_group_filters.Get()[index]);
+      enabled_filters_bitmap |= 1 << index;
+    }
+    if (index++ >= MAX_TRACE_EVENT_FILTERS) {
+      NOTREACHED();
+      break;
     }
   }
+  category->set_enabled_filters(enabled_filters_bitmap);
+  category->set_state(state_flags);
+}
 
-  g_category_group_enabled[category_index] = enabled_flag;
+void TraceLog::UpdateCategoryRegistry() {
+  CreateFiltersForTraceConfig();
+  for (TraceCategory& category : CategoryRegistry::GetAllCategories()) {
+    UpdateCategoryState(&category);
+  }
 }
 
-void TraceLog::UpdateCategoryGroupEnabledFlags() {
-  size_t category_index = base::subtle::NoBarrier_Load(&g_category_index);
-  for (size_t i = 0; i < category_index; i++)
-    UpdateCategoryGroupEnabledFlag(i);
+void TraceLog::CreateFiltersForTraceConfig() {
+  if (!(enabled_modes_ & FILTERING_MODE))
+    return;
+
+  // Filters were already added and tracing could be enabled. Filters list
+  // cannot be changed when trace events are using them.
+  if (g_category_group_filters.Get().size())
+    return;
+
+  for (auto& event_filter : enabled_event_filters_) {
+    if (g_category_group_filters.Get().size() >= MAX_TRACE_EVENT_FILTERS) {
+      NOTREACHED()
+          << "Too many trace event filters installed in the current session";
+      break;
+    }
+
+    std::unique_ptr<TraceEventFilter> new_filter;
+    if (event_filter.predicate_name() ==
+        TraceEventFilter::kEventWhitelistPredicate) {
+      new_filter = MakeUnique<EventNameFilter>(event_filter.filter_args());
+    } else if (event_filter.predicate_name() ==
+               TraceEventFilter::kHeapProfilerPredicate) {
+      new_filter = MakeUnique<HeapProfilerFilter>();
+    } else if (event_filter.predicate_name() == "testing_predicate") {
+      CHECK(g_trace_event_filter_constructor_for_testing);
+      new_filter = g_trace_event_filter_constructor_for_testing();
+    } else {
+      NOTREACHED();
+    }
+    g_category_group_filters.Get().push_back(std::move(new_filter));
+  }
 }
 
 void TraceLog::UpdateSyntheticDelaysFromTraceConfig() {
@@ -640,67 +624,16 @@ void TraceLog::UpdateSyntheticDelaysFromTraceConfig() {
   }
 }
 
-const unsigned char* TraceLog::GetCategoryGroupEnabledInternal(
-    const char* category_group) {
-  DCHECK(!strchr(category_group, '"'))
-      << "Category groups may not contain double quote";
-  // The g_category_groups is append only, avoid using a lock for the fast path.
-  size_t current_category_index = base::subtle::Acquire_Load(&g_category_index);
-
-  // Search for pre-existing category group.
-  for (size_t i = 0; i < current_category_index; ++i) {
-    if (strcmp(g_category_groups[i], category_group) == 0) {
-      return &g_category_group_enabled[i];
-    }
-  }
-
-  // This is the slow path: the lock is not held in the case above, so more
-  // than one thread could have reached here trying to add the same category.
-  // Only hold to lock when actually appending a new category, and
-  // check the categories groups again.
-  AutoLock lock(lock_);
-  size_t category_index = base::subtle::Acquire_Load(&g_category_index);
-  for (size_t i = 0; i < category_index; ++i) {
-    if (strcmp(g_category_groups[i], category_group) == 0) {
-      return &g_category_group_enabled[i];
-    }
-  }
-
-  // Create a new category group.
-  DCHECK(category_index < MAX_CATEGORY_GROUPS)
-      << "must increase MAX_CATEGORY_GROUPS";
-  unsigned char* category_group_enabled = nullptr;
-  if (category_index < MAX_CATEGORY_GROUPS) {
-    // Don't hold on to the category_group pointer, so that we can create
-    // category groups with strings not known at compile time (this is
-    // required by SetWatchEvent).
-    const char* new_group = strdup(category_group);
-    ANNOTATE_LEAKING_OBJECT_PTR(new_group);
-    g_category_groups[category_index] = new_group;
-    DCHECK(!g_category_group_enabled[category_index]);
-    // Note that if both included and excluded patterns in the
-    // TraceConfig are empty, we exclude nothing,
-    // thereby enabling this category group.
-    UpdateCategoryGroupEnabledFlag(category_index);
-    category_group_enabled = &g_category_group_enabled[category_index];
-    // Update the max index now.
-    base::subtle::Release_Store(&g_category_index, category_index + 1);
-  } else {
-    category_group_enabled =
-        &g_category_group_enabled[kCategoryCategoriesExhausted];
-  }
-  return category_group_enabled;
-}
-
 void TraceLog::GetKnownCategoryGroups(
     std::vector<std::string>* category_groups) {
-  AutoLock lock(lock_);
-  size_t category_index = base::subtle::NoBarrier_Load(&g_category_index);
-  for (size_t i = kNumBuiltinCategories; i < category_index; i++)
-    category_groups->push_back(g_category_groups[i]);
+  for (const auto& category : CategoryRegistry::GetAllCategories()) {
+    if (!CategoryRegistry::IsBuiltinCategory(&category))
+      category_groups->push_back(category.name());
+  }
 }
 
-void TraceLog::SetEnabled(const TraceConfig& trace_config, Mode mode) {
+void TraceLog::SetEnabled(const TraceConfig& trace_config,
+                          uint8_t modes_to_enable) {
   std::vector<EnabledStateObserver*> observer_list;
   std::map<AsyncEnabledStateObserver*, RegisteredAsyncObserver> observer_map;
   {
@@ -714,28 +647,58 @@ void TraceLog::SetEnabled(const TraceConfig& trace_config, Mode mode) {
 
     InternalTraceOptions old_options = trace_options();
 
-    if (IsEnabled()) {
-      if (new_options != old_options) {
-        DLOG(ERROR) << "Attempting to re-enable tracing with a different "
-                    << "set of options.";
-      }
-
-      if (mode != mode_) {
-        DLOG(ERROR) << "Attempting to re-enable tracing with a different mode.";
-      }
-
-      trace_config_.Merge(trace_config);
-      UpdateCategoryGroupEnabledFlags();
-      return;
-    }
-
     if (dispatching_to_observer_list_) {
+      // TODO(ssid): Change to NOTREACHED after fixing crbug.com/625170.
       DLOG(ERROR)
           << "Cannot manipulate TraceLog::Enabled state from an observer.";
       return;
     }
 
-    mode_ = mode;
+    // Clear all filters from previous tracing session. These filters are not
+    // cleared at the end of tracing because some threads which hit trace event
+    // when disabling, could try to use the filters.
+    if (!enabled_modes_)
+      g_category_group_filters.Get().clear();
+
+    // Update trace config for recording.
+    const bool already_recording = enabled_modes_ & RECORDING_MODE;
+    if (modes_to_enable & RECORDING_MODE) {
+      if (already_recording) {
+        // TODO(ssid): Stop suporting enabling of RECODING_MODE when already
+        // enabled crbug.com/625170.
+        DCHECK_EQ(new_options, old_options) << "Attempting to re-enable "
+                                               "tracing with a different set "
+                                               "of options.";
+        trace_config_.Merge(trace_config);
+      } else {
+        trace_config_ = trace_config;
+      }
+    }
+
+    // Update event filters.
+    if (modes_to_enable & FILTERING_MODE) {
+      DCHECK(!trace_config.event_filters().empty())
+          << "Attempting to enable filtering without any filters";
+      DCHECK(enabled_event_filters_.empty()) << "Attempting to re-enable "
+                                                "filtering when filters are "
+                                                "already enabled.";
+
+      // Use the given event filters only if filtering was not enabled.
+      if (enabled_event_filters_.empty())
+        enabled_event_filters_ = trace_config.event_filters();
+    }
+    // Keep the |trace_config_| updated with only enabled filters in case anyone
+    // tries to read it using |GetCurrentTraceConfig| (even if filters are
+    // empty).
+    trace_config_.SetEventFilters(enabled_event_filters_);
+
+    enabled_modes_ |= modes_to_enable;
+    UpdateCategoryRegistry();
+
+    // Do not notify observers or create trace buffer if only enabled for
+    // filtering or if recording was already enabled.
+    if (!(modes_to_enable & RECORDING_MODE) || already_recording)
+      return;
 
     if (new_options != old_options) {
       subtle::NoBarrier_Store(&trace_options_, new_options);
@@ -744,27 +707,9 @@ void TraceLog::SetEnabled(const TraceConfig& trace_config, Mode mode) {
 
     num_traces_recorded_++;
 
-    trace_config_ = TraceConfig(trace_config);
-    UpdateCategoryGroupEnabledFlags();
+    UpdateCategoryRegistry();
     UpdateSyntheticDelaysFromTraceConfig();
 
-    if (new_options & kInternalEnableSampling) {
-      sampling_thread_.reset(new TraceSamplingThread);
-      sampling_thread_->RegisterSampleBucket(
-          &g_trace_state[0], "bucket0",
-          Bind(&TraceSamplingThread::DefaultSamplingCallback));
-      sampling_thread_->RegisterSampleBucket(
-          &g_trace_state[1], "bucket1",
-          Bind(&TraceSamplingThread::DefaultSamplingCallback));
-      sampling_thread_->RegisterSampleBucket(
-          &g_trace_state[2], "bucket2",
-          Bind(&TraceSamplingThread::DefaultSamplingCallback));
-      if (!PlatformThread::Create(0, sampling_thread_.get(),
-                                  &sampling_thread_handle_)) {
-        NOTREACHED() << "failed to create thread";
-      }
-    }
-
     dispatching_to_observer_list_ = true;
     observer_list = enabled_state_observer_list_;
     observer_map = async_observers_;
@@ -794,10 +739,9 @@ void TraceLog::SetArgumentFilterPredicate(
 
 TraceLog::InternalTraceOptions TraceLog::GetInternalOptionsFromTraceConfig(
     const TraceConfig& config) {
-  InternalTraceOptions ret =
-      config.IsSamplingEnabled() ? kInternalEnableSampling : kInternalNone;
-  if (config.IsArgumentFilterEnabled())
-    ret |= kInternalEnableArgumentFilter;
+  InternalTraceOptions ret = config.IsArgumentFilterEnabled()
+                                 ? kInternalEnableArgumentFilter
+                                 : kInternalNone;
   switch (config.GetTraceRecordMode()) {
     case RECORD_UNTIL_FULL:
       return ret | kInternalRecordUntilFull;
@@ -819,37 +763,45 @@ TraceConfig TraceLog::GetCurrentTraceConfig() const {
 
 void TraceLog::SetDisabled() {
   AutoLock lock(lock_);
-  SetDisabledWhileLocked();
+  SetDisabledWhileLocked(RECORDING_MODE);
+}
+
+void TraceLog::SetDisabled(uint8_t modes_to_disable) {
+  AutoLock lock(lock_);
+  SetDisabledWhileLocked(modes_to_disable);
 }
 
-void TraceLog::SetDisabledWhileLocked() {
+void TraceLog::SetDisabledWhileLocked(uint8_t modes_to_disable) {
   lock_.AssertAcquired();
 
-  if (!IsEnabled())
+  if (!(enabled_modes_ & modes_to_disable))
     return;
 
   if (dispatching_to_observer_list_) {
+    // TODO(ssid): Change to NOTREACHED after fixing crbug.com/625170.
     DLOG(ERROR)
         << "Cannot manipulate TraceLog::Enabled state from an observer.";
     return;
   }
 
-  mode_ = DISABLED;
+  bool is_recording_mode_disabled =
+      (enabled_modes_ & RECORDING_MODE) && (modes_to_disable & RECORDING_MODE);
+  enabled_modes_ &= ~modes_to_disable;
+
+  if (modes_to_disable & FILTERING_MODE)
+    enabled_event_filters_.clear();
 
-  if (sampling_thread_) {
-    // Stop the sampling thread.
-    sampling_thread_->Stop();
-    lock_.Release();
-    PlatformThread::Join(sampling_thread_handle_);
-    lock_.Acquire();
-    sampling_thread_handle_ = PlatformThreadHandle();
-    sampling_thread_.reset();
+  if (modes_to_disable & RECORDING_MODE) {
+    trace_config_.Clear();
   }
 
-  trace_config_.Clear();
-  subtle::NoBarrier_Store(&watch_category_, 0);
-  watch_event_name_.clear();
-  UpdateCategoryGroupEnabledFlags();
+  UpdateCategoryRegistry();
+
+  // Add metadata events and notify observers only if recording mode was
+  // disabled now.
+  if (!is_recording_mode_disabled)
+    return;
+
   AddMetadataEventsWhileLocked();
 
   // Remove metadata events so they will not get added to a subsequent trace.
@@ -949,25 +901,10 @@ void TraceLog::CheckIfBufferIsFullWhileLocked() {
     if (buffer_limit_reached_timestamp_.is_null()) {
       buffer_limit_reached_timestamp_ = OffsetNow();
     }
-    SetDisabledWhileLocked();
+    SetDisabledWhileLocked(RECORDING_MODE);
   }
 }
 
-void TraceLog::SetEventCallbackEnabled(const TraceConfig& trace_config,
-                                       EventCallback cb) {
-  AutoLock lock(lock_);
-  subtle::NoBarrier_Store(&event_callback_,
-                          reinterpret_cast<subtle::AtomicWord>(cb));
-  event_callback_trace_config_ = trace_config;
-  UpdateCategoryGroupEnabledFlags();
-}
-
-void TraceLog::SetEventCallbackDisabled() {
-  AutoLock lock(lock_);
-  subtle::NoBarrier_Store(&event_callback_, 0);
-  UpdateCategoryGroupEnabledFlags();
-}
-
 // Flush() works as the following:
 // 1. Flush() is called in thread A whose task runner is saved in
 //    flush_task_runner_;
@@ -1336,10 +1273,13 @@ TraceEventHandle TraceLog::AddTraceEventWithThreadIdAndTimestamp(
   TimeTicks offset_event_timestamp = OffsetTimestamp(timestamp);
   ThreadTicks thread_now = ThreadNow();
 
-  // |thread_local_event_buffer_| can be null if the current thread doesn't have
-  // a message loop or the message loop is blocked.
-  InitializeThreadLocalEventBufferIfSupported();
-  auto* thread_local_event_buffer = thread_local_event_buffer_.Get();
+  ThreadLocalEventBuffer* thread_local_event_buffer = nullptr;
+  if (*category_group_enabled & RECORDING_MODE) {
+    // |thread_local_event_buffer_| can be null if the current thread doesn't
+    // have a message loop or the message loop is blocked.
+    InitializeThreadLocalEventBufferIfSupported();
+    thread_local_event_buffer = thread_local_event_buffer_.Get();
+  }
 
   // Check and update the current thread name only if the event is for the
   // current thread to avoid locks in most cases.
@@ -1381,7 +1321,7 @@ TraceEventHandle TraceLog::AddTraceEventWithThreadIdAndTimestamp(
 #if defined(OS_WIN)
   // This is done sooner rather than later, to avoid creating the event and
   // acquiring the lock, which is not needed for ETW as it's already threadsafe.
-  if (*category_group_enabled & ENABLED_FOR_ETW_EXPORT)
+  if (*category_group_enabled & TraceCategory::ENABLED_FOR_ETW_EXPORT)
     TraceEventETWExport::AddEvent(phase, category_group_enabled, name, id,
                                   num_args, arg_names, arg_types, arg_values,
                                   convertable_values);
@@ -1390,29 +1330,27 @@ TraceEventHandle TraceLog::AddTraceEventWithThreadIdAndTimestamp(
   std::string console_message;
   std::unique_ptr<TraceEvent> filtered_trace_event;
   bool disabled_by_filters = false;
-  if (*category_group_enabled & ENABLED_FOR_FILTERING) {
+  if (*category_group_enabled & TraceCategory::ENABLED_FOR_FILTERING) {
     std::unique_ptr<TraceEvent> new_trace_event(new TraceEvent);
     new_trace_event->Initialize(thread_id, offset_event_timestamp, thread_now,
                                 phase, category_group_enabled, name, scope, id,
                                 bind_id, num_args, arg_names, arg_types,
                                 arg_values, convertable_values, flags);
 
-    auto filter_list = GetCategoryGroupFilter(category_group_enabled);
-    DCHECK(!filter_list->empty());
-
     disabled_by_filters = true;
-    for (const auto& trace_event_filter : *filter_list) {
-      if (trace_event_filter->FilterTraceEvent(*new_trace_event))
-        disabled_by_filters = false;
-    }
-
+    ForEachCategoryGroupFilter(
+        category_group_enabled, [&new_trace_event, &disabled_by_filters](
+                                    TraceEventFilter* trace_event_filter) {
+          if (trace_event_filter->FilterTraceEvent(*new_trace_event))
+            disabled_by_filters = false;
+        });
     if (!disabled_by_filters)
       filtered_trace_event = std::move(new_trace_event);
   }
 
   // If enabled for recording, the event should be added only if one of the
   // filters indicates or category is not enabled for filtering.
-  if ((*category_group_enabled & ENABLED_FOR_RECORDING) &&
+  if ((*category_group_enabled & TraceCategory::ENABLED_FOR_RECORDING) &&
       !disabled_by_filters) {
     OptionalAutoLock lock(&lock_);
 
@@ -1449,33 +1387,6 @@ TraceEventHandle TraceLog::AddTraceEventWithThreadIdAndTimestamp(
   if (!console_message.empty())
     LOG(ERROR) << console_message;
 
-  if (reinterpret_cast<const unsigned char*>(
-          subtle::NoBarrier_Load(&watch_category_)) == category_group_enabled) {
-    bool event_name_matches;
-    WatchEventCallback watch_event_callback_copy;
-    {
-      AutoLock lock(lock_);
-      event_name_matches = watch_event_name_ == name;
-      watch_event_callback_copy = watch_event_callback_;
-    }
-    if (event_name_matches) {
-      if (!watch_event_callback_copy.is_null())
-        watch_event_callback_copy.Run();
-    }
-  }
-
-  if (*category_group_enabled & ENABLED_FOR_EVENT_CALLBACK) {
-    EventCallback event_callback = reinterpret_cast<EventCallback>(
-        subtle::NoBarrier_Load(&event_callback_));
-    if (event_callback) {
-      event_callback(
-          offset_event_timestamp,
-          phase == TRACE_EVENT_PHASE_COMPLETE ? TRACE_EVENT_PHASE_BEGIN : phase,
-          category_group_enabled, name, scope, id, num_args, arg_names,
-          arg_types, arg_values, flags);
-    }
-  }
-
   return handle;
 }
 
@@ -1556,13 +1467,12 @@ std::string TraceLog::EventToConsoleMessage(unsigned char phase,
 void TraceLog::EndFilteredEvent(const unsigned char* category_group_enabled,
                                 const char* name,
                                 TraceEventHandle handle) {
-  auto filter_list = GetCategoryGroupFilter(category_group_enabled);
-  DCHECK(!filter_list->empty());
-
-  for (const auto& trace_event_filter : *filter_list) {
-    trace_event_filter->EndEvent(name,
-                                 GetCategoryGroupName(category_group_enabled));
-  }
+  const char* category_name = GetCategoryGroupName(category_group_enabled);
+  ForEachCategoryGroupFilter(
+      category_group_enabled,
+      [name, category_name](TraceEventFilter* trace_event_filter) {
+        trace_event_filter->EndEvent(name, category_name);
+      });
 }
 
 void TraceLog::UpdateTraceEventDuration(
@@ -1586,12 +1496,12 @@ void TraceLog::UpdateTraceEventDuration(
 
 #if defined(OS_WIN)
   // Generate an ETW event that marks the end of a complete event.
-  if (category_group_enabled_local & ENABLED_FOR_ETW_EXPORT)
+  if (category_group_enabled_local & TraceCategory::ENABLED_FOR_ETW_EXPORT)
     TraceEventETWExport::AddCompleteEndEvent(name);
 #endif  // OS_WIN
 
   std::string console_message;
-  if (category_group_enabled_local & ENABLED_FOR_RECORDING) {
+  if (category_group_enabled_local & TraceCategory::ENABLED_FOR_RECORDING) {
     OptionalAutoLock lock(&lock_);
 
     TraceEvent* trace_event = GetEventByHandleInternal(handle, &lock);
@@ -1624,35 +1534,8 @@ void TraceLog::UpdateTraceEventDuration(
   if (!console_message.empty())
     LOG(ERROR) << console_message;
 
-  if (category_group_enabled_local & ENABLED_FOR_EVENT_CALLBACK) {
-    EventCallback event_callback = reinterpret_cast<EventCallback>(
-        subtle::NoBarrier_Load(&event_callback_));
-    if (event_callback) {
-      event_callback(
-        now, TRACE_EVENT_PHASE_END, category_group_enabled, name,
-        trace_event_internal::kGlobalScope, trace_event_internal::kNoId, 0,
-        nullptr, nullptr, nullptr, TRACE_EVENT_FLAG_NONE);
-    }
-  }
-}
-
-void TraceLog::SetWatchEvent(const std::string& category_name,
-                             const std::string& event_name,
-                             const WatchEventCallback& callback) {
-  const unsigned char* category =
-      GetCategoryGroupEnabled(category_name.c_str());
-  AutoLock lock(lock_);
-  subtle::NoBarrier_Store(&watch_category_,
-                          reinterpret_cast<subtle::AtomicWord>(category));
-  watch_event_name_ = event_name;
-  watch_event_callback_ = callback;
-}
-
-void TraceLog::CancelWatchEvent() {
-  AutoLock lock(lock_);
-  subtle::NoBarrier_Store(&watch_category_, 0);
-  watch_event_name_.clear();
-  watch_event_callback_.Reset();
+  if (category_group_enabled_local & TraceCategory::ENABLED_FOR_FILTERING)
+    EndFilteredEvent(category_group_enabled, name, handle);
 }
 
 uint64_t TraceLog::MangleEventId(uint64_t id) {
@@ -1724,14 +1607,9 @@ void TraceLog::AddMetadataEventsWhileLocked() {
   }
 }
 
-void TraceLog::WaitSamplingEventForTesting() {
-  if (!sampling_thread_)
-    return;
-  sampling_thread_->WaitSamplingEventForTesting();
-}
-
 void TraceLog::DeleteForTesting() {
   internal::DeleteTraceLogForTesting::Delete();
+  CategoryRegistry::ResetForTesting();
 }
 
 void TraceLog::SetTraceEventFilterConstructorForTesting(
@@ -1848,18 +1726,14 @@ TraceBuffer* TraceLog::CreateTraceBuffer() {
 
 #if defined(OS_WIN)
 void TraceLog::UpdateETWCategoryGroupEnabledFlags() {
-  AutoLock lock(lock_);
-  size_t category_index = base::subtle::NoBarrier_Load(&g_category_index);
   // Go through each category and set/clear the ETW bit depending on whether the
   // category is enabled.
-  for (size_t i = 0; i < category_index; i++) {
-    const char* category_group = g_category_groups[i];
-    DCHECK(category_group);
+  for (TraceCategory& category : CategoryRegistry::GetAllCategories()) {
     if (base::trace_event::TraceEventETWExport::IsCategoryGroupEnabled(
-            category_group)) {
-      g_category_group_enabled[i] |= ENABLED_FOR_ETW_EXPORT;
+            category.name())) {
+      category.set_state_flag(TraceCategory::ENABLED_FOR_ETW_EXPORT);
     } else {
-      g_category_group_enabled[i] &= ~ENABLED_FOR_ETW_EXPORT;
+      category.clear_state_flag(TraceCategory::ENABLED_FOR_ETW_EXPORT);
     }
   }
 }
diff --git a/src/base/trace_event/trace_log.h b/src/base/trace_event/trace_log.h
index 540d7d0..68a7fbb 100644
--- a/src/base/trace_event/trace_log.h
+++ b/src/base/trace_event/trace_log.h
@@ -26,15 +26,16 @@ namespace base {
 
 template <typename Type>
 struct DefaultSingletonTraits;
+class MessageLoop;
 class RefCountedString;
 
 namespace trace_event {
 
+struct TraceCategory;
 class TraceBuffer;
 class TraceBufferChunk;
 class TraceEvent;
 class TraceEventMemoryOverhead;
-class TraceSamplingThread;
 
 struct BASE_EXPORT TraceLogStatus {
   TraceLogStatus();
@@ -45,24 +46,14 @@ struct BASE_EXPORT TraceLogStatus {
 
 class BASE_EXPORT TraceLog : public MemoryDumpProvider {
  public:
-  enum Mode {
-    DISABLED = 0,
-    RECORDING_MODE
-  };
-
-  // The pointer returned from GetCategoryGroupEnabledInternal() points to a
-  // value with zero or more of the following bits. Used in this class only.
-  // The TRACE_EVENT macros should only use the value as a bool.
-  // These values must be in sync with macro values in TraceEvent.h in Blink.
-  enum CategoryGroupEnabledFlags {
-    // Category group enabled for the recording mode.
-    ENABLED_FOR_RECORDING = 1 << 0,
-    // Category group enabled by SetEventCallbackEnabled().
-    ENABLED_FOR_EVENT_CALLBACK = 1 << 2,
-    // Category group enabled to export events to ETW.
-    ENABLED_FOR_ETW_EXPORT = 1 << 3,
-    // Category group being filtered before logged.
-    ENABLED_FOR_FILTERING = 1 << 4
+  // Argument passed to TraceLog::SetEnabled.
+  enum Mode : uint8_t {
+    // Enables normal tracing (recording trace events in the trace buffer).
+    RECORDING_MODE = 1 << 0,
+
+    // Trace events are enabled just for filtering but not for recording. Only
+    // event filters config of |trace_config| argument is used.
+    FILTERING_MODE = 1 << 1
   };
 
   static TraceLog* GetInstance();
@@ -78,16 +69,30 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
   // if the current thread supports that (has a message loop).
   void InitializeThreadLocalEventBufferIfSupported();
 
-  // Enables normal tracing (recording trace events in the trace buffer).
-  // See TraceConfig comments for details on how to control what categories
-  // will be traced. If tracing has already been enabled, |category_filter| will
-  // be merged into the current category filter.
-  void SetEnabled(const TraceConfig& trace_config, Mode mode);
-
-  // Disables normal tracing for all categories.
+  // See TraceConfig comments for details on how to control which categories
+  // will be traced. SetDisabled must be called distinctly for each mode that is
+  // enabled. If tracing has already been enabled for recording, category filter
+  // (enabled and disabled categories) will be merged into the current category
+  // filter. Enabling RECORDING_MODE does not enable filters. Trace event
+  // filters will be used only if FILTERING_MODE is set on |modes_to_enable|.
+  // Conversely to RECORDING_MODE, FILTERING_MODE doesn't support upgrading,
+  // i.e. filters can only be enabled if not previously enabled.
+  void SetEnabled(const TraceConfig& trace_config, uint8_t modes_to_enable);
+
+  // TODO(ssid): Remove the default SetEnabled and IsEnabled. They should take
+  // Mode as argument.
+
+  // Disables tracing for all categories for the specified |modes_to_disable|
+  // only. Only RECORDING_MODE is taken as default |modes_to_disable|.
   void SetDisabled();
+  void SetDisabled(uint8_t modes_to_disable);
 
-  bool IsEnabled() { return mode_ != DISABLED; }
+  // Returns true if TraceLog is enabled on recording mode.
+  // Note: Returns false even if FILTERING_MODE is enabled.
+  bool IsEnabled() { return enabled_modes_ & RECORDING_MODE; }
+
+  // Returns a bitmap of enabled modes from TraceLog::Mode.
+  uint8_t enabled_modes() { return enabled_modes_; }
 
   // The number of times we have begun recording traces. If tracing is off,
   // returns -1. If tracing is on, then it returns the number of times we have
@@ -150,31 +155,6 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
   // objects.
   void EstimateTraceMemoryOverhead(TraceEventMemoryOverhead* overhead);
 
-  // Not using base::Callback because of its limited by 7 parameters.
-  // Also, using primitive type allows directly passing callback from WebCore.
-  // WARNING: It is possible for the previously set callback to be called
-  // after a call to SetEventCallbackEnabled() that replaces or a call to
-  // SetEventCallbackDisabled() that disables the callback.
-  // This callback may be invoked on any thread.
-  // For TRACE_EVENT_PHASE_COMPLETE events, the client will still receive pairs
-  // of TRACE_EVENT_PHASE_BEGIN and TRACE_EVENT_PHASE_END events to keep the
-  // interface simple.
-  typedef void (*EventCallback)(TimeTicks timestamp,
-                                char phase,
-                                const unsigned char* category_group_enabled,
-                                const char* name,
-                                const char* scope,
-                                unsigned long long id,
-                                int num_args,
-                                const char* const arg_names[],
-                                const unsigned char arg_types[],
-                                const unsigned long long arg_values[],
-                                unsigned int flags);
-
-  // Enable tracing for EventCallback.
-  void SetEventCallbackEnabled(const TraceConfig& trace_config,
-                               EventCallback cb);
-  void SetEventCallbackDisabled();
   void SetArgumentFilterPredicate(
       const ArgumentFilterPredicate& argument_filter_predicate);
 
@@ -292,23 +272,12 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
                         const char* name,
                         TraceEventHandle handle);
 
-  // For every matching event, the callback will be called.
-  typedef base::Callback<void()> WatchEventCallback;
-  void SetWatchEvent(const std::string& category_name,
-                     const std::string& event_name,
-                     const WatchEventCallback& callback);
-  // Cancel the watch event. If tracing is enabled, this may race with the
-  // watch event notification firing.
-  void CancelWatchEvent();
-
   int process_id() const { return process_id_; }
 
   uint64_t MangleEventId(uint64_t id);
 
   // Exposed for unittesting:
 
-  void WaitSamplingEventForTesting();
-
   // Allows deleting our singleton instance.
   static void DeleteForTesting();
 
@@ -396,12 +365,14 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
                     ProcessMemoryDump* pmd) override;
 
   // Enable/disable each category group based on the current mode_,
-  // category_filter_, event_callback_ and event_callback_category_filter_.
-  // Enable the category group in the enabled mode if category_filter_ matches
-  // the category group, or event_callback_ is not null and
-  // event_callback_category_filter_ matches the category group.
-  void UpdateCategoryGroupEnabledFlags();
-  void UpdateCategoryGroupEnabledFlag(size_t category_index);
+  // category_filter_ and event_filters_enabled_.
+  // Enable the category group in the recording mode if category_filter_ matches
+  // the category group, is not null. Enable category for filtering if any
+  // filter in event_filters_enabled_ enables it.
+  void UpdateCategoryRegistry();
+  void UpdateCategoryState(TraceCategory* category);
+
+  void CreateFiltersForTraceConfig();
 
   // Configure synthetic delays based on the values set in the current
   // trace config.
@@ -416,7 +387,6 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
 
   TraceLog();
   ~TraceLog() override;
-  const unsigned char* GetCategoryGroupEnabledInternal(const char* name);
   void AddMetadataEventsWhileLocked();
 
   InternalTraceOptions trace_options() const {
@@ -434,7 +404,7 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
   TraceEvent* AddEventToThreadSharedChunkWhileLocked(TraceEventHandle* handle,
                                                      bool check_buffer_is_full);
   void CheckIfBufferIsFullWhileLocked();
-  void SetDisabledWhileLocked();
+  void SetDisabledWhileLocked(uint8_t modes);
 
   TraceEvent* GetEventByHandleInternal(TraceEventHandle handle,
                                        OptionalAutoLock* lock);
@@ -473,7 +443,6 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
   static const InternalTraceOptions kInternalRecordUntilFull;
   static const InternalTraceOptions kInternalRecordContinuously;
   static const InternalTraceOptions kInternalEchoToConsole;
-  static const InternalTraceOptions kInternalEnableSampling;
   static const InternalTraceOptions kInternalRecordAsMuchAsPossible;
   static const InternalTraceOptions kInternalEnableArgumentFilter;
 
@@ -483,11 +452,10 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
   // This lock protects accesses to thread_names_, thread_event_start_times_
   // and thread_colors_.
   Lock thread_info_lock_;
-  Mode mode_;
+  uint8_t enabled_modes_;  // See TraceLog::Mode.
   int num_traces_recorded_;
   std::unique_ptr<TraceBuffer> logged_events_;
   std::vector<std::unique_ptr<TraceEvent>> metadata_events_;
-  subtle::AtomicWord /* EventCallback */ event_callback_;
   bool dispatching_to_observer_list_;
   std::vector<EnabledStateObserver*> enabled_state_observer_list_;
   std::map<AsyncEnabledStateObserver*, RegisteredAsyncObserver>
@@ -512,19 +480,10 @@ class BASE_EXPORT TraceLog : public MemoryDumpProvider {
 
   TimeDelta time_offset_;
 
-  // Allow tests to wake up when certain events occur.
-  WatchEventCallback watch_event_callback_;
-  subtle::AtomicWord /* const unsigned char* */ watch_category_;
-  std::string watch_event_name_;
-
   subtle::AtomicWord /* Options */ trace_options_;
 
-  // Sampling thread handles.
-  std::unique_ptr<TraceSamplingThread> sampling_thread_;
-  PlatformThreadHandle sampling_thread_handle_;
-
   TraceConfig trace_config_;
-  TraceConfig event_callback_trace_config_;
+  TraceConfig::EventFilters enabled_event_filters_;
 
   ThreadLocalPointer<ThreadLocalEventBuffer> thread_local_event_buffer_;
   ThreadLocalBoolean thread_blocks_message_loop_;
diff --git a/src/base/trace_event/trace_sampling_thread.cc b/src/base/trace_event/trace_sampling_thread.cc
deleted file mode 100644
index 5a0d2f8..0000000
--- a/src/base/trace_event/trace_sampling_thread.cc
+++ /dev/null
@@ -1,107 +0,0 @@
-// Copyright 2015 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include <stddef.h>
-
-#include "base/trace_event/trace_event.h"
-#include "base/trace_event/trace_event_impl.h"
-#include "base/trace_event/trace_log.h"
-#include "base/trace_event/trace_sampling_thread.h"
-
-namespace base {
-namespace trace_event {
-
-class TraceBucketData {
- public:
-  TraceBucketData(base::subtle::AtomicWord* bucket,
-                  const char* name,
-                  TraceSampleCallback callback);
-  ~TraceBucketData();
-
-  TRACE_EVENT_API_ATOMIC_WORD* bucket;
-  const char* bucket_name;
-  TraceSampleCallback callback;
-};
-
-TraceSamplingThread::TraceSamplingThread()
-    : thread_running_(false),
-      waitable_event_for_testing_(WaitableEvent::ResetPolicy::AUTOMATIC,
-                                  WaitableEvent::InitialState::NOT_SIGNALED) {}
-
-TraceSamplingThread::~TraceSamplingThread() {}
-
-void TraceSamplingThread::ThreadMain() {
-  PlatformThread::SetName("Sampling Thread");
-  thread_running_ = true;
-  const int kSamplingFrequencyMicroseconds = 1000;
-  while (!cancellation_flag_.IsSet()) {
-    PlatformThread::Sleep(
-        TimeDelta::FromMicroseconds(kSamplingFrequencyMicroseconds));
-    GetSamples();
-    waitable_event_for_testing_.Signal();
-  }
-}
-
-// static
-void TraceSamplingThread::DefaultSamplingCallback(
-    TraceBucketData* bucket_data) {
-  TRACE_EVENT_API_ATOMIC_WORD category_and_name =
-      TRACE_EVENT_API_ATOMIC_LOAD(*bucket_data->bucket);
-  if (!category_and_name)
-    return;
-  const char* const combined =
-      reinterpret_cast<const char* const>(category_and_name);
-  const char* category_group;
-  const char* name;
-  ExtractCategoryAndName(combined, &category_group, &name);
-  TRACE_EVENT_API_ADD_TRACE_EVENT(
-      TRACE_EVENT_PHASE_SAMPLE,
-      TraceLog::GetCategoryGroupEnabled(category_group), name,
-      trace_event_internal::kGlobalScope, trace_event_internal::kNoId, 0,
-      NULL, NULL, NULL, NULL, 0);
-}
-
-void TraceSamplingThread::GetSamples() {
-  for (size_t i = 0; i < sample_buckets_.size(); ++i) {
-    TraceBucketData* bucket_data = &sample_buckets_[i];
-    bucket_data->callback.Run(bucket_data);
-  }
-}
-
-void TraceSamplingThread::RegisterSampleBucket(
-    TRACE_EVENT_API_ATOMIC_WORD* bucket,
-    const char* const name,
-    TraceSampleCallback callback) {
-  // Access to sample_buckets_ doesn't cause races with the sampling thread
-  // that uses the sample_buckets_, because it is guaranteed that
-  // RegisterSampleBucket is called before the sampling thread is created.
-  DCHECK(!thread_running_);
-  sample_buckets_.push_back(TraceBucketData(bucket, name, callback));
-}
-
-// static
-void TraceSamplingThread::ExtractCategoryAndName(const char* combined,
-                                                 const char** category,
-                                                 const char** name) {
-  *category = combined;
-  *name = &combined[strlen(combined) + 1];
-}
-
-void TraceSamplingThread::Stop() {
-  cancellation_flag_.Set();
-}
-
-void TraceSamplingThread::WaitSamplingEventForTesting() {
-  waitable_event_for_testing_.Wait();
-}
-
-TraceBucketData::TraceBucketData(base::subtle::AtomicWord* bucket,
-                                 const char* name,
-                                 TraceSampleCallback callback)
-    : bucket(bucket), bucket_name(name), callback(callback) {}
-
-TraceBucketData::~TraceBucketData() {}
-
-}  // namespace trace_event
-}  // namespace base
diff --git a/src/base/trace_event/trace_sampling_thread.h b/src/base/trace_event/trace_sampling_thread.h
deleted file mode 100644
index f976a80..0000000
--- a/src/base/trace_event/trace_sampling_thread.h
+++ /dev/null
@@ -1,54 +0,0 @@
-// Copyright 2015 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef BASE_TRACE_EVENT_TRACE_SAMPLING_THREAD_H_
-#define BASE_TRACE_EVENT_TRACE_SAMPLING_THREAD_H_
-
-#include "base/synchronization/cancellation_flag.h"
-#include "base/synchronization/waitable_event.h"
-#include "base/trace_event/trace_event.h"
-
-namespace base {
-namespace trace_event {
-
-class TraceBucketData;
-typedef base::Callback<void(TraceBucketData*)> TraceSampleCallback;
-
-// This object must be created on the IO thread.
-class TraceSamplingThread : public PlatformThread::Delegate {
- public:
-  TraceSamplingThread();
-  ~TraceSamplingThread() override;
-
-  // Implementation of PlatformThread::Delegate:
-  void ThreadMain() override;
-
-  static void DefaultSamplingCallback(TraceBucketData* bucket_data);
-
-  void Stop();
-  void WaitSamplingEventForTesting();
-
- private:
-  friend class TraceLog;
-
-  void GetSamples();
-  // Not thread-safe. Once the ThreadMain has been called, this can no longer
-  // be called.
-  void RegisterSampleBucket(TRACE_EVENT_API_ATOMIC_WORD* bucket,
-                            const char* const name,
-                            TraceSampleCallback callback);
-  // Splits a combined "category\0name" into the two component parts.
-  static void ExtractCategoryAndName(const char* combined,
-                                     const char** category,
-                                     const char** name);
-  std::vector<TraceBucketData> sample_buckets_;
-  bool thread_running_;
-  CancellationFlag cancellation_flag_;
-  WaitableEvent waitable_event_for_testing_;
-};
-
-}  // namespace trace_event
-}  // namespace base
-
-#endif  // BASE_TRACE_EVENT_TRACE_SAMPLING_THREAD_H_
diff --git a/src/base/tuple.h b/src/base/tuple.h
index 9f62339..ca8d31d 100644
--- a/src/base/tuple.h
+++ b/src/base/tuple.h
@@ -28,7 +28,6 @@
 #include <stddef.h>
 #include <tuple>
 
-#include "base/bind_helpers.h"
 #include "build/build_config.h"
 
 namespace base {
diff --git a/src/base/values.cc b/src/base/values.cc
index 4d9db78..fd0bbe1 100644
--- a/src/base/values.cc
+++ b/src/base/values.cc
@@ -23,7 +23,8 @@ namespace {
 
 const char* const kTypeNames[] = {"null",   "boolean", "integer",    "double",
                                   "string", "binary",  "dictionary", "list"};
-static_assert(arraysize(kTypeNames) == Value::TYPE_LIST + 1,
+static_assert(arraysize(kTypeNames) ==
+                  static_cast<size_t>(Value::Type::LIST) + 1,
               "kTypeNames Has Wrong Size");
 
 std::unique_ptr<Value> CopyWithoutEmptyChildren(const Value& node);
@@ -60,10 +61,10 @@ std::unique_ptr<DictionaryValue> CopyDictionaryWithoutEmptyChildren(
 
 std::unique_ptr<Value> CopyWithoutEmptyChildren(const Value& node) {
   switch (node.GetType()) {
-    case Value::TYPE_LIST:
+    case Value::Type::LIST:
       return CopyListWithoutEmptyChildren(static_cast<const ListValue&>(node));
 
-    case Value::TYPE_DICTIONARY:
+    case Value::Type::DICTIONARY:
       return CopyDictionaryWithoutEmptyChildren(
           static_cast<const DictionaryValue&>(node));
 
@@ -79,14 +80,14 @@ Value::~Value() {
 
 // static
 std::unique_ptr<Value> Value::CreateNullValue() {
-  return WrapUnique(new Value(TYPE_NULL));
+  return WrapUnique(new Value(Type::NONE));
 }
 
 // static
 const char* Value::GetTypeName(Value::Type type) {
-  DCHECK_GE(type, 0);
+  DCHECK_GE(static_cast<int>(type), 0);
   DCHECK_LT(static_cast<size_t>(type), arraysize(kTypeNames));
-  return kTypeNames[type];
+  return kTypeNames[static_cast<size_t>(type)];
 }
 
 bool Value::GetAsBinary(const BinaryValue** out_value) const {
@@ -136,7 +137,7 @@ bool Value::GetAsDictionary(const DictionaryValue** out_value) const {
 Value* Value::DeepCopy() const {
   // This method should only be getting called for null Values--all subclasses
   // need to provide their own implementation;.
-  DCHECK(IsType(TYPE_NULL));
+  DCHECK(IsType(Type::NONE));
   return CreateNullValue().release();
 }
 
@@ -147,8 +148,8 @@ std::unique_ptr<Value> Value::CreateDeepCopy() const {
 bool Value::Equals(const Value* other) const {
   // This method should only be getting called for null Values--all subclasses
   // need to provide their own implementation;.
-  DCHECK(IsType(TYPE_NULL));
-  return other->IsType(TYPE_NULL);
+  DCHECK(IsType(Type::NONE));
+  return other->IsType(Type::NONE);
 }
 
 // static
@@ -170,15 +171,13 @@ Value& Value::operator=(const Value& that) {
 ///////////////////// FundamentalValue ////////////////////
 
 FundamentalValue::FundamentalValue(bool in_value)
-    : Value(TYPE_BOOLEAN), boolean_value_(in_value) {
-}
+    : Value(Type::BOOLEAN), boolean_value_(in_value) {}
 
 FundamentalValue::FundamentalValue(int in_value)
-    : Value(TYPE_INTEGER), integer_value_(in_value) {
-}
+    : Value(Type::INTEGER), integer_value_(in_value) {}
 
 FundamentalValue::FundamentalValue(double in_value)
-    : Value(TYPE_DOUBLE), double_value_(in_value) {
+    : Value(Type::DOUBLE), double_value_(in_value) {
   if (!std::isfinite(double_value_)) {
     NOTREACHED() << "Non-finite (i.e. NaN or positive/negative infinity) "
                  << "values cannot be represented in JSON";
@@ -190,34 +189,34 @@ FundamentalValue::~FundamentalValue() {
 }
 
 bool FundamentalValue::GetAsBoolean(bool* out_value) const {
-  if (out_value && IsType(TYPE_BOOLEAN))
+  if (out_value && IsType(Type::BOOLEAN))
     *out_value = boolean_value_;
-  return (IsType(TYPE_BOOLEAN));
+  return (IsType(Type::BOOLEAN));
 }
 
 bool FundamentalValue::GetAsInteger(int* out_value) const {
-  if (out_value && IsType(TYPE_INTEGER))
+  if (out_value && IsType(Type::INTEGER))
     *out_value = integer_value_;
-  return (IsType(TYPE_INTEGER));
+  return (IsType(Type::INTEGER));
 }
 
 bool FundamentalValue::GetAsDouble(double* out_value) const {
-  if (out_value && IsType(TYPE_DOUBLE))
+  if (out_value && IsType(Type::DOUBLE))
     *out_value = double_value_;
-  else if (out_value && IsType(TYPE_INTEGER))
+  else if (out_value && IsType(Type::INTEGER))
     *out_value = integer_value_;
-  return (IsType(TYPE_DOUBLE) || IsType(TYPE_INTEGER));
+  return (IsType(Type::DOUBLE) || IsType(Type::INTEGER));
 }
 
 FundamentalValue* FundamentalValue::DeepCopy() const {
   switch (GetType()) {
-    case TYPE_BOOLEAN:
+    case Type::BOOLEAN:
       return new FundamentalValue(boolean_value_);
 
-    case TYPE_INTEGER:
+    case Type::INTEGER:
       return new FundamentalValue(integer_value_);
 
-    case TYPE_DOUBLE:
+    case Type::DOUBLE:
       return new FundamentalValue(double_value_);
 
     default:
@@ -231,15 +230,15 @@ bool FundamentalValue::Equals(const Value* other) const {
     return false;
 
   switch (GetType()) {
-    case TYPE_BOOLEAN: {
+    case Type::BOOLEAN: {
       bool lhs, rhs;
       return GetAsBoolean(&lhs) && other->GetAsBoolean(&rhs) && lhs == rhs;
     }
-    case TYPE_INTEGER: {
+    case Type::INTEGER: {
       int lhs, rhs;
       return GetAsInteger(&lhs) && other->GetAsInteger(&rhs) && lhs == rhs;
     }
-    case TYPE_DOUBLE: {
+    case Type::DOUBLE: {
       double lhs, rhs;
       return GetAsDouble(&lhs) && other->GetAsDouble(&rhs) && lhs == rhs;
     }
@@ -252,14 +251,12 @@ bool FundamentalValue::Equals(const Value* other) const {
 ///////////////////// StringValue ////////////////////
 
 StringValue::StringValue(StringPiece in_value)
-    : Value(TYPE_STRING), value_(in_value.as_string()) {
+    : Value(Type::STRING), value_(in_value.as_string()) {
   DCHECK(IsStringUTF8(in_value));
 }
 
 StringValue::StringValue(const string16& in_value)
-    : Value(TYPE_STRING),
-      value_(UTF16ToUTF8(in_value)) {
-}
+    : Value(Type::STRING), value_(UTF16ToUTF8(in_value)) {}
 
 StringValue::~StringValue() {
 }
@@ -303,13 +300,10 @@ bool StringValue::Equals(const Value* other) const {
 
 ///////////////////// BinaryValue ////////////////////
 
-BinaryValue::BinaryValue()
-    : Value(TYPE_BINARY),
-      size_(0) {
-}
+BinaryValue::BinaryValue() : Value(Type::BINARY), size_(0) {}
 
 BinaryValue::BinaryValue(std::unique_ptr<char[]> buffer, size_t size)
-    : Value(TYPE_BINARY), buffer_(std::move(buffer)), size_(size) {}
+    : Value(Type::BINARY), buffer_(std::move(buffer)), size_(size) {}
 
 BinaryValue::~BinaryValue() {
 }
@@ -320,7 +314,7 @@ std::unique_ptr<BinaryValue> BinaryValue::CreateWithCopiedBuffer(
     size_t size) {
   std::unique_ptr<char[]> buffer_copy(new char[size]);
   memcpy(buffer_copy.get(), buffer, size);
-  return base::MakeUnique<BinaryValue>(std::move(buffer_copy), size);
+  return MakeUnique<BinaryValue>(std::move(buffer_copy), size);
 }
 
 bool BinaryValue::GetAsBinary(const BinaryValue** out_value) const {
@@ -355,9 +349,7 @@ std::unique_ptr<DictionaryValue> DictionaryValue::From(
   return nullptr;
 }
 
-DictionaryValue::DictionaryValue()
-    : Value(TYPE_DICTIONARY) {
-}
+DictionaryValue::DictionaryValue() : Value(Type::DICTIONARY) {}
 
 DictionaryValue::~DictionaryValue() {
   Clear();
@@ -390,21 +382,22 @@ void DictionaryValue::Set(StringPiece path, std::unique_ptr<Value> in_value) {
   DCHECK(IsStringUTF8(path));
   DCHECK(in_value);
 
-  std::string current_path(path.as_string());
+  StringPiece current_path(path);
   DictionaryValue* current_dictionary = this;
   for (size_t delimiter_position = current_path.find('.');
-       delimiter_position != std::string::npos;
+       delimiter_position != StringPiece::npos;
        delimiter_position = current_path.find('.')) {
     // Assume that we're indexing into a dictionary.
-    std::string key(current_path, 0, delimiter_position);
-    DictionaryValue* child_dictionary = NULL;
+    StringPiece key = current_path.substr(0, delimiter_position);
+    DictionaryValue* child_dictionary = nullptr;
     if (!current_dictionary->GetDictionary(key, &child_dictionary)) {
       child_dictionary = new DictionaryValue;
-      current_dictionary->SetWithoutPathExpansion(key, child_dictionary);
+      current_dictionary->SetWithoutPathExpansion(
+          key, base::WrapUnique(child_dictionary));
     }
 
     current_dictionary = child_dictionary;
-    current_path.erase(0, delimiter_position + 1);
+    current_path = current_path.substr(delimiter_position + 1);
   }
 
   current_dictionary->SetWithoutPathExpansion(current_path,
@@ -428,7 +421,7 @@ void DictionaryValue::SetDouble(StringPiece path, double in_value) {
 }
 
 void DictionaryValue::SetString(StringPiece path, StringPiece in_value) {
-  Set(path, new StringValue(in_value.as_string()));
+  Set(path, new StringValue(in_value));
 }
 
 void DictionaryValue::SetString(StringPiece path, const string16& in_value) {
@@ -447,27 +440,30 @@ void DictionaryValue::SetWithoutPathExpansion(StringPiece key,
 
 void DictionaryValue::SetBooleanWithoutPathExpansion(StringPiece path,
                                                      bool in_value) {
-  SetWithoutPathExpansion(path, new FundamentalValue(in_value));
+  SetWithoutPathExpansion(path,
+                          base::MakeUnique<base::FundamentalValue>(in_value));
 }
 
 void DictionaryValue::SetIntegerWithoutPathExpansion(StringPiece path,
                                                      int in_value) {
-  SetWithoutPathExpansion(path, new FundamentalValue(in_value));
+  SetWithoutPathExpansion(path,
+                          base::MakeUnique<base::FundamentalValue>(in_value));
 }
 
 void DictionaryValue::SetDoubleWithoutPathExpansion(StringPiece path,
                                                     double in_value) {
-  SetWithoutPathExpansion(path, new FundamentalValue(in_value));
+  SetWithoutPathExpansion(path,
+                          base::MakeUnique<base::FundamentalValue>(in_value));
 }
 
 void DictionaryValue::SetStringWithoutPathExpansion(StringPiece path,
                                                     StringPiece in_value) {
-  SetWithoutPathExpansion(path, new StringValue(in_value.as_string()));
+  SetWithoutPathExpansion(path, base::MakeUnique<base::StringValue>(in_value));
 }
 
 void DictionaryValue::SetStringWithoutPathExpansion(StringPiece path,
                                                     const string16& in_value) {
-  SetWithoutPathExpansion(path, new StringValue(in_value));
+  SetWithoutPathExpansion(path, base::MakeUnique<base::StringValue>(in_value));
 }
 
 bool DictionaryValue::Get(StringPiece path,
@@ -480,8 +476,7 @@ bool DictionaryValue::Get(StringPiece path,
        delimiter_position = current_path.find('.')) {
     const DictionaryValue* child_dictionary = NULL;
     if (!current_dictionary->GetDictionaryWithoutPathExpansion(
-            current_path.substr(0, delimiter_position).as_string(),
-            &child_dictionary)) {
+            current_path.substr(0, delimiter_position), &child_dictionary)) {
       return false;
     }
 
@@ -489,8 +484,7 @@ bool DictionaryValue::Get(StringPiece path,
     current_path = current_path.substr(delimiter_position + 1);
   }
 
-  return current_dictionary->GetWithoutPathExpansion(current_path.as_string(),
-                                                     out_value);
+  return current_dictionary->GetWithoutPathExpansion(current_path, out_value);
 }
 
 bool DictionaryValue::Get(StringPiece path, Value** out_value)  {
@@ -559,7 +553,7 @@ bool DictionaryValue::GetBinary(StringPiece path,
                                 const BinaryValue** out_value) const {
   const Value* value;
   bool result = Get(path, &value);
-  if (!result || !value->IsType(TYPE_BINARY))
+  if (!result || !value->IsType(Type::BINARY))
     return false;
 
   if (out_value)
@@ -578,7 +572,7 @@ bool DictionaryValue::GetDictionary(StringPiece path,
                                     const DictionaryValue** out_value) const {
   const Value* value;
   bool result = Get(path, &value);
-  if (!result || !value->IsType(TYPE_DICTIONARY))
+  if (!result || !value->IsType(Type::DICTIONARY))
     return false;
 
   if (out_value)
@@ -598,7 +592,7 @@ bool DictionaryValue::GetList(StringPiece path,
                               const ListValue** out_value) const {
   const Value* value;
   bool result = Get(path, &value);
-  if (!result || !value->IsType(TYPE_LIST))
+  if (!result || !value->IsType(Type::LIST))
     return false;
 
   if (out_value)
@@ -683,7 +677,7 @@ bool DictionaryValue::GetDictionaryWithoutPathExpansion(
     const DictionaryValue** out_value) const {
   const Value* value;
   bool result = GetWithoutPathExpansion(key, &value);
-  if (!result || !value->IsType(TYPE_DICTIONARY))
+  if (!result || !value->IsType(Type::DICTIONARY))
     return false;
 
   if (out_value)
@@ -707,7 +701,7 @@ bool DictionaryValue::GetListWithoutPathExpansion(
     const ListValue** out_value) const {
   const Value* value;
   bool result = GetWithoutPathExpansion(key, &value);
-  if (!result || !value->IsType(TYPE_LIST))
+  if (!result || !value->IsType(Type::LIST))
     return false;
 
   if (out_value)
@@ -727,14 +721,14 @@ bool DictionaryValue::GetListWithoutPathExpansion(StringPiece key,
 bool DictionaryValue::Remove(StringPiece path,
                              std::unique_ptr<Value>* out_value) {
   DCHECK(IsStringUTF8(path));
-  std::string current_path(path.as_string());
+  StringPiece current_path(path);
   DictionaryValue* current_dictionary = this;
   size_t delimiter_position = current_path.rfind('.');
-  if (delimiter_position != std::string::npos) {
+  if (delimiter_position != StringPiece::npos) {
     if (!GetDictionary(current_path.substr(0, delimiter_position),
                        &current_dictionary))
       return false;
-    current_path.erase(0, delimiter_position + 1);
+    current_path = current_path.substr(delimiter_position + 1);
   }
 
   return current_dictionary->RemoveWithoutPathExpansion(current_path,
@@ -788,7 +782,7 @@ void DictionaryValue::MergeDictionary(const DictionaryValue* dictionary) {
   for (DictionaryValue::Iterator it(*dictionary); !it.IsAtEnd(); it.Advance()) {
     const Value* merge_value = &it.value();
     // Check whether we have to merge dictionaries.
-    if (merge_value->IsType(Value::TYPE_DICTIONARY)) {
+    if (merge_value->IsType(Value::Type::DICTIONARY)) {
       DictionaryValue* sub_dict;
       if (GetDictionaryWithoutPathExpansion(it.key(), &sub_dict)) {
         sub_dict->MergeDictionary(
@@ -797,7 +791,8 @@ void DictionaryValue::MergeDictionary(const DictionaryValue* dictionary) {
       }
     }
     // All other cases: Make a copy and hook it up.
-    SetWithoutPathExpansion(it.key(), merge_value->DeepCopy());
+    SetWithoutPathExpansion(it.key(),
+                            base::WrapUnique(merge_value->DeepCopy()));
   }
 }
 
@@ -862,8 +857,7 @@ std::unique_ptr<ListValue> ListValue::From(std::unique_ptr<Value> value) {
   return nullptr;
 }
 
-ListValue::ListValue() : Value(TYPE_LIST) {
-}
+ListValue::ListValue() : Value(Type::LIST) {}
 
 ListValue::~ListValue() {
   Clear();
@@ -953,7 +947,7 @@ bool ListValue::GetString(size_t index, string16* out_value) const {
 bool ListValue::GetBinary(size_t index, const BinaryValue** out_value) const {
   const Value* value;
   bool result = Get(index, &value);
-  if (!result || !value->IsType(TYPE_BINARY))
+  if (!result || !value->IsType(Type::BINARY))
     return false;
 
   if (out_value)
@@ -972,7 +966,7 @@ bool ListValue::GetDictionary(size_t index,
                               const DictionaryValue** out_value) const {
   const Value* value;
   bool result = Get(index, &value);
-  if (!result || !value->IsType(TYPE_DICTIONARY))
+  if (!result || !value->IsType(Type::DICTIONARY))
     return false;
 
   if (out_value)
@@ -990,7 +984,7 @@ bool ListValue::GetDictionary(size_t index, DictionaryValue** out_value) {
 bool ListValue::GetList(size_t index, const ListValue** out_value) const {
   const Value* value;
   bool result = Get(index, &value);
-  if (!result || !value->IsType(TYPE_LIST))
+  if (!result || !value->IsType(Type::LIST))
     return false;
 
   if (out_value)
@@ -1042,29 +1036,31 @@ void ListValue::Append(std::unique_ptr<Value> in_value) {
   list_.push_back(std::move(in_value));
 }
 
+#if !defined(OS_LINUX)
 void ListValue::Append(Value* in_value) {
   DCHECK(in_value);
   Append(WrapUnique(in_value));
 }
+#endif
 
 void ListValue::AppendBoolean(bool in_value) {
-  Append(new FundamentalValue(in_value));
+  Append(MakeUnique<FundamentalValue>(in_value));
 }
 
 void ListValue::AppendInteger(int in_value) {
-  Append(new FundamentalValue(in_value));
+  Append(MakeUnique<FundamentalValue>(in_value));
 }
 
 void ListValue::AppendDouble(double in_value) {
-  Append(new FundamentalValue(in_value));
+  Append(MakeUnique<FundamentalValue>(in_value));
 }
 
 void ListValue::AppendString(StringPiece in_value) {
-  Append(new StringValue(in_value.as_string()));
+  Append(MakeUnique<StringValue>(in_value));
 }
 
 void ListValue::AppendString(const string16& in_value) {
-  Append(new StringValue(in_value));
+  Append(MakeUnique<StringValue>(in_value));
 }
 
 void ListValue::AppendStrings(const std::vector<std::string>& in_values) {
@@ -1168,4 +1164,11 @@ std::ostream& operator<<(std::ostream& out, const Value& value) {
   return out << json;
 }
 
+std::ostream& operator<<(std::ostream& out, const Value::Type& type) {
+  if (static_cast<int>(type) < 0 ||
+      static_cast<size_t>(type) >= arraysize(kTypeNames))
+    return out << "Invalid Type (index = " << static_cast<int>(type) << ")";
+  return out << Value::GetTypeName(type);
+}
+
 }  // namespace base
diff --git a/src/base/values.h b/src/base/values.h
index 32441ae..14a02e4 100644
--- a/src/base/values.h
+++ b/src/base/values.h
@@ -49,15 +49,15 @@ class Value;
 // See the file-level comment above for more information.
 class BASE_EXPORT Value {
  public:
-  enum Type {
-    TYPE_NULL = 0,
-    TYPE_BOOLEAN,
-    TYPE_INTEGER,
-    TYPE_DOUBLE,
-    TYPE_STRING,
-    TYPE_BINARY,
-    TYPE_DICTIONARY,
-    TYPE_LIST
+  enum class Type {
+    NONE = 0,
+    BOOLEAN,
+    INTEGER,
+    DOUBLE,
+    STRING,
+    BINARY,
+    DICTIONARY,
+    LIST
     // Note: Do not add more types. See the file-level comment above for why.
   };
 
@@ -89,8 +89,10 @@ class BASE_EXPORT Value {
   virtual bool GetAsString(string16* out_value) const;
   virtual bool GetAsString(const StringValue** out_value) const;
   virtual bool GetAsBinary(const BinaryValue** out_value) const;
+  // ListValue::From is the equivalent for std::unique_ptr conversions.
   virtual bool GetAsList(ListValue** out_value);
   virtual bool GetAsList(const ListValue** out_value) const;
+  // DictionaryValue::From is the equivalent for std::unique_ptr conversions.
   virtual bool GetAsDictionary(DictionaryValue** out_value);
   virtual bool GetAsDictionary(const DictionaryValue** out_value) const;
   // Note: Do not add more types. See the file-level comment above for why.
@@ -132,7 +134,7 @@ class BASE_EXPORT FundamentalValue : public Value {
   // Overridden from Value:
   bool GetAsBoolean(bool* out_value) const override;
   bool GetAsInteger(int* out_value) const override;
-  // Values of both type TYPE_INTEGER and TYPE_DOUBLE can be obtained as
+  // Values of both type Type::INTEGER and Type::DOUBLE can be obtained as
   // doubles.
   bool GetAsDouble(double* out_value) const override;
   FundamentalValue* DeepCopy() const override;
@@ -285,7 +287,7 @@ class BASE_EXPORT DictionaryValue : public Value {
   // |out_value| is optional and will only be set if non-NULL.
   bool GetBoolean(StringPiece path, bool* out_value) const;
   bool GetInteger(StringPiece path, int* out_value) const;
-  // Values of both type TYPE_INTEGER and TYPE_DOUBLE can be obtained as
+  // Values of both type Type::INTEGER and Type::DOUBLE can be obtained as
   // doubles.
   bool GetDouble(StringPiece path, double* out_value) const;
   bool GetString(StringPiece path, std::string* out_value) const;
@@ -325,7 +327,7 @@ class BASE_EXPORT DictionaryValue : public Value {
   // |out_value|.  If |out_value| is NULL, the removed value will be deleted.
   // This method returns true if |path| is a valid path; otherwise it will
   // return false and the DictionaryValue object will be unchanged.
-  virtual bool Remove(StringPiece path, std::unique_ptr<Value>* out_value);
+  bool Remove(StringPiece path, std::unique_ptr<Value>* out_value);
 
   // Like Remove(), but without special treatment of '.'.  This allows e.g. URLs
   // to be used as paths.
@@ -334,7 +336,7 @@ class BASE_EXPORT DictionaryValue : public Value {
 
   // Removes a path, clearing out all dictionaries on |path| that remain empty
   // after removing the value at |path|.
-  virtual bool RemovePath(StringPiece path, std::unique_ptr<Value>* out_value);
+  bool RemovePath(StringPiece path, std::unique_ptr<Value>* out_value);
 
   // Makes a copy of |this| but doesn't include empty dictionaries and lists in
   // the copy.  This never returns NULL, even if |this| itself is empty.
@@ -425,7 +427,7 @@ class BASE_EXPORT ListValue : public Value {
   // |out_value| is optional and will only be set if non-NULL.
   bool GetBoolean(size_t index, bool* out_value) const;
   bool GetInteger(size_t index, int* out_value) const;
-  // Values of both type TYPE_INTEGER and TYPE_DOUBLE can be obtained as
+  // Values of both type Type::INTEGER and Type::DOUBLE can be obtained as
   // doubles.
   bool GetDouble(size_t index, double* out_value) const;
   bool GetString(size_t index, std::string* out_value) const;
@@ -457,8 +459,10 @@ class BASE_EXPORT ListValue : public Value {
 
   // Appends a Value to the end of the list.
   void Append(std::unique_ptr<Value> in_value);
+#if !defined(OS_LINUX)
   // Deprecated version of the above. TODO(estade): remove.
   void Append(Value* in_value);
+#endif
 
   // Convenience forms of Append.
   void AppendBoolean(bool in_value);
@@ -558,6 +562,10 @@ BASE_EXPORT inline std::ostream& operator<<(std::ostream& out,
   return out << static_cast<const Value&>(value);
 }
 
+// Stream operator so that enum class Types can be used in log statements.
+BASE_EXPORT std::ostream& operator<<(std::ostream& out,
+                                     const Value::Type& type);
+
 }  // namespace base
 
 #endif  // BASE_VALUES_H_
diff --git a/src/build/build_config.h b/src/build/build_config.h
index 5785abf..fd5489f 100644
--- a/src/build/build_config.h
+++ b/src/build/build_config.h
@@ -6,6 +6,7 @@
 //  Operating System:
 //    OS_WIN / OS_MACOSX / OS_LINUX / OS_POSIX (MACOSX or LINUX) /
 //    OS_NACL (NACL_SFI or NACL_NONSFI) / OS_NACL_SFI / OS_NACL_NONSFI
+//    OS_CHROMEOS is set by the build system
 //  Compiler:
 //    COMPILER_MSVC / COMPILER_GCC
 //  Processor:
@@ -48,7 +49,6 @@
 #endif
 #elif defined(_WIN32)
 #define OS_WIN 1
-#define TOOLKIT_VIEWS 1
 #elif defined(__FreeBSD__)
 #define OS_FREEBSD 1
 #elif defined(__NetBSD__)
@@ -111,6 +111,31 @@
 #define ARCH_CPU_X86 1
 #define ARCH_CPU_32_BITS 1
 #define ARCH_CPU_LITTLE_ENDIAN 1
+#elif defined(__s390x__)
+#define ARCH_CPU_S390_FAMILY 1
+#define ARCH_CPU_S390X 1
+#define ARCH_CPU_64_BITS 1
+#define ARCH_CPU_BIG_ENDIAN 1
+#elif defined(__s390__)
+#define ARCH_CPU_S390_FAMILY 1
+#define ARCH_CPU_S390 1
+#define ARCH_CPU_31_BITS 1
+#define ARCH_CPU_BIG_ENDIAN 1
+#elif defined(__PPC64__) && defined(__BIG_ENDIAN__)
+#define ARCH_CPU_PPC64_FAMILY 1
+#define ARCH_CPU_PPC64 1
+#define ARCH_CPU_64_BITS 1
+#define ARCH_CPU_BIG_ENDIAN 1
+#elif defined(__PPC64__) && defined(__LITTLE_ENDIAN__)
+#define ARCH_CPU_PPC64_FAMILY 1
+#define ARCH_CPU_PPC64 1
+#define ARCH_CPU_64_BITS 1
+#define ARCH_CPU_LITTLE_ENDIAN 1
+#elif defined(__PPC__)
+#define ARCH_CPU_PPC_FAMILY 1
+#define ARCH_CPU_PPC 1
+#define ARCH_CPU_32_BITS 1
+#define ARCH_CPU_BIG_ENDIAN 1
 #elif defined(__ARMEL__)
 #define ARCH_CPU_ARM_FAMILY 1
 #define ARCH_CPU_ARMEL 1
diff --git a/src/crypto/curve25519.cc b/src/crypto/curve25519.cc
index 06c2f01..e540927 100644
--- a/src/crypto/curve25519.cc
+++ b/src/crypto/curve25519.cc
@@ -4,9 +4,10 @@
 
 #include "crypto/curve25519.h"
 
-#include <openssl/curve25519.h>
 #include <stdint.h>
 
+#include "third_party/boringssl/src/include/openssl/curve25519.h"
+
 namespace crypto {
 
 namespace curve25519 {
diff --git a/src/crypto/hmac.cc b/src/crypto/hmac.cc
index b4dd6cf..a9bb483 100644
--- a/src/crypto/hmac.cc
+++ b/src/crypto/hmac.cc
@@ -4,7 +4,6 @@
 
 #include "crypto/hmac.h"
 
-#include <openssl/hmac.h>
 #include <stddef.h>
 
 #include <algorithm>
@@ -14,6 +13,7 @@
 #include "crypto/openssl_util.h"
 #include "crypto/secure_util.h"
 #include "crypto/symmetric_key.h"
+#include "third_party/boringssl/src/include/openssl/hmac.h"
 
 namespace crypto {
 
diff --git a/src/crypto/openssl_util.cc b/src/crypto/openssl_util.cc
index 28355d6..4ad5c11 100644
--- a/src/crypto/openssl_util.cc
+++ b/src/crypto/openssl_util.cc
@@ -4,13 +4,13 @@
 
 #include "crypto/openssl_util.h"
 
-#include <openssl/crypto.h>
-#include <openssl/err.h>
 #include <stddef.h>
 #include <stdint.h>
 
 #include "base/logging.h"
 #include "base/strings/string_piece.h"
+#include "third_party/boringssl/src/include/openssl/crypto.h"
+#include "third_party/boringssl/src/include/openssl/err.h"
 
 namespace crypto {
 
diff --git a/src/crypto/scoped_openssl_types.h b/src/crypto/scoped_openssl_types.h
deleted file mode 100644
index 76dd0f4..0000000
--- a/src/crypto/scoped_openssl_types.h
+++ /dev/null
@@ -1,60 +0,0 @@
-// Copyright 2014 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef CRYPTO_SCOPED_OPENSSL_TYPES_H_
-#define CRYPTO_SCOPED_OPENSSL_TYPES_H_
-
-#include <openssl/bio.h>
-#include <openssl/bn.h>
-#include <openssl/dsa.h>
-#include <openssl/ec.h>
-#include <openssl/ecdsa.h>
-#include <openssl/evp.h>
-#include <openssl/mem.h>
-#include <openssl/rsa.h>
-#include <stdint.h>
-
-#include <memory>
-
-namespace crypto {
-
-// Simplistic helper that wraps a call to a deleter function. In a C++11 world,
-// this would be std::function<>. An alternative would be to re-use
-// base::internal::RunnableAdapter<>, but that's far too heavy weight.
-template <typename Type, void (*Destroyer)(Type*)>
-struct OpenSSLDestroyer {
-  void operator()(Type* ptr) const { Destroyer(ptr); }
-};
-
-template <typename PointerType, void (*Destroyer)(PointerType*)>
-using ScopedOpenSSL =
-    std::unique_ptr<PointerType, OpenSSLDestroyer<PointerType, Destroyer>>;
-
-struct OpenSSLFree {
-  void operator()(uint8_t* ptr) const { OPENSSL_free(ptr); }
-};
-
-// Several typedefs are provided for crypto-specific primitives, for
-// short-hand and prevalence. Note that OpenSSL types related to X.509 are
-// intentionally not included, as crypto/ does not generally deal with
-// certificates or PKI.
-using ScopedBIGNUM = ScopedOpenSSL<BIGNUM, BN_free>;
-using ScopedEC_Key = ScopedOpenSSL<EC_KEY, EC_KEY_free>;
-using ScopedBIO = ScopedOpenSSL<BIO, BIO_free_all>;
-using ScopedDSA = ScopedOpenSSL<DSA, DSA_free>;
-using ScopedECDSA_SIG = ScopedOpenSSL<ECDSA_SIG, ECDSA_SIG_free>;
-using ScopedEC_GROUP = ScopedOpenSSL<EC_GROUP, EC_GROUP_free>;
-using ScopedEC_KEY = ScopedOpenSSL<EC_KEY, EC_KEY_free>;
-using ScopedEC_POINT = ScopedOpenSSL<EC_POINT, EC_POINT_free>;
-using ScopedEVP_MD_CTX = ScopedOpenSSL<EVP_MD_CTX, EVP_MD_CTX_destroy>;
-using ScopedEVP_PKEY = ScopedOpenSSL<EVP_PKEY, EVP_PKEY_free>;
-using ScopedEVP_PKEY_CTX = ScopedOpenSSL<EVP_PKEY_CTX, EVP_PKEY_CTX_free>;
-using ScopedRSA = ScopedOpenSSL<RSA, RSA_free>;
-
-// The bytes must have been allocated with OPENSSL_malloc.
-using ScopedOpenSSLBytes = std::unique_ptr<uint8_t, OpenSSLFree>;
-
-}  // namespace crypto
-
-#endif  // CRYPTO_SCOPED_OPENSSL_TYPES_H_
diff --git a/src/crypto/secure_hash.cc b/src/crypto/secure_hash.cc
index 76d42d3..80286df 100644
--- a/src/crypto/secure_hash.cc
+++ b/src/crypto/secure_hash.cc
@@ -4,14 +4,14 @@
 
 #include "crypto/secure_hash.h"
 
-#include <openssl/mem.h>
-#include <openssl/sha.h>
 #include <stddef.h>
 
 #include "base/logging.h"
 #include "base/memory/ptr_util.h"
 #include "base/pickle.h"
 #include "crypto/openssl_util.h"
+#include "third_party/boringssl/src/include/openssl/mem.h"
+#include "third_party/boringssl/src/include/openssl/sha.h"
 
 namespace crypto {
 
diff --git a/src/crypto/symmetric_key.cc b/src/crypto/symmetric_key.cc
index e3ecf62..6a19f84 100644
--- a/src/crypto/symmetric_key.cc
+++ b/src/crypto/symmetric_key.cc
@@ -4,8 +4,6 @@
 
 #include "crypto/symmetric_key.h"
 
-#include <openssl/evp.h>
-#include <openssl/rand.h>
 #include <stddef.h>
 #include <stdint.h>
 
@@ -15,6 +13,8 @@
 #include "base/logging.h"
 #include "base/strings/string_util.h"
 #include "crypto/openssl_util.h"
+#include "third_party/boringssl/src/include/openssl/evp.h"
+#include "third_party/boringssl/src/include/openssl/rand.h"
 
 namespace crypto {
 
diff --git a/src/net/base/iovec.h b/src/net/base/iovec.h
index a98ed21..61e2593 100644
--- a/src/net/base/iovec.h
+++ b/src/net/base/iovec.h
@@ -7,6 +7,8 @@
 
 #include <stddef.h>
 
+#include "build/build_config.h"
+
 #if defined(OS_POSIX) && !defined(OS_NACL)
 #include <sys/uio.h>
 #else
diff --git a/src/net/base/linked_hash_map.h b/src/net/base/linked_hash_map.h
index 306ac52..8397243 100644
--- a/src/net/base/linked_hash_map.h
+++ b/src/net/base/linked_hash_map.h
@@ -24,6 +24,8 @@
 #include "base/logging.h"
 #include "base/macros.h"
 
+namespace net {
+
 // This holds a list of pair<Key, Value> items.  This list is what gets
 // traversed, and it's iterators from this list that we return from
 // begin/end/find.
@@ -115,6 +117,9 @@ class linked_hash_map {
     return list_.empty();
   }
 
+  // Removes the first element from the list.
+  void pop_front() { erase(begin()); }
+
   // Erases values with the provided key.  Returns the number of elements
   // erased.  In this implementation, this will be 0 or 1.
   size_type erase(const Key& key) {
@@ -254,4 +259,6 @@ class linked_hash_map {
   DISALLOW_COPY_AND_ASSIGN(linked_hash_map);
 };
 
+}  // namespace net
+
 #endif  // UTIL_GTL_LINKED_HASH_MAP_H_
diff --git a/src/net/base/net_error_list.h b/src/net/base/net_error_list.h
index 0b08b32..0a880f8 100644
--- a/src/net/base/net_error_list.h
+++ b/src/net/base/net_error_list.h
@@ -112,6 +112,10 @@ NET_ERROR(CONTEXT_SHUT_DOWN, -26)
 // checks, for instance).
 NET_ERROR(BLOCKED_BY_RESPONSE, -27)
 
+// The request failed after the response was received, based on client-side
+// heuristics that point to the possiblility of a cross-site scripting attack.
+NET_ERROR(BLOCKED_BY_XSS_AUDITOR, -28)
+
 // A connection was closed (corresponding to a TCP FIN).
 NET_ERROR(CONNECTION_CLOSED, -100)
 
@@ -190,7 +194,7 @@ NET_ERROR(SOCKS_CONNECTION_FAILED, -120)
 NET_ERROR(SOCKS_CONNECTION_HOST_UNREACHABLE, -121)
 
 // The request to negotiate an alternate protocol failed.
-NET_ERROR(NPN_NEGOTIATION_FAILED, -122)
+NET_ERROR(ALPN_NEGOTIATION_FAILED, -122)
 
 // The peer sent an SSL no_renegotiation alert message.
 NET_ERROR(SSL_NO_RENEGOTIATION, -123)
@@ -314,9 +318,7 @@ NET_ERROR(WS_THROTTLE_QUEUE_TOO_LARGE, -154)
 // The SSL server certificate changed in a renegotiation.
 NET_ERROR(SSL_SERVER_CERT_CHANGED, -156)
 
-// The SSL server indicated that an unnecessary TLS version fallback was
-// performed.
-NET_ERROR(SSL_INAPPROPRIATE_FALLBACK, -157)
+// Error -157 was removed (SSL_INAPPROPRIATE_FALLBACK).
 
 // Certificate Transparency: All Signed Certificate Timestamps failed to verify.
 NET_ERROR(CT_NO_SCTS_VERIFIED_OK, -158)
@@ -342,9 +344,7 @@ NET_ERROR(SOCKET_SEND_BUFFER_SIZE_UNCHANGEABLE, -163)
 // library.
 NET_ERROR(SSL_CLIENT_AUTH_CERT_BAD_FORMAT, -164)
 
-// The SSL server requires falling back to a version older than the configured
-// minimum fallback version, and thus fallback failed.
-NET_ERROR(SSL_FALLBACK_BEYOND_MINIMUM_VERSION, -165)
+// Error -165 was removed (SSL_FALLBACK_BEYOND_MINIMUM_VERSION).
 
 // Resolving a hostname to an IP address list included the IPv4 address
 // "127.0.53.53". This is a special IP address which ICANN has recommended to
@@ -683,6 +683,14 @@ NET_ERROR(PAC_SCRIPT_TERMINATED, -367)
 // than treat it as HTTP/0.9, this error is returned.
 NET_ERROR(INVALID_HTTP_RESPONSE, -370)
 
+// Initializing content decoding failed.
+NET_ERROR(CONTENT_DECODING_INIT_FAILED, -371)
+
+// Received HTTP/2 RST_STREAM frame with NO_ERROR error code.  This error should
+// be handled internally by HTTP/2 code, and should not make it above the
+// SpdyStream layer.
+NET_ERROR(SPDY_RST_STREAM_NO_ERROR_RECEIVED, -372)
+
 // The cache does not have the requested entry.
 NET_ERROR(CACHE_MISS, -400)
 
diff --git a/src/net/base/net_errors.cc b/src/net/base/net_errors.cc
index ddba87b..9d91659 100644
--- a/src/net/base/net_errors.cc
+++ b/src/net/base/net_errors.cc
@@ -52,6 +52,11 @@ bool IsClientCertificateError(int error) {
   }
 }
 
+bool IsDnsError(int error) {
+  return (error == ERR_NAME_NOT_RESOLVED ||
+          error == ERR_NAME_RESOLUTION_FAILED);
+}
+
 Error FileErrorToNetError(base::File::Error file_error) {
   switch (file_error) {
     case base::File::FILE_OK:
diff --git a/src/net/base/net_errors.h b/src/net/base/net_errors.h
index 27a2e51..8fe976d 100644
--- a/src/net/base/net_errors.h
+++ b/src/net/base/net_errors.h
@@ -44,6 +44,9 @@ NET_EXPORT bool IsCertificateError(int error);
 // certificate.
 NET_EXPORT bool IsClientCertificateError(int error);
 
+// Returns true if |error| is a DNS error.
+NET_EXPORT bool IsDnsError(int error);
+
 // Map system error code to Error.
 NET_EXPORT Error MapSystemError(logging::SystemErrorCode os_error);
 
diff --git a/src/net/base/net_errors_posix.cc b/src/net/base/net_errors_posix.cc
index a8573fd..123f7e5 100644
--- a/src/net/base/net_errors_posix.cc
+++ b/src/net/base/net_errors_posix.cc
@@ -10,7 +10,6 @@
 #include <unistd.h>
 
 #include "base/logging.h"
-#include "base/strings/stringprintf.h"
 
 namespace net {
 
diff --git a/src/net/base/parse_number.h b/src/net/base/parse_number.h
index dc66fb6..0b4cfc1 100644
--- a/src/net/base/parse_number.h
+++ b/src/net/base/parse_number.h
@@ -27,8 +27,6 @@
 //   This API tries to avoid these problems by picking sensible defaults for
 //   //net code. For more details see crbug.com/596523.
 
-class GURL;
-
 namespace net {
 
 // Format to use when parsing integers.
diff --git a/src/net/base/url_util.cc b/src/net/base/url_util.cc
index 562f39c..d699018 100644
--- a/src/net/base/url_util.cc
+++ b/src/net/base/url_util.cc
@@ -345,10 +345,9 @@ bool IsHostnameNonUnique(const std::string& hostname) {
   // is updated. However, because gTLDs are expected to provide significant
   // advance notice to deprecate older versions of this code, this an
   // acceptable tradeoff.
-  return 0 == registry_controlled_domains::GetRegistryLength(
-                  canonical_name,
-                  registry_controlled_domains::EXCLUDE_UNKNOWN_REGISTRIES,
-                  registry_controlled_domains::EXCLUDE_PRIVATE_REGISTRIES);
+  return !registry_controlled_domains::HostHasRegistryControlledDomain(
+      canonical_name, registry_controlled_domains::EXCLUDE_UNKNOWN_REGISTRIES,
+      registry_controlled_domains::EXCLUDE_PRIVATE_REGISTRIES);
 }
 #endif
 
@@ -378,6 +377,9 @@ bool IsLocalhost(base::StringPiece host) {
 
 GURL SimplifyUrlForRequest(const GURL& url) {
   DCHECK(url.is_valid());
+  // Fast path to avoid re-canonicalization via ReplaceComponents.
+  if (!url.has_username() && !url.has_password() && !url.has_ref())
+    return url;
   GURL::Replacements replacements;
   replacements.ClearUsername();
   replacements.ClearPassword();
diff --git a/src/net/http/http_auth_scheme.cc b/src/net/http/http_auth_scheme.cc
index 75debb3..4adfc74 100644
--- a/src/net/http/http_auth_scheme.cc
+++ b/src/net/http/http_auth_scheme.cc
@@ -2,7 +2,6 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-#include "net/base/net_export.h"
 #include "net/http/http_auth_scheme.h"
 
 namespace net {
diff --git a/src/net/http/http_auth_scheme.h b/src/net/http/http_auth_scheme.h
index 98e1785..fc74da9 100644
--- a/src/net/http/http_auth_scheme.h
+++ b/src/net/http/http_auth_scheme.h
@@ -5,6 +5,8 @@
 #ifndef NET_HTTP_HTTP_AUTH_SCHEME_H_
 #define NET_HTTP_HTTP_AUTH_SCHEME_H_
 
+#include "net/base/net_export.h"
+
 namespace net {
 NET_EXPORT extern const char kBasicAuthScheme[];
 NET_EXPORT extern const char kDigestAuthScheme[];
diff --git a/src/net/http/http_log_util.cc b/src/net/http/http_log_util.cc
index 9d86c4d..f92d3ee 100644
--- a/src/net/http/http_log_util.cc
+++ b/src/net/http/http_log_util.cc
@@ -11,6 +11,7 @@
 #include "net/http/http_auth_challenge_tokenizer.h"
 #include "net/http/http_auth_scheme.h"
 #include "net/http/http_util.h"
+#include "net/log/net_log_capture_mode.h"
 
 namespace net {
 
diff --git a/src/net/http/http_log_util.h b/src/net/http/http_log_util.h
index ce47139..3b8103c 100644
--- a/src/net/http/http_log_util.h
+++ b/src/net/http/http_log_util.h
@@ -9,7 +9,6 @@
 
 #include "base/strings/string_piece.h"
 #include "net/base/net_export.h"
-#include "net/log/net_log.h"
 #include "net/spdy/spdy_header_block.h"
 
 namespace base {
@@ -18,6 +17,8 @@ class ListValue;
 
 namespace net {
 
+class NetLogCaptureMode;
+
 // Given an HTTP header |header| with value |value|, returns the elided version
 // of the header value at |log_level|.
 NET_EXPORT_PRIVATE std::string ElideHeaderValueForNetLog(
diff --git a/src/net/http/http_util.cc b/src/net/http/http_util.cc
index aa2fdb6..26552e3 100644
--- a/src/net/http/http_util.cc
+++ b/src/net/http/http_util.cc
@@ -265,6 +265,79 @@ bool HttpUtil::ParseRangeHeader(const std::string& ranges_specifier,
 }
 
 // static
+// From RFC 2616 14.16:
+// content-range-spec =
+//     bytes-unit SP byte-range-resp-spec "/" ( instance-length | "*" )
+// byte-range-resp-spec = (first-byte-pos "-" last-byte-pos) | "*"
+// instance-length = 1*DIGIT
+// bytes-unit = "bytes"
+bool HttpUtil::ParseContentRangeHeader(base::StringPiece content_range_spec,
+                                       int64_t* first_byte_position,
+                                       int64_t* last_byte_position,
+                                       int64_t* instance_length) {
+  *first_byte_position = *last_byte_position = *instance_length = -1;
+  content_range_spec = TrimLWS(content_range_spec);
+
+  size_t space_position = content_range_spec.find(' ');
+  if (space_position == base::StringPiece::npos)
+    return false;
+
+  // Invalid header if it doesn't contain "bytes-unit".
+  if (!base::LowerCaseEqualsASCII(
+          TrimLWS(content_range_spec.substr(0, space_position)), "bytes")) {
+    return false;
+  }
+
+  size_t slash_position = content_range_spec.find('/', space_position + 1);
+  if (slash_position == base::StringPiece::npos)
+    return false;
+
+  // Obtain the part behind the space and before slash.
+  base::StringPiece byte_range_resp_spec = TrimLWS(content_range_spec.substr(
+      space_position + 1, slash_position - (space_position + 1)));
+
+  if (byte_range_resp_spec != "*") {
+    size_t minus_position = byte_range_resp_spec.find('-');
+    if (minus_position == base::StringPiece::npos)
+      return false;
+
+    // Obtain first-byte-pos and last-byte-pos.
+    if (!base::StringToInt64(
+            TrimLWS(byte_range_resp_spec.substr(0, minus_position)),
+            first_byte_position) ||
+        !base::StringToInt64(
+            TrimLWS(byte_range_resp_spec.substr(minus_position + 1)),
+            last_byte_position)) {
+      *first_byte_position = *last_byte_position = -1;
+      return false;
+    }
+    if (*first_byte_position < 0 || *last_byte_position < 0 ||
+        *first_byte_position > *last_byte_position)
+      return false;
+  }
+
+  // Parse the instance-length part.
+  base::StringPiece instance_length_spec =
+      TrimLWS(content_range_spec.substr(slash_position + 1));
+
+  if (base::StartsWith(instance_length_spec, "*",
+                       base::CompareCase::SENSITIVE)) {
+    return false;
+  } else if (!base::StringToInt64(instance_length_spec, instance_length)) {
+    *instance_length = -1;
+    return false;
+  }
+
+  // We have all the values; let's verify that they make sense for a 206
+  // response.
+  if (*first_byte_position < 0 || *last_byte_position < 0 ||
+      *instance_length < 0 || *instance_length - 1 < *last_byte_position)
+    return false;
+
+  return true;
+}
+
+// static
 bool HttpUtil::ParseRetryAfterHeader(const std::string& retry_after_string,
                                      base::Time now,
                                      base::TimeDelta* retry_after) {
@@ -345,8 +418,9 @@ bool HttpUtil::IsSafeHeader(const std::string& name) {
   if (base::StartsWith(lower_name, "proxy-", base::CompareCase::SENSITIVE) ||
       base::StartsWith(lower_name, "sec-", base::CompareCase::SENSITIVE))
     return false;
-  for (size_t i = 0; i < arraysize(kForbiddenHeaderFields); ++i) {
-    if (lower_name == kForbiddenHeaderFields[i])
+
+  for (const char* field : kForbiddenHeaderFields) {
+    if (lower_name == field)
       return false;
   }
   return true;
@@ -414,16 +488,19 @@ bool HttpUtil::IsNonCoalescingHeader(std::string::const_iterator name_begin,
     // one.
     "strict-transport-security"
   };
-  for (size_t i = 0; i < arraysize(kNonCoalescingHeaders); ++i) {
+
+  for (const char* header : kNonCoalescingHeaders) {
     if (base::LowerCaseEqualsASCII(base::StringPiece(name_begin, name_end),
-                                   kNonCoalescingHeaders[i]))
+                                   header)) {
       return true;
+    }
   }
   return false;
 }
 
 bool HttpUtil::IsLWS(char c) {
-  return strchr(HTTP_LWS, c) != NULL;
+  const base::StringPiece kWhiteSpaceCharacters(HTTP_LWS);
+  return kWhiteSpaceCharacters.find(c) != base::StringPiece::npos;
 }
 
 // static
diff --git a/src/net/http/http_util.h b/src/net/http/http_util.h
index 8658b57..fe68423 100644
--- a/src/net/http/http_util.h
+++ b/src/net/http/http_util.h
@@ -6,6 +6,7 @@
 #define NET_HTTP_HTTP_UTIL_H_
 
 #include <stddef.h>
+#include <stdint.h>
 
 #include <string>
 #include <vector>
@@ -59,6 +60,21 @@ class NET_EXPORT HttpUtil {
   static bool ParseRangeHeader(const std::string& range_specifier,
                                std::vector<HttpByteRange>* ranges);
 
+  // Extracts the values in a Content-Range header and returns true if they are
+  // valid for a 206 response; otherwise returns false.
+  // The following values will be outputted:
+  // |*first_byte_position| = inclusive position of the first byte of the range
+  // |*last_byte_position| = inclusive position of the last byte of the range
+  // |*instance_length| = size in bytes of the object requested
+  // If any of the above values is unknown, its value will be -1.
+  // TODO(sclittle): Change this method to only support Content-Range headers
+  // from 206 responses, since right now it only has incomplete support for
+  // Content-Range headers from 416 responses. See crbug.com/670913.
+  static bool ParseContentRangeHeader(base::StringPiece content_range_spec,
+                                      int64_t* first_byte_position,
+                                      int64_t* last_byte_position,
+                                      int64_t* instance_length);
+
   // Parses a Retry-After header that is either an absolute date/time or a
   // number of seconds in the future. Interprets absolute times as relative to
   // |now|. If |retry_after_string| is successfully parsed and indicates a time
diff --git a/src/net/log/net_log.cc b/src/net/log/net_log.cc
index 8abaea4..c482877 100644
--- a/src/net/log/net_log.cc
+++ b/src/net/log/net_log.cc
@@ -4,47 +4,19 @@
 
 #include "net/log/net_log.h"
 
+#include <algorithm>
 #include <utility>
 
 #include "base/bind.h"
-#include "base/debug/alias.h"
 #include "base/logging.h"
 #include "base/strings/string_number_conversions.h"
 #include "base/strings/utf_string_conversions.h"
-#include "base/time/time.h"
 #include "base/values.h"
-#include "net/base/net_errors.h"
 
 namespace net {
 
 namespace {
 
-// Returns parameters for logging data transferred events. At a minimum includes
-// the number of bytes transferred. If the capture mode allows logging byte
-// contents and |byte_count| > 0, then will include the actual bytes. The
-// bytes are hex-encoded, since base::StringValue only supports UTF-8.
-std::unique_ptr<base::Value> BytesTransferredCallback(
-    int byte_count,
-    const char* bytes,
-    NetLogCaptureMode capture_mode) {
-  std::unique_ptr<base::DictionaryValue> dict(new base::DictionaryValue());
-  dict->SetInteger("byte_count", byte_count);
-  if (capture_mode.include_socket_bytes() && byte_count > 0)
-    dict->SetString("hex_encoded_bytes", base::HexEncode(bytes, byte_count));
-  return std::move(dict);
-}
-
-std::unique_ptr<base::Value> SourceEventParametersCallback(
-    const NetLog::Source source,
-    NetLogCaptureMode /* capture_mode */) {
-  if (!source.IsValid())
-    return std::unique_ptr<base::Value>();
-  std::unique_ptr<base::DictionaryValue> event_params(
-      new base::DictionaryValue());
-  source.AddToEventParameters(event_params.get());
-  return std::move(event_params);
-}
-
 std::unique_ptr<base::Value> NetLogBoolCallback(
     const char* name,
     bool value,
@@ -107,106 +79,6 @@ std::unique_ptr<base::Value> NetLogString16Callback(
 
 }  // namespace
 
-// LoadTimingInfo requires this be 0.
-const uint32_t NetLog::Source::kInvalidId = 0;
-
-NetLog::Source::Source() : type(NetLogSourceType::NONE), id(kInvalidId) {}
-
-NetLog::Source::Source(NetLogSourceType type, uint32_t id)
-    : type(type), id(id) {}
-
-bool NetLog::Source::IsValid() const {
-  return id != kInvalidId;
-}
-
-void NetLog::Source::AddToEventParameters(
-    base::DictionaryValue* event_params) const {
-  std::unique_ptr<base::DictionaryValue> dict(new base::DictionaryValue());
-  dict->SetInteger("type", static_cast<int>(type));
-  dict->SetInteger("id", static_cast<int>(id));
-  event_params->Set("source_dependency", std::move(dict));
-}
-
-NetLog::ParametersCallback NetLog::Source::ToEventParametersCallback() const {
-  return base::Bind(&SourceEventParametersCallback, *this);
-}
-
-// static
-bool NetLog::Source::FromEventParameters(base::Value* event_params,
-                                         Source* source) {
-  base::DictionaryValue* dict = NULL;
-  base::DictionaryValue* source_dict = NULL;
-  int source_id = -1;
-  int source_type = static_cast<int>(NetLogSourceType::COUNT);
-  if (!event_params || !event_params->GetAsDictionary(&dict) ||
-      !dict->GetDictionary("source_dependency", &source_dict) ||
-      !source_dict->GetInteger("id", &source_id) ||
-      !source_dict->GetInteger("type", &source_type)) {
-    *source = Source();
-    return false;
-  }
-
-  DCHECK_GE(source_id, 0);
-  DCHECK_LT(source_type, static_cast<int>(NetLogSourceType::COUNT));
-  *source = Source(static_cast<NetLogSourceType>(source_type), source_id);
-  return true;
-}
-
-std::unique_ptr<base::Value> NetLog::Entry::ToValue() const {
-  std::unique_ptr<base::DictionaryValue> entry_dict(
-      new base::DictionaryValue());
-
-  entry_dict->SetString("time", TickCountToString(data_->time));
-
-  // Set the entry source.
-  std::unique_ptr<base::DictionaryValue> source_dict(
-      new base::DictionaryValue());
-  source_dict->SetInteger("id", data_->source.id);
-  source_dict->SetInteger("type", static_cast<int>(data_->source.type));
-  entry_dict->Set("source", std::move(source_dict));
-
-  // Set the event info.
-  entry_dict->SetInteger("type", static_cast<int>(data_->type));
-  entry_dict->SetInteger("phase", static_cast<int>(data_->phase));
-
-  // Set the event-specific parameters.
-  if (data_->parameters_callback) {
-    std::unique_ptr<base::Value> value(
-        data_->parameters_callback->Run(capture_mode_));
-    if (value)
-      entry_dict->Set("params", std::move(value));
-  }
-
-  return std::move(entry_dict);
-}
-
-std::unique_ptr<base::Value> NetLog::Entry::ParametersToValue() const {
-  if (data_->parameters_callback)
-    return data_->parameters_callback->Run(capture_mode_);
-  return nullptr;
-}
-
-NetLog::EntryData::EntryData(NetLogEventType type,
-                             Source source,
-                             NetLogEventPhase phase,
-                             base::TimeTicks time,
-                             const ParametersCallback* parameters_callback)
-    : type(type),
-      source(source),
-      phase(phase),
-      time(time),
-      parameters_callback(parameters_callback) {}
-
-NetLog::EntryData::~EntryData() {
-}
-
-NetLog::Entry::Entry(const EntryData* data, NetLogCaptureMode capture_mode)
-    : data_(data), capture_mode_(capture_mode) {
-}
-
-NetLog::Entry::~Entry() {
-}
-
 NetLog::ThreadSafeObserver::ThreadSafeObserver() : net_log_(NULL) {
 }
 
@@ -226,8 +98,9 @@ NetLog* NetLog::ThreadSafeObserver::net_log() const {
   return net_log_;
 }
 
-void NetLog::ThreadSafeObserver::OnAddEntryData(const EntryData& entry_data) {
-  OnAddEntry(Entry(&entry_data, capture_mode()));
+void NetLog::ThreadSafeObserver::OnAddEntryData(
+    const NetLogEntryData& entry_data) {
+  OnAddEntry(NetLogEntry(&entry_data, capture_mode()));
 }
 
 NetLog::NetLog() : last_id_(0), is_capturing_(0) {
@@ -237,14 +110,14 @@ NetLog::~NetLog() {
 }
 
 void NetLog::AddGlobalEntry(NetLogEventType type) {
-  AddEntry(type, Source(NetLogSourceType::NONE, NextID()),
+  AddEntry(type, NetLogSource(NetLogSourceType::NONE, NextID()),
            NetLogEventPhase::NONE, NULL);
 }
 
 void NetLog::AddGlobalEntry(
     NetLogEventType type,
-    const NetLog::ParametersCallback& parameters_callback) {
-  AddEntry(type, Source(NetLogSourceType::NONE, NextID()),
+    const NetLogParametersCallback& parameters_callback) {
+  AddEntry(type, NetLogSource(NetLogSourceType::NONE, NextID()),
            NetLogEventPhase::NONE, &parameters_callback);
 }
 
@@ -261,7 +134,11 @@ void NetLog::DeprecatedAddObserver(NetLog::ThreadSafeObserver* observer,
   base::AutoLock lock(lock_);
 
   DCHECK(!observer->net_log_);
-  observers_.AddObserver(observer);
+  DCHECK(!HasObserver(observer));
+  DCHECK_LT(observers_.size(), 20u);  // Performance sanity check.
+
+  observers_.push_back(observer);
+
   observer->net_log_ = this;
   observer->capture_mode_ = capture_mode;
   UpdateIsCapturing();
@@ -271,7 +148,7 @@ void NetLog::SetObserverCaptureMode(NetLog::ThreadSafeObserver* observer,
                                     NetLogCaptureMode capture_mode) {
   base::AutoLock lock(lock_);
 
-  DCHECK(observers_.HasObserver(observer));
+  DCHECK(HasObserver(observer));
   DCHECK_EQ(this, observer->net_log_);
   observer->capture_mode_ = capture_mode;
 }
@@ -279,9 +156,12 @@ void NetLog::SetObserverCaptureMode(NetLog::ThreadSafeObserver* observer,
 void NetLog::DeprecatedRemoveObserver(NetLog::ThreadSafeObserver* observer) {
   base::AutoLock lock(lock_);
 
-  DCHECK(observers_.HasObserver(observer));
   DCHECK_EQ(this, observer->net_log_);
-  observers_.RemoveObserver(observer);
+
+  auto it = std::find(observers_.begin(), observers_.end(), observer);
+  DCHECK(it != observers_.end());
+  observers_.erase(it);
+
   observer->net_log_ = NULL;
   observer->capture_mode_ = NetLogCaptureMode();
   UpdateIsCapturing();
@@ -289,8 +169,13 @@ void NetLog::DeprecatedRemoveObserver(NetLog::ThreadSafeObserver* observer) {
 
 void NetLog::UpdateIsCapturing() {
   lock_.AssertAcquired();
-  base::subtle::NoBarrier_Store(&is_capturing_,
-                                observers_.might_have_observers() ? 1 : 0);
+  base::subtle::NoBarrier_Store(&is_capturing_, observers_.size() ? 1 : 0);
+}
+
+bool NetLog::HasObserver(ThreadSafeObserver* observer) {
+  lock_.AssertAcquired();
+  auto it = std::find(observers_.begin(), observers_.end(), observer);
+  return it != observers_.end();
 }
 
 // static
@@ -360,157 +245,55 @@ const char* NetLog::EventPhaseToString(NetLogEventPhase phase) {
 }
 
 // static
-NetLog::ParametersCallback NetLog::BoolCallback(const char* name, bool value) {
+NetLogParametersCallback NetLog::BoolCallback(const char* name, bool value) {
   return base::Bind(&NetLogBoolCallback, name, value);
 }
 
 // static
-NetLog::ParametersCallback NetLog::IntCallback(const char* name, int value) {
+NetLogParametersCallback NetLog::IntCallback(const char* name, int value) {
   return base::Bind(&NetLogIntCallback, name, value);
 }
 
 // static
-NetLog::ParametersCallback NetLog::Int64Callback(const char* name,
-                                                 int64_t value) {
+NetLogParametersCallback NetLog::Int64Callback(const char* name,
+                                               int64_t value) {
   return base::Bind(&NetLogInt64Callback, name, value);
 }
 
 // static
-NetLog::ParametersCallback NetLog::StringCallback(const char* name,
-                                                  const std::string* value) {
+NetLogParametersCallback NetLog::StringCallback(const char* name,
+                                                const std::string* value) {
   DCHECK(value);
   return base::Bind(&NetLogStringCallback, name, value);
 }
 
 // static
-NetLog::ParametersCallback NetLog::StringCallback(const char* name,
-                                                  const char* value) {
+NetLogParametersCallback NetLog::StringCallback(const char* name,
+                                                const char* value) {
   DCHECK(value);
   return base::Bind(&NetLogCharStringCallback, name, value);
 }
 
 // static
-NetLog::ParametersCallback NetLog::StringCallback(const char* name,
-                                                  const base::string16* value) {
+NetLogParametersCallback NetLog::StringCallback(const char* name,
+                                                const base::string16* value) {
   DCHECK(value);
   return base::Bind(&NetLogString16Callback, name, value);
 }
 
 void NetLog::AddEntry(NetLogEventType type,
-                      const Source& source,
+                      const NetLogSource& source,
                       NetLogEventPhase phase,
-                      const NetLog::ParametersCallback* parameters_callback) {
+                      const NetLogParametersCallback* parameters_callback) {
   if (!IsCapturing())
     return;
-  EntryData entry_data(type, source, phase, base::TimeTicks::Now(),
-                       parameters_callback);
+  NetLogEntryData entry_data(type, source, phase, base::TimeTicks::Now(),
+                             parameters_callback);
 
   // Notify all of the log observers.
   base::AutoLock lock(lock_);
-  FOR_EACH_OBSERVER(ThreadSafeObserver, observers_, OnAddEntryData(entry_data));
-}
-
-BoundNetLog::~BoundNetLog() {
-  liveness_ = DEAD;
-}
-
-void BoundNetLog::AddEntry(NetLogEventType type, NetLogEventPhase phase) const {
-  CrashIfInvalid();
-
-  if (!net_log_)
-    return;
-  net_log_->AddEntry(type, source_, phase, NULL);
-}
-
-void BoundNetLog::AddEntry(
-    NetLogEventType type,
-    NetLogEventPhase phase,
-    const NetLog::ParametersCallback& get_parameters) const {
-  CrashIfInvalid();
-
-  if (!net_log_)
-    return;
-  net_log_->AddEntry(type, source_, phase, &get_parameters);
-}
-
-void BoundNetLog::AddEvent(NetLogEventType type) const {
-  AddEntry(type, NetLogEventPhase::NONE);
-}
-
-void BoundNetLog::AddEvent(
-    NetLogEventType type,
-    const NetLog::ParametersCallback& get_parameters) const {
-  AddEntry(type, NetLogEventPhase::NONE, get_parameters);
-}
-
-void BoundNetLog::BeginEvent(NetLogEventType type) const {
-  AddEntry(type, NetLogEventPhase::BEGIN);
-}
-
-void BoundNetLog::BeginEvent(
-    NetLogEventType type,
-    const NetLog::ParametersCallback& get_parameters) const {
-  AddEntry(type, NetLogEventPhase::BEGIN, get_parameters);
-}
-
-void BoundNetLog::EndEvent(NetLogEventType type) const {
-  AddEntry(type, NetLogEventPhase::END);
-}
-
-void BoundNetLog::EndEvent(
-    NetLogEventType type,
-    const NetLog::ParametersCallback& get_parameters) const {
-  AddEntry(type, NetLogEventPhase::END, get_parameters);
-}
-
-void BoundNetLog::AddEventWithNetErrorCode(NetLogEventType event_type,
-                                           int net_error) const {
-  DCHECK_NE(ERR_IO_PENDING, net_error);
-  if (net_error >= 0) {
-    AddEvent(event_type);
-  } else {
-    AddEvent(event_type, NetLog::IntCallback("net_error", net_error));
-  }
-}
-
-void BoundNetLog::EndEventWithNetErrorCode(NetLogEventType event_type,
-                                           int net_error) const {
-  DCHECK_NE(ERR_IO_PENDING, net_error);
-  if (net_error >= 0) {
-    EndEvent(event_type);
-  } else {
-    EndEvent(event_type, NetLog::IntCallback("net_error", net_error));
-  }
-}
-
-void BoundNetLog::AddByteTransferEvent(NetLogEventType event_type,
-                                       int byte_count,
-                                       const char* bytes) const {
-  AddEvent(event_type, base::Bind(BytesTransferredCallback, byte_count, bytes));
-}
-
-bool BoundNetLog::IsCapturing() const {
-  CrashIfInvalid();
-  return net_log_ && net_log_->IsCapturing();
-}
-
-// static
-BoundNetLog BoundNetLog::Make(NetLog* net_log, NetLogSourceType source_type) {
-  if (!net_log)
-    return BoundNetLog();
-
-  NetLog::Source source(source_type, net_log->NextID());
-  return BoundNetLog(source, net_log);
-}
-
-void BoundNetLog::CrashIfInvalid() const {
-  Liveness liveness = liveness_;
-
-  if (liveness == ALIVE)
-    return;
-
-  base::debug::Alias(&liveness);
-  CHECK_EQ(ALIVE, liveness);
+  for (auto* observer : observers_)
+    observer->OnAddEntryData(entry_data);
 }
 
 }  // namespace net
diff --git a/src/net/log/net_log.h b/src/net/log/net_log.h
index 842116c..41e8cc6 100644
--- a/src/net/log/net_log.h
+++ b/src/net/log/net_log.h
@@ -7,25 +7,25 @@
 
 #include <stdint.h>
 
-#include <memory>
 #include <string>
+#include <vector>
 
 #include "base/atomicops.h"
-#include "base/callback_forward.h"
 #include "base/compiler_specific.h"
 #include "base/macros.h"
-#include "base/observer_list.h"
 #include "base/strings/string16.h"
 #include "base/synchronization/lock.h"
 #include "base/time/time.h"
 #include "build/build_config.h"
 #include "net/base/net_export.h"
 #include "net/log/net_log_capture_mode.h"
+#include "net/log/net_log_entry.h"
 #include "net/log/net_log_event_type.h"
+#include "net/log/net_log_parameters_callback.h"
+#include "net/log/net_log_source.h"
 #include "net/log/net_log_source_type.h"
 
 namespace base {
-class DictionaryValue;
 class Value;
 }
 
@@ -37,7 +37,7 @@ namespace net {
 // SpdySession).
 //
 // To avoid needing to pass in the "source ID" to the logging functions, NetLog
-// is usually accessed through a BoundNetLog, which will always pass in a
+// is usually accessed through a NetLogWithSource, which will always pass in a
 // specific source ID.
 //
 // All methods are thread safe, with the exception that no NetLog or
@@ -49,88 +49,6 @@ namespace net {
 class NET_EXPORT NetLog {
  public:
 
-  // A callback that returns a Value representation of the parameters
-  // associated with an event.  If called, it will be called synchronously,
-  // so it need not have owning references.  May be called more than once, or
-  // not at all.  May return NULL.
-  typedef base::Callback<std::unique_ptr<base::Value>(NetLogCaptureMode)>
-      ParametersCallback;
-
-  // Identifies the entity that generated this log. The |id| field should
-  // uniquely identify the source, and is used by log observers to infer
-  // message groupings. Can use NetLog::NextID() to create unique IDs.
-  struct NET_EXPORT Source {
-    static const uint32_t kInvalidId;
-
-    Source();
-    Source(NetLogSourceType type, uint32_t id);
-    bool IsValid() const;
-
-    // Adds the source to a DictionaryValue containing event parameters,
-    // using the name "source_dependency".
-    void AddToEventParameters(base::DictionaryValue* event_params) const;
-
-    // Returns a callback that returns a dictionary with a single entry
-    // named "source_dependency" that describes |this|.
-    ParametersCallback ToEventParametersCallback() const;
-
-    // Attempts to extract a Source from a set of event parameters.  Returns
-    // true and writes the result to |source| on success.  Returns false and
-    // makes |source| an invalid source on failure.
-    // TODO(mmenke):  Long term, we want to remove this.
-    static bool FromEventParameters(base::Value* event_params, Source* source);
-
-    NetLogSourceType type;
-    uint32_t id;
-  };
-
-  struct NET_EXPORT EntryData {
-    EntryData(NetLogEventType type,
-              Source source,
-              NetLogEventPhase phase,
-              base::TimeTicks time,
-              const ParametersCallback* parameters_callback);
-    ~EntryData();
-
-    const NetLogEventType type;
-    const Source source;
-    const NetLogEventPhase phase;
-    const base::TimeTicks time;
-    const ParametersCallback* const parameters_callback;
-  };
-
-  // An Entry pre-binds EntryData to a capture mode, so observers will observe
-  // the output of ToValue() and ParametersToValue() at their log capture mode
-  // rather than the current maximum.
-  class NET_EXPORT Entry {
-   public:
-    Entry(const EntryData* data, NetLogCaptureMode capture_mode);
-    ~Entry();
-
-    NetLogEventType type() const { return data_->type; }
-    Source source() const { return data_->source; }
-    NetLogEventPhase phase() const { return data_->phase; }
-
-    // Serializes the specified event to a Value.  The Value also includes the
-    // current time.  Takes in a time to allow back-dating entries.
-    std::unique_ptr<base::Value> ToValue() const;
-
-    // Returns the parameters as a Value.  Returns NULL if there are no
-    // parameters.
-    std::unique_ptr<base::Value> ParametersToValue() const;
-
-   private:
-    const EntryData* const data_;
-
-    // Log capture mode when the event occurred.
-    const NetLogCaptureMode capture_mode_;
-
-    // It is not safe to copy this class, since |parameters_callback_| may
-    // include pointers that become stale immediately after the event is added,
-    // even if the code were modified to keep its own copy of the callback.
-    DISALLOW_COPY_AND_ASSIGN(Entry);
-  };
-
   // An observer that is notified of entries added to the NetLog. The
   // "ThreadSafe" prefix of the name emphasizes that this observer may be
   // called from different threads then the one which added it as an observer.
@@ -169,7 +87,7 @@ class NET_EXPORT NetLog {
     //   * It is illegal for an observer to call back into the NetLog, or the
     //     observer itself, as this can result in deadlock or violating
     //     expectations of non re-entrancy into ThreadSafeObserver.
-    virtual void OnAddEntry(const Entry& entry) = 0;
+    virtual void OnAddEntry(const NetLogEntry& entry) = 0;
 
    protected:
     virtual ~ThreadSafeObserver();
@@ -177,7 +95,7 @@ class NET_EXPORT NetLog {
    private:
     friend class NetLog;
 
-    void OnAddEntryData(const EntryData& entry_data);
+    void OnAddEntryData(const NetLogEntryData& entry_data);
 
     // Both of these values are only modified by the NetLog.
     NetLogCaptureMode capture_mode_;
@@ -192,7 +110,7 @@ class NET_EXPORT NetLog {
   // Emits a global event to the log stream, with its own unique source ID.
   void AddGlobalEntry(NetLogEventType type);
   void AddGlobalEntry(NetLogEventType type,
-                      const NetLog::ParametersCallback& parameters_callback);
+                      const NetLogParametersCallback& parameters_callback);
 
   // Returns a unique ID which can be used as a source ID.  All returned IDs
   // will be unique and greater than 0.
@@ -249,43 +167,50 @@ class NET_EXPORT NetLog {
   // Returns a C-String symbolic name for |event_phase|.
   static const char* EventPhaseToString(NetLogEventPhase event_phase);
 
-  // Creates a ParametersCallback that encapsulates a single bool.
+  // Creates a NetLogParametersCallback that encapsulates a single bool.
   // Warning: |name| must remain valid for the life of the callback.
-  static ParametersCallback BoolCallback(const char* name, bool value);
+  static NetLogParametersCallback BoolCallback(const char* name, bool value);
 
   // Warning: |name| must remain valid for the life of the callback.
-  static ParametersCallback IntCallback(const char* name, int value);
+  static NetLogParametersCallback IntCallback(const char* name, int value);
 
-  // Creates a ParametersCallback that encapsulates a single int64_t.  The
+  // Creates a NetLogParametersCallback that encapsulates a single int64_t.  The
   // callback will return the value as a StringValue, since IntegerValues
   // only support 32-bit values.
   // Warning: |name| must remain valid for the life of the callback.
-  static ParametersCallback Int64Callback(const char* name, int64_t value);
+  static NetLogParametersCallback Int64Callback(const char* name,
+                                                int64_t value);
 
-  // Creates a ParametersCallback that encapsulates a single UTF8 string.  Takes
+  // Creates a NetLogParametersCallback that encapsulates a single UTF8 string.
+  // Takes
   // |value| as a pointer to avoid copying, and emphasize it must be valid for
   // the life of the callback.  |value| may not be NULL.
   // Warning: |name| and |value| must remain valid for the life of the callback.
-  static ParametersCallback StringCallback(const char* name,
-                                           const std::string* value);
-  static ParametersCallback StringCallback(const char* name, const char* value);
+  static NetLogParametersCallback StringCallback(const char* name,
+                                                 const std::string* value);
+  static NetLogParametersCallback StringCallback(const char* name,
+                                                 const char* value);
 
   // Same as above, but takes in a UTF16 string.
-  static ParametersCallback StringCallback(const char* name,
-                                           const base::string16* value);
+  static NetLogParametersCallback StringCallback(const char* name,
+                                                 const base::string16* value);
 
  private:
-  friend class BoundNetLog;
+  friend class NetLogWithSource;
 
   void AddEntry(NetLogEventType type,
-                const Source& source,
+                const NetLogSource& source,
                 NetLogEventPhase phase,
-                const NetLog::ParametersCallback* parameters_callback);
+                const NetLogParametersCallback* parameters_callback);
 
   // Called whenever an observer is added or removed, to update
   // |has_observers_|. Must have acquired |lock_| prior to calling.
   void UpdateIsCapturing();
 
+  // Returns true if |observer| is watching this NetLog. Must
+  // be called while |lock_| is already held.
+  bool HasObserver(ThreadSafeObserver* observer);
+
   // |lock_| protects access to |observers_|.
   base::Lock lock_;
 
@@ -297,89 +222,19 @@ class NET_EXPORT NetLog {
   // so it can be accessed without needing a lock.
   base::subtle::Atomic32 is_capturing_;
 
+  // |observers_| is a list of observers, ordered by when they were added.
+  // Pointers contained in |observers_| are non-owned, and must
+  // remain valid.
+  //
   // |lock_| must be acquired whenever reading or writing to this.
-  base::ObserverList<ThreadSafeObserver, true> observers_;
+  //
+  // In practice |observers_| will be very small (<5) so O(n)
+  // operations on it are fine.
+  std::vector<ThreadSafeObserver*> observers_;
 
   DISALLOW_COPY_AND_ASSIGN(NetLog);
 };
 
-// Helper that binds a Source to a NetLog, and exposes convenience methods to
-// output log messages without needing to pass in the source.
-class NET_EXPORT BoundNetLog {
- public:
-  BoundNetLog() : net_log_(NULL) {}
-  ~BoundNetLog();
-
-  // Add a log entry to the NetLog for the bound source.
-  void AddEntry(NetLogEventType type, NetLogEventPhase phase) const;
-  void AddEntry(NetLogEventType type,
-                NetLogEventPhase phase,
-                const NetLog::ParametersCallback& get_parameters) const;
-
-  // Convenience methods that call AddEntry with a fixed "capture phase"
-  // (begin, end, or none).
-  void BeginEvent(NetLogEventType type) const;
-  void BeginEvent(NetLogEventType type,
-                  const NetLog::ParametersCallback& get_parameters) const;
-
-  void EndEvent(NetLogEventType type) const;
-  void EndEvent(NetLogEventType type,
-                const NetLog::ParametersCallback& get_parameters) const;
-
-  void AddEvent(NetLogEventType type) const;
-  void AddEvent(NetLogEventType type,
-                const NetLog::ParametersCallback& get_parameters) const;
-
-  // Just like AddEvent, except |net_error| is a net error code.  A parameter
-  // called "net_error" with the indicated value will be recorded for the event.
-  // |net_error| must be negative, and not ERR_IO_PENDING, as it's not a true
-  // error.
-  void AddEventWithNetErrorCode(NetLogEventType event_type,
-                                int net_error) const;
-
-  // Just like EndEvent, except |net_error| is a net error code.  If it's
-  // negative, a parameter called "net_error" with a value of |net_error| is
-  // associated with the event.  Otherwise, the end event has no parameters.
-  // |net_error| must not be ERR_IO_PENDING, as it's not a true error.
-  void EndEventWithNetErrorCode(NetLogEventType event_type,
-                                int net_error) const;
-
-  // Logs a byte transfer event to the NetLog.  Determines whether to log the
-  // received bytes or not based on the current logging level.
-  void AddByteTransferEvent(NetLogEventType event_type,
-                            int byte_count,
-                            const char* bytes) const;
-
-  bool IsCapturing() const;
-
-  // Helper to create a BoundNetLog given a NetLog and a NetLogSourceType.
-  // Takes care of creating a unique source ID, and handles
-  //  the case of NULL net_log.
-  static BoundNetLog Make(NetLog* net_log, NetLogSourceType source_type);
-
-  const NetLog::Source& source() const { return source_; }
-  NetLog* net_log() const { return net_log_; }
-
- private:
-  // TODO(eroman): Temporary until crbug.com/467797 is solved.
-  enum Liveness {
-    ALIVE = 0xCA11AB13,
-    DEAD = 0xDEADBEEF,
-  };
-
-  BoundNetLog(const NetLog::Source& source, NetLog* net_log)
-      : source_(source), net_log_(net_log) {}
-
-  // TODO(eroman): Temporary until crbug.com/467797 is solved.
-  void CrashIfInvalid() const;
-
-  NetLog::Source source_;
-  NetLog* net_log_;
-
-  // TODO(eroman): Temporary until crbug.com/467797 is solved.
-  Liveness liveness_ = ALIVE;
-};
-
 }  // namespace net
 
 #endif  // NET_LOG_NET_LOG_H_
diff --git a/src/net/log/net_log_event_type_list.h b/src/net/log/net_log_event_type_list.h
index f0d43ff..c7cb11d 100644
--- a/src/net/log/net_log_event_type_list.h
+++ b/src/net/log/net_log_event_type_list.h
@@ -797,7 +797,7 @@ EVENT_TYPE(BACKUP_CONNECT_JOB_CREATED)
 //   }
 EVENT_TYPE(SOCKET_POOL_BOUND_TO_CONNECT_JOB)
 
-// Identifies the NetLog::Source() for the Socket assigned to the pending
+// Identifies the NetLogSource() for the Socket assigned to the pending
 // request. The event parameters are:
 //   {
 //      "source_dependency": <Source identifier for the socket we acquired>,
@@ -1043,21 +1043,21 @@ EVENT_TYPE(HTTP_STREAM_REQUEST)
 //   }
 EVENT_TYPE(HTTP_STREAM_JOB)
 
-// Identifies the NetLog::Source() for a Job started by the Request.
+// Identifies the NetLogSource() for a Job started by the Request.
 // The event parameters are:
 //   {
 //      "source_dependency": <Source identifier for Job we started>,
 //   }
 EVENT_TYPE(HTTP_STREAM_REQUEST_STARTED_JOB)
 
-// Identifies the NetLog::Source() for the Job that fulfilled the Request.
+// Identifies the NetLogSource() for the Job that fulfilled the Request.
 // The event parameters are:
 //   {
 //      "source_dependency": <Source identifier for Job we acquired>,
 //   }
 EVENT_TYPE(HTTP_STREAM_REQUEST_BOUND_TO_JOB)
 
-// Identifies the NetLog::Source() for the Request that the Job was attached to.
+// Identifies the NetLogSource() for the Request that the Job was attached to.
 // The event parameters are:
 //   {
 //      "source_dependency": <Source identifier for the Request to which we were
@@ -1166,6 +1166,12 @@ EVENT_TYPE(HTTP_TRANSACTION_DRAIN_BODY_FOR_AUTH_RESTART)
 // Measures the time taken to look up the key used for Token Binding.
 EVENT_TYPE(HTTP_TRANSACTION_GET_TOKEN_BINDING_KEY)
 
+// Measures the time taken due to throttling by the NetworkThrottleManager.
+EVENT_TYPE(HTTP_TRANSACTION_THROTTLED)
+
+// Record priority changes on the network transaction.
+EVENT_TYPE(HTTP_TRANSACTION_SET_PRIORITY)
+
 // This event is sent when we try to restart a transaction after an error.
 // The following parameters are attached:
 //   {
@@ -1748,48 +1754,6 @@ EVENT_TYPE(QUIC_SESSION_RST_STREAM_FRAME_RECEIVED)
 //   }
 EVENT_TYPE(QUIC_SESSION_RST_STREAM_FRAME_SENT)
 
-// Session received a CONGESTION_FEEDBACK frame.
-//   {
-//     "type": <The specific type of feedback being provided>,
-//     Other per-feedback type details:
-//
-//     for InterArrival:
-//     "accumulated_number_of_lost_packets": <Total number of lost packets
-//                                            over the life of this session>,
-//     "received_packets": <List of strings of the form:
-//                          <sequence_number>@<receive_time_in_ms>>,
-//
-//     for FixRate:
-//     "bitrate_in_bytes_per_second": <The configured bytes per second>,
-//
-//     for TCP:
-//     "accumulated_number_of_lost_packets": <Total number of lost packets
-//                                            over the life of this session>,
-//     "receive_window": <Number of bytes in the receive window>,
-//   }
-EVENT_TYPE(QUIC_SESSION_CONGESTION_FEEDBACK_FRAME_RECEIVED)
-
-// Session received a CONGESTION_FEEDBACK frame.
-//   {
-//     "type": <The specific type of feedback being provided>,
-//     Other per-feedback type details:
-//
-//     for InterArrival:
-//     "accumulated_number_of_lost_packets": <Total number of lost packets
-//                                            over the life of this session>,
-//     "received_packets": <List of strings of the form:
-//                          <sequence_number>@<receive_time_in_ms>>,
-//
-//     for FixRate:
-//     "bitrate_in_bytes_per_second": <The configured bytes per second>,
-//
-//     for TCP:
-//     "accumulated_number_of_lost_packets": <Total number of lost packets
-//                                            over the life of this session>,
-//     "receive_window": <Number of bytes in the receive window>,
-//   }
-EVENT_TYPE(QUIC_SESSION_CONGESTION_FEEDBACK_FRAME_SENT)
-
 // Session received a CONNECTION_CLOSE frame.
 //   {
 //     "quic_error": <QuicErrorCode in the frame>,
@@ -1884,7 +1848,7 @@ EVENT_TYPE(QUIC_HTTP_STREAM_PUSH_PROMISE_RENDEZVOUS)
 //   }
 EVENT_TYPE(QUIC_HTTP_STREAM_ADOPTED_PUSH_STREAM)
 
-// Identifies the NetLog::Source() for the QuicSesssion that handled the stream.
+// Identifies the NetLogSource() for the QuicSesssion that handled the stream.
 // The event parameters are:
 //   {
 //      "source_dependency": <Source identifier for session that was used>,
@@ -2066,12 +2030,13 @@ EVENT_TYPE(SERVICE_WORKER_ERROR_KILLED_WITH_BLOB)
 EVENT_TYPE(SERVICE_WORKER_ERROR_KILLED_WITH_STREAM)
 
 // This event is emitted when a request to be forwarded to a Service Worker has
-// request body blobs, and it may be necessary to wait for them to finish
-// construction. The END phase event parameter is:
+// request body, and it may be necessary to wait for sizes of files in the body
+// to be resolved. The END phase event parameter is:
 //   {
-//     "success": Whether the request blobs finished construction successfully.
+//     "success": Whether file sizes in the request body have been resolved
+//     successfully
 //   }
-EVENT_TYPE(SERVICE_WORKER_WAITING_FOR_REQUEST_BODY_BLOB)
+EVENT_TYPE(SERVICE_WORKER_WAITING_FOR_REQUEST_BODY_FILES)
 
 // This event is emitted when a request failed to be forwarded to a Service
 // Worker, because it had a request body with a blob that failed to be
@@ -3020,6 +2985,21 @@ EVENT_TYPE(SAFE_BROWSING_CHECKING_URL)
 //  }
 EVENT_TYPE(SAFE_BROWSING_DEFERRED)
 
+// The start/end of a Safe Browsing ping being sent.
+//
+// The BEGIN phase contains the following parameters:
+//  {
+//    "url": <The URL the ping is going to, which identifies the type of ping
+//            that is being sent (eg: ThreatReport, SafeBrowsingHit)>
+//    "data": <The base64 encoding of the payload sent with the ping>
+//
+// The END phase contains the following parameters:
+//  {
+//    "status": <The integer status of the report transmission. Corresponds to
+//               URLRequestStatus::Status>
+//    "error": <The error code returned by the server, 0 indicating success>
+EVENT_TYPE(SAFE_BROWSING_PING)
+
 // Marks start of UploadDataStream that is logged on initialization.
 // The END phase contains the following parameters:
 // {
diff --git a/src/net/log/net_log_source_type_list.h b/src/net/log/net_log_source_type_list.h
index 1c729a6..b874529 100644
--- a/src/net/log/net_log_source_type_list.h
+++ b/src/net/log/net_log_source_type_list.h
@@ -10,7 +10,11 @@ SOURCE_TYPE(NONE)
 
 SOURCE_TYPE(URL_REQUEST)
 SOURCE_TYPE(PROXY_SCRIPT_DECIDER)
-SOURCE_TYPE(CONNECT_JOB)
+SOURCE_TYPE(HTTP_PROXY_CONNECT_JOB)
+SOURCE_TYPE(SOCKS_CONNECT_JOB)
+SOURCE_TYPE(SSL_CONNECT_JOB)
+SOURCE_TYPE(TRANSPORT_CONNECT_JOB)
+SOURCE_TYPE(WEB_SOCKET_TRANSPORT_CONNECT_JOB)
 SOURCE_TYPE(SOCKET)
 SOURCE_TYPE(HTTP2_SESSION)
 SOURCE_TYPE(QUIC_SESSION)
diff --git a/src/net/quic/core/congestion_control/cubic.cc b/src/net/quic/core/congestion_control/cubic.cc
index fc596c9..26ce069 100644
--- a/src/net/quic/core/congestion_control/cubic.cc
+++ b/src/net/quic/core/congestion_control/cubic.cc
@@ -10,10 +10,9 @@
 
 #include "base/logging.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
-using std::max;
 
 namespace net {
 
@@ -43,7 +42,8 @@ Cubic::Cubic(const QuicClock* clock)
       num_connections_(kDefaultNumConnections),
       epoch_(QuicTime::Zero()),
       app_limited_start_time_(QuicTime::Zero()),
-      last_update_time_(QuicTime::Zero()) {
+      last_update_time_(QuicTime::Zero()),
+      fix_convex_mode_(false) {
   Reset();
 }
 
@@ -74,10 +74,12 @@ void Cubic::Reset() {
   last_congestion_window_ = 0;
   last_max_congestion_window_ = 0;
   acked_packets_count_ = 0;
+  epoch_packets_count_ = 0;
   estimated_tcp_congestion_window_ = 0;
   origin_point_congestion_window_ = 0;
   time_to_origin_point_ = 0;
   last_target_congestion_window_ = 0;
+  fix_convex_mode_ = false;
 }
 
 void Cubic::OnApplicationLimited() {
@@ -86,6 +88,10 @@ void Cubic::OnApplicationLimited() {
   epoch_ = QuicTime::Zero();
 }
 
+void Cubic::SetFixConvexMode(bool fix_convex_mode) {
+  fix_convex_mode_ = fix_convex_mode;
+}
+
 QuicPacketCount Cubic::CongestionWindowAfterPacketLoss(
     QuicPacketCount current_congestion_window) {
   if (current_congestion_window < last_max_congestion_window_) {
@@ -104,13 +110,14 @@ QuicPacketCount Cubic::CongestionWindowAfterAck(
     QuicPacketCount current_congestion_window,
     QuicTime::Delta delay_min) {
   acked_packets_count_ += 1;  // Packets acked.
+  epoch_packets_count_ += 1;
   QuicTime current_time = clock_->ApproximateNow();
 
   // Cubic is "independent" of RTT, the update is limited by the time elapsed.
   if (last_congestion_window_ == current_congestion_window &&
       (current_time - last_update_time_ <= MaxCubicTimeInterval())) {
-    return max(last_target_congestion_window_,
-               estimated_tcp_congestion_window_);
+    return std::max(last_target_congestion_window_,
+                    estimated_tcp_congestion_window_);
   }
   last_congestion_window_ = current_congestion_window;
   last_update_time_ = current_time;
@@ -119,6 +126,7 @@ QuicPacketCount Cubic::CongestionWindowAfterAck(
     // First ACK after a loss event.
     epoch_ = current_time;     // Start of epoch.
     acked_packets_count_ = 1;  // Reset count.
+    epoch_packets_count_ = 1;
     // Reset estimated_tcp_congestion_window_ to be in sync with cubic.
     estimated_tcp_congestion_window_ = current_congestion_window;
     if (last_max_congestion_window_ <= current_congestion_window) {
@@ -135,16 +143,35 @@ QuicPacketCount Cubic::CongestionWindowAfterAck(
   // Change the time unit from microseconds to 2^10 fractions per second. Take
   // the round trip time in account. This is done to allow us to use shift as a
   // divide operator.
-  int64_t elapsed_time =
+  const int64_t elapsed_time =
       ((current_time + delay_min - epoch_).ToMicroseconds() << 10) /
       kNumMicrosPerSecond;
+  DCHECK_GE(elapsed_time, 0);
 
   int64_t offset = time_to_origin_point_ - elapsed_time;
+  if (fix_convex_mode_) {
+    // Right-shifts of negative, signed numbers have
+    // implementation-dependent behavior.  Force the offset to be
+    // positive, similar to the kernel implementation.
+    offset = std::abs(time_to_origin_point_ - elapsed_time);
+  }
+
   QuicPacketCount delta_congestion_window =
       (kCubeCongestionWindowScale * offset * offset * offset) >> kCubeScale;
 
+  const bool add_delta = elapsed_time > time_to_origin_point_;
+  DCHECK(add_delta ||
+         (origin_point_congestion_window_ > delta_congestion_window));
   QuicPacketCount target_congestion_window =
-      origin_point_congestion_window_ - delta_congestion_window;
+      (fix_convex_mode_ && add_delta)
+          ? origin_point_congestion_window_ + delta_congestion_window
+          : origin_point_congestion_window_ - delta_congestion_window;
+
+  // Limit the CWND increase to half the acked packets rounded up to the
+  // nearest packet.
+  target_congestion_window =
+      std::min(target_congestion_window,
+               current_congestion_window + (epoch_packets_count_ + 1) / 2);
 
   DCHECK_LT(0u, estimated_tcp_congestion_window_);
   // With dynamic beta/alpha based on number of active streams, it is possible
@@ -160,6 +187,7 @@ QuicPacketCount Cubic::CongestionWindowAfterAck(
     acked_packets_count_ -= required_ack_count;
     estimated_tcp_congestion_window_++;
   }
+  epoch_packets_count_ = 0;
 
   // We have a new cubic congestion window.
   last_target_congestion_window_ = target_congestion_window;
diff --git a/src/net/quic/core/congestion_control/cubic.h b/src/net/quic/core/congestion_control/cubic.h
index c9de982..350c59b 100644
--- a/src/net/quic/core/congestion_control/cubic.h
+++ b/src/net/quic/core/congestion_control/cubic.h
@@ -13,9 +13,9 @@
 #include "base/macros.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/quic_bandwidth.h"
-#include "net/quic/core/quic_clock.h"
 #include "net/quic/core/quic_connection_stats.h"
 #include "net/quic/core/quic_time.h"
+#include "net/quic/platform/api/quic_clock.h"
 
 namespace net {
 
@@ -34,9 +34,9 @@ class NET_EXPORT_PRIVATE Cubic {
   QuicPacketCount CongestionWindowAfterPacketLoss(QuicPacketCount current);
 
   // Compute a new congestion window to use after a received ACK.
-  // Returns the new congestion window in packets. The new congestion window
-  // follows a cubic function that depends on the time passed since last
-  // packet loss.
+  // Returns the new congestion window in packets. The new congestion
+  // window follows a cubic function that depends on the time passed
+  // since last packet loss.
   QuicPacketCount CongestionWindowAfterAck(QuicPacketCount current,
                                            QuicTime::Delta delay_min);
 
@@ -44,6 +44,11 @@ class NET_EXPORT_PRIVATE Cubic {
   // window. Resets Cubic state during quiescence.
   void OnApplicationLimited();
 
+  // If true, enable the fix for the convex-mode signing bug.  See
+  // b/32170105 for more information about the bug.
+  // TODO(jokulik):  Remove once the fix is enabled by default.
+  void SetFixConvexMode(bool fix_convex_mode);
+
  private:
   static const QuicTime::Delta MaxCubicTimeInterval() {
     return QuicTime::Delta::FromMilliseconds(30);
@@ -77,9 +82,14 @@ class NET_EXPORT_PRIVATE Cubic {
   // applied to this value if the new value is below our latest value.
   QuicPacketCount last_max_congestion_window_;
 
-  // Number of acked packets since the cycle started (epoch).
+  // Number of acked packets accumulated to increase the CWND via Reno
+  // 'tcp friendly' mode.
   QuicPacketCount acked_packets_count_;
 
+  // Number of acked packets since the cycle started (epoch).
+  // Used to limit CWND increases to 1/2 the number of acked packets.
+  QuicPacketCount epoch_packets_count_;
+
   // TCP Reno equivalent congestion window in packets.
   QuicPacketCount estimated_tcp_congestion_window_;
 
@@ -92,6 +102,10 @@ class NET_EXPORT_PRIVATE Cubic {
   // Last congestion window in packets computed by cubic function.
   QuicPacketCount last_target_congestion_window_;
 
+  // Fix convex mode for cubic.
+  // TODO(jokulik):  Remove once the cubic convex experiment is done.
+  bool fix_convex_mode_;
+
   DISALLOW_COPY_AND_ASSIGN(Cubic);
 };
 
diff --git a/src/net/quic/core/congestion_control/cubic_bytes.cc b/src/net/quic/core/congestion_control/cubic_bytes.cc
index 6d40d63..bbc9f69 100644
--- a/src/net/quic/core/congestion_control/cubic_bytes.cc
+++ b/src/net/quic/core/congestion_control/cubic_bytes.cc
@@ -9,9 +9,9 @@
 #include <cmath>
 
 #include "base/logging.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_flags.h"
+#include "net/quic/core/quic_packets.h"
 
-using std::max;
 
 namespace net {
 
@@ -41,7 +41,8 @@ CubicBytes::CubicBytes(const QuicClock* clock)
     : clock_(clock),
       num_connections_(kDefaultNumConnections),
       epoch_(QuicTime::Zero()),
-      last_update_time_(QuicTime::Zero()) {
+      last_update_time_(QuicTime::Zero()),
+      fix_convex_mode_(false) {
   Reset();
 }
 
@@ -75,6 +76,11 @@ void CubicBytes::Reset() {
   origin_point_congestion_window_ = 0;
   time_to_origin_point_ = 0;
   last_target_congestion_window_ = 0;
+  fix_convex_mode_ = false;
+}
+
+void CubicBytes::SetFixConvexMode(bool fix_convex_mode) {
+  fix_convex_mode_ = fix_convex_mode;
 }
 
 void CubicBytes::OnApplicationLimited() {
@@ -113,8 +119,8 @@ QuicByteCount CubicBytes::CongestionWindowAfterAck(
   // Cubic is "independent" of RTT, the update is limited by the time elapsed.
   if (last_congestion_window_ == current_congestion_window &&
       (current_time - last_update_time_ <= MaxCubicTimeInterval())) {
-    return max(last_target_congestion_window_,
-               estimated_tcp_congestion_window_);
+    return std::max(last_target_congestion_window_,
+                    estimated_tcp_congestion_window_);
   }
   last_congestion_window_ = current_congestion_window;
   last_update_time_ = current_time;
@@ -144,16 +150,36 @@ QuicByteCount CubicBytes::CongestionWindowAfterAck(
       kNumMicrosPerSecond;
 
   int64_t offset = time_to_origin_point_ - elapsed_time;
+  if (fix_convex_mode_) {
+    // Right-shifts of negative, signed numbers have
+    // implementation-dependent behavior.  In the fix, force the
+    // offset to be positive, as is done in the kernel.
+    const int64_t positive_offset =
+        std::abs(time_to_origin_point_ - elapsed_time);
+    offset = positive_offset;
+  }
   QuicByteCount delta_congestion_window =
       ((kCubeCongestionWindowScale * offset * offset * offset) >> kCubeScale) *
       kDefaultTCPMSS;
 
+  const bool add_delta = elapsed_time > time_to_origin_point_;
+  DCHECK(add_delta ||
+         (origin_point_congestion_window_ > delta_congestion_window));
   QuicByteCount target_congestion_window =
-      origin_point_congestion_window_ - delta_congestion_window;
+      (fix_convex_mode_ && add_delta)
+          ? origin_point_congestion_window_ + delta_congestion_window
+          : origin_point_congestion_window_ - delta_congestion_window;
+  // Limit the CWND increase to half the acked bytes.
+  target_congestion_window =
+      std::min(target_congestion_window,
+               current_congestion_window + acked_bytes_count_ / 2);
 
   DCHECK_LT(0u, estimated_tcp_congestion_window_);
-  // Increase the window by Alpha * 1 MSS of bytes every time we ack an
-  // estimated tcp window of bytes.
+  // Increase the window by approximately Alpha * 1 MSS of bytes every
+  // time we ack an estimated tcp window of bytes.  For small
+  // congestion windows (less than 25), the formula below will
+  // increase slightly slower than linearly per estimated tcp window
+  // of bytes.
   estimated_tcp_congestion_window_ += acked_bytes_count_ *
                                       (Alpha() * kDefaultTCPMSS) /
                                       estimated_tcp_congestion_window_;
diff --git a/src/net/quic/core/congestion_control/cubic_bytes.h b/src/net/quic/core/congestion_control/cubic_bytes.h
index 73998ad..5a026ba 100644
--- a/src/net/quic/core/congestion_control/cubic_bytes.h
+++ b/src/net/quic/core/congestion_control/cubic_bytes.h
@@ -13,9 +13,9 @@
 #include "base/macros.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/quic_bandwidth.h"
-#include "net/quic/core/quic_clock.h"
 #include "net/quic/core/quic_connection_stats.h"
 #include "net/quic/core/quic_time.h"
+#include "net/quic/platform/api/quic_clock.h"
 
 namespace net {
 
@@ -45,6 +45,8 @@ class NET_EXPORT_PRIVATE CubicBytes {
   // window. Resets Cubic state during quiescence.
   void OnApplicationLimited();
 
+  void SetFixConvexMode(bool fix_convex_mode);
+
  private:
   static const QuicTime::Delta MaxCubicTimeInterval() {
     return QuicTime::Delta::FromMilliseconds(30);
@@ -89,6 +91,10 @@ class NET_EXPORT_PRIVATE CubicBytes {
   // Last congestion window in packets computed by cubic function.
   QuicByteCount last_target_congestion_window_;
 
+  // Fix convex mode for cubic.
+  // TODO(jokulik):  Remove once the cubic convex experiment is done.
+  bool fix_convex_mode_;
+
   DISALLOW_COPY_AND_ASSIGN(CubicBytes);
 };
 
diff --git a/src/net/quic/core/congestion_control/general_loss_algorithm.cc b/src/net/quic/core/congestion_control/general_loss_algorithm.cc
index 6415f2c..2694c95 100644
--- a/src/net/quic/core/congestion_control/general_loss_algorithm.cc
+++ b/src/net/quic/core/congestion_control/general_loss_algorithm.cc
@@ -7,7 +7,7 @@
 #include "net/quic/core/congestion_control/rtt_stats.h"
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
@@ -30,7 +30,8 @@ GeneralLossAlgorithm::GeneralLossAlgorithm()
     : loss_detection_timeout_(QuicTime::Zero()),
       largest_sent_on_spurious_retransmit_(0),
       loss_type_(kNack),
-      reordering_shift_(kDefaultLossDelayShift) {}
+      reordering_shift_(kDefaultLossDelayShift),
+      largest_previously_acked_(0) {}
 
 GeneralLossAlgorithm::GeneralLossAlgorithm(LossDetectionType loss_type)
     : loss_detection_timeout_(QuicTime::Zero()),
@@ -38,7 +39,8 @@ GeneralLossAlgorithm::GeneralLossAlgorithm(LossDetectionType loss_type)
       loss_type_(loss_type),
       reordering_shift_(loss_type == kAdaptiveTime
                             ? kDefaultAdaptiveLossDelayShift
-                            : kDefaultLossDelayShift) {}
+                            : kDefaultLossDelayShift),
+      largest_previously_acked_(0) {}
 
 LossDetectionType GeneralLossAlgorithm::GetLossDetectionType() const {
   return loss_type_;
@@ -51,6 +53,7 @@ void GeneralLossAlgorithm::SetLossDetectionType(LossDetectionType loss_type) {
   reordering_shift_ = loss_type == kAdaptiveTime
                           ? kDefaultAdaptiveLossDelayShift
                           : kDefaultLossDelayShift;
+  largest_previously_acked_ = 0;
 }
 
 // Uses nack counts to decide when packets are lost.
@@ -81,13 +84,26 @@ void GeneralLossAlgorithm::DetectLosses(
         packets_lost->push_back(std::make_pair(packet_number, it->bytes_sent));
         continue;
       }
+    } else if (loss_type_ == kLazyFack) {
+      // Require two in order acks to invoke FACK, which avoids spuriously
+      // retransmitting packets when one packet is reordered by a large amount.
+      if (largest_newly_acked > largest_previously_acked_ &&
+          largest_previously_acked_ > packet_number &&
+          largest_previously_acked_ - packet_number >=
+              (kNumberOfNacksBeforeRetransmission - 1)) {
+        packets_lost->push_back(std::make_pair(packet_number, it->bytes_sent));
+        continue;
+      }
     }
 
     // Only early retransmit(RFC5827) when the last packet gets acked and
     // there are retransmittable packets in flight.
     // This also implements a timer-protected variant of FACK.
     if ((!it->retransmittable_frames.empty() &&
-         unacked_packets.largest_sent_packet() == largest_newly_acked) ||
+         (FLAGS_quic_largest_sent_retransmittable
+              ? unacked_packets.largest_sent_retransmittable_packet()
+              : unacked_packets.largest_sent_packet()) <=
+             largest_newly_acked) ||
         (loss_type_ == kTime || loss_type_ == kAdaptiveTime)) {
       QuicTime when_lost = it->sent_time + loss_delay;
       if (time < when_lost) {
@@ -105,6 +121,7 @@ void GeneralLossAlgorithm::DetectLosses(
       continue;
     }
   }
+  largest_previously_acked_ = largest_newly_acked;
 }
 
 QuicTime GeneralLossAlgorithm::GetLossTimeout() const {
diff --git a/src/net/quic/core/congestion_control/general_loss_algorithm.h b/src/net/quic/core/congestion_control/general_loss_algorithm.h
index 5ceaa37..bd5f037 100644
--- a/src/net/quic/core/congestion_control/general_loss_algorithm.h
+++ b/src/net/quic/core/congestion_control/general_loss_algorithm.h
@@ -9,8 +9,9 @@
 #include <map>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/congestion_control/loss_detection_interface.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 #include "net/quic/core/quic_unacked_packet_map.h"
 
@@ -64,6 +65,8 @@ class NET_EXPORT_PRIVATE GeneralLossAlgorithm : public LossDetectionInterface {
   // loss.  Fraction calculated by shifting max(SRTT, latest_rtt) to the right
   // by reordering_shift.
   int reordering_shift_;
+  // The largest newly acked from the previous call to DetectLosses.
+  QuicPacketNumber largest_previously_acked_;
 
   DISALLOW_COPY_AND_ASSIGN(GeneralLossAlgorithm);
 };
diff --git a/src/net/quic/core/congestion_control/hybrid_slow_start.cc b/src/net/quic/core/congestion_control/hybrid_slow_start.cc
index 3224cd6..16b7dcf 100644
--- a/src/net/quic/core/congestion_control/hybrid_slow_start.cc
+++ b/src/net/quic/core/congestion_control/hybrid_slow_start.cc
@@ -6,8 +6,6 @@
 
 #include <algorithm>
 
-using std::max;
-using std::min;
 
 namespace net {
 
@@ -88,11 +86,11 @@ bool HybridSlowStart::ShouldExitSlowStart(QuicTime::Delta latest_rtt,
     int64_t min_rtt_increase_threshold_us =
         min_rtt.ToMicroseconds() >> kHybridStartDelayFactorExp;
     // Ensure the rtt threshold is never less than 2ms or more than 16ms.
-    min_rtt_increase_threshold_us =
-        min(min_rtt_increase_threshold_us, kHybridStartDelayMaxThresholdUs);
+    min_rtt_increase_threshold_us = std::min(min_rtt_increase_threshold_us,
+                                             kHybridStartDelayMaxThresholdUs);
     QuicTime::Delta min_rtt_increase_threshold =
-        QuicTime::Delta::FromMicroseconds(max(min_rtt_increase_threshold_us,
-                                              kHybridStartDelayMinThresholdUs));
+        QuicTime::Delta::FromMicroseconds(std::max(
+            min_rtt_increase_threshold_us, kHybridStartDelayMinThresholdUs));
 
     if (current_min_rtt_ > min_rtt + min_rtt_increase_threshold) {
       hystart_found_ = DELAY;
diff --git a/src/net/quic/core/congestion_control/hybrid_slow_start.h b/src/net/quic/core/congestion_control/hybrid_slow_start.h
index 1ca1448..ad264e1 100644
--- a/src/net/quic/core/congestion_control/hybrid_slow_start.h
+++ b/src/net/quic/core/congestion_control/hybrid_slow_start.h
@@ -20,7 +20,7 @@
 
 #include "base/macros.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
diff --git a/src/net/quic/core/congestion_control/loss_detection_interface.h b/src/net/quic/core/congestion_control/loss_detection_interface.h
index a4e2c3b..5a16a68 100644
--- a/src/net/quic/core/congestion_control/loss_detection_interface.h
+++ b/src/net/quic/core/congestion_control/loss_detection_interface.h
@@ -7,8 +7,9 @@
 #ifndef NET_QUIC_CONGESTION_CONTROL_LOSS_DETECTION_INTERFACE_H_
 #define NET_QUIC_CONGESTION_CONTROL_LOSS_DETECTION_INTERFACE_H_
 
+#include "net/base/net_export.h"
 #include "net/quic/core/congestion_control/send_algorithm_interface.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
diff --git a/src/net/quic/core/congestion_control/pacing_sender.cc b/src/net/quic/core/congestion_control/pacing_sender.cc
index cc2c40b..5cac490 100644
--- a/src/net/quic/core/congestion_control/pacing_sender.cc
+++ b/src/net/quic/core/congestion_control/pacing_sender.cc
@@ -8,7 +8,6 @@
 
 #include "net/quic/core/quic_flags.h"
 
-using std::min;
 
 namespace net {
 namespace {
@@ -41,6 +40,7 @@ void PacingSender::set_sender(SendAlgorithmInterface* sender) {
 void PacingSender::OnCongestionEvent(
     bool rtt_updated,
     QuicByteCount bytes_in_flight,
+    QuicTime event_time,
     const SendAlgorithmInterface::CongestionVector& acked_packets,
     const SendAlgorithmInterface::CongestionVector& lost_packets) {
   DCHECK(sender_ != nullptr);
@@ -48,8 +48,8 @@ void PacingSender::OnCongestionEvent(
     // Clear any burst tokens when entering recovery.
     burst_tokens_ = 0;
   }
-  sender_->OnCongestionEvent(rtt_updated, bytes_in_flight, acked_packets,
-                             lost_packets);
+  sender_->OnCongestionEvent(rtt_updated, bytes_in_flight, event_time,
+                             acked_packets, lost_packets);
 }
 
 bool PacingSender::OnPacketSent(
@@ -70,7 +70,7 @@ bool PacingSender::OnPacketSent(
     // Add more burst tokens anytime the connection is leaving quiescence, but
     // limit it to the equivalent of a single bulk write, not exceeding the
     // current CWND in packets.
-    burst_tokens_ = min(
+    burst_tokens_ = std::min(
         kInitialUnpacedBurst,
         static_cast<uint32_t>(sender_->GetCongestionWindow() / kDefaultTCPMSS));
   }
@@ -145,8 +145,8 @@ QuicBandwidth PacingSender::PacingRate(QuicByteCount bytes_in_flight) const {
   DCHECK(sender_ != nullptr);
   if (!max_pacing_rate_.IsZero()) {
     return QuicBandwidth::FromBitsPerSecond(
-        min(max_pacing_rate_.ToBitsPerSecond(),
-            sender_->PacingRate(bytes_in_flight).ToBitsPerSecond()));
+        std::min(max_pacing_rate_.ToBitsPerSecond(),
+                 sender_->PacingRate(bytes_in_flight).ToBitsPerSecond()));
   }
   return sender_->PacingRate(bytes_in_flight);
 }
diff --git a/src/net/quic/core/congestion_control/pacing_sender.h b/src/net/quic/core/congestion_control/pacing_sender.h
index 9349871..4f6ff3c 100644
--- a/src/net/quic/core/congestion_control/pacing_sender.h
+++ b/src/net/quic/core/congestion_control/pacing_sender.h
@@ -17,10 +17,11 @@
 #include <memory>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/congestion_control/send_algorithm_interface.h"
 #include "net/quic/core/quic_bandwidth.h"
 #include "net/quic/core/quic_config.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
@@ -42,6 +43,7 @@ class NET_EXPORT_PRIVATE PacingSender {
   void OnCongestionEvent(
       bool rtt_updated,
       QuicByteCount bytes_in_flight,
+      QuicTime event_time,
       const SendAlgorithmInterface::CongestionVector& acked_packets,
       const SendAlgorithmInterface::CongestionVector& lost_packets);
   bool OnPacketSent(QuicTime sent_time,
diff --git a/src/net/quic/core/congestion_control/prr_sender.cc b/src/net/quic/core/congestion_control/prr_sender.cc
index 75ed65b..bb8ac5c 100644
--- a/src/net/quic/core/congestion_control/prr_sender.cc
+++ b/src/net/quic/core/congestion_control/prr_sender.cc
@@ -4,7 +4,7 @@
 
 #include "net/quic/core/congestion_control/prr_sender.h"
 
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
@@ -23,9 +23,9 @@ void PrrSender::OnPacketSent(QuicByteCount sent_bytes) {
   bytes_sent_since_loss_ += sent_bytes;
 }
 
-void PrrSender::OnPacketLost(QuicByteCount bytes_in_flight) {
+void PrrSender::OnPacketLost(QuicByteCount prior_in_flight) {
   bytes_sent_since_loss_ = 0;
-  bytes_in_flight_before_loss_ = bytes_in_flight;
+  bytes_in_flight_before_loss_ = prior_in_flight;
   bytes_delivered_since_loss_ = 0;
   ack_count_since_loss_ = 0;
 }
diff --git a/src/net/quic/core/congestion_control/prr_sender.h b/src/net/quic/core/congestion_control/prr_sender.h
index 1f1ce0c..a68fa7a 100644
--- a/src/net/quic/core/congestion_control/prr_sender.h
+++ b/src/net/quic/core/congestion_control/prr_sender.h
@@ -9,6 +9,7 @@
 
 #include <stddef.h>
 
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_bandwidth.h"
 #include "net/quic/core/quic_time.h"
 
@@ -20,7 +21,7 @@ class NET_EXPORT_PRIVATE PrrSender {
   // OnPacketLost should be called on the first loss that triggers a recovery
   // period and all other methods in this class should only be called when in
   // recovery.
-  void OnPacketLost(QuicByteCount bytes_in_flight);
+  void OnPacketLost(QuicByteCount prior_in_flight);
   void OnPacketSent(QuicByteCount sent_bytes);
   void OnPacketAcked(QuicByteCount acked_bytes);
   QuicTime::Delta TimeUntilSend(QuicByteCount congestion_window,
diff --git a/src/net/quic/core/congestion_control/rtt_stats.cc b/src/net/quic/core/congestion_control/rtt_stats.cc
index 91d3e2a..e5da34a 100644
--- a/src/net/quic/core/congestion_control/rtt_stats.cc
+++ b/src/net/quic/core/congestion_control/rtt_stats.cc
@@ -8,7 +8,6 @@
 
 #include "net/quic/core/quic_flags.h"
 
-using std::max;
 
 namespace net {
 
@@ -20,8 +19,6 @@ const float kAlpha = 0.125f;
 const float kOneMinusAlpha = (1 - kAlpha);
 const float kBeta = 0.25f;
 const float kOneMinusBeta = (1 - kBeta);
-// 10-second window length for windowed min RTT.
-const int kMinRttWindowLengthMs = 10000;
 
 }  // namespace
 
@@ -31,26 +28,13 @@ RttStats::RttStats()
       smoothed_rtt_(QuicTime::Delta::Zero()),
       previous_srtt_(QuicTime::Delta::Zero()),
       mean_deviation_(QuicTime::Delta::Zero()),
-      initial_rtt_us_(kInitialRttMs * kNumMicrosPerMilli),
-      forced_windowed_min_rtt_(QuicTime::Delta::Zero()),
-      forced_windowed_min_rtt_time_(QuicTime::Zero()),
-      num_samples_for_forced_min_(0),
-      windowed_min_rtt_(
-          QuicTime::Delta::FromMilliseconds(kMinRttWindowLengthMs),
-          QuicTime::Delta::Zero(),
-          QuicTime::Zero()) {}
-
-void RttStats::SampleNewWindowedMinRtt(uint32_t num_samples) {
-  num_samples_for_forced_min_ = num_samples;
-  forced_windowed_min_rtt_ = QuicTime::Delta::Zero();
-  forced_windowed_min_rtt_time_ = QuicTime::Zero();
-}
+      initial_rtt_us_(kInitialRttMs * kNumMicrosPerMilli) {}
 
 void RttStats::ExpireSmoothedMetrics() {
-  mean_deviation_ = max(mean_deviation_,
-                        QuicTime::Delta::FromMicroseconds(std::abs(
-                            (smoothed_rtt_ - latest_rtt_).ToMicroseconds())));
-  smoothed_rtt_ = max(smoothed_rtt_, latest_rtt_);
+  mean_deviation_ = std::max(
+      mean_deviation_, QuicTime::Delta::FromMicroseconds(std::abs(
+                           (smoothed_rtt_ - latest_rtt_).ToMicroseconds())));
+  smoothed_rtt_ = std::max(smoothed_rtt_, latest_rtt_);
 }
 
 // Updates the RTT based on a new sample.
@@ -71,7 +55,6 @@ void RttStats::UpdateRtt(QuicTime::Delta send_delta,
   if (min_rtt_.IsZero() || min_rtt_ > send_delta) {
     min_rtt_ = send_delta;
   }
-  UpdateWindowedMinRtt(send_delta, now);
 
   // Correct for ack_delay if information received from the peer results in a
   // positive RTT sample. Otherwise, we use the send_delta as a reasonable
@@ -98,33 +81,12 @@ void RttStats::UpdateRtt(QuicTime::Delta send_delta,
   }
 }
 
-void RttStats::UpdateWindowedMinRtt(QuicTime::Delta rtt_sample, QuicTime now) {
-  // Update windowed_min_rtt.
-  windowed_min_rtt_.Update(rtt_sample, now);
-  if (num_samples_for_forced_min_ <= 0) {
-    return;
-  }
-  // Reset windowed_min_rtt to the min of num_samples_for_forced_min_ samples.
-  if (forced_windowed_min_rtt_.IsZero() ||
-      rtt_sample <= forced_windowed_min_rtt_) {
-    forced_windowed_min_rtt_ = rtt_sample;
-    forced_windowed_min_rtt_time_ = now;
-  }
-  if (num_samples_for_forced_min_ == 1) {
-    windowed_min_rtt_.Reset(forced_windowed_min_rtt_,
-                            forced_windowed_min_rtt_time_);
-  }
-  --num_samples_for_forced_min_;
-}
-
 void RttStats::OnConnectionMigration() {
   latest_rtt_ = QuicTime::Delta::Zero();
   min_rtt_ = QuicTime::Delta::Zero();
   smoothed_rtt_ = QuicTime::Delta::Zero();
   mean_deviation_ = QuicTime::Delta::Zero();
   initial_rtt_us_ = kInitialRttMs * kNumMicrosPerMilli;
-  num_samples_for_forced_min_ = 0;
-  windowed_min_rtt_.Reset(QuicTime::Delta::Zero(), QuicTime::Zero());
 }
 
 }  // namespace net
diff --git a/src/net/quic/core/congestion_control/rtt_stats.h b/src/net/quic/core/congestion_control/rtt_stats.h
index b59909e..57253cc 100644
--- a/src/net/quic/core/congestion_control/rtt_stats.h
+++ b/src/net/quic/core/congestion_control/rtt_stats.h
@@ -12,9 +12,9 @@
 #include <algorithm>
 
 #include "base/macros.h"
-#include "net/quic/core/congestion_control/windowed_filter.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_bug_tracker.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
@@ -38,10 +38,6 @@ class NET_EXPORT_PRIVATE RttStats {
   // it's larger.
   void ExpireSmoothedMetrics();
 
-  // Forces RttStats to sample a new windowed min rtt within the next
-  // |num_samples| UpdateRtt calls.
-  void SampleNewWindowedMinRtt(uint32_t num_samples);
-
   // Called when connection migrates and rtt measurement needs to be reset.
   void OnConnectionMigration();
 
@@ -73,15 +69,9 @@ class NET_EXPORT_PRIVATE RttStats {
 
   QuicTime::Delta mean_deviation() const { return mean_deviation_; }
 
-  QuicTime::Delta WindowedMinRtt() { return windowed_min_rtt_.GetBest(); }
-
  private:
   friend class test::RttStatsPeer;
 
-  // Updates the windowed min rtt. Also forces a new windowed_min_rtt sample,
-  // if set by a call to SampleNewWindowedMinRtt() above.
-  void UpdateWindowedMinRtt(QuicTime::Delta rtt_sample, QuicTime now);
-
   QuicTime::Delta latest_rtt_;
   QuicTime::Delta min_rtt_;
   QuicTime::Delta smoothed_rtt_;
@@ -92,19 +82,6 @@ class NET_EXPORT_PRIVATE RttStats {
   QuicTime::Delta mean_deviation_;
   int64_t initial_rtt_us_;
 
-  // Variables used to force a new windowed_min_rtt measurement within
-  // num_samples_for_forced_min_.
-  QuicTime::Delta forced_windowed_min_rtt_;
-  QuicTime forced_windowed_min_rtt_time_;
-  uint32_t num_samples_for_forced_min_;
-
-  // Windowed min_rtt.
-  WindowedFilter<QuicTime::Delta,
-                 MinFilter<QuicTime::Delta>,
-                 QuicTime,
-                 QuicTime::Delta>
-      windowed_min_rtt_;
-
   DISALLOW_COPY_AND_ASSIGN(RttStats);
 };
 
diff --git a/src/net/quic/core/congestion_control/send_algorithm_interface.cc b/src/net/quic/core/congestion_control/send_algorithm_interface.cc
index a0daace..bc44de0 100644
--- a/src/net/quic/core/congestion_control/send_algorithm_interface.cc
+++ b/src/net/quic/core/congestion_control/send_algorithm_interface.cc
@@ -4,10 +4,12 @@
 
 #include "net/quic/core/congestion_control/send_algorithm_interface.h"
 
+#include "net/quic/core/congestion_control/bbr_sender.h"
 #include "net/quic/core/congestion_control/tcp_cubic_sender_bytes.h"
 #include "net/quic/core/congestion_control/tcp_cubic_sender_packets.h"
+#include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
@@ -17,11 +19,21 @@ class RttStats;
 SendAlgorithmInterface* SendAlgorithmInterface::Create(
     const QuicClock* clock,
     const RttStats* rtt_stats,
+    const QuicUnackedPacketMap* unacked_packets,
     CongestionControlType congestion_control_type,
+    QuicRandom* random,
     QuicConnectionStats* stats,
     QuicPacketCount initial_congestion_window) {
   QuicPacketCount max_congestion_window = kDefaultMaxCongestionWindowPackets;
   switch (congestion_control_type) {
+    case kBBR:
+      if (FLAGS_quic_allow_new_bbr) {
+        return new BbrSender(clock, rtt_stats, unacked_packets,
+                             initial_congestion_window, max_congestion_window,
+                             random);
+      }
+
+    // Fall back to CUBIC if BBR is disabled.
     case kCubic:
       return new TcpCubicSenderPackets(
           clock, rtt_stats, false /* don't use Reno */,
@@ -38,14 +50,6 @@ SendAlgorithmInterface* SendAlgorithmInterface::Create(
       return new TcpCubicSenderBytes(clock, rtt_stats, true /* use Reno */,
                                      initial_congestion_window,
                                      max_congestion_window, stats);
-    case kBBR:
-// TODO(rtenneti): Enable BbrTcpSender.
-#if 0
-      return new BbrTcpSender(clock, rtt_stats, initial_congestion_window,
-                              max_congestion_window, stats, true);
-#endif
-      LOG(DFATAL) << "BbrTcpSender is not supported.";
-      return nullptr;
   }
   return nullptr;
 }
diff --git a/src/net/quic/core/congestion_control/send_algorithm_interface.h b/src/net/quic/core/congestion_control/send_algorithm_interface.h
index b9c1d4c..084e739 100644
--- a/src/net/quic/core/congestion_control/send_algorithm_interface.h
+++ b/src/net/quic/core/congestion_control/send_algorithm_interface.h
@@ -11,12 +11,14 @@
 #include <map>
 
 #include "net/base/net_export.h"
+#include "net/quic/core/crypto/quic_random.h"
 #include "net/quic/core/quic_bandwidth.h"
-#include "net/quic/core/quic_clock.h"
 #include "net/quic/core/quic_config.h"
 #include "net/quic/core/quic_connection_stats.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
+#include "net/quic/core/quic_unacked_packet_map.h"
+#include "net/quic/platform/api/quic_clock.h"
 
 namespace net {
 
@@ -27,14 +29,16 @@ const QuicPacketCount kDefaultMaxCongestionWindowPackets = 2000;
 
 class NET_EXPORT_PRIVATE SendAlgorithmInterface {
  public:
-  // A sorted vector of packets.
+  // A sorted std::vector of packets.
   typedef std::vector<std::pair<QuicPacketNumber, QuicPacketLength>>
       CongestionVector;
 
   static SendAlgorithmInterface* Create(
       const QuicClock* clock,
       const RttStats* rtt_stats,
+      const QuicUnackedPacketMap* unacked_packets,
       CongestionControlType type,
+      QuicRandom* random,
       QuicConnectionStats* stats,
       QuicPacketCount initial_congestion_window);
 
@@ -49,11 +53,12 @@ class NET_EXPORT_PRIVATE SendAlgorithmInterface {
 
   // Indicates an update to the congestion state, caused either by an incoming
   // ack or loss event timeout.  |rtt_updated| indicates whether a new
-  // latest_rtt sample has been taken, |byte_in_flight| the bytes in flight
-  // prior to the congestion event.  |acked_packets| and |lost_packets| are
-  // any packets considered acked or lost as a result of the congestion event.
+  // latest_rtt sample has been taken, |prior_in_flight| the bytes in flight
+  // prior to the congestion event.  |acked_packets| and |lost_packets| are any
+  // packets considered acked or lost as a result of the congestion event.
   virtual void OnCongestionEvent(bool rtt_updated,
-                                 QuicByteCount bytes_in_flight,
+                                 QuicByteCount prior_in_flight,
+                                 QuicTime event_time,
                                  const CongestionVector& acked_packets,
                                  const CongestionVector& lost_packets) = 0;
 
@@ -88,11 +93,6 @@ class NET_EXPORT_PRIVATE SendAlgorithmInterface {
   // Returns 0 when it does not have an estimate.
   virtual QuicBandwidth BandwidthEstimate() const = 0;
 
-  // Get the send algorithm specific retransmission delay, called RTO in TCP,
-  // Note 1: the caller is responsible for sanity checking this value.
-  // Note 2: this will return zero if we don't have enough data for an estimate.
-  virtual QuicTime::Delta RetransmissionDelay() const = 0;
-
   // Returns the size of the current congestion window in bytes.  Note, this is
   // not the *available* window.  Some send algorithms may not use a congestion
   // window and will return 0.
diff --git a/src/net/quic/core/congestion_control/tcp_cubic_sender_base.cc b/src/net/quic/core/congestion_control/tcp_cubic_sender_base.cc
index a94b662..3a74855 100644
--- a/src/net/quic/core/congestion_control/tcp_cubic_sender_base.cc
+++ b/src/net/quic/core/congestion_control/tcp_cubic_sender_base.cc
@@ -15,8 +15,6 @@
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
 
-using std::max;
-using std::min;
 
 namespace net {
 
@@ -115,7 +113,7 @@ void TcpCubicSenderBase::ResumeConnectionState(
 }
 
 void TcpCubicSenderBase::SetNumEmulatedConnections(int num_connections) {
-  num_connections_ = max(1, num_connections);
+  num_connections_ = std::max(1, num_connections);
 }
 
 float TcpCubicSenderBase::RenoBeta() const {
@@ -128,7 +126,8 @@ float TcpCubicSenderBase::RenoBeta() const {
 
 void TcpCubicSenderBase::OnCongestionEvent(
     bool rtt_updated,
-    QuicByteCount bytes_in_flight,
+    QuicByteCount prior_in_flight,
+    QuicTime /*event_time*/,
     const CongestionVector& acked_packets,
     const CongestionVector& lost_packets) {
   if (rtt_updated && InSlowStart() &&
@@ -139,19 +138,19 @@ void TcpCubicSenderBase::OnCongestionEvent(
   }
   for (CongestionVector::const_iterator it = lost_packets.begin();
        it != lost_packets.end(); ++it) {
-    OnPacketLost(it->first, it->second, bytes_in_flight);
+    OnPacketLost(it->first, it->second, prior_in_flight);
   }
   for (CongestionVector::const_iterator it = acked_packets.begin();
        it != acked_packets.end(); ++it) {
-    OnPacketAcked(it->first, it->second, bytes_in_flight);
+    OnPacketAcked(it->first, it->second, prior_in_flight);
   }
 }
 
 void TcpCubicSenderBase::OnPacketAcked(QuicPacketNumber acked_packet_number,
                                        QuicByteCount acked_bytes,
-                                       QuicByteCount bytes_in_flight) {
+                                       QuicByteCount prior_in_flight) {
   largest_acked_packet_number_ =
-      max(acked_packet_number, largest_acked_packet_number_);
+      std::max(acked_packet_number, largest_acked_packet_number_);
   if (InRecovery()) {
     if (!no_prr_) {
       // PRR is used when in recovery.
@@ -159,7 +158,7 @@ void TcpCubicSenderBase::OnPacketAcked(QuicPacketNumber acked_packet_number,
     }
     return;
   }
-  MaybeIncreaseCwnd(acked_packet_number, acked_bytes, bytes_in_flight);
+  MaybeIncreaseCwnd(acked_packet_number, acked_bytes, prior_in_flight);
   if (InSlowStart()) {
     hybrid_slow_start_.OnPacketAcked(acked_packet_number);
   }
@@ -238,13 +237,6 @@ QuicBandwidth TcpCubicSenderBase::BandwidthEstimate() const {
   return QuicBandwidth::FromBytesAndTimeDelta(GetCongestionWindow(), srtt);
 }
 
-QuicTime::Delta TcpCubicSenderBase::RetransmissionDelay() const {
-  if (rtt_stats_->smoothed_rtt().IsZero()) {
-    return QuicTime::Delta::Zero();
-  }
-  return rtt_stats_->smoothed_rtt() + 4 * rtt_stats_->mean_deviation();
-}
-
 bool TcpCubicSenderBase::InSlowStart() const {
   return GetCongestionWindow() < GetSlowStartThreshold();
 }
diff --git a/src/net/quic/core/congestion_control/tcp_cubic_sender_base.h b/src/net/quic/core/congestion_control/tcp_cubic_sender_base.h
index a6ddff3..d1ca16e 100644
--- a/src/net/quic/core/congestion_control/tcp_cubic_sender_base.h
+++ b/src/net/quic/core/congestion_control/tcp_cubic_sender_base.h
@@ -18,7 +18,7 @@
 #include "net/quic/core/congestion_control/send_algorithm_interface.h"
 #include "net/quic/core/quic_bandwidth.h"
 #include "net/quic/core/quic_connection_stats.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
@@ -49,7 +49,8 @@ class NET_EXPORT_PRIVATE TcpCubicSenderBase : public SendAlgorithmInterface {
       bool max_bandwidth_resumption) override;
   void SetNumEmulatedConnections(int num_connections) override;
   void OnCongestionEvent(bool rtt_updated,
-                         QuicByteCount bytes_in_flight,
+                         QuicByteCount prior_in_flight,
+                         QuicTime event_time,
                          const CongestionVector& acked_packets,
                          const CongestionVector& lost_packets) override;
   bool OnPacketSent(QuicTime sent_time,
@@ -63,7 +64,6 @@ class NET_EXPORT_PRIVATE TcpCubicSenderBase : public SendAlgorithmInterface {
                                 QuicByteCount bytes_in_flight) const override;
   QuicBandwidth PacingRate(QuicByteCount bytes_in_flight) const override;
   QuicBandwidth BandwidthEstimate() const override;
-  QuicTime::Delta RetransmissionDelay() const override;
   bool InSlowStart() const override;
   bool InRecovery() const override;
   std::string GetDebugState() const override;
@@ -88,13 +88,13 @@ class NET_EXPORT_PRIVATE TcpCubicSenderBase : public SendAlgorithmInterface {
   // Called when a packet is lost.
   virtual void OnPacketLost(QuicPacketNumber largest_loss,
                             QuicByteCount lost_bytes,
-                            QuicByteCount bytes_in_flight) = 0;
+                            QuicByteCount prior_in_flight) = 0;
 
   // Called when a packet has been acked to possibly increase the congestion
   // window.
   virtual void MaybeIncreaseCwnd(QuicPacketNumber acked_packet_number,
                                  QuicByteCount acked_bytes,
-                                 QuicByteCount bytes_in_flight) = 0;
+                                 QuicByteCount prior_in_flight) = 0;
 
   // Called when a retransmission has occured which resulted in packets
   // being retransmitted.
@@ -111,7 +111,7 @@ class NET_EXPORT_PRIVATE TcpCubicSenderBase : public SendAlgorithmInterface {
   // TODO(ianswett): Remove these and migrate to OnCongestionEvent.
   void OnPacketAcked(QuicPacketNumber acked_packet_number,
                      QuicByteCount acked_bytes,
-                     QuicByteCount bytes_in_flight);
+                     QuicByteCount prior_in_flight);
 
  protected:
   // TODO(rch): Make these private and clean up subclass access to them.
diff --git a/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.cc b/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.cc
index a974246..269cfda 100644
--- a/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.cc
+++ b/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.cc
@@ -13,8 +13,6 @@
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
 
-using std::max;
-using std::min;
 
 namespace net {
 
@@ -47,22 +45,25 @@ TcpCubicSenderBytes::TcpCubicSenderBytes(
 
 TcpCubicSenderBytes::~TcpCubicSenderBytes() {}
 
+void TcpCubicSenderBytes::SetFromConfig(const QuicConfig& config,
+                                        Perspective perspective) {
+  TcpCubicSenderBase::SetFromConfig(config, perspective);
+  if (FLAGS_quic_fix_cubic_convex_mode &&
+      config.HasReceivedConnectionOptions() &&
+      ContainsQuicTag(config.ReceivedConnectionOptions(), kCCVX)) {
+    cubic_.SetFixConvexMode(true);
+  }
+}
+
 void TcpCubicSenderBytes::SetCongestionWindowFromBandwidthAndRtt(
     QuicBandwidth bandwidth,
     QuicTime::Delta rtt) {
   QuicByteCount new_congestion_window = bandwidth.ToBytesPerPeriod(rtt);
-  if (FLAGS_quic_no_lower_bw_resumption_limit) {
-    // Limit new CWND if needed.
-    congestion_window_ =
-        max(min_congestion_window_,
-            min(new_congestion_window,
-                kMaxResumptionCongestionWindow * kDefaultTCPMSS));
-  } else {
-    congestion_window_ =
-        max(min(new_congestion_window,
-                kMaxResumptionCongestionWindow * kDefaultTCPMSS),
-            kMinCongestionWindowForBandwidthResumption * kDefaultTCPMSS);
-  }
+  // Limit new CWND if needed.
+  congestion_window_ =
+      std::max(min_congestion_window_,
+               std::min(new_congestion_window,
+                        kMaxResumptionCongestionWindow * kDefaultTCPMSS));
 }
 
 void TcpCubicSenderBytes::SetCongestionWindowInPackets(
@@ -86,7 +87,7 @@ void TcpCubicSenderBytes::ExitSlowstart() {
 
 void TcpCubicSenderBytes::OnPacketLost(QuicPacketNumber packet_number,
                                        QuicByteCount lost_bytes,
-                                       QuicByteCount bytes_in_flight) {
+                                       QuicByteCount prior_in_flight) {
   // TCP NewReno (RFC6582) says that once a loss occurs, any losses in packets
   // already sent should be treated as a single loss event, since it's expected.
   if (packet_number <= largest_sent_at_last_cutback_) {
@@ -95,8 +96,8 @@ void TcpCubicSenderBytes::OnPacketLost(QuicPacketNumber packet_number,
       stats_->slowstart_bytes_lost += lost_bytes;
       if (slow_start_large_reduction_) {
         // Reduce congestion window by lost_bytes for every loss.
-        congestion_window_ =
-            max(congestion_window_ - lost_bytes, min_slow_start_exit_window_);
+        congestion_window_ = std::max(congestion_window_ - lost_bytes,
+                                      min_slow_start_exit_window_);
         slowstart_threshold_ = congestion_window_;
       }
     }
@@ -111,7 +112,7 @@ void TcpCubicSenderBytes::OnPacketLost(QuicPacketNumber packet_number,
   }
 
   if (!no_prr_) {
-    prr_.OnPacketLost(bytes_in_flight);
+    prr_.OnPacketLost(prior_in_flight);
   }
 
   // TODO(jri): Separate out all of slow start into a separate class.
@@ -152,11 +153,11 @@ QuicByteCount TcpCubicSenderBytes::GetSlowStartThreshold() const {
 void TcpCubicSenderBytes::MaybeIncreaseCwnd(
     QuicPacketNumber acked_packet_number,
     QuicByteCount acked_bytes,
-    QuicByteCount bytes_in_flight) {
+    QuicByteCount prior_in_flight) {
   QUIC_BUG_IF(InRecovery()) << "Never increase the CWND during recovery.";
   // Do not increase the congestion window unless the sender is close to using
   // the current window.
-  if (!IsCwndLimited(bytes_in_flight)) {
+  if (!IsCwndLimited(prior_in_flight)) {
     cubic_.OnApplicationLimited();
     return;
   }
@@ -187,9 +188,9 @@ void TcpCubicSenderBytes::MaybeIncreaseCwnd(
              << " congestion window count: " << num_acked_packets_;
   } else {
     congestion_window_ =
-        min(max_congestion_window_,
-            cubic_.CongestionWindowAfterAck(acked_bytes, congestion_window_,
-                                            rtt_stats_->min_rtt()));
+        std::min(max_congestion_window_,
+                 cubic_.CongestionWindowAfterAck(
+                     acked_bytes, congestion_window_, rtt_stats_->min_rtt()));
     DVLOG(1) << "Cubic; congestion window: " << congestion_window_
              << " slowstart threshold: " << slowstart_threshold_;
   }
diff --git a/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.h b/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.h
index cf47f7e..5711ccd 100644
--- a/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.h
+++ b/src/net/quic/core/congestion_control/tcp_cubic_sender_bytes.h
@@ -17,7 +17,7 @@
 #include "net/quic/core/congestion_control/tcp_cubic_sender_base.h"
 #include "net/quic/core/quic_bandwidth.h"
 #include "net/quic/core/quic_connection_stats.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
@@ -39,6 +39,8 @@ class NET_EXPORT_PRIVATE TcpCubicSenderBytes : public TcpCubicSenderBase {
   ~TcpCubicSenderBytes() override;
 
   // Start implementation of SendAlgorithmInterface.
+  void SetFromConfig(const QuicConfig& config,
+                     Perspective perspective) override;
   void SetNumEmulatedConnections(int num_connections) override;
   void OnConnectionMigration() override;
   QuicByteCount GetCongestionWindow() const override;
@@ -58,10 +60,10 @@ class NET_EXPORT_PRIVATE TcpCubicSenderBytes : public TcpCubicSenderBase {
   void ExitSlowstart() override;
   void OnPacketLost(QuicPacketNumber largest_loss,
                     QuicByteCount lost_bytes,
-                    QuicByteCount bytes_in_flight) override;
+                    QuicByteCount prior_in_flight) override;
   void MaybeIncreaseCwnd(QuicPacketNumber acked_packet_number,
                          QuicByteCount acked_bytes,
-                         QuicByteCount bytes_in_flight) override;
+                         QuicByteCount prior_in_flight) override;
   void HandleRetransmissionTimeout() override;
 
  private:
diff --git a/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.cc b/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.cc
index c89895a..600e379 100644
--- a/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.cc
+++ b/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.cc
@@ -14,8 +14,6 @@
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
 
-using std::max;
-using std::min;
 
 namespace net {
 
@@ -46,21 +44,25 @@ TcpCubicSenderPackets::TcpCubicSenderPackets(
 
 TcpCubicSenderPackets::~TcpCubicSenderPackets() {}
 
+void TcpCubicSenderPackets::SetFromConfig(const QuicConfig& config,
+                                          Perspective perspective) {
+  TcpCubicSenderBase::SetFromConfig(config, perspective);
+  if (FLAGS_quic_fix_cubic_convex_mode &&
+      config.HasReceivedConnectionOptions() &&
+      ContainsQuicTag(config.ReceivedConnectionOptions(), kCCVX)) {
+    cubic_.SetFixConvexMode(true);
+  }
+}
+
 void TcpCubicSenderPackets::SetCongestionWindowFromBandwidthAndRtt(
     QuicBandwidth bandwidth,
     QuicTime::Delta rtt) {
   QuicPacketCount new_congestion_window =
       bandwidth.ToBytesPerPeriod(rtt) / kDefaultTCPMSS;
-  if (FLAGS_quic_no_lower_bw_resumption_limit) {
-    // Limit new CWND to be in the range [1, kMaxCongestionWindow].
-    congestion_window_ =
-        max(min_congestion_window_,
-            min(new_congestion_window, kMaxResumptionCongestionWindow));
-  } else {
-    congestion_window_ =
-        max(min(new_congestion_window, kMaxResumptionCongestionWindow),
-            kMinCongestionWindowForBandwidthResumption);
-  }
+  // Limit new CWND to be in the range [1, kMaxCongestionWindow].
+  congestion_window_ =
+      std::max(min_congestion_window_,
+               std::min(new_congestion_window, kMaxResumptionCongestionWindow));
 }
 
 void TcpCubicSenderPackets::SetCongestionWindowInPackets(
@@ -84,7 +86,7 @@ void TcpCubicSenderPackets::ExitSlowstart() {
 
 void TcpCubicSenderPackets::OnPacketLost(QuicPacketNumber packet_number,
                                          QuicByteCount lost_bytes,
-                                         QuicByteCount bytes_in_flight) {
+                                         QuicByteCount prior_in_flight) {
   // TCP NewReno (RFC6582) says that once a loss occurs, any losses in packets
   // already sent should be treated as a single loss event, since it's expected.
   if (packet_number <= largest_sent_at_last_cutback_) {
@@ -97,7 +99,7 @@ void TcpCubicSenderPackets::OnPacketLost(QuicPacketNumber packet_number,
                 (stats_->slowstart_bytes_lost - lost_bytes) / kDefaultTCPMSS) {
           // Reduce congestion window by 1 for every mss of bytes lost.
           congestion_window_ =
-              max(congestion_window_ - 1, min_slow_start_exit_window_);
+              std::max(congestion_window_ - 1, min_slow_start_exit_window_);
         }
         slowstart_threshold_ = congestion_window_;
       }
@@ -113,7 +115,7 @@ void TcpCubicSenderPackets::OnPacketLost(QuicPacketNumber packet_number,
   }
 
   if (!no_prr_) {
-    prr_.OnPacketLost(bytes_in_flight);
+    prr_.OnPacketLost(prior_in_flight);
   }
 
   // TODO(jri): Separate out all of slow start into a separate class.
@@ -155,11 +157,11 @@ QuicByteCount TcpCubicSenderPackets::GetSlowStartThreshold() const {
 void TcpCubicSenderPackets::MaybeIncreaseCwnd(
     QuicPacketNumber acked_packet_number,
     QuicByteCount /*acked_bytes*/,
-    QuicByteCount bytes_in_flight) {
+    QuicByteCount prior_in_flight) {
   QUIC_BUG_IF(InRecovery()) << "Never increase the CWND during recovery.";
   // Do not increase the congestion window unless the sender is close to using
   // the current window.
-  if (!IsCwndLimited(bytes_in_flight)) {
+  if (!IsCwndLimited(prior_in_flight)) {
     cubic_.OnApplicationLimited();
     return;
   }
@@ -188,9 +190,10 @@ void TcpCubicSenderPackets::MaybeIncreaseCwnd(
              << " slowstart threshold: " << slowstart_threshold_
              << " congestion window count: " << congestion_window_count_;
   } else {
-    congestion_window_ = min(max_tcp_congestion_window_,
-                             cubic_.CongestionWindowAfterAck(
-                                 congestion_window_, rtt_stats_->min_rtt()));
+    congestion_window_ =
+        std::min(max_tcp_congestion_window_,
+                 cubic_.CongestionWindowAfterAck(congestion_window_,
+                                                 rtt_stats_->min_rtt()));
     DVLOG(1) << "Cubic; congestion window: " << congestion_window_
              << " slowstart threshold: " << slowstart_threshold_;
   }
diff --git a/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.h b/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.h
index 76e3ad6..5e3c7c2 100644
--- a/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.h
+++ b/src/net/quic/core/congestion_control/tcp_cubic_sender_packets.h
@@ -18,7 +18,7 @@
 #include "net/quic/core/congestion_control/tcp_cubic_sender_base.h"
 #include "net/quic/core/quic_bandwidth.h"
 #include "net/quic/core/quic_connection_stats.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
@@ -41,6 +41,8 @@ class NET_EXPORT_PRIVATE TcpCubicSenderPackets : public TcpCubicSenderBase {
   ~TcpCubicSenderPackets() override;
 
   // Start implementation of SendAlgorithmInterface.
+  void SetFromConfig(const QuicConfig& config,
+                     Perspective perspective) override;
   void SetNumEmulatedConnections(int num_connections) override;
   void OnConnectionMigration() override;
   QuicByteCount GetCongestionWindow() const override;
@@ -60,10 +62,10 @@ class NET_EXPORT_PRIVATE TcpCubicSenderPackets : public TcpCubicSenderBase {
   void ExitSlowstart() override;
   void OnPacketLost(QuicPacketNumber largest_loss,
                     QuicByteCount lost_bytes,
-                    QuicByteCount bytes_in_flight) override;
+                    QuicByteCount prior_in_flight) override;
   void MaybeIncreaseCwnd(QuicPacketNumber acked_packet_number,
                          QuicByteCount acked_bytes,
-                         QuicByteCount bytes_in_flight) override;
+                         QuicByteCount prior_in_flight) override;
   void HandleRetransmissionTimeout() override;
 
  private:
diff --git a/src/net/quic/core/crypto/aead_base_decrypter.cc b/src/net/quic/core/crypto/aead_base_decrypter.cc
index 721fe5b..1da2261 100644
--- a/src/net/quic/core/crypto/aead_base_decrypter.cc
+++ b/src/net/quic/core/crypto/aead_base_decrypter.cc
@@ -2,15 +2,15 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-#include <openssl/err.h>
-#include <openssl/evp.h>
+#include "net/quic/core/crypto/aead_base_decrypter.h"
 
 #include <memory>
 
-#include "net/quic/core/crypto/aead_base_decrypter.h"
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_utils.h"
+#include "third_party/boringssl/src/include/openssl/err.h"
+#include "third_party/boringssl/src/include/openssl/evp.h"
 
 using base::StringPiece;
 using std::string;
diff --git a/src/net/quic/core/crypto/aead_base_decrypter.h b/src/net/quic/core/crypto/aead_base_decrypter.h
index a47de35..f6da359 100644
--- a/src/net/quic/core/crypto/aead_base_decrypter.h
+++ b/src/net/quic/core/crypto/aead_base_decrypter.h
@@ -9,6 +9,7 @@
 
 #include "base/compiler_specific.h"
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/quic_decrypter.h"
 #include "net/quic/core/crypto/scoped_evp_aead_ctx.h"
 
diff --git a/src/net/quic/core/crypto/aead_base_encrypter.cc b/src/net/quic/core/crypto/aead_base_encrypter.cc
index 195aba7..477810f 100644
--- a/src/net/quic/core/crypto/aead_base_encrypter.cc
+++ b/src/net/quic/core/crypto/aead_base_encrypter.cc
@@ -2,8 +2,6 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-#include <openssl/err.h>
-#include <openssl/evp.h>
 #include <string.h>
 
 #include <memory>
@@ -11,6 +9,8 @@
 #include "net/quic/core/crypto/aead_base_encrypter.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_utils.h"
+#include "third_party/boringssl/src/include/openssl/err.h"
+#include "third_party/boringssl/src/include/openssl/evp.h"
 
 using base::StringPiece;
 
diff --git a/src/net/quic/core/crypto/aead_base_encrypter.h b/src/net/quic/core/crypto/aead_base_encrypter.h
index b5537e3..4e2c68a 100644
--- a/src/net/quic/core/crypto/aead_base_encrypter.h
+++ b/src/net/quic/core/crypto/aead_base_encrypter.h
@@ -9,6 +9,7 @@
 
 #include "base/compiler_specific.h"
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/quic_encrypter.h"
 #include "net/quic/core/crypto/scoped_evp_aead_ctx.h"
 
diff --git a/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.cc b/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.cc
index a9eb9cb..8926fad 100644
--- a/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.cc
+++ b/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.cc
@@ -4,8 +4,8 @@
 
 #include "net/quic/core/crypto/aes_128_gcm_12_decrypter.h"
 
-#include <openssl/evp.h>
-#include <openssl/tls1.h>
+#include "third_party/boringssl/src/include/openssl/evp.h"
+#include "third_party/boringssl/src/include/openssl/tls1.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.h b/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.h
index 9ca3538..58d992b 100644
--- a/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.h
+++ b/src/net/quic/core/crypto/aes_128_gcm_12_decrypter.h
@@ -9,6 +9,7 @@
 #include <stdint.h>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/aead_base_decrypter.h"
 
 namespace net {
diff --git a/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.cc b/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.cc
index 50c24cb..dde7e3e 100644
--- a/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.cc
+++ b/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.cc
@@ -4,7 +4,7 @@
 
 #include "net/quic/core/crypto/aes_128_gcm_12_encrypter.h"
 
-#include <openssl/evp.h>
+#include "third_party/boringssl/src/include/openssl/evp.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.h b/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.h
index a7ccfb3..70b8623 100644
--- a/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.h
+++ b/src/net/quic/core/crypto/aes_128_gcm_12_encrypter.h
@@ -8,6 +8,7 @@
 #include <stddef.h>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/aead_base_encrypter.h"
 
 namespace net {
diff --git a/src/net/quic/core/crypto/cert_compressor.cc b/src/net/quic/core/crypto/cert_compressor.cc
index 4010826..0e0ca06 100644
--- a/src/net/quic/core/crypto/cert_compressor.cc
+++ b/src/net/quic/core/crypto/cert_compressor.cc
@@ -13,7 +13,6 @@
 
 using base::StringPiece;
 using std::string;
-using std::vector;
 
 namespace net {
 
@@ -177,18 +176,18 @@ struct CertEntry {
 // efficiently represent |certs| to a peer who has the common sets identified
 // by |client_common_set_hashes| and who has cached the certificates with the
 // 64-bit, FNV-1a hashes in |client_cached_cert_hashes|.
-vector<CertEntry> MatchCerts(const vector<string>& certs,
-                             StringPiece client_common_set_hashes,
-                             StringPiece client_cached_cert_hashes,
-                             const CommonCertSets* common_sets) {
-  vector<CertEntry> entries;
+std::vector<CertEntry> MatchCerts(const std::vector<string>& certs,
+                                  StringPiece client_common_set_hashes,
+                                  StringPiece client_cached_cert_hashes,
+                                  const CommonCertSets* common_sets) {
+  std::vector<CertEntry> entries;
   entries.reserve(certs.size());
 
   const bool cached_valid =
       client_cached_cert_hashes.size() % sizeof(uint64_t) == 0 &&
       !client_cached_cert_hashes.empty();
 
-  for (vector<string>::const_iterator i = certs.begin(); i != certs.end();
+  for (std::vector<string>::const_iterator i = certs.begin(); i != certs.end();
        ++i) {
     CertEntry entry;
 
@@ -235,10 +234,10 @@ vector<CertEntry> MatchCerts(const vector<string>& certs,
 
 // CertEntriesSize returns the size, in bytes, of the serialised form of
 // |entries|.
-size_t CertEntriesSize(const vector<CertEntry>& entries) {
+size_t CertEntriesSize(const std::vector<CertEntry>& entries) {
   size_t entries_size = 0;
 
-  for (vector<CertEntry>::const_iterator i = entries.begin();
+  for (std::vector<CertEntry>::const_iterator i = entries.begin();
        i != entries.end(); ++i) {
     entries_size++;
     switch (i->type) {
@@ -260,8 +259,8 @@ size_t CertEntriesSize(const vector<CertEntry>& entries) {
 
 // SerializeCertEntries serialises |entries| to |out|, which must have enough
 // space to contain them.
-void SerializeCertEntries(uint8_t* out, const vector<CertEntry>& entries) {
-  for (vector<CertEntry>::const_iterator i = entries.begin();
+void SerializeCertEntries(uint8_t* out, const std::vector<CertEntry>& entries) {
+  for (std::vector<CertEntry>::const_iterator i = entries.begin();
        i != entries.end(); ++i) {
     *out++ = static_cast<uint8_t>(i->type);
     switch (i->type) {
@@ -288,8 +287,8 @@ void SerializeCertEntries(uint8_t* out, const vector<CertEntry>& entries) {
 // dictionary to use in order to decompress a zlib block following |entries|.
 // |certs| is one-to-one with |entries| and contains the certificates for those
 // entries that are CACHED or COMMON.
-string ZlibDictForEntries(const vector<CertEntry>& entries,
-                          const vector<string>& certs) {
+string ZlibDictForEntries(const std::vector<CertEntry>& entries,
+                          const std::vector<string>& certs) {
   string zlib_dict;
 
   // The dictionary starts with the common and cached certs in reverse order.
@@ -320,11 +319,11 @@ string ZlibDictForEntries(const vector<CertEntry>& entries,
 }
 
 // HashCerts returns the FNV-1a hashes of |certs|.
-vector<uint64_t> HashCerts(const vector<string>& certs) {
-  vector<uint64_t> ret;
+std::vector<uint64_t> HashCerts(const std::vector<string>& certs) {
+  std::vector<uint64_t> ret;
   ret.reserve(certs.size());
 
-  for (vector<string>::const_iterator i = certs.begin(); i != certs.end();
+  for (std::vector<string>::const_iterator i = certs.begin(); i != certs.end();
        ++i) {
     ret.push_back(QuicUtils::FNV1a_64_Hash(i->data(), i->size()));
   }
@@ -337,12 +336,12 @@ vector<uint64_t> HashCerts(const vector<string>& certs) {
 // resolved using |cached_certs| and |common_sets| and written to |out_certs|.
 // |in_out| is updated to contain the trailing data.
 bool ParseEntries(StringPiece* in_out,
-                  const vector<string>& cached_certs,
+                  const std::vector<string>& cached_certs,
                   const CommonCertSets* common_sets,
-                  vector<CertEntry>* out_entries,
-                  vector<string>* out_certs) {
+                  std::vector<CertEntry>* out_entries,
+                  std::vector<string>* out_certs) {
   StringPiece in = *in_out;
-  vector<uint64_t> cached_hashes;
+  std::vector<uint64_t> cached_hashes;
 
   out_entries->clear();
   out_certs->clear();
@@ -455,11 +454,11 @@ class ScopedZLib {
 }  // anonymous namespace
 
 // static
-string CertCompressor::CompressChain(const vector<string>& certs,
+string CertCompressor::CompressChain(const std::vector<string>& certs,
                                      StringPiece client_common_set_hashes,
                                      StringPiece client_cached_cert_hashes,
                                      const CommonCertSets* common_sets) {
-  const vector<CertEntry> entries = MatchCerts(
+  const std::vector<CertEntry> entries = MatchCerts(
       certs, client_common_set_hashes, client_cached_cert_hashes, common_sets);
   DCHECK_EQ(entries.size(), certs.size());
 
@@ -557,10 +556,10 @@ string CertCompressor::CompressChain(const vector<string>& certs,
 
 // static
 bool CertCompressor::DecompressChain(StringPiece in,
-                                     const vector<string>& cached_certs,
+                                     const std::vector<string>& cached_certs,
                                      const CommonCertSets* common_sets,
-                                     vector<string>* out_certs) {
-  vector<CertEntry> entries;
+                                     std::vector<string>* out_certs) {
+  std::vector<CertEntry> entries;
   if (!ParseEntries(&in, cached_certs, common_sets, &entries, out_certs)) {
     return false;
   }
diff --git a/src/net/quic/core/crypto/chacha20_poly1305_decrypter.cc b/src/net/quic/core/crypto/chacha20_poly1305_decrypter.cc
index 302d105..0c65229 100644
--- a/src/net/quic/core/crypto/chacha20_poly1305_decrypter.cc
+++ b/src/net/quic/core/crypto/chacha20_poly1305_decrypter.cc
@@ -4,8 +4,8 @@
 
 #include "net/quic/core/crypto/chacha20_poly1305_decrypter.h"
 
-#include <openssl/evp.h>
-#include <openssl/tls1.h>
+#include "third_party/boringssl/src/include/openssl/evp.h"
+#include "third_party/boringssl/src/include/openssl/tls1.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/crypto/chacha20_poly1305_decrypter.h b/src/net/quic/core/crypto/chacha20_poly1305_decrypter.h
index 4d0db6c..0aa3568 100644
--- a/src/net/quic/core/crypto/chacha20_poly1305_decrypter.h
+++ b/src/net/quic/core/crypto/chacha20_poly1305_decrypter.h
@@ -9,6 +9,7 @@
 #include <stdint.h>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/aead_base_decrypter.h"
 
 namespace net {
diff --git a/src/net/quic/core/crypto/chacha20_poly1305_encrypter.cc b/src/net/quic/core/crypto/chacha20_poly1305_encrypter.cc
index 3a79622..520ed17 100644
--- a/src/net/quic/core/crypto/chacha20_poly1305_encrypter.cc
+++ b/src/net/quic/core/crypto/chacha20_poly1305_encrypter.cc
@@ -4,7 +4,7 @@
 
 #include "net/quic/core/crypto/chacha20_poly1305_encrypter.h"
 
-#include <openssl/evp.h>
+#include "third_party/boringssl/src/include/openssl/evp.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/crypto/chacha20_poly1305_encrypter.h b/src/net/quic/core/crypto/chacha20_poly1305_encrypter.h
index aa5d0cd..8f3eaa7 100644
--- a/src/net/quic/core/crypto/chacha20_poly1305_encrypter.h
+++ b/src/net/quic/core/crypto/chacha20_poly1305_encrypter.h
@@ -8,6 +8,7 @@
 #include <stddef.h>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/aead_base_encrypter.h"
 
 namespace net {
diff --git a/src/net/quic/core/crypto/channel_id.cc b/src/net/quic/core/crypto/channel_id.cc
index 0d989c8..abc0ae5 100644
--- a/src/net/quic/core/crypto/channel_id.cc
+++ b/src/net/quic/core/crypto/channel_id.cc
@@ -4,14 +4,13 @@
 
 #include "net/quic/core/crypto/channel_id.h"
 
-#include <openssl/bn.h>
-#include <openssl/ec.h>
-#include <openssl/ecdsa.h>
-#include <openssl/obj_mac.h>
-#include <openssl/sha.h>
-
 #include "crypto/openssl_util.h"
-#include "crypto/scoped_openssl_types.h"
+#include "third_party/boringssl/src/include/openssl/bn.h"
+#include "third_party/boringssl/src/include/openssl/ec.h"
+#include "third_party/boringssl/src/include/openssl/ec_key.h"
+#include "third_party/boringssl/src/include/openssl/ecdsa.h"
+#include "third_party/boringssl/src/include/openssl/nid.h"
+#include "third_party/boringssl/src/include/openssl/sha.h"
 
 using base::StringPiece;
 
@@ -38,12 +37,13 @@ bool ChannelIDVerifier::VerifyRaw(StringPiece key,
     return false;
   }
 
-  crypto::ScopedEC_GROUP p256(EC_GROUP_new_by_curve_name(NID_X9_62_prime256v1));
+  bssl::UniquePtr<EC_GROUP> p256(
+      EC_GROUP_new_by_curve_name(NID_X9_62_prime256v1));
   if (!p256) {
     return false;
   }
 
-  crypto::ScopedBIGNUM x(BN_new()), y(BN_new()), r(BN_new()), s(BN_new());
+  bssl::UniquePtr<BIGNUM> x(BN_new()), y(BN_new()), r(BN_new()), s(BN_new());
 
   ECDSA_SIG sig;
   sig.r = r.get();
@@ -60,14 +60,14 @@ bool ChannelIDVerifier::VerifyRaw(StringPiece key,
     return false;
   }
 
-  crypto::ScopedEC_POINT point(EC_POINT_new(p256.get()));
-  if (!point ||
+  bssl::UniquePtr<EC_POINT> point(EC_POINT_new(p256.get()));
+  if (point.get() == nullptr ||
       !EC_POINT_set_affine_coordinates_GFp(p256.get(), point.get(), x.get(),
                                            y.get(), nullptr)) {
     return false;
   }
 
-  crypto::ScopedEC_KEY ecdsa_key(EC_KEY_new());
+  bssl::UniquePtr<EC_KEY> ecdsa_key(EC_KEY_new());
   if (ecdsa_key.get() == nullptr ||
       !EC_KEY_set_group(ecdsa_key.get(), p256.get()) ||
       !EC_KEY_set_public_key(ecdsa_key.get(), point.get())) {
diff --git a/src/net/quic/core/crypto/crypto_framer.cc b/src/net/quic/core/crypto/crypto_framer.cc
index 2dd8f63..c2a83d6 100644
--- a/src/net/quic/core/crypto/crypto_framer.cc
+++ b/src/net/quic/core/crypto/crypto_framer.cc
@@ -12,8 +12,6 @@
 #include "net/quic/core/quic_data_writer.h"
 
 using base::StringPiece;
-using std::pair;
-using std::vector;
 
 namespace net {
 
@@ -260,7 +258,7 @@ QuicErrorCode CryptoFramer::Process(StringPiece input) {
       if (reader.BytesRemaining() < values_len_) {
         break;
       }
-      for (const pair<QuicTag, size_t>& item : tags_and_lengths_) {
+      for (const std::pair<QuicTag, size_t>& item : tags_and_lengths_) {
         StringPiece value;
         reader.ReadStringPiece(&value, item.second);
         message_.SetStringPiece(item.first, value);
diff --git a/src/net/quic/core/crypto/crypto_framer.h b/src/net/quic/core/crypto/crypto_framer.h
index c581a62..312efc3 100644
--- a/src/net/quic/core/crypto/crypto_framer.h
+++ b/src/net/quic/core/crypto/crypto_framer.h
@@ -15,13 +15,12 @@
 #include "base/strings/string_piece.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/crypto/crypto_handshake_message.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
 class CryptoFramer;
 class QuicData;
-class QuicDataReader;
 class QuicDataWriter;
 
 class NET_EXPORT_PRIVATE CryptoFramerVisitorInterface {
diff --git a/src/net/quic/core/crypto/crypto_handshake.h b/src/net/quic/core/crypto/crypto_handshake.h
index 017fa05..170a7b2 100644
--- a/src/net/quic/core/crypto/crypto_handshake.h
+++ b/src/net/quic/core/crypto/crypto_handshake.h
@@ -13,7 +13,7 @@
 
 #include "base/macros.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
@@ -99,10 +99,10 @@ struct NET_EXPORT_PRIVATE CrypterPair {
 };
 
 // Parameters negotiated by the crypto handshake.
-struct NET_EXPORT_PRIVATE QuicCryptoNegotiatedParameters {
+struct NET_EXPORT_PRIVATE QuicCryptoNegotiatedParameters
+    : public base::RefCounted<QuicCryptoNegotiatedParameters> {
   // Initializes the members to 0 or empty values.
   QuicCryptoNegotiatedParameters();
-  ~QuicCryptoNegotiatedParameters();
 
   QuicTag key_exchange;
   QuicTag aead;
@@ -149,6 +149,10 @@ struct NET_EXPORT_PRIVATE QuicCryptoNegotiatedParameters {
   // Default to false; set to true if the client indicates that it supports sct
   // by sending CSCT tag with an empty value in client hello.
   bool sct_supported_by_client;
+
+ private:
+  friend class base::RefCounted<QuicCryptoNegotiatedParameters>;
+  virtual ~QuicCryptoNegotiatedParameters();
 };
 
 // QuicCryptoConfig contains common configuration between clients and servers.
diff --git a/src/net/quic/core/crypto/crypto_handshake_message.cc b/src/net/quic/core/crypto/crypto_handshake_message.cc
index 6d09164..2f9e230 100644
--- a/src/net/quic/core/crypto/crypto_handshake_message.cc
+++ b/src/net/quic/core/crypto/crypto_handshake_message.cc
@@ -6,6 +6,7 @@
 
 #include <memory>
 
+#include "base/stl_util.h"
 #include "base/strings/string_number_conversions.h"
 #include "base/strings/stringprintf.h"
 #include "net/quic/core/crypto/crypto_framer.h"
@@ -17,7 +18,6 @@
 using base::StringPiece;
 using base::StringPrintf;
 using std::string;
-using std::vector;
 
 namespace net {
 
@@ -110,6 +110,10 @@ bool CryptoHandshakeMessage::GetStringPiece(QuicTag tag,
   return true;
 }
 
+bool CryptoHandshakeMessage::HasStringPiece(QuicTag tag) const {
+  return base::ContainsKey(tag_value_map_, tag);
+}
+
 QuicErrorCode CryptoHandshakeMessage::GetNthValue24(QuicTag tag,
                                                     unsigned index,
                                                     StringPiece* out) const {
@@ -207,11 +211,11 @@ QuicErrorCode CryptoHandshakeMessage::GetPOD(QuicTag tag,
 }
 
 string CryptoHandshakeMessage::DebugStringInternal(size_t indent) const {
-  string ret = string(2 * indent, ' ') + QuicUtils::TagToString(tag_) + "<\n";
+  string ret = string(2 * indent, ' ') + QuicTagToString(tag_) + "<\n";
   ++indent;
   for (QuicTagValueMap::const_iterator it = tag_value_map_.begin();
        it != tag_value_map_.end(); ++it) {
-    ret += string(2 * indent, ' ') + QuicUtils::TagToString(it->first) + ": ";
+    ret += string(2 * indent, ' ') + QuicTagToString(it->first) + ": ";
 
     bool done = false;
     switch (it->first) {
@@ -222,6 +226,9 @@ string CryptoHandshakeMessage::DebugStringInternal(size_t indent) const {
       case kMSPC:
       case kSRBF:
       case kSWND:
+      case kMIDS:
+      case kSCLS:
+      case kTCID:
         // uint32_t value
         if (it->second.size() == 4) {
           uint32_t value;
@@ -253,7 +260,7 @@ string CryptoHandshakeMessage::DebugStringInternal(size_t indent) const {
             if (j > 0) {
               ret += ",";
             }
-            ret += "'" + QuicUtils::TagToString(tag) + "'";
+            ret += "'" + QuicTagToString(tag) + "'";
           }
           done = true;
         }
@@ -278,7 +285,7 @@ string CryptoHandshakeMessage::DebugStringInternal(size_t indent) const {
         if (!it->second.empty()) {
           QuicSocketAddressCoder decoder;
           if (decoder.Decode(it->second.data(), it->second.size())) {
-            ret += IPAddressToStringWithPort(decoder.ip(), decoder.port());
+            ret += QuicSocketAddress(decoder.ip(), decoder.port()).ToString();
             done = true;
           }
         }
diff --git a/src/net/quic/core/crypto/crypto_handshake_message.h b/src/net/quic/core/crypto/crypto_handshake_message.h
index ab4f238..f09691d 100644
--- a/src/net/quic/core/crypto/crypto_handshake_message.h
+++ b/src/net/quic/core/crypto/crypto_handshake_message.h
@@ -15,7 +15,7 @@
 
 #include "base/strings/string_piece.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
@@ -74,15 +74,17 @@ class NET_EXPORT_PRIVATE CryptoHandshakeMessage {
   void Erase(QuicTag tag);
 
   // GetTaglist finds an element with the given tag containing zero or more
-  // tags. If such a tag doesn't exist, it returns false. Otherwise it sets
-  // |out_tags| and |out_len| to point to the array of tags and returns true.
-  // The array points into the CryptoHandshakeMessage and is valid only for as
-  // long as the CryptoHandshakeMessage exists and is not modified.
+  // tags. If such a tag doesn't exist, it returns an error code. Otherwise it
+  // sets |out_tags| and |out_len| to point to the array of tags and returns
+  // QUIC_NO_ERROR.  The array points into the CryptoHandshakeMessage and is
+  // valid only for as long as the CryptoHandshakeMessage exists and is not
+  // modified.
   QuicErrorCode GetTaglist(QuicTag tag,
                            const QuicTag** out_tags,
                            size_t* out_len) const;
 
   bool GetStringPiece(QuicTag tag, base::StringPiece* out) const;
+  bool HasStringPiece(QuicTag tag) const;
 
   // GetNthValue24 interprets the value with the given tag to be a series of
   // 24-bit, length prefixed values and it returns the subvalue with the given
diff --git a/src/net/quic/core/crypto/crypto_protocol.h b/src/net/quic/core/crypto/crypto_protocol.h
index 8060526..f9e8640 100644
--- a/src/net/quic/core/crypto/crypto_protocol.h
+++ b/src/net/quic/core/crypto/crypto_protocol.h
@@ -10,8 +10,7 @@
 
 #include <string>
 
-#include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_tag.h"
 
 // Version and Crypto tags are written to the wire with a big-endian
 // representation of the name of the tag.  For example
@@ -104,7 +103,17 @@ const QuicTag k5RTO = TAG('5', 'R', 'T', 'O');   // Close connection on 5 RTOs
 const QuicTag kCTIM = TAG('C', 'T', 'I', 'M');   // Client timestamp in seconds
                                                  // since UNIX epoch.
 const QuicTag kDHDT = TAG('D', 'H', 'D', 'T');   // Disable HPACK dynamic table.
-const QuicTag kIPFS = TAG('I', 'P', 'F', 'S');   // No Immediate Forward Secrecy
+const QuicTag kCONH = TAG('C', 'O', 'N', 'H');   // Conservative Handshake
+                                                 // Retransmissions.
+const QuicTag kLFAK = TAG('L', 'F', 'A', 'K');   // Don't invoke FACK on the
+                                                 // first ack.
+
+// TODO(fayang): Remove this connection option in QUIC_VERSION_37, in which
+// MAX_HEADER_LIST_SIZE settings frame should be supported.
+const QuicTag kSMHL = TAG('S', 'M', 'H', 'L');   // Support MAX_HEADER_LIST_SIZE
+                                                 // settings frame.
+
+const QuicTag kCCVX = TAG('C', 'C', 'V', 'X');   // Fix Cubic convex bug.
 
 // Optional support of truncated Connection IDs.  If sent by a peer, the value
 // is the minimum number of bytes allowed for the connection ID sent to the
@@ -127,7 +136,11 @@ const QuicTag kBWS2 = TAG('B', 'W', 'S', '2');  // Server bw resumption v2.
 const QuicTag kMTUH = TAG('M', 'T', 'U', 'H');  // High-target MTU discovery.
 const QuicTag kMTUL = TAG('M', 'T', 'U', 'L');  // Low-target MTU discovery.
 
-const QuicTag kFHOL = TAG('F', 'H', 'O', 'L');   // Force head of line blocking.
+// Tags for async signing experiments
+const QuicTag kASYN = TAG('A', 'S', 'Y', 'N');  // Perform asynchronous signing
+const QuicTag kSYNC = TAG('S', 'Y', 'N', 'C');  // Perform synchronous signing
+
+const QuicTag kFHL2 = TAG('F', 'H', 'L', '2');   // Force head of line blocking.
 
 // Proof types (i.e. certificate types)
 // NOTE: although it would be silly to do so, specifying both kX509 and kX59R
@@ -146,8 +159,8 @@ const QuicTag kKEXS = TAG('K', 'E', 'X', 'S');   // Key exchange methods
 const QuicTag kAEAD = TAG('A', 'E', 'A', 'D');   // Authenticated
                                                  // encryption algorithms
 const QuicTag kCOPT = TAG('C', 'O', 'P', 'T');   // Connection options
-const QuicTag kICSL = TAG('I', 'C', 'S', 'L');   // Idle connection state
-                                                 // lifetime
+const QuicTag kCLOP = TAG('C', 'L', 'O', 'P');   // Client connection options
+const QuicTag kICSL = TAG('I', 'C', 'S', 'L');   // Idle network timeout
 const QuicTag kSCLS = TAG('S', 'C', 'L', 'S');   // Silently close on timeout
 const QuicTag kMSPC = TAG('M', 'S', 'P', 'C');   // Max streams per connection.
 const QuicTag kMIDS = TAG('M', 'I', 'D', 'S');   // Max incoming dynamic streams
@@ -200,8 +213,6 @@ const QuicTag kPAD  = TAG('P', 'A', 'D', '\0');  // Padding
 // Server push tags
 const QuicTag kSPSH = TAG('S', 'P', 'S', 'H');  // Support server push.
 
-// Sent by clients with the fix to crbug/566156
-const QuicTag kFIXD = TAG('F', 'I', 'X', 'D');   // Client hello
 // clang-format on
 
 // These tags have a special form so that they appear either at the beginning
@@ -233,11 +244,6 @@ const size_t kNonceSize = 32;  // Size in bytes of the connection nonce.
 
 const size_t kOrbitSize = 8;  // Number of bytes in an orbit value.
 
-// kProofSignatureLabel is prepended to server configs before signing to avoid
-// any cross-protocol attacks on the signature.
-// TODO(rch): Remove this when QUIC_VERSION_30 is removed.
-const char kProofSignatureLabelOld[] = "QUIC server config signature";
-
 // kProofSignatureLabel is prepended to the CHLO hash and server configs before
 // signing to avoid any cross-protocol attacks on the signature.
 const char kProofSignatureLabel[] = "QUIC CHLO and server config signature";
diff --git a/src/net/quic/core/crypto/crypto_secret_boxer.cc b/src/net/quic/core/crypto/crypto_secret_boxer.cc
index 37f48b5..6c5807c 100644
--- a/src/net/quic/core/crypto/crypto_secret_boxer.cc
+++ b/src/net/quic/core/crypto/crypto_secret_boxer.cc
@@ -16,7 +16,6 @@
 
 using base::StringPiece;
 using std::string;
-using std::vector;
 
 namespace net {
 
@@ -45,9 +44,9 @@ size_t CryptoSecretBoxer::GetKeySize() {
   return kKeySize;
 }
 
-void CryptoSecretBoxer::SetKeys(const vector<string>& keys) {
+void CryptoSecretBoxer::SetKeys(const std::vector<string>& keys) {
   DCHECK(!keys.empty());
-  vector<string> copy = keys;
+  std::vector<string> copy = keys;
   for (const string& key : keys) {
     DCHECK_EQ(kKeySize, key.size());
   }
diff --git a/src/net/quic/core/crypto/crypto_secret_boxer.h b/src/net/quic/core/crypto/crypto_secret_boxer.h
index 09ec23c..3bc9284 100644
--- a/src/net/quic/core/crypto/crypto_secret_boxer.h
+++ b/src/net/quic/core/crypto/crypto_secret_boxer.h
@@ -30,10 +30,9 @@ class NET_EXPORT_PRIVATE CryptoSecretBoxer {
   // GetKeySize returns the number of bytes in a key.
   static size_t GetKeySize();
 
-  // SetKeys sets a std::list of encryption keys. The first key in the std::list
-  // will be used by |Box|, but all supplied keys will be tried by |Unbox|, to
-  // handle key skew across the fleet. This must be called before |Box| or
-  // |Unbox|. Keys must be |GetKeySize()| bytes long.
+  // used by |Box|, but all supplied keys will be tried by |Unbox|, to handle
+  // key skew across the fleet. This must be called before |Box| or |Unbox|.
+  // Keys must be |GetKeySize()| bytes long.
   void SetKeys(const std::vector<std::string>& keys);
 
   // Box encrypts |plaintext| using a random nonce generated from |rand| and
@@ -53,7 +52,7 @@ class NET_EXPORT_PRIVATE CryptoSecretBoxer {
 
  private:
   mutable base::Lock lock_;
-  //  GUARDED_BY(lock_).
+  //  GUARDED_BY(lock_).mutable Mutex lock_;
   std::vector<std::string> keys_;
 
   DISALLOW_COPY_AND_ASSIGN(CryptoSecretBoxer);
diff --git a/src/net/quic/core/crypto/crypto_server_config_protobuf.cc b/src/net/quic/core/crypto/crypto_server_config_protobuf.cc
index c8e70ed..0c66e6a 100644
--- a/src/net/quic/core/crypto/crypto_server_config_protobuf.cc
+++ b/src/net/quic/core/crypto/crypto_server_config_protobuf.cc
@@ -11,8 +11,6 @@ namespace net {
 QuicServerConfigProtobuf::QuicServerConfigProtobuf()
     : primary_time_(QuicWallTime::Zero().ToUNIXSeconds()), priority_(0) {}
 
-QuicServerConfigProtobuf::~QuicServerConfigProtobuf() {
-  base::STLDeleteElements(&keys_);
-}
+QuicServerConfigProtobuf::~QuicServerConfigProtobuf() {}
 
 }  // namespace net
diff --git a/src/net/quic/core/crypto/crypto_server_config_protobuf.h b/src/net/quic/core/crypto/crypto_server_config_protobuf.h
index 28c2eb9..bd5e641 100644
--- a/src/net/quic/core/crypto/crypto_server_config_protobuf.h
+++ b/src/net/quic/core/crypto/crypto_server_config_protobuf.h
@@ -8,12 +8,13 @@
 #include <stddef.h>
 #include <stdint.h>
 
+#include <memory>
 #include <string>
 #include <vector>
 
 #include "base/logging.h"
 #include "base/macros.h"
-#include "base/stl_util.h"
+#include "base/memory/ptr_util.h"
 #include "base/strings/string_piece.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/crypto/crypto_protocol.h"
@@ -47,7 +48,7 @@ class NET_EXPORT_PRIVATE QuicServerConfigProtobuf {
 
   const PrivateKey& key(size_t i) const {
     DCHECK_GT(keys_.size(), i);
-    return *keys_[i];
+    return *keys_[i].get();
   }
 
   std::string config() const { return config_; }
@@ -55,11 +56,11 @@ class NET_EXPORT_PRIVATE QuicServerConfigProtobuf {
   void set_config(base::StringPiece config) { config.CopyToString(&config_); }
 
   QuicServerConfigProtobuf::PrivateKey* add_key() {
-    keys_.push_back(new PrivateKey);
-    return keys_.back();
+    keys_.push_back(base::MakeUnique<PrivateKey>());
+    return keys_.back().get();
   }
 
-  void clear_key() { base::STLDeleteElements(&keys_); }
+  void clear_key() { keys_.clear(); }
 
   bool has_primary_time() const { return primary_time_ > 0; }
 
@@ -88,7 +89,7 @@ class NET_EXPORT_PRIVATE QuicServerConfigProtobuf {
   }
 
  private:
-  std::vector<PrivateKey*> keys_;
+  std::vector<std::unique_ptr<PrivateKey>> keys_;
 
   // config_ is a serialised config in QUIC wire format.
   std::string config_;
diff --git a/src/net/quic/core/crypto/crypto_utils.cc b/src/net/quic/core/crypto/crypto_utils.cc
index b382339..362971d 100644
--- a/src/net/quic/core/crypto/crypto_utils.cc
+++ b/src/net/quic/core/crypto/crypto_utils.cc
@@ -20,7 +20,6 @@
 #include "url/url_canon.h"
 
 using base::StringPiece;
-using std::numeric_limits;
 using std::string;
 
 namespace net {
@@ -191,7 +190,7 @@ bool CryptoUtils::ExportKeyingMaterial(StringPiece subkey_secret,
     }
   }
   // Create HKDF info input: null-terminated label + length-prefixed context
-  if (context.length() >= numeric_limits<uint32_t>::max()) {
+  if (context.length() >= std::numeric_limits<uint32_t>::max()) {
     LOG(ERROR) << "Context value longer than 2^32";
     return false;
   }
diff --git a/src/net/quic/core/crypto/crypto_utils.h b/src/net/quic/core/crypto/crypto_utils.h
index 60a4f06..782cb44 100644
--- a/src/net/quic/core/crypto/crypto_utils.h
+++ b/src/net/quic/core/crypto/crypto_utils.h
@@ -18,14 +18,12 @@
 #include "net/quic/core/crypto/crypto_handshake.h"
 #include "net/quic/core/crypto/crypto_handshake_message.h"
 #include "net/quic/core/crypto/crypto_protocol.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
 
-class QuicTime;
 class QuicRandom;
-struct QuicCryptoNegotiatedParameters;
 
 class NET_EXPORT_PRIVATE CryptoUtils {
  public:
diff --git a/src/net/quic/core/crypto/local_strike_register_client.cc b/src/net/quic/core/crypto/local_strike_register_client.cc
deleted file mode 100644
index bd70e0b..0000000
--- a/src/net/quic/core/crypto/local_strike_register_client.cc
+++ /dev/null
@@ -1,52 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "net/quic/core/crypto/local_strike_register_client.h"
-
-#include "net/quic/core/crypto/crypto_protocol.h"
-
-using base::StringPiece;
-using std::string;
-
-namespace net {
-
-LocalStrikeRegisterClient::LocalStrikeRegisterClient(
-    unsigned max_entries,
-    uint32_t current_time_external,
-    uint32_t window_secs,
-    const uint8_t orbit[8],
-    StrikeRegister::StartupType startup)
-    : strike_register_(max_entries,
-                       current_time_external,
-                       window_secs,
-                       orbit,
-                       startup) {}
-
-bool LocalStrikeRegisterClient::IsKnownOrbit(StringPiece orbit) const {
-  base::AutoLock lock(m_);
-  if (orbit.length() != kOrbitSize) {
-    return false;
-  }
-  return memcmp(orbit.data(), strike_register_.orbit(), kOrbitSize) == 0;
-}
-
-void LocalStrikeRegisterClient::VerifyNonceIsValidAndUnique(
-    StringPiece nonce,
-    QuicWallTime now,
-    ResultCallback* cb) {
-  InsertStatus nonce_error;
-  if (nonce.length() != kNonceSize) {
-    nonce_error = NONCE_INVALID_FAILURE;
-  } else {
-    base::AutoLock lock(m_);
-    nonce_error =
-        strike_register_.Insert(reinterpret_cast<const uint8_t*>(nonce.data()),
-                                static_cast<uint32_t>(now.ToUNIXSeconds()));
-  }
-
-  // m_ must not be held when the ResultCallback runs.
-  cb->Run((nonce_error == NONCE_OK), nonce_error);
-}
-
-}  // namespace net
diff --git a/src/net/quic/core/crypto/local_strike_register_client.h b/src/net/quic/core/crypto/local_strike_register_client.h
deleted file mode 100644
index f1d043c..0000000
--- a/src/net/quic/core/crypto/local_strike_register_client.h
+++ /dev/null
@@ -1,45 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef NET_QUIC_CRYPTO_LOCAL_STRIKE_REGISTER_CLIENT_H_
-#define NET_QUIC_CRYPTO_LOCAL_STRIKE_REGISTER_CLIENT_H_
-
-#include <stdint.h>
-
-#include "base/macros.h"
-#include "base/strings/string_piece.h"
-#include "base/synchronization/lock.h"
-#include "net/base/net_export.h"
-#include "net/quic/core/crypto/strike_register.h"
-#include "net/quic/core/crypto/strike_register_client.h"
-#include "net/quic/core/quic_time.h"
-
-namespace net {
-
-// StrikeRegisterClient implementation that wraps a local in-memory
-// strike register.
-class NET_EXPORT_PRIVATE LocalStrikeRegisterClient
-    : public StrikeRegisterClient {
- public:
-  LocalStrikeRegisterClient(unsigned max_entries,
-                            uint32_t current_time_external,
-                            uint32_t window_secs,
-                            const uint8_t orbit[8],
-                            StrikeRegister::StartupType startup);
-
-  bool IsKnownOrbit(base::StringPiece orbit) const override;
-  void VerifyNonceIsValidAndUnique(base::StringPiece nonce,
-                                   QuicWallTime now,
-                                   ResultCallback* cb) override;
-
- private:
-  mutable base::Lock m_;
-  StrikeRegister strike_register_;
-
-  DISALLOW_COPY_AND_ASSIGN(LocalStrikeRegisterClient);
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_CRYPTO_LOCAL_STRIKE_REGISTER_CLIENT_H_
diff --git a/src/net/quic/core/crypto/p256_key_exchange.cc b/src/net/quic/core/crypto/p256_key_exchange.cc
index 6e401a6..bfef924 100644
--- a/src/net/quic/core/crypto/p256_key_exchange.cc
+++ b/src/net/quic/core/crypto/p256_key_exchange.cc
@@ -4,19 +4,21 @@
 
 #include "net/quic/core/crypto/p256_key_exchange.h"
 
-#include <openssl/ec.h>
-#include <openssl/ecdh.h>
-#include <openssl/evp.h>
+#include <utility>
 
 #include "base/logging.h"
+#include "third_party/boringssl/src/include/openssl/ec.h"
+#include "third_party/boringssl/src/include/openssl/ecdh.h"
+#include "third_party/boringssl/src/include/openssl/evp.h"
 
 using base::StringPiece;
 using std::string;
 
 namespace net {
 
-P256KeyExchange::P256KeyExchange(EC_KEY* private_key, const uint8_t* public_key)
-    : private_key_(private_key) {
+P256KeyExchange::P256KeyExchange(bssl::UniquePtr<EC_KEY> private_key,
+                                 const uint8_t* public_key)
+    : private_key_(std::move(private_key)) {
   memcpy(public_key_, public_key, sizeof(public_key_));
 }
 
@@ -30,7 +32,7 @@ P256KeyExchange* P256KeyExchange::New(StringPiece key) {
   }
 
   const uint8_t* keyp = reinterpret_cast<const uint8_t*>(key.data());
-  crypto::ScopedEC_KEY private_key(
+  bssl::UniquePtr<EC_KEY> private_key(
       d2i_ECPrivateKey(nullptr, &keyp, key.size()));
   if (!private_key.get() || !EC_KEY_check_key(private_key.get())) {
     DVLOG(1) << "Private key is invalid.";
@@ -46,12 +48,12 @@ P256KeyExchange* P256KeyExchange::New(StringPiece key) {
     return nullptr;
   }
 
-  return new P256KeyExchange(private_key.release(), public_key);
+  return new P256KeyExchange(std::move(private_key), public_key);
 }
 
 // static
 string P256KeyExchange::NewPrivateKey() {
-  crypto::ScopedEC_KEY key(EC_KEY_new_by_curve_name(NID_X9_62_prime256v1));
+  bssl::UniquePtr<EC_KEY> key(EC_KEY_new_by_curve_name(NID_X9_62_prime256v1));
   if (!key.get() || !EC_KEY_generate_key(key.get())) {
     DVLOG(1) << "Can't generate a new private key.";
     return string();
@@ -84,7 +86,7 @@ bool P256KeyExchange::CalculateSharedKey(StringPiece peer_public_value,
     return false;
   }
 
-  crypto::ScopedEC_POINT point(
+  bssl::UniquePtr<EC_POINT> point(
       EC_POINT_new(EC_KEY_get0_group(private_key_.get())));
   if (!point ||
       !EC_POINT_oct2point(/* also test if point is on curve */
diff --git a/src/net/quic/core/crypto/p256_key_exchange.h b/src/net/quic/core/crypto/p256_key_exchange.h
index e6b32a2..059cd20 100644
--- a/src/net/quic/core/crypto/p256_key_exchange.h
+++ b/src/net/quic/core/crypto/p256_key_exchange.h
@@ -13,10 +13,9 @@
 #include "base/macros.h"
 #include "base/strings/string_piece.h"
 #include "crypto/openssl_util.h"
-#include "crypto/scoped_openssl_types.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/crypto/key_exchange.h"
-
+#include "third_party/boringssl/src/include/openssl/base.h"
 
 namespace net {
 
@@ -54,11 +53,12 @@ class NET_EXPORT_PRIVATE P256KeyExchange : public KeyExchange {
     kUncompressedECPointForm = 0x04,
   };
 
-  // P256KeyExchange takes ownership of |private_key|, and expects
-  // |public_key| consists of |kUncompressedP256PointBytes| bytes.
-  P256KeyExchange(EC_KEY* private_key, const uint8_t* public_key);
+  // P256KeyExchange wraps |private_key|, and expects |public_key| consists of
+  // |kUncompressedP256PointBytes| bytes.
+  P256KeyExchange(bssl::UniquePtr<EC_KEY> private_key,
+                  const uint8_t* public_key);
 
-  crypto::ScopedEC_KEY private_key_;
+  bssl::UniquePtr<EC_KEY> private_key_;
   // The public key stored as an uncompressed P-256 point.
   uint8_t public_key_[kUncompressedP256PointBytes];
 
diff --git a/src/net/quic/core/crypto/proof_source.h b/src/net/quic/core/crypto/proof_source.h
index 0160f22..c5990ba 100644
--- a/src/net/quic/core/crypto/proof_source.h
+++ b/src/net/quic/core/crypto/proof_source.h
@@ -11,12 +11,12 @@
 
 #include "base/memory/ref_counted.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/crypto/quic_crypto_proof.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 
 namespace net {
 
-class IPAddress;
-
 // ProofSource is an interface by which a QUIC server can obtain certificate
 // chains and signatures that prove its identity.
 class NET_EXPORT_PRIVATE ProofSource {
@@ -62,13 +62,11 @@ class NET_EXPORT_PRIVATE ProofSource {
     // |leaf_cert_sct| holds the signed timestamp (RFC6962) of the leaf cert.
     //
     // |details| holds a pointer to an object representing the statistics, if
-    // any,
-    // gathered during the operation of GetProof.  If no stats are available,
-    // this will be nullptr.
+    // any, gathered during the operation of GetProof.  If no stats are
+    // available, this will be nullptr.
     virtual void Run(bool ok,
                      const scoped_refptr<Chain>& chain,
-                     const std::string& signature,
-                     const std::string& leaf_cert_sct,
+                     const QuicCryptoProof& proof,
                      std::unique_ptr<Details> details) = 0;
 
    private:
@@ -95,14 +93,8 @@ class NET_EXPORT_PRIVATE ProofSource {
   // the ProofSource retains ownership of the contents of |out_chain|. The
   // expectation is that they will be cached forever.
   //
-  // For version before QUIC_VERSION_30, the signature values should be cached
-  // because |server_config| will be somewhat static. However, since they aren't
-  // bounded, the ProofSource may wish to evict entries from that cache, thus
-  // the caller takes ownership of |*out_signature|.
-  //
-  // For QUIC_VERSION_30 and later, the signature depends on |chlo_hash|
-  // which means that the signature can not be cached. The caller takes
-  // ownership of |*out_signature|.
+  // The signature depends on |chlo_hash| which means that the signature can not
+  // be cached. The caller takes ownership of |*out_signature|.
   //
   // |hostname| may be empty to signify that a default certificate should be
   // used.
@@ -111,24 +103,25 @@ class NET_EXPORT_PRIVATE ProofSource {
   // cert.
   //
   // This function may be called concurrently.
-  virtual bool GetProof(const IPAddress& server_ip,
+  virtual bool GetProof(const QuicSocketAddress& server_address,
                         const std::string& hostname,
                         const std::string& server_config,
                         QuicVersion quic_version,
                         base::StringPiece chlo_hash,
+                        const QuicTagVector& connection_options,
                         scoped_refptr<Chain>* out_chain,
-                        std::string* out_signature,
-                        std::string* out_leaf_cert_sct) = 0;
+                        QuicCryptoProof* out_proof) = 0;
 
   // Async version of GetProof with identical semantics, except that the results
   // are delivered to |callback|.  Callers should expect that |callback| might
   // be invoked synchronously.  The ProofSource takes ownership of |callback| in
   // any case.
-  virtual void GetProof(const IPAddress& server_ip,
+  virtual void GetProof(const QuicSocketAddress& server_address,
                         const std::string& hostname,
                         const std::string& server_config,
                         QuicVersion quic_version,
                         base::StringPiece chlo_hash,
+                        const QuicTagVector& connection_options,
                         std::unique_ptr<Callback> callback) = 0;
 };
 
diff --git a/src/net/quic/core/crypto/proof_verifier.h b/src/net/quic/core/crypto/proof_verifier.h
index c87b5c8..9c224da 100644
--- a/src/net/quic/core/crypto/proof_verifier.h
+++ b/src/net/quic/core/crypto/proof_verifier.h
@@ -10,7 +10,7 @@
 #include <vector>
 
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_types.h"
 
 namespace net {
diff --git a/src/net/quic/core/crypto/quic_compressed_certs_cache.h b/src/net/quic/core/crypto/quic_compressed_certs_cache.h
index e663469..84989f7 100644
--- a/src/net/quic/core/crypto/quic_compressed_certs_cache.h
+++ b/src/net/quic/core/crypto/quic_compressed_certs_cache.h
@@ -10,6 +10,7 @@
 
 #include "base/containers/mru_cache.h"
 #include "base/memory/ref_counted.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/proof_source.h"
 
 namespace net {
diff --git a/src/net/quic/core/crypto/quic_crypto_client_config.cc b/src/net/quic/core/crypto/quic_crypto_client_config.cc
index e1fd5f4..a94cbf8 100644
--- a/src/net/quic/core/crypto/quic_crypto_client_config.cc
+++ b/src/net/quic/core/crypto/quic_crypto_client_config.cc
@@ -4,8 +4,10 @@
 
 #include "net/quic/core/crypto/quic_crypto_client_config.h"
 
+#include <algorithm>
 #include <memory>
 
+#include "base/memory/ptr_util.h"
 #include "base/metrics/histogram_macros.h"
 #include "base/stl_util.h"
 #include "base/strings/string_util.h"
@@ -26,10 +28,7 @@
 #include "net/quic/core/quic_utils.h"
 
 using base::StringPiece;
-using std::map;
 using std::string;
-using std::queue;
-using std::vector;
 
 namespace net {
 
@@ -61,9 +60,7 @@ QuicCryptoClientConfig::QuicCryptoClientConfig(
   SetDefaults();
 }
 
-QuicCryptoClientConfig::~QuicCryptoClientConfig() {
-  base::STLDeleteValues(&cached_states_);
-}
+QuicCryptoClientConfig::~QuicCryptoClientConfig() {}
 
 QuicCryptoClientConfig::CachedState::CachedState()
     : server_config_valid_(false),
@@ -91,17 +88,17 @@ bool QuicCryptoClientConfig::CachedState::IsComplete(QuicWallTime now) const {
     return false;
   }
 
-  if (now.IsAfter(expiration_time_)) {
-    UMA_HISTOGRAM_CUSTOM_TIMES(
-        "Net.QuicClientHelloServerConfig.InvalidDuration",
-        base::TimeDelta::FromSeconds(now.ToUNIXSeconds() -
-                                     expiration_time_.ToUNIXSeconds()),
-        base::TimeDelta::FromMinutes(1), base::TimeDelta::FromDays(20), 50);
-    RecordInchoateClientHelloReason(SERVER_CONFIG_EXPIRED);
-    return false;
+  if (now.IsBefore(expiration_time_)) {
+    return true;
   }
 
-  return true;
+  UMA_HISTOGRAM_CUSTOM_TIMES(
+      "Net.QuicClientHelloServerConfig.InvalidDuration",
+      base::TimeDelta::FromSeconds(now.ToUNIXSeconds() -
+                                   expiration_time_.ToUNIXSeconds()),
+      base::TimeDelta::FromMinutes(1), base::TimeDelta::FromDays(20), 50);
+  RecordInchoateClientHelloReason(SERVER_CONFIG_EXPIRED);
+  return false;
 }
 
 bool QuicCryptoClientConfig::CachedState::IsEmpty() const {
@@ -192,14 +189,15 @@ void QuicCryptoClientConfig::CachedState::InvalidateServerConfig() {
   server_config_.clear();
   scfg_.reset();
   SetProofInvalid();
-  queue<QuicConnectionId> empty_queue;
+  std::queue<QuicConnectionId> empty_queue;
   swap(server_designated_connection_ids_, empty_queue);
 }
 
-void QuicCryptoClientConfig::CachedState::SetProof(const vector<string>& certs,
-                                                   StringPiece cert_sct,
-                                                   StringPiece chlo_hash,
-                                                   StringPiece signature) {
+void QuicCryptoClientConfig::CachedState::SetProof(
+    const std::vector<string>& certs,
+    StringPiece cert_sct,
+    StringPiece chlo_hash,
+    StringPiece signature) {
   bool has_changed = signature != server_config_sig_ ||
                      chlo_hash != chlo_hash_ || certs_.size() != certs.size();
 
@@ -235,7 +233,7 @@ void QuicCryptoClientConfig::CachedState::Clear() {
   proof_verify_details_.reset();
   scfg_.reset();
   ++generation_counter_;
-  queue<QuicConnectionId> empty_queue;
+  std::queue<QuicConnectionId> empty_queue;
   swap(server_designated_connection_ids_, empty_queue);
 }
 
@@ -259,8 +257,8 @@ void QuicCryptoClientConfig::CachedState::SetProofInvalid() {
 bool QuicCryptoClientConfig::CachedState::Initialize(
     StringPiece server_config,
     StringPiece source_address_token,
-    const vector<string>& certs,
-    StringPiece cert_sct,
+    const std::vector<string>& certs,
+    const string& cert_sct,
     StringPiece chlo_hash,
     StringPiece signature,
     QuicWallTime now,
@@ -281,11 +279,11 @@ bool QuicCryptoClientConfig::CachedState::Initialize(
     return false;
   }
 
+  chlo_hash.CopyToString(&chlo_hash_);
   signature.CopyToString(&server_config_sig_);
   source_address_token.CopyToString(&source_address_token_);
-  cert_sct.CopyToString(&cert_sct_);
-  chlo_hash.CopyToString(&chlo_hash_);
   certs_ = certs;
+  cert_sct_ = cert_sct;
   return true;
 }
 
@@ -298,7 +296,7 @@ const string& QuicCryptoClientConfig::CachedState::source_address_token()
   return source_address_token_;
 }
 
-const vector<string>& QuicCryptoClientConfig::CachedState::certs() const {
+const std::vector<string>& QuicCryptoClientConfig::CachedState::certs() const {
   return certs_;
 }
 
@@ -393,13 +391,13 @@ void QuicCryptoClientConfig::SetDefaults() {
 
 QuicCryptoClientConfig::CachedState* QuicCryptoClientConfig::LookupOrCreate(
     const QuicServerId& server_id) {
-  CachedStateMap::const_iterator it = cached_states_.find(server_id);
+  auto it = cached_states_.find(server_id);
   if (it != cached_states_.end()) {
-    return it->second;
+    return it->second.get();
   }
 
   CachedState* cached = new CachedState;
-  cached_states_.insert(std::make_pair(server_id, cached));
+  cached_states_.insert(std::make_pair(server_id, base::WrapUnique(cached)));
   bool cache_populated = PopulateFromCanonicalConfig(server_id, cached);
   UMA_HISTOGRAM_BOOLEAN(
       "Net.QuicCryptoClientConfig.PopulatedFromCanonicalConfig",
@@ -408,8 +406,7 @@ QuicCryptoClientConfig::CachedState* QuicCryptoClientConfig::LookupOrCreate(
 }
 
 void QuicCryptoClientConfig::ClearCachedStates(const ServerIdFilter& filter) {
-  for (CachedStateMap::const_iterator it = cached_states_.begin();
-       it != cached_states_.end(); ++it) {
+  for (auto it = cached_states_.begin(); it != cached_states_.end(); ++it) {
     if (filter.Matches(it->first))
       it->second->Clear();
   }
@@ -421,7 +418,7 @@ void QuicCryptoClientConfig::FillInchoateClientHello(
     const CachedState* cached,
     QuicRandom* rand,
     bool demand_x509_proof,
-    QuicCryptoNegotiatedParameters* out_params,
+    scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
     CryptoHandshakeMessage* out) const {
   out->set_tag(kCHLO);
   // TODO(rch): Remove this when we remove:
@@ -469,17 +466,17 @@ void QuicCryptoClientConfig::FillInchoateClientHello(
 
   out->SetStringPiece(kCertificateSCTTag, "");
 
-  const vector<string>& certs = cached->certs();
+  const std::vector<string>& certs = cached->certs();
   // We save |certs| in the QuicCryptoNegotiatedParameters so that, if the
   // client config is being used for multiple connections, another connection
   // doesn't update the cached certificates and cause us to be unable to
   // process the server's compressed certificate chain.
   out_params->cached_certs = certs;
   if (!certs.empty()) {
-    vector<uint64_t> hashes;
+    std::vector<uint64_t> hashes;
     hashes.reserve(certs.size());
-    for (vector<string>::const_iterator i = certs.begin(); i != certs.end();
-         ++i) {
+    for (std::vector<string>::const_iterator i = certs.begin();
+         i != certs.end(); ++i) {
       hashes.push_back(QuicUtils::FNV1a_64_Hash(i->data(), i->size()));
     }
     out->SetVector(kCCRT, hashes);
@@ -489,13 +486,12 @@ void QuicCryptoClientConfig::FillInchoateClientHello(
 QuicErrorCode QuicCryptoClientConfig::FillClientHello(
     const QuicServerId& server_id,
     QuicConnectionId connection_id,
-    const QuicVersion actual_version,
     const QuicVersion preferred_version,
     const CachedState* cached,
     QuicWallTime now,
     QuicRandom* rand,
     const ChannelIDKey* channel_id_key,
-    QuicCryptoNegotiatedParameters* out_params,
+    scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
     CryptoHandshakeMessage* out,
     string* error_details) const {
   DCHECK(error_details != nullptr);
@@ -537,30 +533,26 @@ QuicErrorCode QuicCryptoClientConfig::FillClientHello(
   // Key exchange: the client does more work than the server, so favor the
   // client's preference.
   size_t key_exchange_index;
-  if (!QuicUtils::FindMutualTag(aead, their_aeads, num_their_aeads,
-                                QuicUtils::LOCAL_PRIORITY, &out_params->aead,
-                                nullptr) ||
-      !QuicUtils::FindMutualTag(
-          kexs, their_key_exchanges, num_their_key_exchanges,
-          QuicUtils::LOCAL_PRIORITY, &out_params->key_exchange,
-          &key_exchange_index)) {
+  if (!FindMutualQuicTag(aead, their_aeads, num_their_aeads, &out_params->aead,
+                         nullptr) ||
+      !FindMutualQuicTag(kexs, their_key_exchanges, num_their_key_exchanges,
+                         &out_params->key_exchange, &key_exchange_index)) {
     *error_details = "Unsupported AEAD or KEXS";
     return QUIC_CRYPTO_NO_SUPPORT;
   }
   out->SetVector(kAEAD, QuicTagVector{out_params->aead});
   out->SetVector(kKEXS, QuicTagVector{out_params->key_exchange});
 
-  if (!tb_key_params.empty()) {
+  if (!tb_key_params.empty() &&
+      server_id.privacy_mode() == PRIVACY_MODE_DISABLED) {
     const QuicTag* their_tbkps;
     size_t num_their_tbkps;
     switch (scfg->GetTaglist(kTBKP, &their_tbkps, &num_their_tbkps)) {
       case QUIC_CRYPTO_MESSAGE_PARAMETER_NOT_FOUND:
         break;
       case QUIC_NO_ERROR:
-        if (QuicUtils::FindMutualTag(tb_key_params, their_tbkps,
-                                     num_their_tbkps, QuicUtils::LOCAL_PRIORITY,
-                                     &out_params->token_binding_key_param,
-                                     nullptr)) {
+        if (FindMutualQuicTag(tb_key_params, their_tbkps, num_their_tbkps,
+                              &out_params->token_binding_key_param, nullptr)) {
           out->SetVector(kTBKP,
                          QuicTagVector{out_params->token_binding_key_param});
         }
@@ -612,7 +604,7 @@ QuicErrorCode QuicCryptoClientConfig::FillClientHello(
   }
   out->SetStringPiece(kPUBS, out_params->client_key_exchange->public_value());
 
-  const vector<string>& certs = cached->certs();
+  const std::vector<string>& certs = cached->certs();
   if (certs.empty()) {
     *error_details = "No certs to calculate XLCT";
     return QUIC_CRYPTO_INTERNAL_ERROR;
@@ -703,17 +695,11 @@ QuicErrorCode QuicCryptoClientConfig::FillClientHello(
 
   string* subkey_secret = &out_params->initial_subkey_secret;
 
-  // Only perform key diversification for QUIC versions 33 and later.
-  // TODO(rch): remove the |actual_version| argument to this method when
-  // QUIC_VERSION_32 is removed.
-  CryptoUtils::Diversification diversification =
-      actual_version > QUIC_VERSION_32 ? CryptoUtils::Diversification::Pending()
-                                       : CryptoUtils::Diversification::Never();
-  if (!CryptoUtils::DeriveKeys(out_params->initial_premaster_secret,
-                               out_params->aead, out_params->client_nonce,
-                               out_params->server_nonce, hkdf_input,
-                               Perspective::IS_CLIENT, diversification,
-                               &out_params->initial_crypters, subkey_secret)) {
+  if (!CryptoUtils::DeriveKeys(
+          out_params->initial_premaster_secret, out_params->aead,
+          out_params->client_nonce, out_params->server_nonce, hkdf_input,
+          Perspective::IS_CLIENT, CryptoUtils::Diversification::Pending(),
+          &out_params->initial_crypters, subkey_secret)) {
     *error_details = "Symmetric key setup failed";
     return QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED;
   }
@@ -726,7 +712,7 @@ QuicErrorCode QuicCryptoClientConfig::CacheNewServerConfig(
     QuicWallTime now,
     QuicVersion version,
     StringPiece chlo_hash,
-    const vector<string>& cached_certs,
+    const std::vector<string>& cached_certs,
     CachedState* cached,
     string* error_details) {
   DCHECK(error_details != nullptr);
@@ -740,7 +726,9 @@ QuicErrorCode QuicCryptoClientConfig::CacheNewServerConfig(
   QuicWallTime expiration_time = QuicWallTime::Zero();
   uint64_t expiry_seconds;
   if (message.GetUint64(kSTTL, &expiry_seconds) == QUIC_NO_ERROR) {
-    expiration_time = now.Add(QuicTime::Delta::FromSeconds(expiry_seconds));
+    // Only cache configs for a maximum of 1 week.
+    expiration_time = now.Add(QuicTime::Delta::FromSeconds(
+        std::min(expiry_seconds, kNumSecondsPerWeek)));
   }
 
   CachedState::ServerConfigState state =
@@ -763,7 +751,7 @@ QuicErrorCode QuicCryptoClientConfig::CacheNewServerConfig(
   bool has_proof = message.GetStringPiece(kPROF, &proof);
   bool has_cert = message.GetStringPiece(kCertificateTag, &cert_bytes);
   if (has_proof && has_cert) {
-    vector<string> certs;
+    std::vector<string> certs;
     if (!CertCompressor::DecompressChain(cert_bytes, cached_certs,
                                          common_cert_sets, &certs)) {
       *error_details = "Certificate data invalid";
@@ -797,7 +785,7 @@ QuicErrorCode QuicCryptoClientConfig::ProcessRejection(
     const QuicVersion version,
     StringPiece chlo_hash,
     CachedState* cached,
-    QuicCryptoNegotiatedParameters* out_params,
+    scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
     string* error_details) {
   DCHECK(error_details != nullptr);
 
@@ -840,7 +828,7 @@ QuicErrorCode QuicCryptoClientConfig::ProcessServerHello(
     QuicVersion version,
     const QuicVersionVector& negotiated_versions,
     CachedState* cached,
-    QuicCryptoNegotiatedParameters* out_params,
+    scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
     string* error_details) {
   DCHECK(error_details != nullptr);
 
@@ -903,7 +891,7 @@ QuicErrorCode QuicCryptoClientConfig::ProcessServerConfigUpdate(
     const QuicVersion version,
     StringPiece chlo_hash,
     CachedState* cached,
-    QuicCryptoNegotiatedParameters* out_params,
+    scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
     string* error_details) {
   DCHECK(error_details != nullptr);
 
@@ -982,7 +970,7 @@ bool QuicCryptoClientConfig::PopulateFromCanonicalConfig(
 
   const QuicServerId& canonical_server_id =
       canonical_server_map_[suffix_server_id];
-  CachedState* canonical_state = cached_states_[canonical_server_id];
+  CachedState* canonical_state = cached_states_[canonical_server_id].get();
   if (!canonical_state->proof_valid()) {
     return false;
   }
diff --git a/src/net/quic/core/crypto/quic_crypto_client_config.h b/src/net/quic/core/crypto/quic_crypto_client_config.h
index 36437c6..24cc492 100644
--- a/src/net/quic/core/crypto/quic_crypto_client_config.h
+++ b/src/net/quic/core/crypto/quic_crypto_client_config.h
@@ -17,7 +17,7 @@
 #include "base/strings/string_piece.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/crypto/crypto_handshake.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_server_id.h"
 
 namespace net {
@@ -160,7 +160,7 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
     bool Initialize(base::StringPiece server_config,
                     base::StringPiece source_address_token,
                     const std::vector<std::string>& certs,
-                    base::StringPiece cert_sct,
+                    const std::string& cert_sct,
                     base::StringPiece chlo_hash,
                     base::StringPiece signature,
                     QuicWallTime now,
@@ -226,13 +226,14 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
   // server to detect downgrade attacks.  If |demand_x509_proof| is true,
   // then |out| will include an X509 proof demand, and the associated
   // certificate related fields.
-  void FillInchoateClientHello(const QuicServerId& server_id,
-                               const QuicVersion preferred_version,
-                               const CachedState* cached,
-                               QuicRandom* rand,
-                               bool demand_x509_proof,
-                               QuicCryptoNegotiatedParameters* out_params,
-                               CryptoHandshakeMessage* out) const;
+  void FillInchoateClientHello(
+      const QuicServerId& server_id,
+      const QuicVersion preferred_version,
+      const CachedState* cached,
+      QuicRandom* rand,
+      bool demand_x509_proof,
+      scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
+      CryptoHandshakeMessage* out) const;
 
   // FillClientHello sets |out| to be a CHLO message based on the configuration
   // of this object. This object must have cached enough information about
@@ -248,17 +249,17 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
   // If |channel_id_key| is not null, it is used to sign a secret value derived
   // from the client and server's keys, and the Channel ID public key and the
   // signature are placed in the CETV value of the CHLO.
-  QuicErrorCode FillClientHello(const QuicServerId& server_id,
-                                QuicConnectionId connection_id,
-                                const QuicVersion actual_version,
-                                const QuicVersion preferred_version,
-                                const CachedState* cached,
-                                QuicWallTime now,
-                                QuicRandom* rand,
-                                const ChannelIDKey* channel_id_key,
-                                QuicCryptoNegotiatedParameters* out_params,
-                                CryptoHandshakeMessage* out,
-                                std::string* error_details) const;
+  QuicErrorCode FillClientHello(
+      const QuicServerId& server_id,
+      QuicConnectionId connection_id,
+      const QuicVersion preferred_version,
+      const CachedState* cached,
+      QuicWallTime now,
+      QuicRandom* rand,
+      const ChannelIDKey* channel_id_key,
+      scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
+      CryptoHandshakeMessage* out,
+      std::string* error_details) const;
 
   // ProcessRejection processes a REJ message from a server and updates the
   // cached information about that server. After this, |IsComplete| may return
@@ -266,13 +267,14 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
   // about a future handshake (i.e. an nonce value from the server), then it
   // will be saved in |out_params|. |now| is used to judge whether the server
   // config in the rejection message has expired.
-  QuicErrorCode ProcessRejection(const CryptoHandshakeMessage& rej,
-                                 QuicWallTime now,
-                                 QuicVersion version,
-                                 base::StringPiece chlo_hash,
-                                 CachedState* cached,
-                                 QuicCryptoNegotiatedParameters* out_params,
-                                 std::string* error_details);
+  QuicErrorCode ProcessRejection(
+      const CryptoHandshakeMessage& rej,
+      QuicWallTime now,
+      QuicVersion version,
+      base::StringPiece chlo_hash,
+      CachedState* cached,
+      scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
+      std::string* error_details);
 
   // ProcessServerHello processes the message in |server_hello|, updates the
   // cached information about that server, writes the negotiated parameters to
@@ -283,13 +285,14 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
   // present in a version negotiation packet previously recevied from the
   // server. The contents of this list will be compared against the list of
   // versions provided in the VER tag of the server hello.
-  QuicErrorCode ProcessServerHello(const CryptoHandshakeMessage& server_hello,
-                                   QuicConnectionId connection_id,
-                                   QuicVersion version,
-                                   const QuicVersionVector& negotiated_versions,
-                                   CachedState* cached,
-                                   QuicCryptoNegotiatedParameters* out_params,
-                                   std::string* error_details);
+  QuicErrorCode ProcessServerHello(
+      const CryptoHandshakeMessage& server_hello,
+      QuicConnectionId connection_id,
+      QuicVersion version,
+      const QuicVersionVector& negotiated_versions,
+      CachedState* cached,
+      scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
+      std::string* error_details);
 
   // Processes the message in |server_update|, updating the cached source
   // address token, and server config.
@@ -302,7 +305,7 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
       const QuicVersion version,
       base::StringPiece chlo_hash,
       CachedState* cached,
-      QuicCryptoNegotiatedParameters* out_params,
+      scoped_refptr<QuicCryptoNegotiatedParameters> out_params,
       std::string* error_details);
 
   ProofVerifier* proof_verifier() const;
@@ -339,8 +342,6 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
   }
 
  private:
-  typedef std::map<QuicServerId, CachedState*> CachedStateMap;
-
   // Sets the members to reasonable, default values.
   void SetDefaults();
 
@@ -366,7 +367,7 @@ class NET_EXPORT_PRIVATE QuicCryptoClientConfig : public QuicCryptoConfig {
 
   // cached_states_ maps from the server_id to the cached information about
   // that server.
-  CachedStateMap cached_states_;
+  std::map<QuicServerId, std::unique_ptr<CachedState>> cached_states_;
 
   // Contains a map of servers which could share the same server config. Map
   // from a canonical host suffix/port/scheme to a representative server with
diff --git a/src/net/quic/core/crypto/quic_crypto_server_config.cc b/src/net/quic/core/crypto/quic_crypto_server_config.cc
index 695223a..fc4c8ad 100644
--- a/src/net/quic/core/crypto/quic_crypto_server_config.cc
+++ b/src/net/quic/core/crypto/quic_crypto_server_config.cc
@@ -11,7 +11,6 @@
 
 #include "base/macros.h"
 #include "base/memory/ref_counted.h"
-#include "base/stl_util.h"
 #include "crypto/hkdf.h"
 #include "crypto/secure_hash.h"
 #include "net/base/ip_address.h"
@@ -27,28 +26,22 @@
 #include "net/quic/core/crypto/curve25519_key_exchange.h"
 #include "net/quic/core/crypto/ephemeral_key_source.h"
 #include "net/quic/core/crypto/key_exchange.h"
-#include "net/quic/core/crypto/local_strike_register_client.h"
 #include "net/quic/core/crypto/p256_key_exchange.h"
 #include "net/quic/core/crypto/proof_source.h"
 #include "net/quic/core/crypto/quic_decrypter.h"
 #include "net/quic/core/crypto/quic_encrypter.h"
 #include "net/quic/core/crypto/quic_random.h"
-#include "net/quic/core/crypto/strike_register.h"
-#include "net/quic/core/crypto/strike_register_client.h"
 #include "net/quic/core/proto/source_address_token.pb.h"
 #include "net/quic/core/quic_bug_tracker.h"
-#include "net/quic/core/quic_clock.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_socket_address_coder.h"
 #include "net/quic/core/quic_utils.h"
+#include "net/quic/platform/api/quic_clock.h"
 
 using base::StringPiece;
 using crypto::SecureHash;
-using std::map;
-using std::sort;
 using std::string;
-using std::vector;
 
 namespace net {
 
@@ -70,23 +63,16 @@ string DeriveSourceAddressTokenKey(StringPiece source_address_token_secret) {
   return hkdf.server_write_key().as_string();
 }
 
-IPAddress DualstackIPAddress(const IPAddress& ip) {
-  if (ip.IsIPv4()) {
-    return ConvertIPv4ToIPv4MappedIPv6(ip);
-  }
-  return ip;
-}
-
 }  // namespace
 
 class ValidateClientHelloHelper {
  public:
-  // Note: stores pointers to unique_ptrs, and std::moves the unique_ptrs when
+  // Note: stores a pointer to a unique_ptr, and std::moves the unique_ptr when
   // ValidationComplete is called.
   ValidateClientHelloHelper(
-      std::unique_ptr<ValidateClientHelloResultCallback::Result>* result,
+      scoped_refptr<ValidateClientHelloResultCallback::Result> result,
       std::unique_ptr<ValidateClientHelloResultCallback>* done_cb)
-      : result_(result), done_cb_(done_cb) {}
+      : result_(std::move(result)), done_cb_(done_cb) {}
 
   ~ValidateClientHelloHelper() {
     QUIC_BUG_IF(done_cb_ != nullptr)
@@ -97,9 +83,9 @@ class ValidateClientHelloHelper {
       QuicErrorCode error_code,
       const char* error_details,
       std::unique_ptr<ProofSource::Details> proof_source_details) {
-    (*result_)->error_code = error_code;
-    (*result_)->error_details = error_details;
-    (*done_cb_)->Run(std::move(*result_), std::move(proof_source_details));
+    result_->error_code = error_code;
+    result_->error_details = error_details;
+    (*done_cb_)->Run(std::move(result_), std::move(proof_source_details));
     DetachCallback();
   }
 
@@ -109,75 +95,16 @@ class ValidateClientHelloHelper {
   }
 
  private:
-  std::unique_ptr<ValidateClientHelloResultCallback::Result>* result_;
+  scoped_refptr<ValidateClientHelloResultCallback::Result> result_;
   std::unique_ptr<ValidateClientHelloResultCallback>* done_cb_;
 
   DISALLOW_COPY_AND_ASSIGN(ValidateClientHelloHelper);
 };
 
-class VerifyNonceIsValidAndUniqueCallback
-    : public StrikeRegisterClient::ResultCallback {
- public:
-  VerifyNonceIsValidAndUniqueCallback(
-      std::unique_ptr<ValidateClientHelloResultCallback::Result> result,
-      std::unique_ptr<ProofSource::Details> proof_source_details,
-      std::unique_ptr<ValidateClientHelloResultCallback> done_cb)
-      : result_(std::move(result)),
-        proof_source_details_(std::move(proof_source_details)),
-        done_cb_(std::move(done_cb)) {}
-
- protected:
-  void RunImpl(bool nonce_is_valid_and_unique,
-               InsertStatus nonce_error) override {
-    DVLOG(1) << "Using client nonce, unique: " << nonce_is_valid_and_unique
-             << " nonce_error: " << nonce_error;
-    if (!nonce_is_valid_and_unique) {
-      HandshakeFailureReason client_nonce_error;
-      switch (nonce_error) {
-        case NONCE_INVALID_FAILURE:
-          client_nonce_error = CLIENT_NONCE_INVALID_FAILURE;
-          break;
-        case NONCE_NOT_UNIQUE_FAILURE:
-          client_nonce_error = CLIENT_NONCE_NOT_UNIQUE_FAILURE;
-          break;
-        case NONCE_INVALID_ORBIT_FAILURE:
-          client_nonce_error = CLIENT_NONCE_INVALID_ORBIT_FAILURE;
-          break;
-        case NONCE_INVALID_TIME_FAILURE:
-          client_nonce_error = CLIENT_NONCE_INVALID_TIME_FAILURE;
-          break;
-        case STRIKE_REGISTER_TIMEOUT:
-          client_nonce_error = CLIENT_NONCE_STRIKE_REGISTER_TIMEOUT;
-          break;
-        case STRIKE_REGISTER_FAILURE:
-          client_nonce_error = CLIENT_NONCE_STRIKE_REGISTER_FAILURE;
-          break;
-        case NONCE_UNKNOWN_FAILURE:
-          client_nonce_error = CLIENT_NONCE_UNKNOWN_FAILURE;
-          break;
-        case NONCE_OK:
-        default:
-          QUIC_BUG << "Unexpected client nonce error: " << nonce_error;
-          client_nonce_error = CLIENT_NONCE_UNKNOWN_FAILURE;
-          break;
-      }
-      result_->info.reject_reasons.push_back(client_nonce_error);
-    }
-    done_cb_->Run(std::move(result_), std::move(proof_source_details_));
-  }
-
- private:
-  std::unique_ptr<ValidateClientHelloResultCallback::Result> result_;
-  std::unique_ptr<ProofSource::Details> proof_source_details_;
-  std::unique_ptr<ValidateClientHelloResultCallback> done_cb_;
-
-  DISALLOW_COPY_AND_ASSIGN(VerifyNonceIsValidAndUniqueCallback);
-};
-
 // static
 const char QuicCryptoServerConfig::TESTING[] = "secret string for testing";
 
-ClientHelloInfo::ClientHelloInfo(const IPAddress& in_client_ip,
+ClientHelloInfo::ClientHelloInfo(const QuicIpAddress& in_client_ip,
                                  QuicWallTime in_now)
     : client_ip(in_client_ip), now(in_now), valid_source_address_token(false) {}
 
@@ -191,7 +118,7 @@ PrimaryConfigChangedCallback::~PrimaryConfigChangedCallback() {}
 
 ValidateClientHelloResultCallback::Result::Result(
     const CryptoHandshakeMessage& in_client_hello,
-    IPAddress in_client_ip,
+    QuicIpAddress in_client_ip,
     QuicWallTime in_now)
     : client_hello(in_client_hello),
       info(in_client_ip, in_now),
@@ -203,6 +130,10 @@ ValidateClientHelloResultCallback::ValidateClientHelloResultCallback() {}
 
 ValidateClientHelloResultCallback::~ValidateClientHelloResultCallback() {}
 
+ProcessClientHelloResultCallback::ProcessClientHelloResultCallback() {}
+
+ProcessClientHelloResultCallback::~ProcessClientHelloResultCallback() {}
+
 QuicCryptoServerConfig::ConfigOptions::ConfigOptions()
     : expiry_time(QuicWallTime::Zero()),
       channel_id_enabled(false),
@@ -222,16 +153,11 @@ QuicCryptoServerConfig::QuicCryptoServerConfig(
       configs_lock_(),
       primary_config_(nullptr),
       next_config_promotion_time_(QuicWallTime::Zero()),
-      server_nonce_strike_register_lock_(),
       proof_source_(std::move(proof_source)),
-      strike_register_no_startup_period_(false),
-      strike_register_max_entries_(1 << 10),
-      strike_register_window_secs_(600),
       source_address_token_future_secs_(3600),
       source_address_token_lifetime_secs_(86400),
-      server_nonce_strike_register_max_entries_(1 << 10),
-      server_nonce_strike_register_window_secs_(120),
-      enable_serving_sct_(false) {
+      enable_serving_sct_(false),
+      rejection_observer_(nullptr) {
   DCHECK(proof_source_.get());
   source_address_token_boxer_.SetKeys(
       {DeriveSourceAddressTokenKey(source_address_token_secret)});
@@ -252,10 +178,10 @@ QuicCryptoServerConfig::~QuicCryptoServerConfig() {
 }
 
 // static
-QuicServerConfigProtobuf* QuicCryptoServerConfig::GenerateConfig(
-    QuicRandom* rand,
-    const QuicClock* clock,
-    const ConfigOptions& options) {
+std::unique_ptr<QuicServerConfigProtobuf>
+QuicCryptoServerConfig::GenerateConfig(QuicRandom* rand,
+                                       const QuicClock* clock,
+                                       const ConfigOptions& options) {
   CryptoHandshakeMessage msg;
 
   const string curve25519_private_key =
@@ -346,7 +272,7 @@ QuicServerConfigProtobuf* QuicCryptoServerConfig::GenerateConfig(
   }
   // Don't put new tags below this point. The SCID generation should hash over
   // everything but itself and so extra tags should be added prior to the
-  // preceeding if block.
+  // preceding if block.
 
   std::unique_ptr<QuicData> serialized(
       CryptoFramer::ConstructHandshakeMessage(msg));
@@ -364,11 +290,11 @@ QuicServerConfigProtobuf* QuicCryptoServerConfig::GenerateConfig(
     p256_key->set_private_key(p256_private_key);
   }
 
-  return config.release();
+  return config;
 }
 
 CryptoHandshakeMessage* QuicCryptoServerConfig::AddConfig(
-    QuicServerConfigProtobuf* protobuf,
+    std::unique_ptr<QuicServerConfigProtobuf> protobuf,
     const QuicWallTime now) {
   std::unique_ptr<CryptoHandshakeMessage> msg(
       CryptoFramer::ParseMessage(protobuf->config()));
@@ -406,20 +332,17 @@ CryptoHandshakeMessage* QuicCryptoServerConfig::AddDefaultConfig(
     QuicRandom* rand,
     const QuicClock* clock,
     const ConfigOptions& options) {
-  std::unique_ptr<QuicServerConfigProtobuf> config(
-      GenerateConfig(rand, clock, options));
-  return AddConfig(config.get(), clock->WallNow());
+  return AddConfig(GenerateConfig(rand, clock, options), clock->WallNow());
 }
 
 bool QuicCryptoServerConfig::SetConfigs(
-    const vector<QuicServerConfigProtobuf*>& protobufs,
+    const std::vector<std::unique_ptr<QuicServerConfigProtobuf>>& protobufs,
     const QuicWallTime now) {
-  vector<scoped_refptr<Config>> parsed_configs;
+  std::vector<scoped_refptr<Config>> parsed_configs;
   bool ok = true;
 
-  for (vector<QuicServerConfigProtobuf*>::const_iterator i = protobufs.begin();
-       i != protobufs.end(); ++i) {
-    scoped_refptr<Config> config(ParseConfigProtobuf(*i));
+  for (auto& protobuf : protobufs) {
+    scoped_refptr<Config> config(ParseConfigProtobuf(protobuf));
     if (!config.get()) {
       ok = false;
       break;
@@ -441,7 +364,7 @@ bool QuicCryptoServerConfig::SetConfigs(
     base::AutoLock locked(configs_lock_);
     ConfigMap new_configs;
 
-    for (vector<scoped_refptr<Config>>::const_iterator i =
+    for (std::vector<scoped_refptr<Config>>::const_iterator i =
              parsed_configs.begin();
          i != parsed_configs.end(); ++i) {
       scoped_refptr<Config> config = *i;
@@ -481,11 +404,11 @@ bool QuicCryptoServerConfig::SetConfigs(
 }
 
 void QuicCryptoServerConfig::SetSourceAddressTokenKeys(
-    const vector<string>& keys) {
+    const std::vector<string>& keys) {
   source_address_token_boxer_.SetKeys(keys);
 }
 
-void QuicCryptoServerConfig::GetConfigIds(vector<string>* scids) const {
+void QuicCryptoServerConfig::GetConfigIds(std::vector<string>* scids) const {
   base::AutoLock locked(configs_lock_);
   for (ConfigMap::const_iterator it = configs_.begin(); it != configs_.end();
        ++it) {
@@ -495,22 +418,21 @@ void QuicCryptoServerConfig::GetConfigIds(vector<string>* scids) const {
 
 void QuicCryptoServerConfig::ValidateClientHello(
     const CryptoHandshakeMessage& client_hello,
-    const IPAddress& client_ip,
-    const IPAddress& server_ip,
+    const QuicIpAddress& client_ip,
+    const QuicSocketAddress& server_address,
     QuicVersion version,
     const QuicClock* clock,
-    QuicCryptoProof* crypto_proof,
+    scoped_refptr<QuicSignedServerConfig> signed_config,
     std::unique_ptr<ValidateClientHelloResultCallback> done_cb) const {
   const QuicWallTime now(clock->WallNow());
 
-  std::unique_ptr<ValidateClientHelloResultCallback::Result> result(
+  scoped_refptr<ValidateClientHelloResultCallback::Result> result(
       new ValidateClientHelloResultCallback::Result(client_hello, client_ip,
                                                     now));
 
   StringPiece requested_scid;
   client_hello.GetStringPiece(kSCID, &requested_scid);
 
-  uint8_t primary_orbit[kOrbitSize];
   scoped_refptr<Config> requested_config;
   scoped_refptr<Config> primary_config;
   {
@@ -526,37 +448,151 @@ void QuicCryptoServerConfig::ValidateClientHello(
         DCHECK(primary_config_.get());
         DCHECK_EQ(configs_.find(primary_config_->id)->second, primary_config_);
       }
-
-      memcpy(primary_orbit, primary_config_->orbit, sizeof(primary_orbit));
     }
 
     requested_config = GetConfigWithScid(requested_scid);
     primary_config = primary_config_;
-    crypto_proof->config = primary_config_;
+    signed_config->config = primary_config_;
   }
 
   if (result->error_code == QUIC_NO_ERROR) {
-    if (version > QUIC_VERSION_30) {
-      // QUIC v31 and above require a new proof for each CHLO so clear the
-      // existing proof, if any.
-      crypto_proof->chain = nullptr;
-      crypto_proof->signature = "";
-      crypto_proof->cert_sct = "";
-    }
-    EvaluateClientHello(server_ip, version, primary_orbit, requested_config,
-                        primary_config, crypto_proof, std::move(result),
+    // QUIC requires a new proof for each CHLO so clear any existing proof.
+    signed_config->chain = nullptr;
+    signed_config->proof.signature = "";
+    signed_config->proof.leaf_cert_scts = "";
+    EvaluateClientHello(server_address, version, requested_config,
+                        primary_config, signed_config, result,
                         std::move(done_cb));
   } else {
-    done_cb->Run(std::move(result), /* details = */ nullptr);
+    done_cb->Run(result, /* details = */ nullptr);
   }
 }
 
-QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
-    const ValidateClientHelloResultCallback::Result& validate_chlo_result,
+class ProcessClientHelloHelper {
+ public:
+  explicit ProcessClientHelloHelper(
+      std::unique_ptr<ProcessClientHelloResultCallback>* done_cb)
+      : done_cb_(done_cb) {}
+
+  ~ProcessClientHelloHelper() {
+    QUIC_BUG_IF(done_cb_ != nullptr)
+        << "Deleting ProcessClientHelloHelper with a pending callback.";
+  }
+
+  void Fail(QuicErrorCode error, const string& error_details) {
+    (*done_cb_)->Run(error, error_details, nullptr, nullptr, nullptr);
+    DetachCallback();
+  }
+
+  void Succeed(std::unique_ptr<CryptoHandshakeMessage> message,
+               std::unique_ptr<DiversificationNonce> diversification_nonce,
+               std::unique_ptr<ProofSource::Details> proof_source_details) {
+    (*done_cb_)->Run(QUIC_NO_ERROR, string(), std::move(message),
+                     std::move(diversification_nonce),
+                     std::move(proof_source_details));
+    DetachCallback();
+  }
+
+  void DetachCallback() {
+    QUIC_BUG_IF(done_cb_ == nullptr) << "Callback already detached.";
+    done_cb_ = nullptr;
+  }
+
+ private:
+  std::unique_ptr<ProcessClientHelloResultCallback>* done_cb_;
+};
+
+class QuicCryptoServerConfig::ProcessClientHelloCallback
+    : public ProofSource::Callback {
+ public:
+  ProcessClientHelloCallback(
+      const QuicCryptoServerConfig* config,
+      scoped_refptr<ValidateClientHelloResultCallback::Result>
+          validate_chlo_result,
+      bool reject_only,
+      QuicConnectionId connection_id,
+      const QuicSocketAddress& client_address,
+      QuicVersion version,
+      const QuicVersionVector& supported_versions,
+      bool use_stateless_rejects,
+      QuicConnectionId server_designated_connection_id,
+      const QuicClock* clock,
+      QuicRandom* rand,
+      QuicCompressedCertsCache* compressed_certs_cache,
+      scoped_refptr<QuicCryptoNegotiatedParameters> params,
+      scoped_refptr<QuicSignedServerConfig> signed_config,
+      QuicByteCount total_framing_overhead,
+      QuicByteCount chlo_packet_size,
+      const scoped_refptr<QuicCryptoServerConfig::Config>& requested_config,
+      const scoped_refptr<QuicCryptoServerConfig::Config>& primary_config,
+      std::unique_ptr<ProcessClientHelloResultCallback> done_cb)
+      : config_(config),
+        validate_chlo_result_(std::move(validate_chlo_result)),
+        reject_only_(reject_only),
+        connection_id_(connection_id),
+        client_address_(client_address),
+        version_(version),
+        supported_versions_(supported_versions),
+        use_stateless_rejects_(use_stateless_rejects),
+        server_designated_connection_id_(server_designated_connection_id),
+        clock_(clock),
+        rand_(rand),
+        compressed_certs_cache_(compressed_certs_cache),
+        params_(params),
+        signed_config_(signed_config),
+        total_framing_overhead_(total_framing_overhead),
+        chlo_packet_size_(chlo_packet_size),
+        requested_config_(requested_config),
+        primary_config_(primary_config),
+        done_cb_(std::move(done_cb)) {}
+
+  void Run(bool ok,
+           const scoped_refptr<ProofSource::Chain>& chain,
+           const QuicCryptoProof& proof,
+           std::unique_ptr<ProofSource::Details> details) override {
+    if (ok) {
+      signed_config_->chain = chain;
+      signed_config_->proof = proof;
+    }
+    config_->ProcessClientHelloAfterGetProof(
+        !ok, std::move(details), *validate_chlo_result_, reject_only_,
+        connection_id_, client_address_, version_, supported_versions_,
+        use_stateless_rejects_, server_designated_connection_id_, clock_, rand_,
+        compressed_certs_cache_, params_, signed_config_,
+        total_framing_overhead_, chlo_packet_size_, requested_config_,
+        primary_config_, std::move(done_cb_));
+  }
+
+ private:
+  const QuicCryptoServerConfig* config_;
+  const scoped_refptr<ValidateClientHelloResultCallback::Result>
+      validate_chlo_result_;
+  const bool reject_only_;
+  const QuicConnectionId connection_id_;
+  const QuicSocketAddress client_address_;
+  const QuicVersion version_;
+  const QuicVersionVector supported_versions_;
+  const bool use_stateless_rejects_;
+  const QuicConnectionId server_designated_connection_id_;
+  const QuicClock* const clock_;
+  QuicRandom* const rand_;
+  QuicCompressedCertsCache* compressed_certs_cache_;
+  scoped_refptr<QuicCryptoNegotiatedParameters> params_;
+  scoped_refptr<QuicSignedServerConfig> signed_config_;
+  const QuicByteCount total_framing_overhead_;
+  const QuicByteCount chlo_packet_size_;
+  const scoped_refptr<QuicCryptoServerConfig::Config> requested_config_;
+  const scoped_refptr<QuicCryptoServerConfig::Config> primary_config_;
+  std::unique_ptr<ProcessClientHelloResultCallback> done_cb_;
+};
+
+void QuicCryptoServerConfig::ProcessClientHello(
+    scoped_refptr<ValidateClientHelloResultCallback::Result>
+        validate_chlo_result,
     bool reject_only,
     QuicConnectionId connection_id,
-    const IPAddress& server_ip,
-    const IPEndPoint& client_address,
+    const QuicSocketAddress& server_address,
+    const QuicSocketAddress& client_address,
     QuicVersion version,
     const QuicVersionVector& supported_versions,
     bool use_stateless_rejects,
@@ -564,23 +600,26 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
     const QuicClock* clock,
     QuicRandom* rand,
     QuicCompressedCertsCache* compressed_certs_cache,
-    QuicCryptoNegotiatedParameters* params,
-    QuicCryptoProof* crypto_proof,
+    scoped_refptr<QuicCryptoNegotiatedParameters> params,
+    scoped_refptr<QuicSignedServerConfig> signed_config,
     QuicByteCount total_framing_overhead,
     QuicByteCount chlo_packet_size,
-    CryptoHandshakeMessage* out,
-    DiversificationNonce* out_diversification_nonce,
-    string* error_details) const {
-  DCHECK(error_details);
+    std::unique_ptr<ProcessClientHelloResultCallback> done_cb) const {
+  DCHECK(done_cb);
+
+  ProcessClientHelloHelper helper(&done_cb);
 
   const CryptoHandshakeMessage& client_hello =
-      validate_chlo_result.client_hello;
-  const ClientHelloInfo& info = validate_chlo_result.info;
+      validate_chlo_result->client_hello;
+  const ClientHelloInfo& info = validate_chlo_result->info;
 
+  string error_details;
   QuicErrorCode valid = CryptoUtils::ValidateClientHello(
-      client_hello, version, supported_versions, error_details);
-  if (valid != QUIC_NO_ERROR)
-    return valid;
+      client_hello, version, supported_versions, &error_details);
+  if (valid != QUIC_NO_ERROR) {
+    helper.Fail(valid, error_details);
+    return;
+  }
 
   StringPiece requested_scid;
   client_hello.GetStringPiece(kSCID, &requested_scid);
@@ -588,67 +627,150 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
 
   scoped_refptr<Config> requested_config;
   scoped_refptr<Config> primary_config;
+  bool no_primary_config = false;
   {
     base::AutoLock locked(configs_lock_);
 
-    if (!primary_config_.get()) {
-      *error_details = "No configurations loaded";
-      return QUIC_CRYPTO_INTERNAL_ERROR;
-    }
+    if (!primary_config_) {
+      no_primary_config = true;
+    } else {
+      if (!next_config_promotion_time_.IsZero() &&
+          next_config_promotion_time_.IsAfter(now)) {
+        SelectNewPrimaryConfig(now);
+        DCHECK(primary_config_.get());
+        DCHECK_EQ(configs_.find(primary_config_->id)->second, primary_config_);
+      }
 
-    if (!next_config_promotion_time_.IsZero() &&
-        next_config_promotion_time_.IsAfter(now)) {
-      SelectNewPrimaryConfig(now);
-      DCHECK(primary_config_.get());
-      DCHECK_EQ(configs_.find(primary_config_->id)->second, primary_config_);
+      // Use the config that the client requested in order to do key-agreement.
+      // Otherwise give it a copy of |primary_config_| to use.
+      primary_config = signed_config->config;
+      requested_config = GetConfigWithScid(requested_scid);
     }
-
-    // Use the config that the client requested in order to do key-agreement.
-    // Otherwise give it a copy of |primary_config_| to use.
-    primary_config = crypto_proof->config;
-    requested_config = GetConfigWithScid(requested_scid);
   }
-
-  if (validate_chlo_result.error_code != QUIC_NO_ERROR) {
-    *error_details = validate_chlo_result.error_details;
-    return validate_chlo_result.error_code;
+  if (no_primary_config) {
+    helper.Fail(QUIC_CRYPTO_INTERNAL_ERROR, "No configurations loaded");
+    return;
   }
 
-  out->Clear();
+  if (validate_chlo_result->error_code != QUIC_NO_ERROR) {
+    helper.Fail(validate_chlo_result->error_code,
+                validate_chlo_result->error_details);
+    return;
+  }
 
   if (!ClientDemandsX509Proof(client_hello)) {
-    *error_details = "Missing or invalid PDMD";
-    return QUIC_UNSUPPORTED_PROOF_DEMAND;
+    helper.Fail(QUIC_UNSUPPORTED_PROOF_DEMAND, "Missing or invalid PDMD");
+    return;
   }
   DCHECK(proof_source_.get());
   string chlo_hash;
   CryptoUtils::HashHandshakeMessage(client_hello, &chlo_hash);
+
   // No need to get a new proof if one was already generated.
-  if (!crypto_proof->chain &&
-      !proof_source_->GetProof(server_ip, info.sni.as_string(),
-                               primary_config->serialized, version, chlo_hash,
-                               &crypto_proof->chain, &crypto_proof->signature,
-                               &crypto_proof->cert_sct)) {
-    return QUIC_HANDSHAKE_FAILED;
+  if (!signed_config->chain) {
+    const QuicTag* tag_ptr;
+    size_t num_tags;
+    QuicTagVector connection_options;
+    if (client_hello.GetTaglist(kCOPT, &tag_ptr, &num_tags) == QUIC_NO_ERROR) {
+      connection_options.assign(tag_ptr, tag_ptr + num_tags);
+    }
+    if (FLAGS_enable_async_get_proof) {
+      std::unique_ptr<ProcessClientHelloCallback> cb(
+          new ProcessClientHelloCallback(
+              this, validate_chlo_result, reject_only, connection_id,
+              client_address, version, supported_versions,
+              use_stateless_rejects, server_designated_connection_id, clock,
+              rand, compressed_certs_cache, params, signed_config,
+              total_framing_overhead, chlo_packet_size, requested_config,
+              primary_config, std::move(done_cb)));
+      proof_source_->GetProof(server_address, info.sni.as_string(),
+                              primary_config->serialized, version, chlo_hash,
+                              connection_options, std::move(cb));
+      helper.DetachCallback();
+      return;
+    }
+
+    QuicCryptoProof proof;
+    if (!proof_source_->GetProof(server_address, info.sni.as_string(),
+                                 primary_config->serialized, version, chlo_hash,
+                                 connection_options, &signed_config->chain,
+                                 &proof)) {
+      helper.Fail(QUIC_HANDSHAKE_FAILED, "Missing or invalid crypto proof.");
+      return;
+    }
+    signed_config->proof = proof;
+  }
+
+  helper.DetachCallback();
+  ProcessClientHelloAfterGetProof(
+      /* found_error = */ false, /* proof_source_details = */ nullptr,
+      *validate_chlo_result, reject_only, connection_id, client_address,
+      version, supported_versions, use_stateless_rejects,
+      server_designated_connection_id, clock, rand, compressed_certs_cache,
+      params, signed_config, total_framing_overhead, chlo_packet_size,
+      requested_config, primary_config, std::move(done_cb));
+}
+
+void QuicCryptoServerConfig::ProcessClientHelloAfterGetProof(
+    bool found_error,
+    std::unique_ptr<ProofSource::Details> proof_source_details,
+    const ValidateClientHelloResultCallback::Result& validate_chlo_result,
+    bool reject_only,
+    QuicConnectionId connection_id,
+    const QuicSocketAddress& client_address,
+    QuicVersion version,
+    const QuicVersionVector& supported_versions,
+    bool use_stateless_rejects,
+    QuicConnectionId server_designated_connection_id,
+    const QuicClock* clock,
+    QuicRandom* rand,
+    QuicCompressedCertsCache* compressed_certs_cache,
+    scoped_refptr<QuicCryptoNegotiatedParameters> params,
+    scoped_refptr<QuicSignedServerConfig> signed_config,
+    QuicByteCount total_framing_overhead,
+    QuicByteCount chlo_packet_size,
+    const scoped_refptr<Config>& requested_config,
+    const scoped_refptr<Config>& primary_config,
+    std::unique_ptr<ProcessClientHelloResultCallback> done_cb) const {
+  ProcessClientHelloHelper helper(&done_cb);
+
+  if (found_error) {
+    helper.Fail(QUIC_HANDSHAKE_FAILED, "Failed to get proof");
+    return;
   }
 
+  const CryptoHandshakeMessage& client_hello =
+      validate_chlo_result.client_hello;
+  const ClientHelloInfo& info = validate_chlo_result.info;
+  std::unique_ptr<DiversificationNonce> out_diversification_nonce(
+      new DiversificationNonce);
+
   StringPiece cert_sct;
   if (client_hello.GetStringPiece(kCertificateSCTTag, &cert_sct) &&
       cert_sct.empty()) {
     params->sct_supported_by_client = true;
   }
 
+  std::unique_ptr<CryptoHandshakeMessage> out(new CryptoHandshakeMessage);
   if (!info.reject_reasons.empty() || !requested_config.get()) {
     BuildRejection(version, clock->WallNow(), *primary_config, client_hello,
                    info, validate_chlo_result.cached_network_params,
                    use_stateless_rejects, server_designated_connection_id, rand,
-                   compressed_certs_cache, params, *crypto_proof,
-                   total_framing_overhead, chlo_packet_size, out);
-    return QUIC_NO_ERROR;
+                   compressed_certs_cache, params, *signed_config,
+                   total_framing_overhead, chlo_packet_size, out.get());
+    if (FLAGS_quic_export_rej_for_all_rejects &&
+        rejection_observer_ != nullptr) {
+      rejection_observer_->OnRejectionBuilt(info.reject_reasons, out.get());
+    }
+    helper.Succeed(std::move(out), std::move(out_diversification_nonce),
+                   std::move(proof_source_details));
+    return;
   }
 
   if (reject_only) {
-    return QUIC_NO_ERROR;
+    helper.Succeed(std::move(out), std::move(out_diversification_nonce),
+                   std::move(proof_source_details));
+    return;
   }
 
   const QuicTag* their_aeads;
@@ -659,20 +781,19 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
       client_hello.GetTaglist(kKEXS, &their_key_exchanges,
                               &num_their_key_exchanges) != QUIC_NO_ERROR ||
       num_their_aeads != 1 || num_their_key_exchanges != 1) {
-    *error_details = "Missing or invalid AEAD or KEXS";
-    return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+    helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER,
+                "Missing or invalid AEAD or KEXS");
+    return;
   }
 
   size_t key_exchange_index;
-  if (!QuicUtils::FindMutualTag(requested_config->aead, their_aeads,
-                                num_their_aeads, QuicUtils::LOCAL_PRIORITY,
-                                &params->aead, nullptr) ||
-      !QuicUtils::FindMutualTag(requested_config->kexs, their_key_exchanges,
-                                num_their_key_exchanges,
-                                QuicUtils::LOCAL_PRIORITY,
-                                &params->key_exchange, &key_exchange_index)) {
-    *error_details = "Unsupported AEAD or KEXS";
-    return QUIC_CRYPTO_NO_SUPPORT;
+  if (!FindMutualQuicTag(requested_config->aead, their_aeads, num_their_aeads,
+                         &params->aead, nullptr) ||
+      !FindMutualQuicTag(requested_config->kexs, their_key_exchanges,
+                         num_their_key_exchanges, &params->key_exchange,
+                         &key_exchange_index)) {
+    helper.Fail(QUIC_CRYPTO_NO_SUPPORT, "Unsupported AEAD or KEXS");
+    return;
   }
 
   if (!requested_config->tb_key_params.empty()) {
@@ -682,30 +803,30 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
       case QUIC_CRYPTO_MESSAGE_PARAMETER_NOT_FOUND:
         break;
       case QUIC_NO_ERROR:
-        if (QuicUtils::FindMutualTag(
-                requested_config->tb_key_params, their_tbkps, num_their_tbkps,
-                QuicUtils::LOCAL_PRIORITY, &params->token_binding_key_param,
-                nullptr)) {
+        if (FindMutualQuicTag(requested_config->tb_key_params, their_tbkps,
+                              num_their_tbkps, &params->token_binding_key_param,
+                              nullptr)) {
           break;
         }
       default:
-        *error_details = "Invalid Token Binding key parameter";
-        return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+        helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER,
+                    "Invalid Token Binding key parameter");
+        return;
     }
   }
 
   StringPiece public_value;
   if (!client_hello.GetStringPiece(kPUBS, &public_value)) {
-    *error_details = "Missing public value";
-    return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+    helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER, "Missing public value");
+    return;
   }
 
   const KeyExchange* key_exchange =
-      requested_config->key_exchanges[key_exchange_index];
+      requested_config->key_exchanges[key_exchange_index].get();
   if (!key_exchange->CalculateSharedKey(public_value,
                                         &params->initial_premaster_secret)) {
-    *error_details = "Invalid public value";
-    return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+    helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER, "Invalid public value");
+    return;
   }
 
   if (!info.sni.empty()) {
@@ -725,11 +846,11 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
                      client_hello_serialized.length());
   hkdf_suffix.append(requested_config->serialized);
   DCHECK(proof_source_.get());
-  if (crypto_proof->chain->certs.empty()) {
-    *error_details = "Failed to get certs";
-    return QUIC_CRYPTO_INTERNAL_ERROR;
+  if (signed_config->chain->certs.empty()) {
+    helper.Fail(QUIC_CRYPTO_INTERNAL_ERROR, "Failed to get certs");
+    return;
   }
-  hkdf_suffix.append(crypto_proof->chain->certs.at(0));
+  hkdf_suffix.append(signed_config->chain->certs.at(0));
 
   StringPiece cetv_ciphertext;
   if (requested_config->channel_id_enabled &&
@@ -755,8 +876,9 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
                                  hkdf_input, Perspective::IS_SERVER,
                                  CryptoUtils::Diversification::Never(),
                                  &crypters, nullptr /* subkey secret */)) {
-      *error_details = "Symmetric key setup failed";
-      return QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED;
+      helper.Fail(QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED,
+                  "Symmetric key setup failed");
+      return;
     }
 
     char plaintext[kMaxPacketSize];
@@ -766,22 +888,24 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
         StringPiece() /* associated data */, cetv_ciphertext, plaintext,
         &plaintext_length, kMaxPacketSize);
     if (!success) {
-      *error_details = "CETV decryption failure";
-      return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+      helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER,
+                  "CETV decryption failure");
+      return;
     }
     std::unique_ptr<CryptoHandshakeMessage> cetv(
         CryptoFramer::ParseMessage(StringPiece(plaintext, plaintext_length)));
     if (!cetv.get()) {
-      *error_details = "CETV parse error";
-      return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+      helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER, "CETV parse error");
+      return;
     }
 
     StringPiece key, signature;
     if (cetv->GetStringPiece(kCIDK, &key) &&
         cetv->GetStringPiece(kCIDS, &signature)) {
       if (!ChannelIDVerifier::Verify(key, hkdf_input, signature)) {
-        *error_details = "ChannelID signature failure";
-        return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+        helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER,
+                    "ChannelID signature failure");
+        return;
       }
 
       params->channel_id = key.as_string();
@@ -794,22 +918,18 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
   hkdf_input.append(QuicCryptoConfig::kInitialLabel, label_len);
   hkdf_input.append(hkdf_suffix);
 
-  string* subkey_secret = &params->initial_subkey_secret;
+  rand->RandBytes(out_diversification_nonce->data(),
+                  out_diversification_nonce->size());
   CryptoUtils::Diversification diversification =
-      CryptoUtils::Diversification::Never();
-  if (version > QUIC_VERSION_32) {
-    rand->RandBytes(out_diversification_nonce->data(),
-                    out_diversification_nonce->size());
-    diversification =
-        CryptoUtils::Diversification::Now(out_diversification_nonce);
-  }
-
+      CryptoUtils::Diversification::Now(out_diversification_nonce.get());
   if (!CryptoUtils::DeriveKeys(params->initial_premaster_secret, params->aead,
                                info.client_nonce, info.server_nonce, hkdf_input,
                                Perspective::IS_SERVER, diversification,
-                               &params->initial_crypters, subkey_secret)) {
-    *error_details = "Symmetric key setup failed";
-    return QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED;
+                               &params->initial_crypters,
+                               &params->initial_subkey_secret)) {
+    helper.Fail(QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED,
+                "Symmetric key setup failed");
+    return;
   }
 
   string forward_secure_public_value;
@@ -825,8 +945,9 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
         forward_secure_key_exchange->public_value().as_string();
     if (!forward_secure_key_exchange->CalculateSharedKey(
             public_value, &params->forward_secure_premaster_secret)) {
-      *error_details = "Invalid public value";
-      return QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER;
+      helper.Fail(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER,
+                  "Invalid public value");
+      return;
     }
   }
 
@@ -848,8 +969,9 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
           forward_secure_hkdf_input, Perspective::IS_SERVER,
           CryptoUtils::Diversification::Never(),
           &params->forward_secure_crypters, &params->subkey_secret)) {
-    *error_details = "Symmetric key setup failed";
-    return QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED;
+    helper.Fail(QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED,
+                "Symmetric key setup failed");
+    return;
   }
 
   out->set_tag(kSHLO);
@@ -862,12 +984,13 @@ QuicErrorCode QuicCryptoServerConfig::ProcessClientHello(
   out->SetStringPiece(
       kSourceAddressTokenTag,
       NewSourceAddressToken(*requested_config.get(), info.source_address_tokens,
-                            client_address.address(), rand, info.now, nullptr));
+                            client_address.host(), rand, info.now, nullptr));
   QuicSocketAddressCoder address_coder(client_address);
   out->SetStringPiece(kCADR, address_coder.Encode());
   out->SetStringPiece(kPUBS, forward_secure_public_value);
 
-  return QUIC_NO_ERROR;
+  helper.Succeed(std::move(out), std::move(out_diversification_nonce),
+                 std::move(proof_source_details));
 }
 
 scoped_refptr<QuicCryptoServerConfig::Config>
@@ -909,7 +1032,7 @@ bool QuicCryptoServerConfig::ConfigPrimaryTimeLessThan(
 
 void QuicCryptoServerConfig::SelectNewPrimaryConfig(
     const QuicWallTime now) const {
-  vector<scoped_refptr<Config>> configs;
+  std::vector<scoped_refptr<Config>> configs;
   configs.reserve(configs_.size());
 
   for (ConfigMap::const_iterator it = configs_.begin(); it != configs_.end();
@@ -990,72 +1113,65 @@ void QuicCryptoServerConfig::SelectNewPrimaryConfig(
   }
 }
 
-class EvaluateClientHelloCallback : public ProofSource::Callback {
+class QuicCryptoServerConfig::EvaluateClientHelloCallback
+    : public ProofSource::Callback {
  public:
   EvaluateClientHelloCallback(
       const QuicCryptoServerConfig& config,
       bool found_error,
-      const IPAddress& server_ip,
+      const QuicIpAddress& server_ip,
       QuicVersion version,
-      const uint8_t* primary_orbit,
       scoped_refptr<QuicCryptoServerConfig::Config> requested_config,
       scoped_refptr<QuicCryptoServerConfig::Config> primary_config,
-      QuicCryptoProof* crypto_proof,
-      std::unique_ptr<ValidateClientHelloResultCallback::Result>
+      scoped_refptr<QuicSignedServerConfig> signed_config,
+      scoped_refptr<ValidateClientHelloResultCallback::Result>
           client_hello_state,
       std::unique_ptr<ValidateClientHelloResultCallback> done_cb)
       : config_(config),
         found_error_(found_error),
         server_ip_(server_ip),
         version_(version),
-        primary_orbit_(primary_orbit),
         requested_config_(std::move(requested_config)),
         primary_config_(std::move(primary_config)),
-        crypto_proof_(crypto_proof),
+        signed_config_(signed_config),
         client_hello_state_(std::move(client_hello_state)),
         done_cb_(std::move(done_cb)) {}
 
   void Run(bool ok,
            const scoped_refptr<ProofSource::Chain>& chain,
-           const string& signature,
-           const string& leaf_cert_sct,
+           const QuicCryptoProof& proof,
            std::unique_ptr<ProofSource::Details> details) override {
     if (ok) {
-      crypto_proof_->chain = chain;
-      crypto_proof_->signature = signature;
-      crypto_proof_->cert_sct = leaf_cert_sct;
+      signed_config_->chain = chain;
+      signed_config_->proof = proof;
     }
     config_.EvaluateClientHelloAfterGetProof(
-        found_error_, server_ip_, version_, primary_orbit_, requested_config_,
-        primary_config_, crypto_proof_, std::move(details), !ok,
-        std::move(client_hello_state_), std::move(done_cb_));
+        found_error_, server_ip_, version_, requested_config_, primary_config_,
+        signed_config_, std::move(details), !ok, client_hello_state_,
+        std::move(done_cb_));
   }
 
  private:
   const QuicCryptoServerConfig& config_;
   const bool found_error_;
-  const IPAddress& server_ip_;
+  const QuicIpAddress& server_ip_;
   const QuicVersion version_;
-  const uint8_t* primary_orbit_;
   const scoped_refptr<QuicCryptoServerConfig::Config> requested_config_;
   const scoped_refptr<QuicCryptoServerConfig::Config> primary_config_;
-  QuicCryptoProof* crypto_proof_;
-  std::unique_ptr<ValidateClientHelloResultCallback::Result>
-      client_hello_state_;
+  scoped_refptr<QuicSignedServerConfig> signed_config_;
+  scoped_refptr<ValidateClientHelloResultCallback::Result> client_hello_state_;
   std::unique_ptr<ValidateClientHelloResultCallback> done_cb_;
 };
 
 void QuicCryptoServerConfig::EvaluateClientHello(
-    const IPAddress& server_ip,
+    const QuicSocketAddress& server_address,
     QuicVersion version,
-    const uint8_t* primary_orbit,
     scoped_refptr<Config> requested_config,
     scoped_refptr<Config> primary_config,
-    QuicCryptoProof* crypto_proof,
-    std::unique_ptr<ValidateClientHelloResultCallback::Result>
-        client_hello_state,
+    scoped_refptr<QuicSignedServerConfig> signed_config,
+    scoped_refptr<ValidateClientHelloResultCallback::Result> client_hello_state,
     std::unique_ptr<ValidateClientHelloResultCallback> done_cb) const {
-  ValidateClientHelloHelper helper(&client_hello_state, &done_cb);
+  ValidateClientHelloHelper helper(client_hello_state, &done_cb);
 
   const CryptoHandshakeMessage& client_hello = client_hello_state->client_hello;
   ClientHelloInfo* info = &(client_hello_state->info);
@@ -1124,66 +1240,72 @@ void QuicCryptoServerConfig::EvaluateClientHello(
   string chlo_hash;
   CryptoUtils::HashHandshakeMessage(client_hello, &chlo_hash);
   bool need_proof = true;
-  need_proof = !crypto_proof->chain;
+  need_proof = !signed_config->chain;
+  const QuicTag* tag_ptr;
+  size_t num_tags;
+  QuicTagVector connection_options;
+  if (client_hello.GetTaglist(kCOPT, &tag_ptr, &num_tags) == QUIC_NO_ERROR) {
+    connection_options.assign(tag_ptr, tag_ptr + num_tags);
+  }
   if (FLAGS_enable_async_get_proof) {
     if (need_proof) {
       // Make an async call to GetProof and setup the callback to trampoline
       // back into EvaluateClientHelloAfterGetProof
       std::unique_ptr<EvaluateClientHelloCallback> cb(
           new EvaluateClientHelloCallback(
-              *this, found_error, server_ip, version, primary_orbit,
-              requested_config, primary_config, crypto_proof,
-              std::move(client_hello_state), std::move(done_cb)));
-      proof_source_->GetProof(server_ip, info->sni.as_string(),
+              *this, found_error, server_address.host(), version,
+              requested_config, primary_config, signed_config,
+              client_hello_state, std::move(done_cb)));
+      proof_source_->GetProof(server_address, info->sni.as_string(),
                               serialized_config, version, chlo_hash,
-                              std::move(cb));
+                              connection_options, std::move(cb));
       helper.DetachCallback();
       return;
     }
   }
 
   // No need to get a new proof if one was already generated.
-  if (need_proof &&
-      !proof_source_->GetProof(server_ip, info->sni.as_string(),
-                               serialized_config, version, chlo_hash,
-                               &crypto_proof->chain, &crypto_proof->signature,
-                               &crypto_proof->cert_sct)) {
-    get_proof_failed = true;
+  if (need_proof) {
+    QuicCryptoProof proof;
+
+    if (proof_source_->GetProof(
+            server_address, info->sni.as_string(), serialized_config, version,
+            chlo_hash, connection_options, &signed_config->chain, &proof)) {
+      signed_config->proof = proof;
+    } else {
+      get_proof_failed = true;
+    }
   }
 
   // Details are null because the synchronous version of GetProof does not
   // return any stats.  Eventually the synchronous codepath will be eliminated.
   EvaluateClientHelloAfterGetProof(
-      found_error, server_ip, version, primary_orbit, requested_config,
-      primary_config, crypto_proof, nullptr /* proof_source_details */,
-      get_proof_failed, std::move(client_hello_state), std::move(done_cb));
+      found_error, server_address.host(), version, requested_config,
+      primary_config, signed_config, nullptr /* proof_source_details */,
+      get_proof_failed, client_hello_state, std::move(done_cb));
   helper.DetachCallback();
 }
 
 void QuicCryptoServerConfig::EvaluateClientHelloAfterGetProof(
     bool found_error,
-    const IPAddress& server_ip,
+    const QuicIpAddress& server_ip,
     QuicVersion version,
-    const uint8_t* primary_orbit,
     scoped_refptr<Config> requested_config,
     scoped_refptr<Config> primary_config,
-    QuicCryptoProof* crypto_proof,
+    scoped_refptr<QuicSignedServerConfig> signed_config,
     std::unique_ptr<ProofSource::Details> proof_source_details,
     bool get_proof_failed,
-    std::unique_ptr<ValidateClientHelloResultCallback::Result>
-        client_hello_state,
+    scoped_refptr<ValidateClientHelloResultCallback::Result> client_hello_state,
     std::unique_ptr<ValidateClientHelloResultCallback> done_cb) const {
-  ValidateClientHelloHelper helper(&client_hello_state, &done_cb);
+  ValidateClientHelloHelper helper(client_hello_state, &done_cb);
   const CryptoHandshakeMessage& client_hello = client_hello_state->client_hello;
   ClientHelloInfo* info = &(client_hello_state->info);
 
   if (get_proof_failed) {
-    found_error = true;
     info->reject_reasons.push_back(SERVER_CONFIG_UNKNOWN_CONFIG_FAILURE);
   }
 
-  if (!ValidateExpectedLeafCertificate(client_hello, *crypto_proof)) {
-    found_error = true;
+  if (!ValidateExpectedLeafCertificate(client_hello, *signed_config)) {
     info->reject_reasons.push_back(INVALID_EXPECTED_LEAF_CERTIFICATE);
   }
 
@@ -1192,100 +1314,32 @@ void QuicCryptoServerConfig::EvaluateClientHelloAfterGetProof(
     // Invalid client nonce.
     LOG(ERROR) << "Invalid client nonce: " << client_hello.DebugString();
     DVLOG(1) << "Invalid client nonce.";
-    found_error = true;
   }
 
   // Server nonce is optional, and used for key derivation if present.
   client_hello.GetStringPiece(kServerNonceTag, &info->server_nonce);
 
-  if (version > QUIC_VERSION_32) {
-    DVLOG(1) << "No 0-RTT replay protection in QUIC_VERSION_33 and higher.";
-    // If the server nonce is empty and we're requiring handshake confirmation
-    // for DoS reasons then we must reject the CHLO.
-    if (FLAGS_quic_require_handshake_confirmation &&
-        info->server_nonce.empty()) {
-      info->reject_reasons.push_back(SERVER_NONCE_REQUIRED_FAILURE);
-    }
-    helper.ValidationComplete(QUIC_NO_ERROR, "",
-                              std::move(proof_source_details));
-    return;
-  }
-
-  if (!replay_protection_) {
-    DVLOG(1) << "No replay protection.";
-    helper.ValidationComplete(QUIC_NO_ERROR, "",
-                              std::move(proof_source_details));
-    return;
-  }
-
-  if (!info->server_nonce.empty()) {
-    // If the server nonce is present, use it to establish uniqueness.
-    HandshakeFailureReason server_nonce_error =
-        ValidateServerNonce(info->server_nonce, info->now);
-    bool is_unique = server_nonce_error == HANDSHAKE_OK;
-    if (!is_unique) {
-      info->reject_reasons.push_back(server_nonce_error);
-    }
-    DVLOG(1) << "Using server nonce, unique: " << is_unique;
-    helper.ValidationComplete(QUIC_NO_ERROR, "",
-                              std::move(proof_source_details));
-    return;
-  }
-  // If we hit this block, the server nonce was empty.  If we're requiring
-  // handshake confirmation for DoS reasons and there's no server nonce present,
-  // reject the CHLO.
-  if (FLAGS_quic_require_handshake_confirmation ||
-      FLAGS_quic_require_handshake_confirmation_pre33) {
-    info->reject_reasons.push_back(SERVER_NONCE_REQUIRED_FAILURE);
-    helper.ValidationComplete(QUIC_NO_ERROR, "",
-                              std::move(proof_source_details));
-    return;
-  }
-
-  // We want to contact strike register only if there are no errors because it
-  // is a RPC call and is expensive.
-  if (found_error) {
-    helper.ValidationComplete(QUIC_NO_ERROR, "",
-                              std::move(proof_source_details));
-    return;
-  }
-
-  // Use the client nonce to establish uniqueness.
-  StrikeRegisterClient* strike_register_client;
-  {
-    base::AutoLock locked(strike_register_client_lock_);
-    strike_register_client = strike_register_client_.get();
-  }
-
-  if (!strike_register_client) {
-    // Either a valid server nonces or a strike register is required.
-    // Since neither are present, reject the handshake which will send a
-    // server nonce to the client.
+  DVLOG(1) << "No 0-RTT replay protection in QUIC_VERSION_33 and higher.";
+  // If the server nonce is empty and we're requiring handshake confirmation
+  // for DoS reasons then we must reject the CHLO.
+  if (FLAGS_quic_require_handshake_confirmation && info->server_nonce.empty()) {
     info->reject_reasons.push_back(SERVER_NONCE_REQUIRED_FAILURE);
-    helper.ValidationComplete(QUIC_NO_ERROR, "",
-                              std::move(proof_source_details));
-    return;
   }
-
-  strike_register_client->VerifyNonceIsValidAndUnique(
-      info->client_nonce, info->now,
-      new VerifyNonceIsValidAndUniqueCallback(std::move(client_hello_state),
-                                              std::move(proof_source_details),
-                                              std::move(done_cb)));
-  helper.DetachCallback();
+  helper.ValidationComplete(QUIC_NO_ERROR, "", std::move(proof_source_details));
 }
 
 bool QuicCryptoServerConfig::BuildServerConfigUpdateMessage(
     QuicVersion version,
     StringPiece chlo_hash,
     const SourceAddressTokens& previous_source_address_tokens,
-    const IPAddress& server_ip,
-    const IPAddress& client_ip,
+    const QuicSocketAddress& server_address,
+    const QuicIpAddress& client_ip,
     const QuicClock* clock,
     QuicRandom* rand,
     QuicCompressedCertsCache* compressed_certs_cache,
     const QuicCryptoNegotiatedParameters& params,
     const CachedNetworkParameters* cached_network_params,
+    const QuicTagVector& connection_options,
     CryptoHandshakeMessage* out) const {
   string serialized;
   string source_address_token;
@@ -1304,16 +1358,13 @@ bool QuicCryptoServerConfig::BuildServerConfigUpdateMessage(
   out->set_tag(kSCUP);
   out->SetStringPiece(kSCFG, serialized);
   out->SetStringPiece(kSourceAddressTokenTag, source_address_token);
-  if (FLAGS_quic_send_scfg_ttl) {
-    out->SetValue(kSTTL,
-                  expiry_time.AbsoluteDifference(clock->WallNow()).ToSeconds());
-  }
+  out->SetValue(kSTTL,
+                expiry_time.AbsoluteDifference(clock->WallNow()).ToSeconds());
 
   scoped_refptr<ProofSource::Chain> chain;
-  string signature;
-  string cert_sct;
-  if (!proof_source_->GetProof(server_ip, params.sni, serialized, version,
-                               chlo_hash, &chain, &signature, &cert_sct)) {
+  QuicCryptoProof proof;
+  if (!proof_source_->GetProof(server_address, params.sni, serialized, version,
+                               chlo_hash, connection_options, &chain, &proof)) {
     DVLOG(1) << "Server: failed to get proof.";
     return false;
   }
@@ -1323,12 +1374,13 @@ bool QuicCryptoServerConfig::BuildServerConfigUpdateMessage(
       params.client_cached_cert_hashes, common_cert_sets);
 
   out->SetStringPiece(kCertificateTag, compressed);
-  out->SetStringPiece(kPROF, signature);
+  out->SetStringPiece(kPROF, proof.signature);
   if (params.sct_supported_by_client && enable_serving_sct_) {
-    if (cert_sct.empty()) {
-      DLOG(WARNING) << "SCT is expected but it is empty.";
+    if (proof.leaf_cert_scts.empty()) {
+      DLOG(WARNING) << "SCT is expected but it is empty. sni: " << params.sni
+                    << " server_address: " << server_address.ToString();
     } else {
-      out->SetStringPiece(kCertificateSCTTag, cert_sct);
+      out->SetStringPiece(kCertificateSCTTag, proof.leaf_cert_scts);
     }
   }
   return true;
@@ -1338,13 +1390,14 @@ void QuicCryptoServerConfig::BuildServerConfigUpdateMessage(
     QuicVersion version,
     StringPiece chlo_hash,
     const SourceAddressTokens& previous_source_address_tokens,
-    const IPAddress& server_ip,
-    const IPAddress& client_ip,
+    const QuicSocketAddress& server_address,
+    const QuicIpAddress& client_ip,
     const QuicClock* clock,
     QuicRandom* rand,
     QuicCompressedCertsCache* compressed_certs_cache,
     const QuicCryptoNegotiatedParameters& params,
     const CachedNetworkParameters* cached_network_params,
+    const QuicTagVector& connection_options,
     std::unique_ptr<BuildServerConfigUpdateMessageResultCallback> cb) const {
   string serialized;
   string source_address_token;
@@ -1368,7 +1421,14 @@ void QuicCryptoServerConfig::BuildServerConfigUpdateMessage(
           this, version, compressed_certs_cache, common_cert_sets, params,
           std::move(message), std::move(cb)));
 
-  proof_source_->GetProof(server_ip, params.sni, serialized, version, chlo_hash,
+  // Note: We unconditionally use the async variant of GetProof here, unlike
+  // elsewhere in this file where we check for the kSYNC tag in the CHLO for the
+  // connection before deciding.  This call is not in the critical serving path,
+  // and so should not have much impact on the experiments associated with that
+  // tag (plus it would be a chore to plumb information about the tag down to
+  // here).
+  proof_source_->GetProof(server_address, params.sni, serialized, version,
+                          chlo_hash, connection_options,
                           std::move(proof_source_cb));
 }
 
@@ -1397,14 +1457,14 @@ QuicCryptoServerConfig::BuildServerConfigUpdateMessageProofSourceCallback::
 void QuicCryptoServerConfig::BuildServerConfigUpdateMessageProofSourceCallback::
     Run(bool ok,
         const scoped_refptr<ProofSource::Chain>& chain,
-        const string& signature,
-        const string& leaf_cert_sct,
+        const QuicCryptoProof& proof,
         std::unique_ptr<ProofSource::Details> details) {
   config_->FinishBuildServerConfigUpdateMessage(
       version_, compressed_certs_cache_, common_cert_sets_,
       client_common_set_hashes_, client_cached_cert_hashes_,
-      sct_supported_by_client_, ok, chain, signature, leaf_cert_sct,
-      std::move(details), std::move(message_), std::move(cb_));
+      sct_supported_by_client_, ok, chain, proof.signature,
+      proof.leaf_cert_scts, std::move(details), std::move(message_),
+      std::move(cb_));
 }
 
 void QuicCryptoServerConfig::FinishBuildServerConfigUpdateMessage(
@@ -1454,8 +1514,8 @@ void QuicCryptoServerConfig::BuildRejection(
     QuicConnectionId server_designated_connection_id,
     QuicRandom* rand,
     QuicCompressedCertsCache* compressed_certs_cache,
-    QuicCryptoNegotiatedParameters* params,
-    const QuicCryptoProof& crypto_proof,
+    scoped_refptr<QuicCryptoNegotiatedParameters> params,
+    const QuicSignedServerConfig& signed_config,
     QuicByteCount total_framing_overhead,
     QuicByteCount chlo_packet_size,
     CryptoHandshakeMessage* out) const {
@@ -1473,10 +1533,7 @@ void QuicCryptoServerConfig::BuildRejection(
       kSourceAddressTokenTag,
       NewSourceAddressToken(config, info.source_address_tokens, info.client_ip,
                             rand, info.now, &cached_network_params));
-  if (FLAGS_quic_send_scfg_ttl) {
-    out->SetValue(kSTTL,
-                  config.expiry_time.AbsoluteDifference(now).ToSeconds());
-  }
+  out->SetValue(kSTTL, config.expiry_time.AbsoluteDifference(now).ToSeconds());
   if (replay_protection_) {
     out->SetStringPiece(kServerNonceTag, NewServerNonce(rand, info.now));
   }
@@ -1502,7 +1559,7 @@ void QuicCryptoServerConfig::BuildRejection(
   }
 
   const string compressed =
-      CompressChain(compressed_certs_cache, crypto_proof.chain,
+      CompressChain(compressed_certs_cache, signed_config.chain,
                     params->client_common_set_hashes,
                     params->client_cached_cert_hashes, config.common_cert_sets);
 
@@ -1518,39 +1575,33 @@ void QuicCryptoServerConfig::BuildRejection(
   // max_unverified_size is the number of bytes that the certificate chain,
   // signature, and (optionally) signed certificate timestamp can consume before
   // we will demand a valid source-address token.
-  const size_t old_max_unverified_size =
-      client_hello.size() * chlo_multiplier_ - kREJOverheadBytes;
-  const size_t new_max_unverified_size =
+  const size_t max_unverified_size =
       chlo_multiplier_ * (chlo_packet_size - total_framing_overhead) -
       kREJOverheadBytes;
-  const size_t max_unverified_size = FLAGS_quic_use_chlo_packet_size
-                                         ? new_max_unverified_size
-                                         : old_max_unverified_size;
   static_assert(kClientHelloMinimumSize * kMultiplier >= kREJOverheadBytes,
                 "overhead calculation may underflow");
   bool should_return_sct =
       params->sct_supported_by_client && enable_serving_sct_;
-  const size_t sct_size = should_return_sct ? crypto_proof.cert_sct.size() : 0;
+  const string& cert_sct = signed_config.proof.leaf_cert_scts;
+  const size_t sct_size = should_return_sct ? cert_sct.size() : 0;
   const size_t total_size =
-      crypto_proof.signature.size() + compressed.size() + sct_size;
+      signed_config.proof.signature.size() + compressed.size() + sct_size;
   if (info.valid_source_address_token || total_size < max_unverified_size) {
     out->SetStringPiece(kCertificateTag, compressed);
-    out->SetStringPiece(kPROF, crypto_proof.signature);
+    out->SetStringPiece(kPROF, signed_config.proof.signature);
     if (should_return_sct) {
-      if (crypto_proof.cert_sct.empty()) {
+      if (cert_sct.empty()) {
         DLOG(WARNING) << "SCT is expected but it is empty.";
       } else {
-        out->SetStringPiece(kCertificateSCTTag, crypto_proof.cert_sct);
+        out->SetStringPiece(kCertificateSCTTag, cert_sct);
       }
     }
   } else {
-    if (FLAGS_quic_use_chlo_packet_size) {
-      DLOG(WARNING) << "Sending inchoate REJ for hostname: " << info.sni
-                    << " signature: " << crypto_proof.signature.size()
-                    << " cert: " << compressed.size() << " sct:" << sct_size
-                    << " total: " << total_size
-                    << " max: " << max_unverified_size;
-    }
+    DLOG(WARNING) << "Sending inchoate REJ for hostname: " << info.sni
+                  << " signature: " << signed_config.proof.signature.size()
+                  << " cert: " << compressed.size() << " sct:" << sct_size
+                  << " total: " << total_size
+                  << " max: " << max_unverified_size;
   }
 }
 
@@ -1580,7 +1631,7 @@ string QuicCryptoServerConfig::CompressChain(
 
 scoped_refptr<QuicCryptoServerConfig::Config>
 QuicCryptoServerConfig::ParseConfigProtobuf(
-    QuicServerConfigProtobuf* protobuf) {
+    const std::unique_ptr<QuicServerConfigProtobuf>& protobuf) {
   std::unique_ptr<CryptoHandshakeMessage> msg(
       CryptoFramer::ParseMessage(protobuf->config()));
 
@@ -1614,7 +1665,7 @@ QuicCryptoServerConfig::ParseConfigProtobuf(
     LOG(WARNING) << "Server config message is missing AEAD";
     return nullptr;
   }
-  config->aead = vector<QuicTag>(aead_tags, aead_tags + aead_len);
+  config->aead = std::vector<QuicTag>(aead_tags, aead_tags + aead_len);
 
   const QuicTag* kexs_tags;
   size_t kexs_len;
@@ -1632,7 +1683,7 @@ QuicCryptoServerConfig::ParseConfigProtobuf(
     LOG(WARNING) << "Server config message is missing or has invalid TBKP";
     return nullptr;
   }
-  config->tb_key_params = vector<QuicTag>(tbkp_tags, tbkp_tags + tbkp_len);
+  config->tb_key_params = std::vector<QuicTag>(tbkp_tags, tbkp_tags + tbkp_len);
 
   StringPiece orbit;
   if (!msg->GetStringPiece(kORBT, &orbit)) {
@@ -1650,22 +1701,6 @@ QuicCryptoServerConfig::ParseConfigProtobuf(
                 "orbit has incorrect size");
   memcpy(config->orbit, orbit.data(), sizeof(config->orbit));
 
-  {
-    StrikeRegisterClient* strike_register_client;
-    {
-      base::AutoLock locked(strike_register_client_lock_);
-      strike_register_client = strike_register_client_.get();
-    }
-
-    if (strike_register_client != nullptr &&
-        !strike_register_client->IsKnownOrbit(orbit)) {
-      LOG(WARNING)
-          << "Rejecting server config with orbit that the strike register "
-             "client doesn't know about.";
-      return nullptr;
-    }
-  }
-
   if (kexs_len != protobuf->key_size()) {
     LOG(WARNING) << "Server config has " << kexs_len
                  << " key exchange methods configured, but "
@@ -1731,24 +1766,22 @@ QuicCryptoServerConfig::ParseConfigProtobuf(
         return nullptr;
     }
 
-    for (const KeyExchange* key_exchange : config->key_exchanges) {
+    for (const auto& key_exchange : config->key_exchanges) {
       if (key_exchange->tag() == tag) {
         LOG(WARNING) << "Duplicate key exchange in config: " << tag;
         return nullptr;
       }
     }
 
-    config->key_exchanges.push_back(ka.release());
+    config->key_exchanges.push_back(std::move(ka));
   }
 
-  if (FLAGS_quic_send_scfg_ttl) {
-    uint64_t expiry_seconds;
-    if (msg->GetUint64(kEXPY, &expiry_seconds) != QUIC_NO_ERROR) {
-      LOG(WARNING) << "Server config message is missing EXPY";
-      return nullptr;
-    }
-    config->expiry_time = QuicWallTime::FromUNIXSeconds(expiry_seconds);
+  uint64_t expiry_seconds;
+  if (msg->GetUint64(kEXPY, &expiry_seconds) != QUIC_NO_ERROR) {
+    LOG(WARNING) << "Server config message is missing EXPY";
+    return nullptr;
   }
+  config->expiry_time = QuicWallTime::FromUNIXSeconds(expiry_seconds);
 
   return config;
 }
@@ -1758,13 +1791,6 @@ void QuicCryptoServerConfig::SetEphemeralKeySource(
   ephemeral_key_source_.reset(ephemeral_key_source);
 }
 
-void QuicCryptoServerConfig::SetStrikeRegisterClient(
-    StrikeRegisterClient* strike_register_client) {
-  base::AutoLock locker(strike_register_client_lock_);
-  DCHECK(!strike_register_client_.get());
-  strike_register_client_.reset(strike_register_client);
-}
-
 void QuicCryptoServerConfig::set_replay_protection(bool on) {
   replay_protection_ = on;
 }
@@ -1773,26 +1799,6 @@ void QuicCryptoServerConfig::set_chlo_multiplier(size_t multiplier) {
   chlo_multiplier_ = multiplier;
 }
 
-void QuicCryptoServerConfig::set_strike_register_no_startup_period() {
-  base::AutoLock locker(strike_register_client_lock_);
-  DCHECK(!strike_register_client_.get());
-  strike_register_no_startup_period_ = true;
-}
-
-void QuicCryptoServerConfig::set_strike_register_max_entries(
-    uint32_t max_entries) {
-  base::AutoLock locker(strike_register_client_lock_);
-  DCHECK(!strike_register_client_.get());
-  strike_register_max_entries_ = max_entries;
-}
-
-void QuicCryptoServerConfig::set_strike_register_window_secs(
-    uint32_t window_secs) {
-  base::AutoLock locker(strike_register_client_lock_);
-  DCHECK(!strike_register_client_.get());
-  strike_register_window_secs_ = window_secs;
-}
-
 void QuicCryptoServerConfig::set_source_address_token_future_secs(
     uint32_t future_secs) {
   source_address_token_future_secs_ = future_secs;
@@ -1803,18 +1809,6 @@ void QuicCryptoServerConfig::set_source_address_token_lifetime_secs(
   source_address_token_lifetime_secs_ = lifetime_secs;
 }
 
-void QuicCryptoServerConfig::set_server_nonce_strike_register_max_entries(
-    uint32_t max_entries) {
-  DCHECK(!server_nonce_strike_register_.get());
-  server_nonce_strike_register_max_entries_ = max_entries;
-}
-
-void QuicCryptoServerConfig::set_server_nonce_strike_register_window_secs(
-    uint32_t window_secs) {
-  DCHECK(!server_nonce_strike_register_.get());
-  server_nonce_strike_register_window_secs_ = window_secs;
-}
-
 void QuicCryptoServerConfig::set_enable_serving_sct(bool enable_serving_sct) {
   enable_serving_sct_ = enable_serving_sct;
 }
@@ -1828,13 +1822,13 @@ void QuicCryptoServerConfig::AcquirePrimaryConfigChangedCb(
 string QuicCryptoServerConfig::NewSourceAddressToken(
     const Config& config,
     const SourceAddressTokens& previous_tokens,
-    const IPAddress& ip,
+    const QuicIpAddress& ip,
     QuicRandom* rand,
     QuicWallTime now,
     const CachedNetworkParameters* cached_network_params) const {
   SourceAddressTokens source_address_tokens;
   SourceAddressToken* source_address_token = source_address_tokens.add_tokens();
-  source_address_token->set_ip(IPAddressToPackedString(DualstackIPAddress(ip)));
+  source_address_token->set_ip(ip.DualStacked().ToPackedString());
   source_address_token->set_timestamp(now.ToUNIXSeconds());
   if (cached_network_params != nullptr) {
     *(source_address_token->mutable_cached_network_parameters()) =
@@ -1895,7 +1889,7 @@ HandshakeFailureReason QuicCryptoServerConfig::ParseSourceAddressToken(
 
 HandshakeFailureReason QuicCryptoServerConfig::ValidateSourceAddressTokens(
     const SourceAddressTokens& source_address_tokens,
-    const IPAddress& ip,
+    const QuicIpAddress& ip,
     QuicWallTime now,
     CachedNetworkParameters* cached_network_params) const {
   HandshakeFailureReason reason =
@@ -1914,10 +1908,9 @@ HandshakeFailureReason QuicCryptoServerConfig::ValidateSourceAddressTokens(
 
 HandshakeFailureReason QuicCryptoServerConfig::ValidateSingleSourceAddressToken(
     const SourceAddressToken& source_address_token,
-    const IPAddress& ip,
+    const QuicIpAddress& ip,
     QuicWallTime now) const {
-  if (source_address_token.ip() !=
-      IPAddressToPackedString(DualstackIPAddress(ip))) {
+  if (source_address_token.ip() != ip.DualStacked().ToPackedString()) {
     // It's for a different IP address.
     return SOURCE_ADDRESS_TOKEN_DIFFERENT_IP_ADDRESS_FAILURE;
   }
@@ -1969,70 +1962,10 @@ string QuicCryptoServerConfig::NewServerNonce(QuicRandom* rand,
       StringPiece(reinterpret_cast<char*>(server_nonce), sizeof(server_nonce)));
 }
 
-HandshakeFailureReason QuicCryptoServerConfig::ValidateServerNonce(
-    StringPiece token,
-    QuicWallTime now) const {
-  string storage;
-  StringPiece plaintext;
-  if (!server_nonce_boxer_.Unbox(token, &storage, &plaintext)) {
-    return SERVER_NONCE_DECRYPTION_FAILURE;
-  }
-
-  // plaintext contains:
-  //   uint32_t timestamp
-  //   uint8_t[20] random bytes
-
-  if (plaintext.size() != kServerNoncePlaintextSize) {
-    // This should never happen because the value decrypted correctly.
-    QUIC_BUG << "Seemingly valid server nonce had incorrect length.";
-    return SERVER_NONCE_INVALID_FAILURE;
-  }
-
-  uint8_t server_nonce[32];
-  memcpy(server_nonce, plaintext.data(), 4);
-  memcpy(server_nonce + 4, server_nonce_orbit_, sizeof(server_nonce_orbit_));
-  memcpy(server_nonce + 4 + sizeof(server_nonce_orbit_), plaintext.data() + 4,
-         20);
-  static_assert(4 + sizeof(server_nonce_orbit_) + 20 == sizeof(server_nonce),
-                "bad nonce buffer length");
-
-  InsertStatus nonce_error;
-  {
-    base::AutoLock auto_lock(server_nonce_strike_register_lock_);
-    if (server_nonce_strike_register_.get() == nullptr) {
-      server_nonce_strike_register_.reset(new StrikeRegister(
-          server_nonce_strike_register_max_entries_,
-          static_cast<uint32_t>(now.ToUNIXSeconds()),
-          server_nonce_strike_register_window_secs_, server_nonce_orbit_,
-          StrikeRegister::NO_STARTUP_PERIOD_NEEDED));
-    }
-    nonce_error = server_nonce_strike_register_->Insert(
-        server_nonce, static_cast<uint32_t>(now.ToUNIXSeconds()));
-  }
-
-  switch (nonce_error) {
-    case NONCE_OK:
-      return HANDSHAKE_OK;
-    case NONCE_INVALID_FAILURE:
-    case NONCE_INVALID_ORBIT_FAILURE:
-      return SERVER_NONCE_INVALID_FAILURE;
-    case NONCE_NOT_UNIQUE_FAILURE:
-      return SERVER_NONCE_NOT_UNIQUE_FAILURE;
-    case NONCE_INVALID_TIME_FAILURE:
-      return SERVER_NONCE_INVALID_TIME_FAILURE;
-    case NONCE_UNKNOWN_FAILURE:
-    case STRIKE_REGISTER_TIMEOUT:
-    case STRIKE_REGISTER_FAILURE:
-    default:
-      QUIC_BUG << "Unexpected server nonce error: " << nonce_error;
-      return SERVER_NONCE_NOT_UNIQUE_FAILURE;
-  }
-}
-
 bool QuicCryptoServerConfig::ValidateExpectedLeafCertificate(
     const CryptoHandshakeMessage& client_hello,
-    const QuicCryptoProof& crypto_proof) const {
-  if (crypto_proof.chain->certs.empty()) {
+    const QuicSignedServerConfig& signed_config) const {
+  if (signed_config.chain->certs.empty()) {
     return false;
   }
 
@@ -2040,7 +1973,7 @@ bool QuicCryptoServerConfig::ValidateExpectedLeafCertificate(
   if (client_hello.GetUint64(kXLCT, &hash_from_client) != QUIC_NO_ERROR) {
     return false;
   }
-  return CryptoUtils::ComputeLeafCertHash(crypto_proof.chain->certs.at(0)) ==
+  return CryptoUtils::ComputeLeafCertHash(signed_config.chain->certs.at(0)) ==
          hash_from_client;
 }
 
@@ -2072,9 +2005,9 @@ QuicCryptoServerConfig::Config::Config()
       source_address_token_boxer(nullptr) {}
 
 QuicCryptoServerConfig::Config::~Config() {
-  base::STLDeleteElements(&key_exchanges);
 }
 
-QuicCryptoProof::QuicCryptoProof() {}
-QuicCryptoProof::~QuicCryptoProof() {}
+QuicSignedServerConfig::QuicSignedServerConfig() {}
+QuicSignedServerConfig::~QuicSignedServerConfig() {}
+
 }  // namespace net
diff --git a/src/net/quic/core/crypto/quic_crypto_server_config.h b/src/net/quic/core/crypto/quic_crypto_server_config.h
index b0d03e2..0da8834 100644
--- a/src/net/quic/core/crypto/quic_crypto_server_config.h
+++ b/src/net/quic/core/crypto/quic_crypto_server_config.h
@@ -26,9 +26,11 @@
 #include "net/quic/core/crypto/crypto_secret_boxer.h"
 #include "net/quic/core/crypto/proof_source.h"
 #include "net/quic/core/crypto/quic_compressed_certs_cache.h"
+#include "net/quic/core/crypto/quic_crypto_proof.h"
 #include "net/quic/core/proto/cached_network_parameters.pb.h"
 #include "net/quic/core/proto/source_address_token.pb.h"
 #include "net/quic/core/quic_time.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 
 namespace net {
 
@@ -37,23 +39,19 @@ class EphemeralKeySource;
 class KeyExchange;
 class ProofSource;
 class QuicClock;
-class QuicDecrypter;
-class QuicEncrypter;
 class QuicRandom;
 class QuicServerConfigProtobuf;
-class StrikeRegister;
-class StrikeRegisterClient;
-struct QuicCryptoProof;
+struct QuicSignedServerConfig;
 
 // ClientHelloInfo contains information about a client hello message that is
 // only kept for as long as it's being processed.
 struct ClientHelloInfo {
-  ClientHelloInfo(const IPAddress& in_client_ip, QuicWallTime in_now);
+  ClientHelloInfo(const QuicIpAddress& in_client_ip, QuicWallTime in_now);
   ClientHelloInfo(const ClientHelloInfo& other);
   ~ClientHelloInfo();
 
   // Inputs to EvaluateClientHello.
-  const IPAddress client_ip;
+  const QuicIpAddress client_ip;
   const QuicWallTime now;
 
   // Outputs from EvaluateClientHello.
@@ -89,11 +87,10 @@ class NET_EXPORT_PRIVATE ValidateClientHelloResultCallback {
  public:
   // Opaque token that holds information about the client_hello and
   // its validity.  Can be interpreted by calling ProcessClientHello.
-  struct NET_EXPORT_PRIVATE Result {
+  struct NET_EXPORT_PRIVATE Result : public base::RefCountedThreadSafe<Result> {
     Result(const CryptoHandshakeMessage& in_client_hello,
-           IPAddress in_client_ip,
+           QuicIpAddress in_client_ip,
            QuicWallTime in_now);
-    ~Result();
 
     CryptoHandshakeMessage client_hello;
     ClientHelloInfo info;
@@ -102,17 +99,36 @@ class NET_EXPORT_PRIVATE ValidateClientHelloResultCallback {
 
     // Populated if the CHLO STK contained a CachedNetworkParameters proto.
     CachedNetworkParameters cached_network_params;
+
+   private:
+    friend class base::RefCountedThreadSafe<Result>;
+    ~Result();
   };
 
   ValidateClientHelloResultCallback();
-  virtual ~ValidateClientHelloResultCallback();
-  virtual void Run(std::unique_ptr<Result> result,
+  virtual void Run(scoped_refptr<Result> result,
                    std::unique_ptr<ProofSource::Details> details) = 0;
+  virtual ~ValidateClientHelloResultCallback();
 
  private:
   DISALLOW_COPY_AND_ASSIGN(ValidateClientHelloResultCallback);
 };
 
+// Callback used to accept the result of the ProcessClientHello method.
+class NET_EXPORT_PRIVATE ProcessClientHelloResultCallback {
+ public:
+  ProcessClientHelloResultCallback();
+  virtual ~ProcessClientHelloResultCallback();
+  virtual void Run(QuicErrorCode error,
+                   const std::string& error_details,
+                   std::unique_ptr<CryptoHandshakeMessage> message,
+                   std::unique_ptr<DiversificationNonce> diversification_nonce,
+                   std::unique_ptr<ProofSource::Details> details) = 0;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(ProcessClientHelloResultCallback);
+};
+
 // Callback used to receive the results of a call to
 // BuildServerConfigUpdateMessage.
 class BuildServerConfigUpdateMessageResultCallback {
@@ -125,6 +141,20 @@ class BuildServerConfigUpdateMessageResultCallback {
   DISALLOW_COPY_AND_ASSIGN(BuildServerConfigUpdateMessageResultCallback);
 };
 
+// Object that is interested in built rejections (which include REJ, SREJ and
+// cheap SREJ).
+class RejectionObserver {
+ public:
+  RejectionObserver() = default;
+  virtual ~RejectionObserver() {}
+  // Called after a rejection is built.
+  virtual void OnRejectionBuilt(const std::vector<uint32_t>& reasons,
+                                CryptoHandshakeMessage* out) const = 0;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(RejectionObserver);
+};
+
 // QuicCryptoServerConfig contains the crypto configuration of a QUIC server.
 // Unlike a client, a QUIC server can have multiple configurations active in
 // order to support clients resuming with a previous configuration.
@@ -178,17 +208,19 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
 
   // Generates a QuicServerConfigProtobuf protobuf suitable for
   // AddConfig and SetConfigs.
-  static QuicServerConfigProtobuf* GenerateConfig(QuicRandom* rand,
-                                                  const QuicClock* clock,
-                                                  const ConfigOptions& options);
+  static std::unique_ptr<QuicServerConfigProtobuf> GenerateConfig(
+      QuicRandom* rand,
+      const QuicClock* clock,
+      const ConfigOptions& options);
 
-  // AddConfig adds a QuicServerConfigProtobuf to the availible configurations.
+  // AddConfig adds a QuicServerConfigProtobuf to the available configurations.
   // It returns the SCFG message from the config if successful. The caller
   // takes ownership of the CryptoHandshakeMessage. |now| is used in
   // conjunction with |protobuf->primary_time()| to determine whether the
   // config should be made primary.
-  CryptoHandshakeMessage* AddConfig(QuicServerConfigProtobuf* protobuf,
-                                    QuicWallTime now);
+  CryptoHandshakeMessage* AddConfig(
+      std::unique_ptr<QuicServerConfigProtobuf> protobuf,
+      QuicWallTime now);
 
   // AddDefaultConfig calls DefaultConfig to create a config and then calls
   // AddConfig to add it. See the comment for |DefaultConfig| for details of
@@ -204,8 +236,9 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // known, but are missing from the protobufs are deleted, unless they are
   // currently the primary config. SetConfigs returns false if any errors were
   // encountered and no changes to the QuicCryptoServerConfig will occur.
-  bool SetConfigs(const std::vector<QuicServerConfigProtobuf*>& protobufs,
-                  QuicWallTime now);
+  bool SetConfigs(
+      const std::vector<std::unique_ptr<QuicServerConfigProtobuf>>& protobufs,
+      QuicWallTime now);
 
   // SetSourceAddressTokenKeys sets the keys to be tried, in order, when
   // decrypting a source address token.  Note that these keys are used *without*
@@ -216,10 +249,10 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // Get the server config ids for all known configs.
   void GetConfigIds(std::vector<std::string>* scids) const;
 
-  // Checks |client_hello| for gross errors and determines whether it
-  // can be shown to be fresh (i.e. not a replay).  The result of the
-  // validation step must be interpreted by calling
-  // QuicCryptoServerConfig::ProcessClientHello from the done_cb.
+  // Checks |client_hello| for gross errors and determines whether it can be
+  // shown to be fresh (i.e. not a replay).  The result of the validation step
+  // must be interpreted by calling QuicCryptoServerConfig::ProcessClientHello
+  // from the done_cb.
   //
   // ValidateClientHello may invoke the done_cb before unrolling the
   // stack if it is able to assess the validity of the client_nonce
@@ -228,12 +261,13 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // client_hello: the incoming client hello message.
   // client_ip: the IP address of the client, which is used to generate and
   //     validate source-address tokens.
-  // server_ip: the IP address of the server. The IP address may be used for
-  //     certificate selection.
+  // server_address: the IP address and port of the server. The IP address and
+  //     port may be used for certificate selection.
   // version: protocol version used for this connection.
   // clock: used to validate client nonces and ephemeral keys.
-  // crypto_proof: output structure containing the crypto proof used in reply to
-  //     a proof demand.
+  // crypto_proof: in/out parameter to which will be written the crypto proof
+  //               used in reply to a proof demand.  The pointed-to-object must
+  //               live until the callback is invoked.
   // done_cb: single-use callback that accepts an opaque
   //     ValidatedClientHelloMsg token that holds information about
   //     the client hello.  The callback will always be called exactly
@@ -241,18 +275,17 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   //     completion of an asynchronous operation.
   void ValidateClientHello(
       const CryptoHandshakeMessage& client_hello,
-      const IPAddress& client_ip,
-      const IPAddress& server_ip,
+      const QuicIpAddress& client_ip,
+      const QuicSocketAddress& server_address,
       QuicVersion version,
       const QuicClock* clock,
-      QuicCryptoProof* crypto_proof,
+      scoped_refptr<QuicSignedServerConfig> crypto_proof,
       std::unique_ptr<ValidateClientHelloResultCallback> done_cb) const;
 
   // ProcessClientHello processes |client_hello| and decides whether to accept
-  // or reject the connection. If the connection is to be accepted, |out| is
-  // set to the contents of the ServerHello, |out_params| is completed and
-  // QUIC_NO_ERROR is returned. Otherwise |out| is set to be a REJ or SREJ
-  // message and QUIC_NO_ERROR is returned.
+  // or reject the connection. If the connection is to be accepted, |done_cb| is
+  // invoked with the contents of the ServerHello and QUIC_NO_ERROR. Otherwise
+  // |done_cb| is called with a REJ or SREJ message and QUIC_NO_ERROR.
   //
   // validate_chlo_result: Output from the asynchronous call to
   //     ValidateClientHello.  Contains the client hello message and
@@ -272,24 +305,19 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // compressed_certs_cache: the cache that caches a set of most recently used
   //     certs. Owned by QuicDispatcher.
   // params: the state of the handshake. This may be updated with a server
-  //     nonce when we send a rejection. After a successful handshake, this will
-  //     contain the state of the connection.
+  //     nonce when we send a rejection.
   // crypto_proof: output structure containing the crypto proof used in reply to
   //     a proof demand.
   // total_framing_overhead: the total per-packet overhead for a stream frame
   // chlo_packet_size: the size, in bytes, of the CHLO packet
-  // out: the resulting handshake message (either REJ or SHLO)
-  // out_diversification_nonce: If the resulting handshake message is SHLO and
-  //     the version is greater than QUIC_VERSION_32 then this contains a
-  //     32-byte value that should be included in the public header of
-  //     initially encrypted packets.
-  // error_details: used to store a std::string describing any error.
-  QuicErrorCode ProcessClientHello(
-      const ValidateClientHelloResultCallback::Result& validate_chlo_result,
+  // done_cb: the callback invoked on completion
+  void ProcessClientHello(
+      scoped_refptr<ValidateClientHelloResultCallback::Result>
+          validate_chlo_result,
       bool reject_only,
       QuicConnectionId connection_id,
-      const IPAddress& server_ip,
-      const IPEndPoint& client_address,
+      const QuicSocketAddress& server_address,
+      const QuicSocketAddress& client_address,
       QuicVersion version,
       const QuicVersionVector& supported_versions,
       bool use_stateless_rejects,
@@ -297,13 +325,11 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
       const QuicClock* clock,
       QuicRandom* rand,
       QuicCompressedCertsCache* compressed_certs_cache,
-      QuicCryptoNegotiatedParameters* params,
-      QuicCryptoProof* crypto_proof,
+      scoped_refptr<QuicCryptoNegotiatedParameters> params,
+      scoped_refptr<QuicSignedServerConfig> crypto_proof,
       QuicByteCount total_framing_overhead,
       QuicByteCount chlo_packet_size,
-      CryptoHandshakeMessage* out,
-      DiversificationNonce* out_diversification_nonce,
-      std::string* error_details) const;
+      std::unique_ptr<ProcessClientHelloResultCallback> done_cb) const;
 
   // BuildServerConfigUpdateMessage sets |out| to be a SCUP message containing
   // the current primary config, an up to date source-address token, and cert
@@ -317,13 +343,14 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
       QuicVersion version,
       base::StringPiece chlo_hash,
       const SourceAddressTokens& previous_source_address_tokens,
-      const IPAddress& server_ip,
-      const IPAddress& client_ip,
+      const QuicSocketAddress& server_address,
+      const QuicIpAddress& client_ip,
       const QuicClock* clock,
       QuicRandom* rand,
       QuicCompressedCertsCache* compressed_certs_cache,
       const QuicCryptoNegotiatedParameters& params,
       const CachedNetworkParameters* cached_network_params,
+      const QuicTagVector& connection_options,
       CryptoHandshakeMessage* out) const;
 
   // BuildServerConfigUpdateMessage invokes |cb| with a SCUP message containing
@@ -340,13 +367,14 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
       QuicVersion version,
       base::StringPiece chlo_hash,
       const SourceAddressTokens& previous_source_address_tokens,
-      const IPAddress& server_ip,
-      const IPAddress& client_ip,
+      const QuicSocketAddress& server_address,
+      const QuicIpAddress& client_ip,
       const QuicClock* clock,
       QuicRandom* rand,
       QuicCompressedCertsCache* compressed_certs_cache,
       const QuicCryptoNegotiatedParameters& params,
       const CachedNetworkParameters* cached_network_params,
+      const QuicTagVector& connection_options,
       std::unique_ptr<BuildServerConfigUpdateMessageResultCallback> cb) const;
 
   // SetEphemeralKeySource installs an object that can cache ephemeral keys for
@@ -355,11 +383,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // per-connection.
   void SetEphemeralKeySource(EphemeralKeySource* ephemeral_key_source);
 
-  // Install an externall created StrikeRegisterClient for use to
-  // interact with the strike register.  This object takes ownership
-  // of the |strike_register_client|.
-  void SetStrikeRegisterClient(StrikeRegisterClient* strike_register_client);
-
   // set_replay_protection controls whether replay protection is enabled. If
   // replay protection is disabled then no strike registers are needed and
   // frontends can share an orbit value without a shared strike-register.
@@ -372,21 +395,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // valid source-address token.
   void set_chlo_multiplier(size_t multiplier);
 
-  // set_strike_register_no_startup_period configures the strike register to
-  // not have a startup period.
-  void set_strike_register_no_startup_period();
-
-  // set_strike_register_max_entries sets the maximum number of entries that
-  // the internal strike register will hold. If the strike register fills up
-  // then the oldest entries (by the client's clock) will be dropped.
-  void set_strike_register_max_entries(uint32_t max_entries);
-
-  // set_strike_register_window_secs sets the number of seconds around the
-  // current time that the strike register will attempt to be authoritative
-  // for. Setting a larger value allows for greater client clock-skew, but
-  // means that the quiescent startup period must be longer.
-  void set_strike_register_window_secs(uint32_t window_secs);
-
   // set_source_address_token_future_secs sets the number of seconds into the
   // future that source-address tokens will be accepted from. Since
   // source-address tokens are authenticated, this should only happen if
@@ -397,21 +405,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // source-address token will be valid for.
   void set_source_address_token_lifetime_secs(uint32_t lifetime_secs);
 
-  // set_server_nonce_strike_register_max_entries sets the number of entries in
-  // the server-nonce strike-register. This is used to record that server nonce
-  // values have been used. If the number of entries is too small then clients
-  // which are depending on server nonces may fail to handshake because their
-  // nonce has expired in the amount of time it took to go from the server to
-  // the client and back.
-  void set_server_nonce_strike_register_max_entries(uint32_t max_entries);
-
-  // set_server_nonce_strike_register_window_secs sets the number of seconds
-  // around the current time that the server-nonce strike-register will accept
-  // nonces from. Setting a larger value allows for clients to delay follow-up
-  // client hellos for longer and still use server nonces as proofs of
-  // uniqueness.
-  void set_server_nonce_strike_register_window_secs(uint32_t window_secs);
-
   // set_enable_serving_sct enables or disables serving signed cert timestamp
   // (RFC6962) in server hello.
   void set_enable_serving_sct(bool enable_serving_sct);
@@ -423,9 +416,15 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // Returns the number of configs this object owns.
   int NumberOfConfigs() const;
 
+  // Callers retain the ownership of |rejection_observer| which must outlive the
+  // config.
+  void set_rejection_observer(RejectionObserver* rejection_observer) {
+    rejection_observer_ = rejection_observer;
+  }
+
  private:
   friend class test::QuicCryptoServerConfigPeer;
-  friend struct QuicCryptoProof;
+  friend struct QuicSignedServerConfig;
 
   // Config represents a server config: a collection of preferences and
   // Diffie-Hellman public values.
@@ -448,7 +447,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
     // key_exchanges contains key exchange objects with the private keys
     // already loaded. The values correspond, one-to-one, with the tags in
     // |kexs| from the parent class.
-    std::vector<KeyExchange*> key_exchanges;
+    std::vector<std::unique_ptr<KeyExchange>> key_exchanges;
 
     // tag_value_map contains the raw key/value pairs for the config.
     QuicTagValueMap tag_value_map;
@@ -512,18 +511,18 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // whether it can be shown to be fresh (i.e. not a replay). The results are
   // written to |info|.
   void EvaluateClientHello(
-      const IPAddress& server_ip,
+      const QuicSocketAddress& server_address,
       QuicVersion version,
-      const uint8_t* primary_orbit,
       scoped_refptr<Config> requested_config,
       scoped_refptr<Config> primary_config,
-      QuicCryptoProof* crypto_proof,
-      std::unique_ptr<ValidateClientHelloResultCallback::Result>
+      scoped_refptr<QuicSignedServerConfig> crypto_proof,
+      scoped_refptr<ValidateClientHelloResultCallback::Result>
           client_hello_state,
       std::unique_ptr<ValidateClientHelloResultCallback> done_cb) const;
 
   // Callback class for bridging between EvaluateClientHello and
-  // EvaluateClientHelloAfterGetProof
+  // EvaluateClientHelloAfterGetProof.
+  class EvaluateClientHelloCallback;
   friend class EvaluateClientHelloCallback;
 
   // Continuation of EvaluateClientHello after the call to
@@ -533,18 +532,45 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // set to false.
   void EvaluateClientHelloAfterGetProof(
       bool found_error,
-      const IPAddress& server_ip,
+      const QuicIpAddress& server_ip,
       QuicVersion version,
-      const uint8_t* primary_orbit,
       scoped_refptr<Config> requested_config,
       scoped_refptr<Config> primary_config,
-      QuicCryptoProof* crypto_proof,
+      scoped_refptr<QuicSignedServerConfig> crypto_proof,
       std::unique_ptr<ProofSource::Details> proof_source_details,
       bool get_proof_failed,
-      std::unique_ptr<ValidateClientHelloResultCallback::Result>
+      scoped_refptr<ValidateClientHelloResultCallback::Result>
           client_hello_state,
       std::unique_ptr<ValidateClientHelloResultCallback> done_cb) const;
 
+  // Callback class for bridging between ProcessClientHello and
+  // ProcessClientHelloAfterGetProof.
+  class ProcessClientHelloCallback;
+  friend class ProcessClientHelloCallback;
+
+  // Portion of ProcessClientHello which executes after GetProof.
+  void ProcessClientHelloAfterGetProof(
+      bool found_error,
+      std::unique_ptr<ProofSource::Details> proof_source_details,
+      const ValidateClientHelloResultCallback::Result& validate_chlo_result,
+      bool reject_only,
+      QuicConnectionId connection_id,
+      const QuicSocketAddress& client_address,
+      QuicVersion version,
+      const QuicVersionVector& supported_versions,
+      bool use_stateless_rejects,
+      QuicConnectionId server_designated_connection_id,
+      const QuicClock* clock,
+      QuicRandom* rand,
+      QuicCompressedCertsCache* compressed_certs_cache,
+      scoped_refptr<QuicCryptoNegotiatedParameters> params,
+      scoped_refptr<QuicSignedServerConfig> crypto_proof,
+      QuicByteCount total_framing_overhead,
+      QuicByteCount chlo_packet_size,
+      const scoped_refptr<Config>& requested_config,
+      const scoped_refptr<Config>& primary_config,
+      std::unique_ptr<ProcessClientHelloResultCallback> done_cb) const;
+
   // BuildRejection sets |out| to be a REJ message in reply to |client_hello|.
   void BuildRejection(QuicVersion version,
                       QuicWallTime now,
@@ -556,8 +582,8 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
                       QuicConnectionId server_designated_connection_id,
                       QuicRandom* rand,
                       QuicCompressedCertsCache* compressed_certs_cache,
-                      QuicCryptoNegotiatedParameters* params,
-                      const QuicCryptoProof& crypto_proof,
+                      scoped_refptr<QuicCryptoNegotiatedParameters> params,
+                      const QuicSignedServerConfig& crypto_proof,
                       QuicByteCount total_framing_overhead,
                       QuicByteCount chlo_packet_size,
                       CryptoHandshakeMessage* out) const;
@@ -577,14 +603,15 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // ParseConfigProtobuf parses the given config protobuf and returns a
   // scoped_refptr<Config> if successful. The caller adopts the reference to the
   // Config. On error, ParseConfigProtobuf returns nullptr.
-  scoped_refptr<Config> ParseConfigProtobuf(QuicServerConfigProtobuf* protobuf);
+  scoped_refptr<Config> ParseConfigProtobuf(
+      const std::unique_ptr<QuicServerConfigProtobuf>& protobuf);
 
   // NewSourceAddressToken returns a fresh source address token for the given
   // IP address. |cached_network_params| is optional, and can be nullptr.
   std::string NewSourceAddressToken(
       const Config& config,
       const SourceAddressTokens& previous_tokens,
-      const IPAddress& ip,
+      const QuicIpAddress& ip,
       QuicRandom* rand,
       QuicWallTime now,
       const CachedNetworkParameters* cached_network_params) const;
@@ -605,7 +632,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // token contains a CachedNetworkParameters proto.
   HandshakeFailureReason ValidateSourceAddressTokens(
       const SourceAddressTokens& tokens,
-      const IPAddress& ip,
+      const QuicIpAddress& ip,
       QuicWallTime now,
       CachedNetworkParameters* cached_network_params) const;
 
@@ -615,7 +642,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // for failure.
   HandshakeFailureReason ValidateSingleSourceAddressToken(
       const SourceAddressToken& token,
-      const IPAddress& ip,
+      const QuicIpAddress& ip,
       QuicWallTime now) const;
 
   // Returns HANDSHAKE_OK if the source address token in |token| is a timely
@@ -628,15 +655,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // NewServerNonce generates and encrypts a random nonce.
   std::string NewServerNonce(QuicRandom* rand, QuicWallTime now) const;
 
-  // ValidateServerNonce decrypts |token| and verifies that it hasn't been
-  // previously used and is recent enough that it is plausible that it was part
-  // of a very recently provided rejection ("recent" will be on the order of
-  // 10-30 seconds). If so, it records that it has been used and returns
-  // HANDSHAKE_OK. Otherwise it returns the reason for failure.
-  HandshakeFailureReason ValidateServerNonce(
-      base::StringPiece echoed_server_nonce,
-      QuicWallTime now) const;
-
   // ValidateExpectedLeafCertificate checks the |client_hello| to see if it has
   // an XLCT tag, and if so, verifies that its value matches the hash of the
   // server's leaf certificate. The certs field of |crypto_proof| is used to
@@ -645,7 +663,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // otherwise.
   bool ValidateExpectedLeafCertificate(
       const CryptoHandshakeMessage& client_hello,
-      const QuicCryptoProof& crypto_proof) const;
+      const QuicSignedServerConfig& crypto_proof) const;
 
   // Returns true if the PDMD field from the client hello demands an X509
   // certificate.
@@ -674,8 +692,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
 
     void Run(bool ok,
              const scoped_refptr<ProofSource::Chain>& chain,
-             const std::string& signature,
-             const std::string& leaf_cert_sct,
+             const QuicCryptoProof& proof,
              std::unique_ptr<ProofSource::Details> details) override;
 
    private:
@@ -734,12 +751,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // Callback to invoke when the primary config changes.
   std::unique_ptr<PrimaryConfigChangedCallback> primary_config_changed_cb_;
 
-  // Protects access to the pointer held by strike_register_client_.
-  mutable base::Lock strike_register_client_lock_;
-  // strike_register_ contains a data structure that keeps track of previously
-  // observed client nonces in order to prevent replay attacks.
-  mutable std::unique_ptr<StrikeRegisterClient> strike_register_client_;
-
   // Used to protect the source-address tokens that are given to clients.
   CryptoSecretBoxer source_address_token_boxer_;
 
@@ -752,12 +763,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
   // cookies).
   uint8_t server_nonce_orbit_[8];
 
-  mutable base::Lock server_nonce_strike_register_lock_;
-  // server_nonce_strike_register_ contains a data structure that keeps track of
-  // previously observed server nonces from this server, in order to prevent
-  // replay attacks.
-  mutable std::unique_ptr<StrikeRegister> server_nonce_strike_register_;
-
   // proof_source_ contains an object that can provide certificate chains and
   // signatures.
   std::unique_ptr<ProofSource> proof_source_;
@@ -768,31 +773,32 @@ class NET_EXPORT_PRIVATE QuicCryptoServerConfig {
 
   // These fields store configuration values. See the comments for their
   // respective setter functions.
-  bool strike_register_no_startup_period_;
-  uint32_t strike_register_max_entries_;
-  uint32_t strike_register_window_secs_;
   uint32_t source_address_token_future_secs_;
   uint32_t source_address_token_lifetime_secs_;
-  uint32_t server_nonce_strike_register_max_entries_;
-  uint32_t server_nonce_strike_register_window_secs_;
 
   // Enable serving SCT or not.
   bool enable_serving_sct_;
 
+  // Does not own this observer.
+  RejectionObserver* rejection_observer_;
+
   DISALLOW_COPY_AND_ASSIGN(QuicCryptoServerConfig);
 };
 
-struct NET_EXPORT_PRIVATE QuicCryptoProof {
-  QuicCryptoProof();
-  ~QuicCryptoProof();
+struct NET_EXPORT_PRIVATE QuicSignedServerConfig
+    : public base::RefCounted<QuicSignedServerConfig> {
+  QuicSignedServerConfig();
 
-  std::string signature;
+  QuicCryptoProof proof;
   scoped_refptr<ProofSource::Chain> chain;
-  std::string cert_sct;
   // The server config that is used for this proof (and the rest of the
   // request).
   scoped_refptr<QuicCryptoServerConfig::Config> config;
   std::string primary_scid;
+
+ private:
+  friend class base::RefCounted<QuicSignedServerConfig>;
+  virtual ~QuicSignedServerConfig();
 };
 
 }  // namespace net
diff --git a/src/net/quic/core/crypto/quic_decrypter.h b/src/net/quic/core/crypto/quic_decrypter.h
index 0a5eea3..e620259 100644
--- a/src/net/quic/core/crypto/quic_decrypter.h
+++ b/src/net/quic/core/crypto/quic_decrypter.h
@@ -9,7 +9,7 @@
 #include <stdint.h>
 
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/crypto/quic_encrypter.h b/src/net/quic/core/crypto/quic_encrypter.h
index fefd777..69f340d 100644
--- a/src/net/quic/core/crypto/quic_encrypter.h
+++ b/src/net/quic/core/crypto/quic_encrypter.h
@@ -8,7 +8,7 @@
 #include <stddef.h>
 
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/crypto/scoped_evp_aead_ctx.h b/src/net/quic/core/crypto/scoped_evp_aead_ctx.h
index d8067fc..afb5861 100644
--- a/src/net/quic/core/crypto/scoped_evp_aead_ctx.h
+++ b/src/net/quic/core/crypto/scoped_evp_aead_ctx.h
@@ -5,9 +5,8 @@
 #ifndef NET_QUIC_CRYPTO_SCOPED_EVP_AEAD_CTX_H_
 #define NET_QUIC_CRYPTO_SCOPED_EVP_AEAD_CTX_H_
 
-#include <openssl/evp.h>
-
 #include "base/macros.h"
+#include "third_party/boringssl/src/include/openssl/evp.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/crypto/strike_register.cc b/src/net/quic/core/crypto/strike_register.cc
deleted file mode 100644
index 5bfb07c..0000000
--- a/src/net/quic/core/crypto/strike_register.cc
+++ /dev/null
@@ -1,519 +0,0 @@
-// Copyright (c) 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "net/quic/core/crypto/strike_register.h"
-
-#include <algorithm>
-#include <limits>
-
-#include "base/logging.h"
-
-using std::pair;
-using std::set;
-using std::vector;
-
-namespace net {
-
-namespace {
-
-uint32_t GetInitialHorizon(uint32_t current_time_internal,
-                           uint32_t window_secs,
-                           StrikeRegister::StartupType startup) {
-  if (startup == StrikeRegister::DENY_REQUESTS_AT_STARTUP) {
-    // The horizon is initially set |window_secs| into the future because, if
-    // we just crashed, then we may have accepted nonces in the span
-    // [current_time...current_time+window_secs] and so we conservatively
-    // reject the whole timespan unless |startup| tells us otherwise.
-    return current_time_internal + window_secs + 1;
-  } else {  // startup == StrikeRegister::NO_STARTUP_PERIOD_NEEDED
-    // The orbit can be assumed to be globally unique.  Use a horizon
-    // in the past.
-    return 0;
-  }
-}
-
-}  // namespace
-
-// static
-const uint32_t StrikeRegister::kExternalNodeSize = 24;
-// static
-const uint32_t StrikeRegister::kNil = (1u << 31) | 1;
-// static
-const uint32_t StrikeRegister::kExternalFlag = 1 << 23;
-
-// InternalNode represents a non-leaf node in the critbit tree. See the comment
-// in the .h file for details.
-class StrikeRegister::InternalNode {
- public:
-  void SetChild(unsigned direction, uint32_t child) {
-    data_[direction] = (data_[direction] & 0xff) | (child << 8);
-  }
-
-  void SetCritByte(uint8_t critbyte) {
-    data_[0] = (data_[0] & 0xffffff00) | critbyte;
-  }
-
-  void SetOtherBits(uint8_t otherbits) {
-    data_[1] = (data_[1] & 0xffffff00) | otherbits;
-  }
-
-  void SetNextPtr(uint32_t next) { data_[0] = next; }
-
-  uint32_t next() const { return data_[0]; }
-
-  uint32_t child(unsigned n) const { return data_[n] >> 8; }
-
-  uint8_t critbyte() const { return static_cast<uint8_t>(data_[0]); }
-
-  uint8_t otherbits() const { return static_cast<uint8_t>(data_[1]); }
-
-  // These bytes are organised thus:
-  //   <24 bits> left child
-  //   <8 bits> crit-byte
-  //   <24 bits> right child
-  //   <8 bits> other-bits
-  uint32_t data_[2];
-};
-
-// kCreationTimeFromInternalEpoch contains the number of seconds between the
-// start of the internal epoch and the creation time. This allows us
-// to consider times that are before the creation time.
-static const uint32_t kCreationTimeFromInternalEpoch = 63115200;  // 2 years.
-
-void StrikeRegister::ValidateStrikeRegisterConfig(unsigned max_entries) {
-  // We only have 23 bits of index available.
-  CHECK_LT(max_entries, 1u << 23);
-  CHECK_GT(max_entries, 1u);           // There must be at least two entries.
-  CHECK_EQ(sizeof(InternalNode), 8u);  // in case of compiler changes.
-}
-
-StrikeRegister::StrikeRegister(unsigned max_entries,
-                               uint32_t current_time,
-                               uint32_t window_secs,
-                               const uint8_t orbit[8],
-                               StartupType startup)
-    : max_entries_(max_entries),
-      window_secs_(window_secs),
-      internal_epoch_(current_time > kCreationTimeFromInternalEpoch
-                          ? current_time - kCreationTimeFromInternalEpoch
-                          : 0),
-      horizon_(GetInitialHorizon(ExternalTimeToInternal(current_time),
-                                 window_secs,
-                                 startup)) {
-  memcpy(orbit_, orbit, sizeof(orbit_));
-
-  ValidateStrikeRegisterConfig(max_entries);
-  internal_nodes_ = new InternalNode[max_entries];
-  external_nodes_.reset(new uint8_t[kExternalNodeSize * max_entries]);
-
-  Reset();
-}
-
-StrikeRegister::~StrikeRegister() {
-  delete[] internal_nodes_;
-}
-
-void StrikeRegister::Reset() {
-  // Thread a free list through all of the internal nodes.
-  internal_node_free_head_ = 0;
-  for (unsigned i = 0; i < max_entries_ - 1; i++) {
-    internal_nodes_[i].SetNextPtr(i + 1);
-  }
-  internal_nodes_[max_entries_ - 1].SetNextPtr(kNil);
-
-  // Also thread a free list through the external nodes.
-  external_node_free_head_ = 0;
-  for (unsigned i = 0; i < max_entries_ - 1; i++) {
-    external_node_next_ptr(i) = i + 1;
-  }
-  external_node_next_ptr(max_entries_ - 1) = kNil;
-
-  // This is the root of the tree.
-  internal_node_head_ = kNil;
-}
-
-InsertStatus StrikeRegister::Insert(const uint8_t nonce[32],
-                                    uint32_t current_time_external) {
-  // Make space for the insertion if the strike register is full.
-  while (external_node_free_head_ == kNil || internal_node_free_head_ == kNil) {
-    DropOldestNode();
-  }
-
-  const uint32_t current_time = ExternalTimeToInternal(current_time_external);
-
-  // Check to see if the orbit is correct.
-  if (memcmp(nonce + sizeof(current_time), orbit_, sizeof(orbit_))) {
-    return NONCE_INVALID_ORBIT_FAILURE;
-  }
-
-  const uint32_t nonce_time = ExternalTimeToInternal(TimeFromBytes(nonce));
-
-  // Check that the timestamp is in the valid range.
-  pair<uint32_t, uint32_t> valid_range =
-      StrikeRegister::GetValidRange(current_time);
-  if (nonce_time < valid_range.first || nonce_time > valid_range.second) {
-    return NONCE_INVALID_TIME_FAILURE;
-  }
-
-  // We strip the orbit out of the nonce.
-  uint8_t value[24];
-  memcpy(value, nonce, sizeof(nonce_time));
-  memcpy(value + sizeof(nonce_time),
-         nonce + sizeof(nonce_time) + sizeof(orbit_),
-         sizeof(value) - sizeof(nonce_time));
-
-  // Find the best match to |value| in the crit-bit tree. The best match is
-  // simply the value which /could/ match |value|, if any does, so we still
-  // need a memcmp to check.
-  uint32_t best_match_index = BestMatch(value);
-  if (best_match_index == kNil) {
-    // Empty tree. Just insert the new value at the root.
-    uint32_t index = GetFreeExternalNode();
-    memcpy(external_node(index), value, sizeof(value));
-    internal_node_head_ = (index | kExternalFlag) << 8;
-    DCHECK_LE(horizon_, nonce_time);
-    return NONCE_OK;
-  }
-
-  const uint8_t* best_match = external_node(best_match_index);
-  if (memcmp(best_match, value, sizeof(value)) == 0) {
-    // We found the value in the tree.
-    return NONCE_NOT_UNIQUE_FAILURE;
-  }
-
-  // We are going to insert a new entry into the tree, so get the nodes now.
-  uint32_t internal_node_index = GetFreeInternalNode();
-  uint32_t external_node_index = GetFreeExternalNode();
-
-  // If we just evicted the best match, then we have to try and match again.
-  // We know that we didn't just empty the tree because we require that
-  // max_entries_ >= 2. Also, we know that it doesn't match because, if it
-  // did, it would have been returned previously.
-  if (external_node_index == best_match_index) {
-    best_match_index = BestMatch(value);
-    best_match = external_node(best_match_index);
-  }
-
-  // Now we need to find the first bit where we differ from |best_match|.
-  uint8_t differing_byte;
-  uint8_t new_other_bits;
-  for (differing_byte = 0; differing_byte < arraysize(value);
-       differing_byte++) {
-    new_other_bits = value[differing_byte] ^ best_match[differing_byte];
-    if (new_other_bits) {
-      break;
-    }
-  }
-
-  // Once we have the XOR the of first differing byte in new_other_bits we need
-  // to find the most significant differing bit. We could do this with a simple
-  // for loop, testing bits 7..0. Instead we fold the bits so that we end up
-  // with a byte where all the bits below the most significant one, are set.
-  new_other_bits |= new_other_bits >> 1;
-  new_other_bits |= new_other_bits >> 2;
-  new_other_bits |= new_other_bits >> 4;
-  // Now this bit trick results in all the bits set, except the original
-  // most-significant one.
-  new_other_bits = (new_other_bits & ~(new_other_bits >> 1)) ^ 255;
-
-  // Consider the effect of ORing against |new_other_bits|. If |value| did not
-  // have the critical bit set, the result is the same as |new_other_bits|. If
-  // it did, the result is all ones.
-
-  unsigned newdirection;
-  if ((new_other_bits | value[differing_byte]) == 0xff) {
-    newdirection = 1;
-  } else {
-    newdirection = 0;
-  }
-
-  memcpy(external_node(external_node_index), value, sizeof(value));
-  InternalNode* inode = &internal_nodes_[internal_node_index];
-
-  inode->SetChild(newdirection, external_node_index | kExternalFlag);
-  inode->SetCritByte(differing_byte);
-  inode->SetOtherBits(new_other_bits);
-
-  // |where_index| is a pointer to the uint32_t which needs to be updated in
-  // order to insert the new internal node into the tree. The internal nodes
-  // store the child indexes in the top 24-bits of a 32-bit word and, to keep
-  // the code simple, we define that |internal_node_head_| is organised the
-  // same way.
-  DCHECK_EQ(internal_node_head_ & 0xff, 0u);
-  uint32_t* where_index = &internal_node_head_;
-  while (((*where_index >> 8) & kExternalFlag) == 0) {
-    InternalNode* node = &internal_nodes_[*where_index >> 8];
-    if (node->critbyte() > differing_byte) {
-      break;
-    }
-    if (node->critbyte() == differing_byte &&
-        node->otherbits() > new_other_bits) {
-      break;
-    }
-    if (node->critbyte() == differing_byte &&
-        node->otherbits() == new_other_bits) {
-      CHECK(false);
-    }
-
-    uint8_t c = value[node->critbyte()];
-    const int direction =
-        (1 + static_cast<unsigned>(node->otherbits() | c)) >> 8;
-    where_index = &node->data_[direction];
-  }
-
-  inode->SetChild(newdirection ^ 1, *where_index >> 8);
-  *where_index = (*where_index & 0xff) | (internal_node_index << 8);
-
-  DCHECK_LE(horizon_, nonce_time);
-  return NONCE_OK;
-}
-
-const uint8_t* StrikeRegister::orbit() const {
-  return orbit_;
-}
-
-uint32_t StrikeRegister::GetCurrentValidWindowSecs(
-    uint32_t current_time_external) const {
-  uint32_t current_time = ExternalTimeToInternal(current_time_external);
-  pair<uint32_t, uint32_t> valid_range =
-      StrikeRegister::GetValidRange(current_time);
-  if (valid_range.second >= valid_range.first) {
-    return valid_range.second - current_time + 1;
-  } else {
-    return 0;
-  }
-}
-
-void StrikeRegister::Validate() {
-  set<uint32_t> free_internal_nodes;
-  for (uint32_t i = internal_node_free_head_; i != kNil;
-       i = internal_nodes_[i].next()) {
-    CHECK_LT(i, max_entries_);
-    CHECK_EQ(free_internal_nodes.count(i), 0u);
-    free_internal_nodes.insert(i);
-  }
-
-  set<uint32_t> free_external_nodes;
-  for (uint32_t i = external_node_free_head_; i != kNil;
-       i = external_node_next_ptr(i)) {
-    CHECK_LT(i, max_entries_);
-    CHECK_EQ(free_external_nodes.count(i), 0u);
-    free_external_nodes.insert(i);
-  }
-
-  set<uint32_t> used_external_nodes;
-  set<uint32_t> used_internal_nodes;
-
-  if (internal_node_head_ != kNil &&
-      ((internal_node_head_ >> 8) & kExternalFlag) == 0) {
-    vector<pair<unsigned, bool>> bits;
-    ValidateTree(internal_node_head_ >> 8, -1, bits, free_internal_nodes,
-                 free_external_nodes, &used_internal_nodes,
-                 &used_external_nodes);
-  }
-}
-
-// static
-uint32_t StrikeRegister::TimeFromBytes(const uint8_t d[4]) {
-  return static_cast<uint32_t>(d[0]) << 24 | static_cast<uint32_t>(d[1]) << 16 |
-         static_cast<uint32_t>(d[2]) << 8 | static_cast<uint32_t>(d[3]);
-}
-
-pair<uint32_t, uint32_t> StrikeRegister::GetValidRange(
-    uint32_t current_time_internal) const {
-  if (current_time_internal < horizon_) {
-    // Empty valid range.
-    return std::make_pair(std::numeric_limits<uint32_t>::max(), 0);
-  }
-
-  uint32_t lower_bound;
-  if (current_time_internal >= window_secs_) {
-    lower_bound = std::max(horizon_, current_time_internal - window_secs_);
-  } else {
-    lower_bound = horizon_;
-  }
-
-  // Also limit the upper range based on horizon_.  This makes the
-  // strike register reject inserts that are far in the future and
-  // would consume strike register resources for a long time.  This
-  // allows the strike server to degrade optimally in cases where the
-  // insert rate exceeds |max_entries_ / (2 * window_secs_)| entries
-  // per second.
-  uint32_t upper_bound =
-      current_time_internal +
-      std::min(current_time_internal - horizon_, window_secs_);
-
-  return std::make_pair(lower_bound, upper_bound);
-}
-
-uint32_t StrikeRegister::ExternalTimeToInternal(uint32_t external_time) const {
-  return external_time - internal_epoch_;
-}
-
-uint32_t StrikeRegister::BestMatch(const uint8_t v[24]) const {
-  if (internal_node_head_ == kNil) {
-    return kNil;
-  }
-
-  uint32_t next = internal_node_head_ >> 8;
-  while ((next & kExternalFlag) == 0) {
-    InternalNode* node = &internal_nodes_[next];
-    uint8_t b = v[node->critbyte()];
-    unsigned direction =
-        (1 + static_cast<unsigned>(node->otherbits() | b)) >> 8;
-    next = node->child(direction);
-  }
-
-  return next & ~kExternalFlag;
-}
-
-uint32_t& StrikeRegister::external_node_next_ptr(unsigned i) {
-  return *reinterpret_cast<uint32_t*>(&external_nodes_[i * kExternalNodeSize]);
-}
-
-uint8_t* StrikeRegister::external_node(unsigned i) {
-  return &external_nodes_[i * kExternalNodeSize];
-}
-
-uint32_t StrikeRegister::GetFreeExternalNode() {
-  uint32_t index = external_node_free_head_;
-  DCHECK(index != kNil);
-  external_node_free_head_ = external_node_next_ptr(index);
-  return index;
-}
-
-uint32_t StrikeRegister::GetFreeInternalNode() {
-  uint32_t index = internal_node_free_head_;
-  DCHECK(index != kNil);
-  internal_node_free_head_ = internal_nodes_[index].next();
-  return index;
-}
-
-void StrikeRegister::DropOldestNode() {
-  // DropOldestNode should never be called on an empty tree.
-  DCHECK(internal_node_head_ != kNil);
-
-  // An internal node in a crit-bit tree always has exactly two children.
-  // This means that, if we are removing an external node (which is one of
-  // those children), then we also need to remove an internal node. In order
-  // to do that we keep pointers to the parent (wherep) and grandparent
-  // (whereq) when walking down the tree.
-
-  uint32_t p = internal_node_head_ >> 8, *wherep = &internal_node_head_,
-           *whereq = nullptr;
-  while ((p & kExternalFlag) == 0) {
-    whereq = wherep;
-    InternalNode* inode = &internal_nodes_[p];
-    // We always go left, towards the smallest element, exploiting the fact
-    // that the timestamp is big-endian and at the start of the value.
-    wherep = &inode->data_[0];
-    p = (*wherep) >> 8;
-  }
-
-  const uint32_t ext_index = p & ~kExternalFlag;
-  const uint8_t* ext_node = external_node(ext_index);
-  uint32_t new_horizon = ExternalTimeToInternal(TimeFromBytes(ext_node)) + 1;
-  DCHECK_LE(horizon_, new_horizon);
-  horizon_ = new_horizon;
-
-  if (!whereq) {
-    // We are removing the last element in a tree.
-    internal_node_head_ = kNil;
-    FreeExternalNode(ext_index);
-    return;
-  }
-
-  // |wherep| points to the left child pointer in the parent so we can add
-  // one and dereference to get the right child.
-  const uint32_t other_child = wherep[1];
-  FreeInternalNode((*whereq) >> 8);
-  *whereq = (*whereq & 0xff) | (other_child & 0xffffff00);
-  FreeExternalNode(ext_index);
-}
-
-void StrikeRegister::FreeExternalNode(uint32_t index) {
-  external_node_next_ptr(index) = external_node_free_head_;
-  external_node_free_head_ = index;
-}
-
-void StrikeRegister::FreeInternalNode(uint32_t index) {
-  internal_nodes_[index].SetNextPtr(internal_node_free_head_);
-  internal_node_free_head_ = index;
-}
-
-void StrikeRegister::ValidateTree(uint32_t internal_node,
-                                  int last_bit,
-                                  const vector<pair<unsigned, bool>>& bits,
-                                  const set<uint32_t>& free_internal_nodes,
-                                  const set<uint32_t>& free_external_nodes,
-                                  set<uint32_t>* used_internal_nodes,
-                                  set<uint32_t>* used_external_nodes) {
-  CHECK_LT(internal_node, max_entries_);
-  const InternalNode* i = &internal_nodes_[internal_node];
-  unsigned bit = 0;
-  switch (i->otherbits()) {
-    case 0xff & ~(1 << 7):
-      bit = 0;
-      break;
-    case 0xff & ~(1 << 6):
-      bit = 1;
-      break;
-    case 0xff & ~(1 << 5):
-      bit = 2;
-      break;
-    case 0xff & ~(1 << 4):
-      bit = 3;
-      break;
-    case 0xff & ~(1 << 3):
-      bit = 4;
-      break;
-    case 0xff & ~(1 << 2):
-      bit = 5;
-      break;
-    case 0xff & ~(1 << 1):
-      bit = 6;
-      break;
-    case 0xff & ~1:
-      bit = 7;
-      break;
-    default:
-      CHECK(false);
-  }
-
-  bit += 8 * i->critbyte();
-  if (last_bit > -1) {
-    CHECK_GT(bit, static_cast<unsigned>(last_bit));
-  }
-
-  CHECK_EQ(free_internal_nodes.count(internal_node), 0u);
-
-  for (unsigned child = 0; child < 2; child++) {
-    if (i->child(child) & kExternalFlag) {
-      uint32_t ext = i->child(child) & ~kExternalFlag;
-      CHECK_EQ(free_external_nodes.count(ext), 0u);
-      CHECK_EQ(used_external_nodes->count(ext), 0u);
-      used_external_nodes->insert(ext);
-      const uint8_t* bytes = external_node(ext);
-      for (const pair<unsigned, bool>& pair : bits) {
-        unsigned byte = pair.first / 8;
-        DCHECK_LE(byte, 0xffu);
-        unsigned bit_new = pair.first % 8;
-        static const uint8_t kMasks[8] = {0x80, 0x40, 0x20, 0x10,
-                                          0x08, 0x04, 0x02, 0x01};
-        CHECK_EQ((bytes[byte] & kMasks[bit_new]) != 0, pair.second);
-      }
-    } else {
-      uint32_t inter = i->child(child);
-      vector<pair<unsigned, bool>> new_bits(bits);
-      new_bits.push_back(pair<unsigned, bool>(bit, child != 0));
-      CHECK_EQ(free_internal_nodes.count(inter), 0u);
-      CHECK_EQ(used_internal_nodes->count(inter), 0u);
-      used_internal_nodes->insert(inter);
-      ValidateTree(inter, bit, bits, free_internal_nodes, free_external_nodes,
-                   used_internal_nodes, used_external_nodes);
-    }
-  }
-}
-
-}  // namespace net
diff --git a/src/net/quic/core/crypto/strike_register.h b/src/net/quic/core/crypto/strike_register.h
deleted file mode 100644
index 9d7431b..0000000
--- a/src/net/quic/core/crypto/strike_register.h
+++ /dev/null
@@ -1,223 +0,0 @@
-// Copyright (c) 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef NET_QUIC_CRYPTO_STRIKE_REGISTER_H_
-#define NET_QUIC_CRYPTO_STRIKE_REGISTER_H_
-
-#include <stdint.h>
-
-#include <memory>
-#include <set>
-#include <utility>
-#include <vector>
-
-#include "base/macros.h"
-#include "net/base/net_export.h"
-
-namespace net {
-
-// InsertStatus enum values cannot be changed, they need to be stable.
-enum InsertStatus {
-  NONCE_OK = 0,
-  // The default error value for nonce verification failures from strike
-  // register (covers old strike registers and unknown failures).
-  NONCE_UNKNOWN_FAILURE = 1,
-  // Decrypted nonce had incorrect length.
-  NONCE_INVALID_FAILURE = 2,
-  // Nonce is not unique.
-  NONCE_NOT_UNIQUE_FAILURE = 3,
-  // Nonce's orbit is invalid or incorrect.
-  NONCE_INVALID_ORBIT_FAILURE = 4,
-  // Nonce's timestamp is not in the strike register's valid time range.
-  NONCE_INVALID_TIME_FAILURE = 5,
-  // Strike register's RPC call timed out, nonce couldn't be verified.
-  STRIKE_REGISTER_TIMEOUT = 6,
-  // Strike register is down, nonce couldn't be verified.
-  STRIKE_REGISTER_FAILURE = 7,
-};
-
-// A StrikeRegister is critbit tree which stores a set of observed nonces.
-// We use a critbit tree because:
-//   1) It's immune to algorithmic complexity attacks. If we had used a hash
-//      tree, an attacker could send us a series of values which stretch out one
-//      of the hash chains, causing us to do much more work than normal.
-//   2) We can write it to use a fixed block of memory: avoiding fragmentation
-//      issues and so forth. (We might be able to do that with the STL
-//      algorithms and a custom allocator, but I don't want to go there.)
-//   3) It's simple (compared to balanced binary trees) and doesn't involve
-//      bouncing nearly as many cache lines around.
-//   4) It allows us to query for the oldest element in log(n) time.
-//
-// This code is based on djb's public domain critbit tree from qhasm.
-//
-// A critbit tree has external and internal nodes. External nodes are just the
-// nonce values (which are stored with internal times, see below, and without
-// the orbit values included). Internal nodes contain the bit number at which
-// the tree is branching and exactly two children. The critical bit is stored
-// as a byte number and a byte (|otherbits|) which has all the bits set
-// /except/ the one in question.
-//
-// Internal nodes have exactly two children: an internal node with only a
-// single child would be useless.
-//
-// The branching bit number (considering the MSB to be the 1st bit) is
-// monotonically increasing as you go down the tree.
-//
-// There are two distinct time representations used. External times are those
-// which are exposed to the users of this class. They are expected to be a
-// count of the number of seconds since the UNIX epoch. Internal times are a
-// count of the number of seconds since a point in time a couple of years
-// before the creation time given to the constructor. (See
-// |ExternalTimeToInternal|) This avoids having to worry about overflow since
-// we assume that no process will run for 130 years.
-class NET_EXPORT_PRIVATE StrikeRegister {
- public:
-  enum StartupType {
-    // DENY_REQUESTS_AT_STARTUP is the typical mode for a strike register.
-    // Because servers can crash and the strike-register memory-based, the
-    // state of the strike-register may be lost at any time. Thus the previous
-    // instance of the server may have accepted an nonce with time
-    // now+window_secs, which was forgotten in the crash. Therefore
-    // DENY_REQUESTS_AT_STARTUP causes the strike-register to reject all
-    // requests timestampped before window_secs + the creation time (the
-    // quiescent period).
-    DENY_REQUESTS_AT_STARTUP,
-    // NO_STARTUP_PERIOD_NEEDED indicates that no quiescent period is required.
-    // This may be because the strike-register is using an orbit randomly
-    // generated at startup and therefore nonces accepted by the previous
-    // instance of the strike-register are invalid for that reason.
-    NO_STARTUP_PERIOD_NEEDED,
-  };
-
-  // An external node takes 24 bytes as we don't record the orbit.
-  static const uint32_t kExternalNodeSize;
-
-  // We address the nodes by their index in the array. This means that 0 is a
-  // valid index. Therefore this is our invalid index. It also has a one bit
-  // in the LSB position because we tend to store indexes shifted up 8 bits
-  // and this distinguishes kNil from (kExternalFlag | 0) << 8.
-  static const uint32_t kNil;
-
-  // Our pointers from internal nodes can either point to an internal or
-  // external node. We flag the 24th bit to mark a pointer as external.
-  static const uint32_t kExternalFlag;
-
-  // Allows early validation before a strike register is created.
-  static void ValidateStrikeRegisterConfig(unsigned max_entries);
-
-  // Construct a new set which can hold, at most, |max_entries| (which must be
-  // less than 2**23). See the comments around StartupType about initial
-  // behaviour. Otherwise, all nonces that are outside +/- |window_secs| from
-  // the current time will be rejected. Additionally, all nonces that have an
-  // orbit value other than |orbit| will be rejected.
-  //
-  // (Note that this code is independent of the actual units of time used, but
-  // you should use seconds.)
-  StrikeRegister(unsigned max_entries,
-                 uint32_t current_time_external,
-                 uint32_t window_secs,
-                 const uint8_t orbit[8],
-                 StartupType startup);
-
-  ~StrikeRegister();
-
-  void Reset();
-
-  // |Insert| queries to see if |nonce| is
-  //   a) for the wrong orbit
-  //   b) before the current horizon
-  //   c) outside of the valid time window
-  //   d) already in the set of observed nonces
-  // and returns the failure reason if any of these are true. It is also free to
-  // return failure reason for other reasons as it's always safe to reject an
-  // nonce.
-  //
-  // nonces are:
-  //   4 bytes of timestamp (UNIX epoch seconds)
-  //   8 bytes of orbit value (a cluster id)
-  //   20 bytes of random data
-  //
-  // Otherwise, it inserts |nonce| into the observed set and returns NONCE_OK.
-  InsertStatus Insert(const uint8_t nonce[32], uint32_t current_time);
-
-  // orbit returns a pointer to the 8-byte orbit value for this
-  // strike-register.
-  const uint8_t* orbit() const;
-
-  // Time window for which the strike register has complete information.
-  uint32_t GetCurrentValidWindowSecs(uint32_t current_time_external) const;
-
-  // This is a debugging aid which checks the tree for sanity.
-  void Validate();
-
- private:
-  class InternalNode;
-
-  // TimeFromBytes returns a big-endian uint32_t from |d|.
-  static uint32_t TimeFromBytes(const uint8_t d[4]);
-
-  // Range of internal times for which the strike register has
-  // complete information.  A nonce is within the valid range of the
-  // strike register if:
-  //   valid_range.first <= nonce_time_internal <= valid_range.second
-  std::pair<uint32_t, uint32_t> GetValidRange(
-      uint32_t current_time_internal) const;
-
-  // ExternalTimeToInternal converts an external time value into an internal
-  // time value using |internal_epoch_|.
-  uint32_t ExternalTimeToInternal(uint32_t external_time) const;
-
-  // BestMatch returns either kNil, or an external node index which could
-  // possibly match |v|.
-  uint32_t BestMatch(const uint8_t v[24]) const;
-
-  // external_node_next_ptr returns the 'next' pointer embedded in external
-  // node |i|. This is used to thread a free list through the external nodes.
-  uint32_t& external_node_next_ptr(unsigned i);
-
-  uint8_t* external_node(unsigned i);
-
-  uint32_t GetFreeExternalNode();
-
-  uint32_t GetFreeInternalNode();
-
-  // DropOldestNode removes the oldest node in the tree and updates |horizon_|
-  // accordingly.
-  void DropOldestNode();
-
-  void FreeExternalNode(uint32_t index);
-
-  void FreeInternalNode(uint32_t index);
-
-  void ValidateTree(uint32_t internal_node,
-                    int last_bit,
-                    const std::vector<std::pair<unsigned, bool>>& bits,
-                    const std::set<uint32_t>& free_internal_nodes,
-                    const std::set<uint32_t>& free_external_nodes,
-                    std::set<uint32_t>* used_internal_nodes,
-                    std::set<uint32_t>* used_external_nodes);
-
-  const uint32_t max_entries_;
-  const uint32_t window_secs_;
-  // internal_epoch_ contains the external time value of the start of internal
-  // time.
-  const uint32_t internal_epoch_;
-  uint8_t orbit_[8];
-  // The strike register will reject nonces with internal times < |horizon_| .
-  uint32_t horizon_;
-
-  uint32_t internal_node_free_head_;
-  uint32_t external_node_free_head_;
-  uint32_t internal_node_head_;
-  // internal_nodes_ can't be a scoped_ptr because the type isn't defined in
-  // this header.
-  InternalNode* internal_nodes_;
-  std::unique_ptr<uint8_t[]> external_nodes_;
-
-  DISALLOW_COPY_AND_ASSIGN(StrikeRegister);
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_CRYPTO_STRIKE_REGISTER_H_
diff --git a/src/net/quic/core/crypto/strike_register_client.h b/src/net/quic/core/crypto/strike_register_client.h
deleted file mode 100644
index 2126d6f..0000000
--- a/src/net/quic/core/crypto/strike_register_client.h
+++ /dev/null
@@ -1,60 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef NET_QUIC_CRYPTO_STRIKE_REGISTER_CLIENT_H_
-#define NET_QUIC_CRYPTO_STRIKE_REGISTER_CLIENT_H_
-
-#include <string>
-
-#include "base/macros.h"
-#include "base/strings/string_piece.h"
-#include "net/base/net_export.h"
-#include "net/quic/core/crypto/strike_register.h"
-#include "net/quic/core/quic_time.h"
-
-namespace net {
-
-// Interface implemented by clients that talk to strike registers
-// implemented as local or remote services.
-class NET_EXPORT_PRIVATE StrikeRegisterClient {
- public:
-  // Single use callback that will be invoked once the validation
-  // operation is complete.
-  class NET_EXPORT_PRIVATE ResultCallback {
-   public:
-    ResultCallback() {}
-    virtual ~ResultCallback() {}
-    void Run(bool nonce_is_valid_and_unique, InsertStatus nonce_error) {
-      RunImpl(nonce_is_valid_and_unique, nonce_error);
-      delete this;
-    }
-
-   protected:
-    virtual void RunImpl(bool nonce_is_valid_and_unique,
-                         InsertStatus nonce_error) = 0;
-
-   private:
-    DISALLOW_COPY_AND_ASSIGN(ResultCallback);
-  };
-
-  StrikeRegisterClient() {}
-  virtual ~StrikeRegisterClient() {}
-
-  // Returns true iff the strike register knows about the given orbit.
-  virtual bool IsKnownOrbit(base::StringPiece orbit) const = 0;
-  // Validate a nonce for freshness and uniqueness.
-  // Will invoke cb->Run(ValidateResponse::nonce_is_valid_and_unique(),
-  //                     ValidateResponse::nonce_error())
-  // once the asynchronous operation is complete.
-  virtual void VerifyNonceIsValidAndUnique(base::StringPiece nonce,
-                                           QuicWallTime now,
-                                           ResultCallback* cb) = 0;
-
- private:
-  DISALLOW_COPY_AND_ASSIGN(StrikeRegisterClient);
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_CRYPTO_STRIKE_REGISTER_CLIENT_H_
diff --git a/src/net/quic/core/interval.h b/src/net/quic/core/interval.h
index ef4661c..d29694e 100644
--- a/src/net/quic/core/interval.h
+++ b/src/net/quic/core/interval.h
@@ -157,19 +157,6 @@ class Interval {
   // to represent that interval, and returns true iff *this was modified.
   bool SpanningUnion(const Interval& i);
 
-  // Determines the difference between two intervals by finding all points that
-  // are contained in *this but not in i, coalesces those points into the
-  // largest possible contiguous intervals, and appends those intervals to the
-  // *difference vector. Intuitively this can be thought of as "erasing" i from
-  // *this. This will either completely erase *this (leaving nothing behind),
-  // partially erase some of *this from the left or right side (leaving some
-  // residual behind), or erase a hole in the middle of *this (leaving behind an
-  // interval on either side). Therefore, 0, 1, or 2 intervals will be appended
-  // to *difference. The method returns true iff the intersection of *this and i
-  // is non-empty. The caller owns the vector and the Interval* pointers
-  // inside it. The difference vector is required to be non-null.
-  bool Difference(const Interval& i, std::vector<Interval*>* difference) const;
-
   // Determines the difference between two intervals as in
   // Difference(Interval&, vector*), but stores the results directly in out
   // parameters rather than dynamically allocating an Interval* and appending
@@ -266,53 +253,6 @@ bool Interval<T>::SpanningUnion(const Interval& i) {
 
 template <typename T>
 bool Interval<T>::Difference(const Interval& i,
-                             std::vector<Interval*>* difference) const {
-  if (Empty()) {
-    // <empty> - <i> = <empty>
-    return false;
-  }
-  if (i.Empty()) {
-    // <this> - <empty> = <this>
-    difference->push_back(new Interval(*this));
-    return false;
-  }
-  if (min() < i.max() && min() >= i.min() && max() > i.max()) {
-    //            [------ this ------)
-    // [------ i ------)
-    //                 [-- result ---)
-    difference->push_back(new Interval(i.max(), max()));
-    return true;
-  }
-  if (max() > i.min() && max() <= i.max() && min() < i.min()) {
-    // [------ this ------)
-    //            [------ i ------)
-    // [- result -)
-    difference->push_back(new Interval(min(), i.min()));
-    return true;
-  }
-  if (min() < i.min() && max() > i.max()) {
-    // [------- this --------)
-    //      [---- i ----)
-    // [ R1 )           [ R2 )
-    // There are two results: R1 and R2.
-    difference->push_back(new Interval(min(), i.min()));
-    difference->push_back(new Interval(i.max(), max()));
-    return true;
-  }
-  if (min() >= i.min() && max() <= i.max()) {
-    //   [--- this ---)
-    // [------ i --------)
-    // Intersection is <this>, so difference yields the empty interval.
-    // Nothing is appended to *difference.
-    return true;
-  }
-  // No intersection. Append <this>.
-  difference->push_back(new Interval(*this));
-  return false;
-}
-
-template <typename T>
-bool Interval<T>::Difference(const Interval& i,
                              Interval* lo,
                              Interval* hi) const {
   // Initialize *lo and *hi to empty
diff --git a/src/net/quic/core/interval_set.h b/src/net/quic/core/interval_set.h
index 9bb763a..dcd69f0 100644
--- a/src/net/quic/core/interval_set.h
+++ b/src/net/quic/core/interval_set.h
@@ -55,6 +55,7 @@
 #include <stddef.h>
 
 #include <algorithm>
+#include <ostream>
 #include <set>
 #include <string>
 #include <utility>
diff --git a/src/net/quic/core/iovector.cc b/src/net/quic/core/iovector.cc
deleted file mode 100644
index d7c919c..0000000
--- a/src/net/quic/core/iovector.cc
+++ /dev/null
@@ -1,15 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "net/quic/core/iovector.h"
-
-namespace net {
-
-IOVector::IOVector() {}
-
-IOVector::IOVector(const IOVector& other) = default;
-
-IOVector::~IOVector() {}
-
-}  // namespace net
diff --git a/src/net/quic/core/iovector.h b/src/net/quic/core/iovector.h
deleted file mode 100644
index cf77a9a..0000000
--- a/src/net/quic/core/iovector.h
+++ /dev/null
@@ -1,238 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef NET_QUIC_IOVECTOR_H_
-#define NET_QUIC_IOVECTOR_H_
-
-#include <stddef.h>
-
-#include <algorithm>
-#include <vector>
-
-#include "base/logging.h"
-#include "net/base/iovec.h"
-#include "net/base/net_export.h"
-
-namespace net {
-
-// Calculate the total number of bytes in an array of iovec structures.
-inline size_t TotalIovecLength(const struct iovec* iov, size_t iovcnt) {
-  size_t length = 0;
-  if (iov != NULL) {
-    for (size_t i = 0; i < iovcnt; ++i) {
-      length += iov[i].iov_len;
-    }
-  }
-  return length;
-}
-
-// IOVector is a helper class that makes it easier to work with POSIX vector I/O
-// struct. It is a thin wrapper by design and thus has no virtual functions and
-// all inlined methods. This class makes no assumptions about the ordering of
-// the pointer values of the blocks appended, it simply counts bytes when asked
-// to consume bytes.
-//
-// IOVector is a bookkeeping object that collects a description of buffers to
-// be read or written together and in order. It does not take ownership of the
-// blocks appended.
-//
-// Because it is used for scatter-gather operations, the order in which the
-// buffer blocks are added to the IOVector is important to the client. The
-// intended usage pattern is:
-//
-//   iovector.Append(p0, len0);
-//   ...
-//   iovector.Append(pn, lenn);
-//   int bytes_written = writev(fd, iovector.iovec(), iovector.Size());
-//   if (bytes_written > 0)
-//     iovector.Consume(bytes_written);
-//
-// The sequence is the same for readv, except that Consume() in this case is
-// used to change the IOVector to only keep track of description of blocks of
-// memory not yet written to.
-//
-// IOVector does not have any method to change the iovec entries that it
-// accumulates. This is due to the block merging nature of Append(): we'd like
-// to avoid accidentally change an entry that is assembled by two or more
-// Append()'s by simply an index access.
-//
-class NET_EXPORT_PRIVATE IOVector {
- public:
-  // Provide a default constructor so it'll never be inhibited by adding other
-  // constructors.
-  IOVector();
-  IOVector(const IOVector& other);
-  ~IOVector();
-
-  // Provides a way to convert system call-like iovec representation to
-  // IOVector.
-  void AppendIovec(const struct iovec* iov, size_t iovcnt) {
-    for (size_t i = 0; i < iovcnt; ++i)
-      Append(static_cast<char*>(iov[i].iov_base), iov[i].iov_len);
-  }
-
-  // Appends at most max_bytes from iovec to the IOVector.
-  size_t AppendIovecAtMostBytes(const struct iovec* iov,
-                                size_t iovcnt,
-                                size_t max_bytes) {
-    size_t bytes_appended = 0;
-    for (size_t i = 0; i < iovcnt && max_bytes > 0; ++i) {
-      const size_t length = std::min(max_bytes, iov[i].iov_len);
-      Append(static_cast<char*>(iov[i].iov_base), length);
-      max_bytes -= length;
-      bytes_appended += length;
-    }
-    return bytes_appended;
-  }
-
-  // Append another block to the IOVector. Since IOVector can be used for read
-  // and write, it always takes char*. Clients that writes will need to cast
-  // away the constant of the pointer before appending a block.
-  void Append(char* buffer, size_t length) {
-    if (buffer != nullptr && length > 0) {
-      if (iovec_.size() > 0) {
-        struct iovec& last = iovec_.back();
-        // If the new block is contiguous with the last block, just extend.
-        if (static_cast<char*>(last.iov_base) + last.iov_len == buffer) {
-          last.iov_len += length;
-          return;
-        }
-      }
-      struct iovec tmp = {buffer, length};
-      iovec_.push_back(tmp);
-    }
-  }
-
-  // Same as Append, but doesn't do the tail merge optimization.
-  // Intended for testing.
-  void AppendNoCoalesce(char* buffer, size_t length) {
-    if (buffer != nullptr && length > 0) {
-      struct iovec tmp = {buffer, length};
-      iovec_.push_back(tmp);
-    }
-  }
-
-  // Remove a number of bytes from the beginning of the IOVector. Since vector
-  // I/O operations always occur at the beginning of the block list, a method
-  // to remove bytes at the end is not provided.
-  // It returns the number of bytes actually consumed (it'll only be smaller
-  // than the requested number if the IOVector contains less data).
-  size_t Consume(size_t length) {
-    if (length == 0)
-      return 0;
-
-    size_t bytes_to_consume = length;
-    std::vector<struct iovec>::iterator iter = iovec_.begin();
-    std::vector<struct iovec>::iterator end = iovec_.end();
-    for (; iter < end && bytes_to_consume >= iter->iov_len; ++iter) {
-      bytes_to_consume -= iter->iov_len;
-    }
-    iovec_.erase(iovec_.begin(), iter);
-    if (!iovec_.empty() && bytes_to_consume != 0) {
-      iovec_[0].iov_base =
-          static_cast<char*>(iovec_[0].iov_base) + bytes_to_consume;
-      iovec_[0].iov_len -= bytes_to_consume;
-      return length;
-    }
-    if (iovec_.size() == 0 && bytes_to_consume > 0) {
-      LOG(DFATAL) << "Attempting to consume " << bytes_to_consume
-                  << " non-existent bytes.";
-    }
-    // At this point bytes_to_consume is the number of wanted bytes left over
-    // after walking through all the iovec entries.
-    return length - bytes_to_consume;
-  }
-
-  // Identical to Consume, but also copies the portion of the buffer being
-  // consumed into |buffer|.  |buffer| must be at least size |length|.  If
-  // the IOVector is less than |length|, the method consumes the entire
-  // IOVector, logs an error and returns the length consumed.
-  size_t ConsumeAndCopy(size_t length, char* buffer) {
-    if (length == 0)
-      return 0;
-
-    size_t bytes_to_consume = length;
-    // First consume all the iovecs which can be consumed completely.
-    std::vector<struct iovec>::iterator iter = iovec_.begin();
-    std::vector<struct iovec>::iterator end = iovec_.end();
-    for (; iter < end && bytes_to_consume >= iter->iov_len; ++iter) {
-      memcpy(buffer, iter->iov_base, iter->iov_len);
-      bytes_to_consume -= iter->iov_len;
-      buffer += iter->iov_len;
-    }
-    iovec_.erase(iovec_.begin(), iter);
-    if (bytes_to_consume == 0) {
-      return length;
-    }
-    if (iovec_.empty()) {
-      LOG_IF(DFATAL, bytes_to_consume > 0) << "Attempting to consume "
-                                           << bytes_to_consume
-                                           << " non-existent bytes.";
-      return length - bytes_to_consume;
-    }
-    // Partially consume the next iovec.
-    memcpy(buffer, iovec_[0].iov_base, bytes_to_consume);
-    iovec_[0].iov_base =
-        static_cast<char*>(iovec_[0].iov_base) + bytes_to_consume;
-    iovec_[0].iov_len -= bytes_to_consume;
-    return length;
-  }
-
-  // TODO(joechan): If capacity is large, swap out for a blank one.
-  // Clears the IOVector object to contain no blocks.
-  void Clear() { iovec_.clear(); }
-
-  // Swap the guts of two IOVector.
-  void Swap(IOVector* other) { iovec_.swap(other->iovec_); }
-
-  // Returns the number of valid blocks in the IOVector (not the number of
-  // bytes).
-  size_t Size() const { return iovec_.size(); }
-
-  // Returns the total storage used by the IOVector in number of blocks (not
-  // the number of bytes).
-  size_t Capacity() const { return iovec_.capacity(); }
-
-  // Returns true if there are no blocks in the IOVector.
-  bool Empty() const { return iovec_.empty(); }
-
-  // Returns the pointer to the beginning of the iovec to be used for vector
-  // I/O operations. If the IOVector has no blocks appened, this function
-  // returns NULL.
-  struct iovec* iovec() {
-    return !Empty() ? &iovec_[0] : NULL;
-  }
-
-  // Const version.
-  const struct iovec* iovec() const { return !Empty() ? &iovec_[0] : NULL; }
-
-  // Returns a pointer to one past the last byte of the last block. If the
-  // IOVector is empty, NULL is returned.
-  const char* LastBlockEnd() const {
-    return iovec_.size() > 0
-               ? static_cast<char*>(iovec_.back().iov_base) +
-                     iovec_.back().iov_len
-               : NULL;
-  }
-
-  // Returns the total number of bytes in the IOVector.
-  size_t TotalBufferSize() const { return TotalIovecLength(iovec(), Size()); }
-
-  void Resize(size_t count) { iovec_.resize(count); }
-
- private:
-  std::vector<struct iovec> iovec_;
-
-  // IOVector has value-semantics; copy and assignment are allowed.
-  // This class does not explicitly define copy/move constructors or the
-  // assignment operator to preserve compiler-generated copy/move constructors
-  // and assignment operators. Note that since IOVector does not own the
-  // actual buffers that the struct iovecs point to, copies and assignments
-  // result in a shallow copy of the buffers; resulting IOVectors will point
-  // to the same copy of the underlying data.
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_IOVECTOR_H_
diff --git a/src/net/quic/core/proto/cached_network_parameters.pb.cc b/src/net/quic/core/proto/cached_network_parameters.pb.cc
deleted file mode 100644
index e2e0fc4..0000000
--- a/src/net/quic/core/proto/cached_network_parameters.pb.cc
+++ /dev/null
@@ -1,728 +0,0 @@
-// Generated by the protocol buffer compiler.  DO NOT EDIT!
-// source: cached_network_parameters.proto
-
-#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
-#include "cached_network_parameters.pb.h"
-
-#include <algorithm>
-
-#include <google/protobuf/stubs/common.h>
-#include <google/protobuf/stubs/port.h>
-#include <google/protobuf/stubs/once.h>
-#include <google/protobuf/io/coded_stream.h>
-#include <google/protobuf/wire_format_lite_inl.h>
-#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
-// @@protoc_insertion_point(includes)
-
-namespace net {
-
-void protobuf_ShutdownFile_cached_5fnetwork_5fparameters_2eproto() {
-  delete CachedNetworkParameters::default_instance_;
-}
-
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-void protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto_impl() {
-  GOOGLE_PROTOBUF_VERIFY_VERSION;
-
-#else
-void protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto() {
-  static bool already_here = false;
-  if (already_here) return;
-  already_here = true;
-  GOOGLE_PROTOBUF_VERIFY_VERSION;
-
-#endif
-  CachedNetworkParameters::default_instance_ = new CachedNetworkParameters();
-  CachedNetworkParameters::default_instance_->InitAsDefaultInstance();
-  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_cached_5fnetwork_5fparameters_2eproto);
-}
-
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto_once_);
-void protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto() {
-  ::google::protobuf::GoogleOnceInit(&protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto_once_,
-                 &protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto_impl);
-}
-#else
-// Force AddDescriptors() to be called at static initialization time.
-struct StaticDescriptorInitializer_cached_5fnetwork_5fparameters_2eproto {
-  StaticDescriptorInitializer_cached_5fnetwork_5fparameters_2eproto() {
-    protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto();
-  }
-} static_descriptor_initializer_cached_5fnetwork_5fparameters_2eproto_;
-#endif
-
-namespace {
-
-static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
-GOOGLE_ATTRIBUTE_NOINLINE static void MergeFromFail(int line) {
-  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
-}
-
-}  // namespace
-
-
-// ===================================================================
-
-static ::std::string* MutableUnknownFieldsForCachedNetworkParameters(
-    CachedNetworkParameters* ptr) {
-  return ptr->mutable_unknown_fields();
-}
-
-bool CachedNetworkParameters_PreviousConnectionState_IsValid(int value) {
-  switch(value) {
-    case 0:
-    case 1:
-      return true;
-    default:
-      return false;
-  }
-}
-
-#if !defined(_MSC_VER) || _MSC_VER >= 1900
-const CachedNetworkParameters_PreviousConnectionState CachedNetworkParameters::SLOW_START;
-const CachedNetworkParameters_PreviousConnectionState CachedNetworkParameters::CONGESTION_AVOIDANCE;
-const CachedNetworkParameters_PreviousConnectionState CachedNetworkParameters::PreviousConnectionState_MIN;
-const CachedNetworkParameters_PreviousConnectionState CachedNetworkParameters::PreviousConnectionState_MAX;
-const int CachedNetworkParameters::PreviousConnectionState_ARRAYSIZE;
-#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
-#if !defined(_MSC_VER) || _MSC_VER >= 1900
-const int CachedNetworkParameters::kServingRegionFieldNumber;
-const int CachedNetworkParameters::kBandwidthEstimateBytesPerSecondFieldNumber;
-const int CachedNetworkParameters::kMaxBandwidthEstimateBytesPerSecondFieldNumber;
-const int CachedNetworkParameters::kMaxBandwidthTimestampSecondsFieldNumber;
-const int CachedNetworkParameters::kMinRttMsFieldNumber;
-const int CachedNetworkParameters::kPreviousConnectionStateFieldNumber;
-const int CachedNetworkParameters::kTimestampFieldNumber;
-#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
-
-CachedNetworkParameters::CachedNetworkParameters()
-  : ::google::protobuf::MessageLite(), _arena_ptr_(NULL) {
-  SharedCtor();
-  // @@protoc_insertion_point(constructor:net.CachedNetworkParameters)
-}
-
-void CachedNetworkParameters::InitAsDefaultInstance() {
-}
-
-CachedNetworkParameters::CachedNetworkParameters(const CachedNetworkParameters& from)
-  : ::google::protobuf::MessageLite(),
-    _arena_ptr_(NULL) {
-  SharedCtor();
-  MergeFrom(from);
-  // @@protoc_insertion_point(copy_constructor:net.CachedNetworkParameters)
-}
-
-void CachedNetworkParameters::SharedCtor() {
-  ::google::protobuf::internal::GetEmptyString();
-  _cached_size_ = 0;
-  _unknown_fields_.UnsafeSetDefault(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  serving_region_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  bandwidth_estimate_bytes_per_second_ = 0;
-  max_bandwidth_estimate_bytes_per_second_ = 0;
-  max_bandwidth_timestamp_seconds_ = GOOGLE_LONGLONG(0);
-  min_rtt_ms_ = 0;
-  previous_connection_state_ = 0;
-  timestamp_ = GOOGLE_LONGLONG(0);
-  ::memset(_has_bits_, 0, sizeof(_has_bits_));
-}
-
-CachedNetworkParameters::~CachedNetworkParameters() {
-  // @@protoc_insertion_point(destructor:net.CachedNetworkParameters)
-  SharedDtor();
-}
-
-void CachedNetworkParameters::SharedDtor() {
-  _unknown_fields_.DestroyNoArena(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  serving_region_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  #ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  if (this != &default_instance()) {
-  #else
-  if (this != default_instance_) {
-  #endif
-  }
-}
-
-void CachedNetworkParameters::SetCachedSize(int size) const {
-  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
-  _cached_size_ = size;
-  GOOGLE_SAFE_CONCURRENT_WRITES_END();
-}
-const CachedNetworkParameters& CachedNetworkParameters::default_instance() {
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto();
-#else
-  if (default_instance_ == NULL) protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto();
-#endif
-  return *default_instance_;
-}
-
-CachedNetworkParameters* CachedNetworkParameters::default_instance_ = NULL;
-
-CachedNetworkParameters* CachedNetworkParameters::New(::google::protobuf::Arena* arena) const {
-  CachedNetworkParameters* n = new CachedNetworkParameters;
-  if (arena != NULL) {
-    arena->Own(n);
-  }
-  return n;
-}
-
-void CachedNetworkParameters::Clear() {
-// @@protoc_insertion_point(message_clear_start:net.CachedNetworkParameters)
-#if defined(__clang__)
-#define ZR_HELPER_(f) \
-  _Pragma("clang diagnostic push") \
-  _Pragma("clang diagnostic ignored \"-Winvalid-offsetof\"") \
-  __builtin_offsetof(CachedNetworkParameters, f) \
-  _Pragma("clang diagnostic pop")
-#else
-#define ZR_HELPER_(f) reinterpret_cast<char*>(\
-  &reinterpret_cast<CachedNetworkParameters*>(16)->f)
-#endif
-
-#define ZR_(first, last) do {\
-  ::memset(&first, 0,\
-           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
-} while (0)
-
-  if (_has_bits_[0 / 32] & 127u) {
-    ZR_(bandwidth_estimate_bytes_per_second_, timestamp_);
-    if (has_serving_region()) {
-      serving_region_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-    }
-  }
-
-#undef ZR_HELPER_
-#undef ZR_
-
-  ::memset(_has_bits_, 0, sizeof(_has_bits_));
-  _unknown_fields_.ClearToEmptyNoArena(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-bool CachedNetworkParameters::MergePartialFromCodedStream(
-    ::google::protobuf::io::CodedInputStream* input) {
-#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
-  ::google::protobuf::uint32 tag;
-  ::google::protobuf::io::LazyStringOutputStream unknown_fields_string(
-      ::google::protobuf::internal::NewPermanentCallback(
-          &MutableUnknownFieldsForCachedNetworkParameters, this));
-  ::google::protobuf::io::CodedOutputStream unknown_fields_stream(
-      &unknown_fields_string, false);
-  // @@protoc_insertion_point(parse_start:net.CachedNetworkParameters)
-  for (;;) {
-    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
-    tag = p.first;
-    if (!p.second) goto handle_unusual;
-    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
-      // optional string serving_region = 1;
-      case 1: {
-        if (tag == 10) {
-          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
-                input, this->mutable_serving_region()));
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(16)) goto parse_bandwidth_estimate_bytes_per_second;
-        break;
-      }
-
-      // optional int32 bandwidth_estimate_bytes_per_second = 2;
-      case 2: {
-        if (tag == 16) {
-         parse_bandwidth_estimate_bytes_per_second:
-          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
-                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
-                 input, &bandwidth_estimate_bytes_per_second_)));
-          set_has_bandwidth_estimate_bytes_per_second();
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(24)) goto parse_min_rtt_ms;
-        break;
-      }
-
-      // optional int32 min_rtt_ms = 3;
-      case 3: {
-        if (tag == 24) {
-         parse_min_rtt_ms:
-          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
-                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
-                 input, &min_rtt_ms_)));
-          set_has_min_rtt_ms();
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(32)) goto parse_previous_connection_state;
-        break;
-      }
-
-      // optional int32 previous_connection_state = 4;
-      case 4: {
-        if (tag == 32) {
-         parse_previous_connection_state:
-          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
-                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
-                 input, &previous_connection_state_)));
-          set_has_previous_connection_state();
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(40)) goto parse_max_bandwidth_estimate_bytes_per_second;
-        break;
-      }
-
-      // optional int32 max_bandwidth_estimate_bytes_per_second = 5;
-      case 5: {
-        if (tag == 40) {
-         parse_max_bandwidth_estimate_bytes_per_second:
-          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
-                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
-                 input, &max_bandwidth_estimate_bytes_per_second_)));
-          set_has_max_bandwidth_estimate_bytes_per_second();
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(48)) goto parse_max_bandwidth_timestamp_seconds;
-        break;
-      }
-
-      // optional int64 max_bandwidth_timestamp_seconds = 6;
-      case 6: {
-        if (tag == 48) {
-         parse_max_bandwidth_timestamp_seconds:
-          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
-                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
-                 input, &max_bandwidth_timestamp_seconds_)));
-          set_has_max_bandwidth_timestamp_seconds();
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(56)) goto parse_timestamp;
-        break;
-      }
-
-      // optional int64 timestamp = 7;
-      case 7: {
-        if (tag == 56) {
-         parse_timestamp:
-          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
-                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
-                 input, &timestamp_)));
-          set_has_timestamp();
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectAtEnd()) goto success;
-        break;
-      }
-
-      default: {
-      handle_unusual:
-        if (tag == 0 ||
-            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
-            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
-          goto success;
-        }
-        DO_(::google::protobuf::internal::WireFormatLite::SkipField(
-            input, tag, &unknown_fields_stream));
-        break;
-      }
-    }
-  }
-success:
-  // @@protoc_insertion_point(parse_success:net.CachedNetworkParameters)
-  return true;
-failure:
-  // @@protoc_insertion_point(parse_failure:net.CachedNetworkParameters)
-  return false;
-#undef DO_
-}
-
-void CachedNetworkParameters::SerializeWithCachedSizes(
-    ::google::protobuf::io::CodedOutputStream* output) const {
-  // @@protoc_insertion_point(serialize_start:net.CachedNetworkParameters)
-  // optional string serving_region = 1;
-  if (has_serving_region()) {
-    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
-      1, this->serving_region(), output);
-  }
-
-  // optional int32 bandwidth_estimate_bytes_per_second = 2;
-  if (has_bandwidth_estimate_bytes_per_second()) {
-    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->bandwidth_estimate_bytes_per_second(), output);
-  }
-
-  // optional int32 min_rtt_ms = 3;
-  if (has_min_rtt_ms()) {
-    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->min_rtt_ms(), output);
-  }
-
-  // optional int32 previous_connection_state = 4;
-  if (has_previous_connection_state()) {
-    ::google::protobuf::internal::WireFormatLite::WriteInt32(4, this->previous_connection_state(), output);
-  }
-
-  // optional int32 max_bandwidth_estimate_bytes_per_second = 5;
-  if (has_max_bandwidth_estimate_bytes_per_second()) {
-    ::google::protobuf::internal::WireFormatLite::WriteInt32(5, this->max_bandwidth_estimate_bytes_per_second(), output);
-  }
-
-  // optional int64 max_bandwidth_timestamp_seconds = 6;
-  if (has_max_bandwidth_timestamp_seconds()) {
-    ::google::protobuf::internal::WireFormatLite::WriteInt64(6, this->max_bandwidth_timestamp_seconds(), output);
-  }
-
-  // optional int64 timestamp = 7;
-  if (has_timestamp()) {
-    ::google::protobuf::internal::WireFormatLite::WriteInt64(7, this->timestamp(), output);
-  }
-
-  output->WriteRaw(unknown_fields().data(),
-                   static_cast<int>(unknown_fields().size()));
-  // @@protoc_insertion_point(serialize_end:net.CachedNetworkParameters)
-}
-
-int CachedNetworkParameters::ByteSize() const {
-// @@protoc_insertion_point(message_byte_size_start:net.CachedNetworkParameters)
-  int total_size = 0;
-
-  if (_has_bits_[0 / 32] & 127u) {
-    // optional string serving_region = 1;
-    if (has_serving_region()) {
-      total_size += 1 +
-        ::google::protobuf::internal::WireFormatLite::StringSize(
-          this->serving_region());
-    }
-
-    // optional int32 bandwidth_estimate_bytes_per_second = 2;
-    if (has_bandwidth_estimate_bytes_per_second()) {
-      total_size += 1 +
-        ::google::protobuf::internal::WireFormatLite::Int32Size(
-          this->bandwidth_estimate_bytes_per_second());
-    }
-
-    // optional int32 max_bandwidth_estimate_bytes_per_second = 5;
-    if (has_max_bandwidth_estimate_bytes_per_second()) {
-      total_size += 1 +
-        ::google::protobuf::internal::WireFormatLite::Int32Size(
-          this->max_bandwidth_estimate_bytes_per_second());
-    }
-
-    // optional int64 max_bandwidth_timestamp_seconds = 6;
-    if (has_max_bandwidth_timestamp_seconds()) {
-      total_size += 1 +
-        ::google::protobuf::internal::WireFormatLite::Int64Size(
-          this->max_bandwidth_timestamp_seconds());
-    }
-
-    // optional int32 min_rtt_ms = 3;
-    if (has_min_rtt_ms()) {
-      total_size += 1 +
-        ::google::protobuf::internal::WireFormatLite::Int32Size(
-          this->min_rtt_ms());
-    }
-
-    // optional int32 previous_connection_state = 4;
-    if (has_previous_connection_state()) {
-      total_size += 1 +
-        ::google::protobuf::internal::WireFormatLite::Int32Size(
-          this->previous_connection_state());
-    }
-
-    // optional int64 timestamp = 7;
-    if (has_timestamp()) {
-      total_size += 1 +
-        ::google::protobuf::internal::WireFormatLite::Int64Size(
-          this->timestamp());
-    }
-
-  }
-  total_size += unknown_fields().size();
-
-  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
-  _cached_size_ = total_size;
-  GOOGLE_SAFE_CONCURRENT_WRITES_END();
-  return total_size;
-}
-
-void CachedNetworkParameters::CheckTypeAndMergeFrom(
-    const ::google::protobuf::MessageLite& from) {
-  MergeFrom(*::google::protobuf::down_cast<const CachedNetworkParameters*>(&from));
-}
-
-void CachedNetworkParameters::MergeFrom(const CachedNetworkParameters& from) {
-// @@protoc_insertion_point(class_specific_merge_from_start:net.CachedNetworkParameters)
-  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
-  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
-    if (from.has_serving_region()) {
-      set_has_serving_region();
-      serving_region_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.serving_region_);
-    }
-    if (from.has_bandwidth_estimate_bytes_per_second()) {
-      set_bandwidth_estimate_bytes_per_second(from.bandwidth_estimate_bytes_per_second());
-    }
-    if (from.has_max_bandwidth_estimate_bytes_per_second()) {
-      set_max_bandwidth_estimate_bytes_per_second(from.max_bandwidth_estimate_bytes_per_second());
-    }
-    if (from.has_max_bandwidth_timestamp_seconds()) {
-      set_max_bandwidth_timestamp_seconds(from.max_bandwidth_timestamp_seconds());
-    }
-    if (from.has_min_rtt_ms()) {
-      set_min_rtt_ms(from.min_rtt_ms());
-    }
-    if (from.has_previous_connection_state()) {
-      set_previous_connection_state(from.previous_connection_state());
-    }
-    if (from.has_timestamp()) {
-      set_timestamp(from.timestamp());
-    }
-  }
-  if (!from.unknown_fields().empty()) {
-    mutable_unknown_fields()->append(from.unknown_fields());
-  }
-}
-
-void CachedNetworkParameters::CopyFrom(const CachedNetworkParameters& from) {
-// @@protoc_insertion_point(class_specific_copy_from_start:net.CachedNetworkParameters)
-  if (&from == this) return;
-  Clear();
-  MergeFrom(from);
-}
-
-bool CachedNetworkParameters::IsInitialized() const {
-
-  return true;
-}
-
-void CachedNetworkParameters::Swap(CachedNetworkParameters* other) {
-  if (other == this) return;
-  InternalSwap(other);
-}
-void CachedNetworkParameters::InternalSwap(CachedNetworkParameters* other) {
-  serving_region_.Swap(&other->serving_region_);
-  std::swap(bandwidth_estimate_bytes_per_second_, other->bandwidth_estimate_bytes_per_second_);
-  std::swap(max_bandwidth_estimate_bytes_per_second_, other->max_bandwidth_estimate_bytes_per_second_);
-  std::swap(max_bandwidth_timestamp_seconds_, other->max_bandwidth_timestamp_seconds_);
-  std::swap(min_rtt_ms_, other->min_rtt_ms_);
-  std::swap(previous_connection_state_, other->previous_connection_state_);
-  std::swap(timestamp_, other->timestamp_);
-  std::swap(_has_bits_[0], other->_has_bits_[0]);
-  _unknown_fields_.Swap(&other->_unknown_fields_);
-  std::swap(_cached_size_, other->_cached_size_);
-}
-
-::std::string CachedNetworkParameters::GetTypeName() const {
-  return "net.CachedNetworkParameters";
-}
-
-#if PROTOBUF_INLINE_NOT_IN_HEADERS
-// CachedNetworkParameters
-
-// optional string serving_region = 1;
-bool CachedNetworkParameters::has_serving_region() const {
-  return (_has_bits_[0] & 0x00000001u) != 0;
-}
-void CachedNetworkParameters::set_has_serving_region() {
-  _has_bits_[0] |= 0x00000001u;
-}
-void CachedNetworkParameters::clear_has_serving_region() {
-  _has_bits_[0] &= ~0x00000001u;
-}
-void CachedNetworkParameters::clear_serving_region() {
-  serving_region_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  clear_has_serving_region();
-}
- const ::std::string& CachedNetworkParameters::serving_region() const {
-  // @@protoc_insertion_point(field_get:net.CachedNetworkParameters.serving_region)
-  return serving_region_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
- void CachedNetworkParameters::set_serving_region(const ::std::string& value) {
-  set_has_serving_region();
-  serving_region_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
-  // @@protoc_insertion_point(field_set:net.CachedNetworkParameters.serving_region)
-}
- void CachedNetworkParameters::set_serving_region(const char* value) {
-  set_has_serving_region();
-  serving_region_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
-  // @@protoc_insertion_point(field_set_char:net.CachedNetworkParameters.serving_region)
-}
- void CachedNetworkParameters::set_serving_region(const char* value, size_t size) {
-  set_has_serving_region();
-  serving_region_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
-      ::std::string(reinterpret_cast<const char*>(value), size));
-  // @@protoc_insertion_point(field_set_pointer:net.CachedNetworkParameters.serving_region)
-}
- ::std::string* CachedNetworkParameters::mutable_serving_region() {
-  set_has_serving_region();
-  // @@protoc_insertion_point(field_mutable:net.CachedNetworkParameters.serving_region)
-  return serving_region_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
- ::std::string* CachedNetworkParameters::release_serving_region() {
-  // @@protoc_insertion_point(field_release:net.CachedNetworkParameters.serving_region)
-  clear_has_serving_region();
-  return serving_region_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
- void CachedNetworkParameters::set_allocated_serving_region(::std::string* serving_region) {
-  if (serving_region != NULL) {
-    set_has_serving_region();
-  } else {
-    clear_has_serving_region();
-  }
-  serving_region_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), serving_region);
-  // @@protoc_insertion_point(field_set_allocated:net.CachedNetworkParameters.serving_region)
-}
-
-// optional int32 bandwidth_estimate_bytes_per_second = 2;
-bool CachedNetworkParameters::has_bandwidth_estimate_bytes_per_second() const {
-  return (_has_bits_[0] & 0x00000002u) != 0;
-}
-void CachedNetworkParameters::set_has_bandwidth_estimate_bytes_per_second() {
-  _has_bits_[0] |= 0x00000002u;
-}
-void CachedNetworkParameters::clear_has_bandwidth_estimate_bytes_per_second() {
-  _has_bits_[0] &= ~0x00000002u;
-}
-void CachedNetworkParameters::clear_bandwidth_estimate_bytes_per_second() {
-  bandwidth_estimate_bytes_per_second_ = 0;
-  clear_has_bandwidth_estimate_bytes_per_second();
-}
- ::google::protobuf::int32 CachedNetworkParameters::bandwidth_estimate_bytes_per_second() const {
-  // @@protoc_insertion_point(field_get:net.CachedNetworkParameters.bandwidth_estimate_bytes_per_second)
-  return bandwidth_estimate_bytes_per_second_;
-}
- void CachedNetworkParameters::set_bandwidth_estimate_bytes_per_second(::google::protobuf::int32 value) {
-  set_has_bandwidth_estimate_bytes_per_second();
-  bandwidth_estimate_bytes_per_second_ = value;
-  // @@protoc_insertion_point(field_set:net.CachedNetworkParameters.bandwidth_estimate_bytes_per_second)
-}
-
-// optional int32 max_bandwidth_estimate_bytes_per_second = 5;
-bool CachedNetworkParameters::has_max_bandwidth_estimate_bytes_per_second() const {
-  return (_has_bits_[0] & 0x00000004u) != 0;
-}
-void CachedNetworkParameters::set_has_max_bandwidth_estimate_bytes_per_second() {
-  _has_bits_[0] |= 0x00000004u;
-}
-void CachedNetworkParameters::clear_has_max_bandwidth_estimate_bytes_per_second() {
-  _has_bits_[0] &= ~0x00000004u;
-}
-void CachedNetworkParameters::clear_max_bandwidth_estimate_bytes_per_second() {
-  max_bandwidth_estimate_bytes_per_second_ = 0;
-  clear_has_max_bandwidth_estimate_bytes_per_second();
-}
- ::google::protobuf::int32 CachedNetworkParameters::max_bandwidth_estimate_bytes_per_second() const {
-  // @@protoc_insertion_point(field_get:net.CachedNetworkParameters.max_bandwidth_estimate_bytes_per_second)
-  return max_bandwidth_estimate_bytes_per_second_;
-}
- void CachedNetworkParameters::set_max_bandwidth_estimate_bytes_per_second(::google::protobuf::int32 value) {
-  set_has_max_bandwidth_estimate_bytes_per_second();
-  max_bandwidth_estimate_bytes_per_second_ = value;
-  // @@protoc_insertion_point(field_set:net.CachedNetworkParameters.max_bandwidth_estimate_bytes_per_second)
-}
-
-// optional int64 max_bandwidth_timestamp_seconds = 6;
-bool CachedNetworkParameters::has_max_bandwidth_timestamp_seconds() const {
-  return (_has_bits_[0] & 0x00000008u) != 0;
-}
-void CachedNetworkParameters::set_has_max_bandwidth_timestamp_seconds() {
-  _has_bits_[0] |= 0x00000008u;
-}
-void CachedNetworkParameters::clear_has_max_bandwidth_timestamp_seconds() {
-  _has_bits_[0] &= ~0x00000008u;
-}
-void CachedNetworkParameters::clear_max_bandwidth_timestamp_seconds() {
-  max_bandwidth_timestamp_seconds_ = GOOGLE_LONGLONG(0);
-  clear_has_max_bandwidth_timestamp_seconds();
-}
- ::google::protobuf::int64 CachedNetworkParameters::max_bandwidth_timestamp_seconds() const {
-  // @@protoc_insertion_point(field_get:net.CachedNetworkParameters.max_bandwidth_timestamp_seconds)
-  return max_bandwidth_timestamp_seconds_;
-}
- void CachedNetworkParameters::set_max_bandwidth_timestamp_seconds(::google::protobuf::int64 value) {
-  set_has_max_bandwidth_timestamp_seconds();
-  max_bandwidth_timestamp_seconds_ = value;
-  // @@protoc_insertion_point(field_set:net.CachedNetworkParameters.max_bandwidth_timestamp_seconds)
-}
-
-// optional int32 min_rtt_ms = 3;
-bool CachedNetworkParameters::has_min_rtt_ms() const {
-  return (_has_bits_[0] & 0x00000010u) != 0;
-}
-void CachedNetworkParameters::set_has_min_rtt_ms() {
-  _has_bits_[0] |= 0x00000010u;
-}
-void CachedNetworkParameters::clear_has_min_rtt_ms() {
-  _has_bits_[0] &= ~0x00000010u;
-}
-void CachedNetworkParameters::clear_min_rtt_ms() {
-  min_rtt_ms_ = 0;
-  clear_has_min_rtt_ms();
-}
- ::google::protobuf::int32 CachedNetworkParameters::min_rtt_ms() const {
-  // @@protoc_insertion_point(field_get:net.CachedNetworkParameters.min_rtt_ms)
-  return min_rtt_ms_;
-}
- void CachedNetworkParameters::set_min_rtt_ms(::google::protobuf::int32 value) {
-  set_has_min_rtt_ms();
-  min_rtt_ms_ = value;
-  // @@protoc_insertion_point(field_set:net.CachedNetworkParameters.min_rtt_ms)
-}
-
-// optional int32 previous_connection_state = 4;
-bool CachedNetworkParameters::has_previous_connection_state() const {
-  return (_has_bits_[0] & 0x00000020u) != 0;
-}
-void CachedNetworkParameters::set_has_previous_connection_state() {
-  _has_bits_[0] |= 0x00000020u;
-}
-void CachedNetworkParameters::clear_has_previous_connection_state() {
-  _has_bits_[0] &= ~0x00000020u;
-}
-void CachedNetworkParameters::clear_previous_connection_state() {
-  previous_connection_state_ = 0;
-  clear_has_previous_connection_state();
-}
- ::google::protobuf::int32 CachedNetworkParameters::previous_connection_state() const {
-  // @@protoc_insertion_point(field_get:net.CachedNetworkParameters.previous_connection_state)
-  return previous_connection_state_;
-}
- void CachedNetworkParameters::set_previous_connection_state(::google::protobuf::int32 value) {
-  set_has_previous_connection_state();
-  previous_connection_state_ = value;
-  // @@protoc_insertion_point(field_set:net.CachedNetworkParameters.previous_connection_state)
-}
-
-// optional int64 timestamp = 7;
-bool CachedNetworkParameters::has_timestamp() const {
-  return (_has_bits_[0] & 0x00000040u) != 0;
-}
-void CachedNetworkParameters::set_has_timestamp() {
-  _has_bits_[0] |= 0x00000040u;
-}
-void CachedNetworkParameters::clear_has_timestamp() {
-  _has_bits_[0] &= ~0x00000040u;
-}
-void CachedNetworkParameters::clear_timestamp() {
-  timestamp_ = GOOGLE_LONGLONG(0);
-  clear_has_timestamp();
-}
- ::google::protobuf::int64 CachedNetworkParameters::timestamp() const {
-  // @@protoc_insertion_point(field_get:net.CachedNetworkParameters.timestamp)
-  return timestamp_;
-}
- void CachedNetworkParameters::set_timestamp(::google::protobuf::int64 value) {
-  set_has_timestamp();
-  timestamp_ = value;
-  // @@protoc_insertion_point(field_set:net.CachedNetworkParameters.timestamp)
-}
-
-#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS
-
-// @@protoc_insertion_point(namespace_scope)
-
-}  // namespace net
-
-// @@protoc_insertion_point(global_scope)
diff --git a/src/net/quic/core/proto/cached_network_parameters.pb.h b/src/net/quic/core/proto/cached_network_parameters.pb.h
deleted file mode 100644
index 1b9041d..0000000
--- a/src/net/quic/core/proto/cached_network_parameters.pb.h
+++ /dev/null
@@ -1,459 +0,0 @@
-// Generated by the protocol buffer compiler.  DO NOT EDIT!
-// source: cached_network_parameters.proto
-
-#ifndef PROTOBUF_cached_5fnetwork_5fparameters_2eproto__INCLUDED
-#define PROTOBUF_cached_5fnetwork_5fparameters_2eproto__INCLUDED
-
-#include <string>
-
-#include <google/protobuf/stubs/common.h>
-
-#if GOOGLE_PROTOBUF_VERSION < 3000000
-#error This file was generated by a newer version of protoc which is
-#error incompatible with your Protocol Buffer headers.  Please update
-#error your headers.
-#endif
-#if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
-#error This file was generated by an older version of protoc which is
-#error incompatible with your Protocol Buffer headers.  Please
-#error regenerate this file with a newer version of protoc.
-#endif
-
-#include <google/protobuf/arena.h>
-#include <google/protobuf/arenastring.h>
-#include <google/protobuf/generated_message_util.h>
-#include <google/protobuf/message_lite.h>
-#include <google/protobuf/repeated_field.h>
-#include <google/protobuf/extension_set.h>
-#include <google/protobuf/generated_enum_util.h>
-// @@protoc_insertion_point(includes)
-#include "net/base/net_export.h"
-
-namespace net {
-
-// Internal implementation detail -- do not call these.
-void NET_EXPORT_PRIVATE protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto();
-void protobuf_AssignDesc_cached_5fnetwork_5fparameters_2eproto();
-void protobuf_ShutdownFile_cached_5fnetwork_5fparameters_2eproto();
-
-class CachedNetworkParameters;
-
-enum CachedNetworkParameters_PreviousConnectionState {
-CachedNetworkParameters_PreviousConnectionState_SLOW_START = 0,
-CachedNetworkParameters_PreviousConnectionState_CONGESTION_AVOIDANCE = 1
-};
-NET_EXPORT_PRIVATE bool CachedNetworkParameters_PreviousConnectionState_IsValid(int value);
-const CachedNetworkParameters_PreviousConnectionState CachedNetworkParameters_PreviousConnectionState_PreviousConnectionState_MIN = CachedNetworkParameters_PreviousConnectionState_SLOW_START;
-const CachedNetworkParameters_PreviousConnectionState CachedNetworkParameters_PreviousConnectionState_PreviousConnectionState_MAX = CachedNetworkParameters_PreviousConnectionState_CONGESTION_AVOIDANCE;
-const int CachedNetworkParameters_PreviousConnectionState_PreviousConnectionState_ARRAYSIZE = CachedNetworkParameters_PreviousConnectionState_PreviousConnectionState_MAX + 1;
-
-// ===================================================================
-
-class NET_EXPORT_PRIVATE CachedNetworkParameters : public ::google::protobuf::MessageLite {
-public:
-CachedNetworkParameters();
-virtual ~CachedNetworkParameters();
-
-CachedNetworkParameters(const CachedNetworkParameters& from);
-
-inline CachedNetworkParameters& operator=(const CachedNetworkParameters& from) {
-CopyFrom(from);
-return *this;
-}
-
-inline const ::std::string& unknown_fields() const {
-return _unknown_fields_.GetNoArena(
-&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-inline ::std::string* mutable_unknown_fields() {
-return _unknown_fields_.MutableNoArena(
-&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-static const CachedNetworkParameters& default_instance();
-
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-// Returns the internal default instance pointer. This function can
-// return NULL thus should not be used by the user. This is intended
-// for Protobuf internal code. Please use default_instance() declared
-// above instead.
-static inline const CachedNetworkParameters* internal_default_instance() {
-return default_instance_;
-}
-#endif
-
-GOOGLE_ATTRIBUTE_NOINLINE void Swap(CachedNetworkParameters* other);
-
-// implements Message ----------------------------------------------
-
-inline CachedNetworkParameters* New() const { return New(NULL); }
-
-CachedNetworkParameters* New(::google::protobuf::Arena* arena) const;
-void CheckTypeAndMergeFrom(const ::google::protobuf::MessageLite& from);
-void CopyFrom(const CachedNetworkParameters& from);
-void MergeFrom(const CachedNetworkParameters& from);
-void Clear();
-bool IsInitialized() const;
-
-int ByteSize() const;
-bool MergePartialFromCodedStream(
-::google::protobuf::io::CodedInputStream* input);
-void SerializeWithCachedSizes(
-::google::protobuf::io::CodedOutputStream* output) const;
-void DiscardUnknownFields();
-int GetCachedSize() const { return _cached_size_; }
-private:
-void SharedCtor();
-void SharedDtor();
-void SetCachedSize(int size) const;
-void InternalSwap(CachedNetworkParameters* other);
-private:
-inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
-return _arena_ptr_;
-}
-inline ::google::protobuf::Arena* MaybeArenaPtr() const {
-return _arena_ptr_;
-}
-public:
-
-::std::string GetTypeName() const;
-
-// nested types ----------------------------------------------------
-
-typedef CachedNetworkParameters_PreviousConnectionState PreviousConnectionState;
-static const PreviousConnectionState SLOW_START =
-CachedNetworkParameters_PreviousConnectionState_SLOW_START;
-static const PreviousConnectionState CONGESTION_AVOIDANCE =
-CachedNetworkParameters_PreviousConnectionState_CONGESTION_AVOIDANCE;
-static inline bool PreviousConnectionState_IsValid(int value) {
-return CachedNetworkParameters_PreviousConnectionState_IsValid(value);
-}
-static const PreviousConnectionState PreviousConnectionState_MIN =
-CachedNetworkParameters_PreviousConnectionState_PreviousConnectionState_MIN;
-static const PreviousConnectionState PreviousConnectionState_MAX =
-CachedNetworkParameters_PreviousConnectionState_PreviousConnectionState_MAX;
-static const int PreviousConnectionState_ARRAYSIZE =
-CachedNetworkParameters_PreviousConnectionState_PreviousConnectionState_ARRAYSIZE;
-
-// accessors -------------------------------------------------------
-
-// optional string serving_region = 1;
-bool has_serving_region() const;
-void clear_serving_region();
-static const int kServingRegionFieldNumber = 1;
-const ::std::string& serving_region() const;
-void set_serving_region(const ::std::string& value);
-void set_serving_region(const char* value);
-void set_serving_region(const char* value, size_t size);
-::std::string* mutable_serving_region();
-::std::string* release_serving_region();
-void set_allocated_serving_region(::std::string* serving_region);
-
-// optional int32 bandwidth_estimate_bytes_per_second = 2;
-bool has_bandwidth_estimate_bytes_per_second() const;
-void clear_bandwidth_estimate_bytes_per_second();
-static const int kBandwidthEstimateBytesPerSecondFieldNumber = 2;
-::google::protobuf::int32 bandwidth_estimate_bytes_per_second() const;
-void set_bandwidth_estimate_bytes_per_second(::google::protobuf::int32 value);
-
-// optional int32 max_bandwidth_estimate_bytes_per_second = 5;
-bool has_max_bandwidth_estimate_bytes_per_second() const;
-void clear_max_bandwidth_estimate_bytes_per_second();
-static const int kMaxBandwidthEstimateBytesPerSecondFieldNumber = 5;
-::google::protobuf::int32 max_bandwidth_estimate_bytes_per_second() const;
-void set_max_bandwidth_estimate_bytes_per_second(::google::protobuf::int32 value);
-
-// optional int64 max_bandwidth_timestamp_seconds = 6;
-bool has_max_bandwidth_timestamp_seconds() const;
-void clear_max_bandwidth_timestamp_seconds();
-static const int kMaxBandwidthTimestampSecondsFieldNumber = 6;
-::google::protobuf::int64 max_bandwidth_timestamp_seconds() const;
-void set_max_bandwidth_timestamp_seconds(::google::protobuf::int64 value);
-
-// optional int32 min_rtt_ms = 3;
-bool has_min_rtt_ms() const;
-void clear_min_rtt_ms();
-static const int kMinRttMsFieldNumber = 3;
-::google::protobuf::int32 min_rtt_ms() const;
-void set_min_rtt_ms(::google::protobuf::int32 value);
-
-// optional int32 previous_connection_state = 4;
-bool has_previous_connection_state() const;
-void clear_previous_connection_state();
-static const int kPreviousConnectionStateFieldNumber = 4;
-::google::protobuf::int32 previous_connection_state() const;
-void set_previous_connection_state(::google::protobuf::int32 value);
-
-// optional int64 timestamp = 7;
-bool has_timestamp() const;
-void clear_timestamp();
-static const int kTimestampFieldNumber = 7;
-::google::protobuf::int64 timestamp() const;
-void set_timestamp(::google::protobuf::int64 value);
-
-// @@protoc_insertion_point(class_scope:net.CachedNetworkParameters)
-private:
-inline void set_has_serving_region();
-inline void clear_has_serving_region();
-inline void set_has_bandwidth_estimate_bytes_per_second();
-inline void clear_has_bandwidth_estimate_bytes_per_second();
-inline void set_has_max_bandwidth_estimate_bytes_per_second();
-inline void clear_has_max_bandwidth_estimate_bytes_per_second();
-inline void set_has_max_bandwidth_timestamp_seconds();
-inline void clear_has_max_bandwidth_timestamp_seconds();
-inline void set_has_min_rtt_ms();
-inline void clear_has_min_rtt_ms();
-inline void set_has_previous_connection_state();
-inline void clear_has_previous_connection_state();
-inline void set_has_timestamp();
-inline void clear_has_timestamp();
-
-::google::protobuf::internal::ArenaStringPtr _unknown_fields_;
-::google::protobuf::Arena* _arena_ptr_;
-
-::google::protobuf::uint32 _has_bits_[1];
-mutable int _cached_size_;
-::google::protobuf::internal::ArenaStringPtr serving_region_;
-::google::protobuf::int32 bandwidth_estimate_bytes_per_second_;
-::google::protobuf::int32 max_bandwidth_estimate_bytes_per_second_;
-::google::protobuf::int64 max_bandwidth_timestamp_seconds_;
-::google::protobuf::int32 min_rtt_ms_;
-::google::protobuf::int32 previous_connection_state_;
-::google::protobuf::int64 timestamp_;
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-friend void NET_EXPORT_PRIVATE protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto_impl();
-#else
-friend void NET_EXPORT_PRIVATE protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto();
-#endif
-friend void protobuf_AssignDesc_cached_5fnetwork_5fparameters_2eproto();
-friend void protobuf_ShutdownFile_cached_5fnetwork_5fparameters_2eproto();
-
-void InitAsDefaultInstance();
-static CachedNetworkParameters* default_instance_;
-};
-// ===================================================================
-
-
-// ===================================================================
-
-#if !PROTOBUF_INLINE_NOT_IN_HEADERS
-// CachedNetworkParameters
-
-// optional string serving_region = 1;
-inline bool CachedNetworkParameters::has_serving_region() const {
-return (_has_bits_[0] & 0x00000001u) != 0;
-}
-inline void CachedNetworkParameters::set_has_serving_region() {
-_has_bits_[0] |= 0x00000001u;
-}
-inline void CachedNetworkParameters::clear_has_serving_region() {
-_has_bits_[0] &= ~0x00000001u;
-}
-inline void CachedNetworkParameters::clear_serving_region() {
-serving_region_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-clear_has_serving_region();
-}
-inline const ::std::string& CachedNetworkParameters::serving_region() const {
-// @@protoc_insertion_point(field_get:net.CachedNetworkParameters.serving_region)
-return serving_region_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-inline void CachedNetworkParameters::set_serving_region(const ::std::string& value) {
-set_has_serving_region();
-serving_region_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
-// @@protoc_insertion_point(field_set:net.CachedNetworkParameters.serving_region)
-}
-inline void CachedNetworkParameters::set_serving_region(const char* value) {
-set_has_serving_region();
-serving_region_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
-// @@protoc_insertion_point(field_set_char:net.CachedNetworkParameters.serving_region)
-}
-inline void CachedNetworkParameters::set_serving_region(const char* value, size_t size) {
-set_has_serving_region();
-serving_region_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
-::std::string(reinterpret_cast<const char*>(value), size));
-// @@protoc_insertion_point(field_set_pointer:net.CachedNetworkParameters.serving_region)
-}
-inline ::std::string* CachedNetworkParameters::mutable_serving_region() {
-set_has_serving_region();
-// @@protoc_insertion_point(field_mutable:net.CachedNetworkParameters.serving_region)
-return serving_region_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-inline ::std::string* CachedNetworkParameters::release_serving_region() {
-// @@protoc_insertion_point(field_release:net.CachedNetworkParameters.serving_region)
-clear_has_serving_region();
-return serving_region_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-inline void CachedNetworkParameters::set_allocated_serving_region(::std::string* serving_region) {
-if (serving_region != NULL) {
-set_has_serving_region();
-} else {
-clear_has_serving_region();
-}
-serving_region_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), serving_region);
-// @@protoc_insertion_point(field_set_allocated:net.CachedNetworkParameters.serving_region)
-}
-
-// optional int32 bandwidth_estimate_bytes_per_second = 2;
-inline bool CachedNetworkParameters::has_bandwidth_estimate_bytes_per_second() const {
-return (_has_bits_[0] & 0x00000002u) != 0;
-}
-inline void CachedNetworkParameters::set_has_bandwidth_estimate_bytes_per_second() {
-_has_bits_[0] |= 0x00000002u;
-}
-inline void CachedNetworkParameters::clear_has_bandwidth_estimate_bytes_per_second() {
-_has_bits_[0] &= ~0x00000002u;
-}
-inline void CachedNetworkParameters::clear_bandwidth_estimate_bytes_per_second() {
-bandwidth_estimate_bytes_per_second_ = 0;
-clear_has_bandwidth_estimate_bytes_per_second();
-}
-inline ::google::protobuf::int32 CachedNetworkParameters::bandwidth_estimate_bytes_per_second() const {
-// @@protoc_insertion_point(field_get:net.CachedNetworkParameters.bandwidth_estimate_bytes_per_second)
-return bandwidth_estimate_bytes_per_second_;
-}
-inline void CachedNetworkParameters::set_bandwidth_estimate_bytes_per_second(::google::protobuf::int32 value) {
-set_has_bandwidth_estimate_bytes_per_second();
-bandwidth_estimate_bytes_per_second_ = value;
-// @@protoc_insertion_point(field_set:net.CachedNetworkParameters.bandwidth_estimate_bytes_per_second)
-}
-
-// optional int32 max_bandwidth_estimate_bytes_per_second = 5;
-inline bool CachedNetworkParameters::has_max_bandwidth_estimate_bytes_per_second() const {
-return (_has_bits_[0] & 0x00000004u) != 0;
-}
-inline void CachedNetworkParameters::set_has_max_bandwidth_estimate_bytes_per_second() {
-_has_bits_[0] |= 0x00000004u;
-}
-inline void CachedNetworkParameters::clear_has_max_bandwidth_estimate_bytes_per_second() {
-_has_bits_[0] &= ~0x00000004u;
-}
-inline void CachedNetworkParameters::clear_max_bandwidth_estimate_bytes_per_second() {
-max_bandwidth_estimate_bytes_per_second_ = 0;
-clear_has_max_bandwidth_estimate_bytes_per_second();
-}
-inline ::google::protobuf::int32 CachedNetworkParameters::max_bandwidth_estimate_bytes_per_second() const {
-// @@protoc_insertion_point(field_get:net.CachedNetworkParameters.max_bandwidth_estimate_bytes_per_second)
-return max_bandwidth_estimate_bytes_per_second_;
-}
-inline void CachedNetworkParameters::set_max_bandwidth_estimate_bytes_per_second(::google::protobuf::int32 value) {
-set_has_max_bandwidth_estimate_bytes_per_second();
-max_bandwidth_estimate_bytes_per_second_ = value;
-// @@protoc_insertion_point(field_set:net.CachedNetworkParameters.max_bandwidth_estimate_bytes_per_second)
-}
-
-// optional int64 max_bandwidth_timestamp_seconds = 6;
-inline bool CachedNetworkParameters::has_max_bandwidth_timestamp_seconds() const {
-return (_has_bits_[0] & 0x00000008u) != 0;
-}
-inline void CachedNetworkParameters::set_has_max_bandwidth_timestamp_seconds() {
-_has_bits_[0] |= 0x00000008u;
-}
-inline void CachedNetworkParameters::clear_has_max_bandwidth_timestamp_seconds() {
-_has_bits_[0] &= ~0x00000008u;
-}
-inline void CachedNetworkParameters::clear_max_bandwidth_timestamp_seconds() {
-max_bandwidth_timestamp_seconds_ = GOOGLE_LONGLONG(0);
-clear_has_max_bandwidth_timestamp_seconds();
-}
-inline ::google::protobuf::int64 CachedNetworkParameters::max_bandwidth_timestamp_seconds() const {
-// @@protoc_insertion_point(field_get:net.CachedNetworkParameters.max_bandwidth_timestamp_seconds)
-return max_bandwidth_timestamp_seconds_;
-}
-inline void CachedNetworkParameters::set_max_bandwidth_timestamp_seconds(::google::protobuf::int64 value) {
-set_has_max_bandwidth_timestamp_seconds();
-max_bandwidth_timestamp_seconds_ = value;
-// @@protoc_insertion_point(field_set:net.CachedNetworkParameters.max_bandwidth_timestamp_seconds)
-}
-
-// optional int32 min_rtt_ms = 3;
-inline bool CachedNetworkParameters::has_min_rtt_ms() const {
-return (_has_bits_[0] & 0x00000010u) != 0;
-}
-inline void CachedNetworkParameters::set_has_min_rtt_ms() {
-_has_bits_[0] |= 0x00000010u;
-}
-inline void CachedNetworkParameters::clear_has_min_rtt_ms() {
-_has_bits_[0] &= ~0x00000010u;
-}
-inline void CachedNetworkParameters::clear_min_rtt_ms() {
-min_rtt_ms_ = 0;
-clear_has_min_rtt_ms();
-}
-inline ::google::protobuf::int32 CachedNetworkParameters::min_rtt_ms() const {
-// @@protoc_insertion_point(field_get:net.CachedNetworkParameters.min_rtt_ms)
-return min_rtt_ms_;
-}
-inline void CachedNetworkParameters::set_min_rtt_ms(::google::protobuf::int32 value) {
-set_has_min_rtt_ms();
-min_rtt_ms_ = value;
-// @@protoc_insertion_point(field_set:net.CachedNetworkParameters.min_rtt_ms)
-}
-
-// optional int32 previous_connection_state = 4;
-inline bool CachedNetworkParameters::has_previous_connection_state() const {
-return (_has_bits_[0] & 0x00000020u) != 0;
-}
-inline void CachedNetworkParameters::set_has_previous_connection_state() {
-_has_bits_[0] |= 0x00000020u;
-}
-inline void CachedNetworkParameters::clear_has_previous_connection_state() {
-_has_bits_[0] &= ~0x00000020u;
-}
-inline void CachedNetworkParameters::clear_previous_connection_state() {
-previous_connection_state_ = 0;
-clear_has_previous_connection_state();
-}
-inline ::google::protobuf::int32 CachedNetworkParameters::previous_connection_state() const {
-// @@protoc_insertion_point(field_get:net.CachedNetworkParameters.previous_connection_state)
-return previous_connection_state_;
-}
-inline void CachedNetworkParameters::set_previous_connection_state(::google::protobuf::int32 value) {
-set_has_previous_connection_state();
-previous_connection_state_ = value;
-// @@protoc_insertion_point(field_set:net.CachedNetworkParameters.previous_connection_state)
-}
-
-// optional int64 timestamp = 7;
-inline bool CachedNetworkParameters::has_timestamp() const {
-return (_has_bits_[0] & 0x00000040u) != 0;
-}
-inline void CachedNetworkParameters::set_has_timestamp() {
-_has_bits_[0] |= 0x00000040u;
-}
-inline void CachedNetworkParameters::clear_has_timestamp() {
-_has_bits_[0] &= ~0x00000040u;
-}
-inline void CachedNetworkParameters::clear_timestamp() {
-timestamp_ = GOOGLE_LONGLONG(0);
-clear_has_timestamp();
-}
-inline ::google::protobuf::int64 CachedNetworkParameters::timestamp() const {
-// @@protoc_insertion_point(field_get:net.CachedNetworkParameters.timestamp)
-return timestamp_;
-}
-inline void CachedNetworkParameters::set_timestamp(::google::protobuf::int64 value) {
-set_has_timestamp();
-timestamp_ = value;
-// @@protoc_insertion_point(field_set:net.CachedNetworkParameters.timestamp)
-}
-
-#endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
-
-// @@protoc_insertion_point(namespace_scope)
-
-}  // namespace net
-
-#ifndef SWIG
-namespace google {
-namespace protobuf {
-
-template <> struct is_proto_enum< ::net::CachedNetworkParameters_PreviousConnectionState> : ::google::protobuf::internal::true_type {};
-
-}  // namespace protobuf
-}  // namespace google
-#endif  // SWIG
-
-// @@protoc_insertion_point(global_scope)
-
-#endif  // PROTOBUF_cached_5fnetwork_5fparameters_2eproto__INCLUDED
diff --git a/src/net/quic/core/proto/source_address_token.pb.cc b/src/net/quic/core/proto/source_address_token.pb.cc
deleted file mode 100644
index 925a0ea..0000000
--- a/src/net/quic/core/proto/source_address_token.pb.cc
+++ /dev/null
@@ -1,767 +0,0 @@
-// Generated by the protocol buffer compiler.  DO NOT EDIT!
-// source: source_address_token.proto
-
-#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
-#include "source_address_token.pb.h"
-
-#include <algorithm>
-
-#include <google/protobuf/stubs/common.h>
-#include <google/protobuf/stubs/port.h>
-#include <google/protobuf/stubs/once.h>
-#include <google/protobuf/io/coded_stream.h>
-#include <google/protobuf/wire_format_lite_inl.h>
-#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
-// @@protoc_insertion_point(includes)
-
-namespace net {
-
-void protobuf_ShutdownFile_source_5faddress_5ftoken_2eproto() {
-  delete SourceAddressToken::default_instance_;
-  delete SourceAddressTokens::default_instance_;
-}
-
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-void protobuf_AddDesc_source_5faddress_5ftoken_2eproto_impl() {
-  GOOGLE_PROTOBUF_VERIFY_VERSION;
-
-#else
-void protobuf_AddDesc_source_5faddress_5ftoken_2eproto() {
-  static bool already_here = false;
-  if (already_here) return;
-  already_here = true;
-  GOOGLE_PROTOBUF_VERIFY_VERSION;
-
-#endif
-  ::net::protobuf_AddDesc_cached_5fnetwork_5fparameters_2eproto();
-  SourceAddressToken::default_instance_ = new SourceAddressToken();
-  SourceAddressTokens::default_instance_ = new SourceAddressTokens();
-  SourceAddressToken::default_instance_->InitAsDefaultInstance();
-  SourceAddressTokens::default_instance_->InitAsDefaultInstance();
-  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_source_5faddress_5ftoken_2eproto);
-}
-
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AddDesc_source_5faddress_5ftoken_2eproto_once_);
-void protobuf_AddDesc_source_5faddress_5ftoken_2eproto() {
-  ::google::protobuf::GoogleOnceInit(&protobuf_AddDesc_source_5faddress_5ftoken_2eproto_once_,
-                 &protobuf_AddDesc_source_5faddress_5ftoken_2eproto_impl);
-}
-#else
-// Force AddDescriptors() to be called at static initialization time.
-struct StaticDescriptorInitializer_source_5faddress_5ftoken_2eproto {
-  StaticDescriptorInitializer_source_5faddress_5ftoken_2eproto() {
-    protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-  }
-} static_descriptor_initializer_source_5faddress_5ftoken_2eproto_;
-#endif
-
-namespace {
-
-static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
-GOOGLE_ATTRIBUTE_NOINLINE static void MergeFromFail(int line) {
-  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
-}
-
-}  // namespace
-
-
-// ===================================================================
-
-static ::std::string* MutableUnknownFieldsForSourceAddressToken(
-    SourceAddressToken* ptr) {
-  return ptr->mutable_unknown_fields();
-}
-
-#if !defined(_MSC_VER) || _MSC_VER >= 1900
-const int SourceAddressToken::kIpFieldNumber;
-const int SourceAddressToken::kTimestampFieldNumber;
-const int SourceAddressToken::kCachedNetworkParametersFieldNumber;
-#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
-
-SourceAddressToken::SourceAddressToken()
-  : ::google::protobuf::MessageLite(), _arena_ptr_(NULL) {
-  SharedCtor();
-  // @@protoc_insertion_point(constructor:net.SourceAddressToken)
-}
-
-void SourceAddressToken::InitAsDefaultInstance() {
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  cached_network_parameters_ = const_cast< ::net::CachedNetworkParameters*>(
-      ::net::CachedNetworkParameters::internal_default_instance());
-#else
-  cached_network_parameters_ = const_cast< ::net::CachedNetworkParameters*>(&::net::CachedNetworkParameters::default_instance());
-#endif
-}
-
-SourceAddressToken::SourceAddressToken(const SourceAddressToken& from)
-  : ::google::protobuf::MessageLite(),
-    _arena_ptr_(NULL) {
-  SharedCtor();
-  MergeFrom(from);
-  // @@protoc_insertion_point(copy_constructor:net.SourceAddressToken)
-}
-
-void SourceAddressToken::SharedCtor() {
-  ::google::protobuf::internal::GetEmptyString();
-  _cached_size_ = 0;
-  _unknown_fields_.UnsafeSetDefault(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  ip_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  timestamp_ = GOOGLE_LONGLONG(0);
-  cached_network_parameters_ = NULL;
-  ::memset(_has_bits_, 0, sizeof(_has_bits_));
-}
-
-SourceAddressToken::~SourceAddressToken() {
-  // @@protoc_insertion_point(destructor:net.SourceAddressToken)
-  SharedDtor();
-}
-
-void SourceAddressToken::SharedDtor() {
-  _unknown_fields_.DestroyNoArena(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  ip_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  #ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  if (this != &default_instance()) {
-  #else
-  if (this != default_instance_) {
-  #endif
-    delete cached_network_parameters_;
-  }
-}
-
-void SourceAddressToken::SetCachedSize(int size) const {
-  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
-  _cached_size_ = size;
-  GOOGLE_SAFE_CONCURRENT_WRITES_END();
-}
-const SourceAddressToken& SourceAddressToken::default_instance() {
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-#else
-  if (default_instance_ == NULL) protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-#endif
-  return *default_instance_;
-}
-
-SourceAddressToken* SourceAddressToken::default_instance_ = NULL;
-
-SourceAddressToken* SourceAddressToken::New(::google::protobuf::Arena* arena) const {
-  SourceAddressToken* n = new SourceAddressToken;
-  if (arena != NULL) {
-    arena->Own(n);
-  }
-  return n;
-}
-
-void SourceAddressToken::Clear() {
-// @@protoc_insertion_point(message_clear_start:net.SourceAddressToken)
-  if (_has_bits_[0 / 32] & 7u) {
-    if (has_ip()) {
-      ip_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-    }
-    timestamp_ = GOOGLE_LONGLONG(0);
-    if (has_cached_network_parameters()) {
-      if (cached_network_parameters_ != NULL) cached_network_parameters_->::net::CachedNetworkParameters::Clear();
-    }
-  }
-  ::memset(_has_bits_, 0, sizeof(_has_bits_));
-  _unknown_fields_.ClearToEmptyNoArena(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-bool SourceAddressToken::MergePartialFromCodedStream(
-    ::google::protobuf::io::CodedInputStream* input) {
-#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
-  ::google::protobuf::uint32 tag;
-  ::google::protobuf::io::LazyStringOutputStream unknown_fields_string(
-      ::google::protobuf::internal::NewPermanentCallback(
-          &MutableUnknownFieldsForSourceAddressToken, this));
-  ::google::protobuf::io::CodedOutputStream unknown_fields_stream(
-      &unknown_fields_string, false);
-  // @@protoc_insertion_point(parse_start:net.SourceAddressToken)
-  for (;;) {
-    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
-    tag = p.first;
-    if (!p.second) goto handle_unusual;
-    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
-      // required bytes ip = 1;
-      case 1: {
-        if (tag == 10) {
-          DO_(::google::protobuf::internal::WireFormatLite::ReadBytes(
-                input, this->mutable_ip()));
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(16)) goto parse_timestamp;
-        break;
-      }
-
-      // required int64 timestamp = 2;
-      case 2: {
-        if (tag == 16) {
-         parse_timestamp:
-          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
-                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
-                 input, &timestamp_)));
-          set_has_timestamp();
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(26)) goto parse_cached_network_parameters;
-        break;
-      }
-
-      // optional .net.CachedNetworkParameters cached_network_parameters = 3;
-      case 3: {
-        if (tag == 26) {
-         parse_cached_network_parameters:
-          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
-               input, mutable_cached_network_parameters()));
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectAtEnd()) goto success;
-        break;
-      }
-
-      default: {
-      handle_unusual:
-        if (tag == 0 ||
-            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
-            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
-          goto success;
-        }
-        DO_(::google::protobuf::internal::WireFormatLite::SkipField(
-            input, tag, &unknown_fields_stream));
-        break;
-      }
-    }
-  }
-success:
-  // @@protoc_insertion_point(parse_success:net.SourceAddressToken)
-  return true;
-failure:
-  // @@protoc_insertion_point(parse_failure:net.SourceAddressToken)
-  return false;
-#undef DO_
-}
-
-void SourceAddressToken::SerializeWithCachedSizes(
-    ::google::protobuf::io::CodedOutputStream* output) const {
-  // @@protoc_insertion_point(serialize_start:net.SourceAddressToken)
-  // required bytes ip = 1;
-  if (has_ip()) {
-    ::google::protobuf::internal::WireFormatLite::WriteBytesMaybeAliased(
-      1, this->ip(), output);
-  }
-
-  // required int64 timestamp = 2;
-  if (has_timestamp()) {
-    ::google::protobuf::internal::WireFormatLite::WriteInt64(2, this->timestamp(), output);
-  }
-
-  // optional .net.CachedNetworkParameters cached_network_parameters = 3;
-  if (has_cached_network_parameters()) {
-    ::google::protobuf::internal::WireFormatLite::WriteMessage(
-      3, *this->cached_network_parameters_, output);
-  }
-
-  output->WriteRaw(unknown_fields().data(),
-                   static_cast<int>(unknown_fields().size()));
-  // @@protoc_insertion_point(serialize_end:net.SourceAddressToken)
-}
-
-int SourceAddressToken::RequiredFieldsByteSizeFallback() const {
-// @@protoc_insertion_point(required_fields_byte_size_fallback_start:net.SourceAddressToken)
-  int total_size = 0;
-
-  if (has_ip()) {
-    // required bytes ip = 1;
-    total_size += 1 +
-      ::google::protobuf::internal::WireFormatLite::BytesSize(
-        this->ip());
-  }
-
-  if (has_timestamp()) {
-    // required int64 timestamp = 2;
-    total_size += 1 +
-      ::google::protobuf::internal::WireFormatLite::Int64Size(
-        this->timestamp());
-  }
-
-  return total_size;
-}
-int SourceAddressToken::ByteSize() const {
-// @@protoc_insertion_point(message_byte_size_start:net.SourceAddressToken)
-  int total_size = 0;
-
-  if (((_has_bits_[0] & 0x00000003) ^ 0x00000003) == 0) {  // All required fields are present.
-    // required bytes ip = 1;
-    total_size += 1 +
-      ::google::protobuf::internal::WireFormatLite::BytesSize(
-        this->ip());
-
-    // required int64 timestamp = 2;
-    total_size += 1 +
-      ::google::protobuf::internal::WireFormatLite::Int64Size(
-        this->timestamp());
-
-  } else {
-    total_size += RequiredFieldsByteSizeFallback();
-  }
-  // optional .net.CachedNetworkParameters cached_network_parameters = 3;
-  if (has_cached_network_parameters()) {
-    total_size += 1 +
-      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
-        *this->cached_network_parameters_);
-  }
-
-  total_size += unknown_fields().size();
-
-  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
-  _cached_size_ = total_size;
-  GOOGLE_SAFE_CONCURRENT_WRITES_END();
-  return total_size;
-}
-
-void SourceAddressToken::CheckTypeAndMergeFrom(
-    const ::google::protobuf::MessageLite& from) {
-  MergeFrom(*::google::protobuf::down_cast<const SourceAddressToken*>(&from));
-}
-
-void SourceAddressToken::MergeFrom(const SourceAddressToken& from) {
-// @@protoc_insertion_point(class_specific_merge_from_start:net.SourceAddressToken)
-  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
-  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
-    if (from.has_ip()) {
-      set_has_ip();
-      ip_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.ip_);
-    }
-    if (from.has_timestamp()) {
-      set_timestamp(from.timestamp());
-    }
-    if (from.has_cached_network_parameters()) {
-      mutable_cached_network_parameters()->::net::CachedNetworkParameters::MergeFrom(from.cached_network_parameters());
-    }
-  }
-  if (!from.unknown_fields().empty()) {
-    mutable_unknown_fields()->append(from.unknown_fields());
-  }
-}
-
-void SourceAddressToken::CopyFrom(const SourceAddressToken& from) {
-// @@protoc_insertion_point(class_specific_copy_from_start:net.SourceAddressToken)
-  if (&from == this) return;
-  Clear();
-  MergeFrom(from);
-}
-
-bool SourceAddressToken::IsInitialized() const {
-  if ((_has_bits_[0] & 0x00000003) != 0x00000003) return false;
-
-  return true;
-}
-
-void SourceAddressToken::Swap(SourceAddressToken* other) {
-  if (other == this) return;
-  InternalSwap(other);
-}
-void SourceAddressToken::InternalSwap(SourceAddressToken* other) {
-  ip_.Swap(&other->ip_);
-  std::swap(timestamp_, other->timestamp_);
-  std::swap(cached_network_parameters_, other->cached_network_parameters_);
-  std::swap(_has_bits_[0], other->_has_bits_[0]);
-  _unknown_fields_.Swap(&other->_unknown_fields_);
-  std::swap(_cached_size_, other->_cached_size_);
-}
-
-::std::string SourceAddressToken::GetTypeName() const {
-  return "net.SourceAddressToken";
-}
-
-#if PROTOBUF_INLINE_NOT_IN_HEADERS
-// SourceAddressToken
-
-// required bytes ip = 1;
-bool SourceAddressToken::has_ip() const {
-  return (_has_bits_[0] & 0x00000001u) != 0;
-}
-void SourceAddressToken::set_has_ip() {
-  _has_bits_[0] |= 0x00000001u;
-}
-void SourceAddressToken::clear_has_ip() {
-  _has_bits_[0] &= ~0x00000001u;
-}
-void SourceAddressToken::clear_ip() {
-  ip_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  clear_has_ip();
-}
- const ::std::string& SourceAddressToken::ip() const {
-  // @@protoc_insertion_point(field_get:net.SourceAddressToken.ip)
-  return ip_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
- void SourceAddressToken::set_ip(const ::std::string& value) {
-  set_has_ip();
-  ip_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
-  // @@protoc_insertion_point(field_set:net.SourceAddressToken.ip)
-}
- void SourceAddressToken::set_ip(const char* value) {
-  set_has_ip();
-  ip_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
-  // @@protoc_insertion_point(field_set_char:net.SourceAddressToken.ip)
-}
- void SourceAddressToken::set_ip(const void* value, size_t size) {
-  set_has_ip();
-  ip_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
-      ::std::string(reinterpret_cast<const char*>(value), size));
-  // @@protoc_insertion_point(field_set_pointer:net.SourceAddressToken.ip)
-}
- ::std::string* SourceAddressToken::mutable_ip() {
-  set_has_ip();
-  // @@protoc_insertion_point(field_mutable:net.SourceAddressToken.ip)
-  return ip_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
- ::std::string* SourceAddressToken::release_ip() {
-  // @@protoc_insertion_point(field_release:net.SourceAddressToken.ip)
-  clear_has_ip();
-  return ip_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
- void SourceAddressToken::set_allocated_ip(::std::string* ip) {
-  if (ip != NULL) {
-    set_has_ip();
-  } else {
-    clear_has_ip();
-  }
-  ip_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ip);
-  // @@protoc_insertion_point(field_set_allocated:net.SourceAddressToken.ip)
-}
-
-// required int64 timestamp = 2;
-bool SourceAddressToken::has_timestamp() const {
-  return (_has_bits_[0] & 0x00000002u) != 0;
-}
-void SourceAddressToken::set_has_timestamp() {
-  _has_bits_[0] |= 0x00000002u;
-}
-void SourceAddressToken::clear_has_timestamp() {
-  _has_bits_[0] &= ~0x00000002u;
-}
-void SourceAddressToken::clear_timestamp() {
-  timestamp_ = GOOGLE_LONGLONG(0);
-  clear_has_timestamp();
-}
- ::google::protobuf::int64 SourceAddressToken::timestamp() const {
-  // @@protoc_insertion_point(field_get:net.SourceAddressToken.timestamp)
-  return timestamp_;
-}
- void SourceAddressToken::set_timestamp(::google::protobuf::int64 value) {
-  set_has_timestamp();
-  timestamp_ = value;
-  // @@protoc_insertion_point(field_set:net.SourceAddressToken.timestamp)
-}
-
-// optional .net.CachedNetworkParameters cached_network_parameters = 3;
-bool SourceAddressToken::has_cached_network_parameters() const {
-  return (_has_bits_[0] & 0x00000004u) != 0;
-}
-void SourceAddressToken::set_has_cached_network_parameters() {
-  _has_bits_[0] |= 0x00000004u;
-}
-void SourceAddressToken::clear_has_cached_network_parameters() {
-  _has_bits_[0] &= ~0x00000004u;
-}
-void SourceAddressToken::clear_cached_network_parameters() {
-  if (cached_network_parameters_ != NULL) cached_network_parameters_->::net::CachedNetworkParameters::Clear();
-  clear_has_cached_network_parameters();
-}
-const ::net::CachedNetworkParameters& SourceAddressToken::cached_network_parameters() const {
-  // @@protoc_insertion_point(field_get:net.SourceAddressToken.cached_network_parameters)
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  return cached_network_parameters_ != NULL ? *cached_network_parameters_ : *default_instance().cached_network_parameters_;
-#else
-  return cached_network_parameters_ != NULL ? *cached_network_parameters_ : *default_instance_->cached_network_parameters_;
-#endif
-}
-::net::CachedNetworkParameters* SourceAddressToken::mutable_cached_network_parameters() {
-  set_has_cached_network_parameters();
-  if (cached_network_parameters_ == NULL) {
-    cached_network_parameters_ = new ::net::CachedNetworkParameters;
-  }
-  // @@protoc_insertion_point(field_mutable:net.SourceAddressToken.cached_network_parameters)
-  return cached_network_parameters_;
-}
-::net::CachedNetworkParameters* SourceAddressToken::release_cached_network_parameters() {
-  // @@protoc_insertion_point(field_release:net.SourceAddressToken.cached_network_parameters)
-  clear_has_cached_network_parameters();
-  ::net::CachedNetworkParameters* temp = cached_network_parameters_;
-  cached_network_parameters_ = NULL;
-  return temp;
-}
-void SourceAddressToken::set_allocated_cached_network_parameters(::net::CachedNetworkParameters* cached_network_parameters) {
-  delete cached_network_parameters_;
-  cached_network_parameters_ = cached_network_parameters;
-  if (cached_network_parameters) {
-    set_has_cached_network_parameters();
-  } else {
-    clear_has_cached_network_parameters();
-  }
-  // @@protoc_insertion_point(field_set_allocated:net.SourceAddressToken.cached_network_parameters)
-}
-
-#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS
-
-// ===================================================================
-
-static ::std::string* MutableUnknownFieldsForSourceAddressTokens(
-    SourceAddressTokens* ptr) {
-  return ptr->mutable_unknown_fields();
-}
-
-#if !defined(_MSC_VER) || _MSC_VER >= 1900
-const int SourceAddressTokens::kTokensFieldNumber;
-#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900
-
-SourceAddressTokens::SourceAddressTokens()
-  : ::google::protobuf::MessageLite(), _arena_ptr_(NULL) {
-  SharedCtor();
-  // @@protoc_insertion_point(constructor:net.SourceAddressTokens)
-}
-
-void SourceAddressTokens::InitAsDefaultInstance() {
-}
-
-SourceAddressTokens::SourceAddressTokens(const SourceAddressTokens& from)
-  : ::google::protobuf::MessageLite(),
-    _arena_ptr_(NULL) {
-  SharedCtor();
-  MergeFrom(from);
-  // @@protoc_insertion_point(copy_constructor:net.SourceAddressTokens)
-}
-
-void SourceAddressTokens::SharedCtor() {
-  ::google::protobuf::internal::GetEmptyString();
-  _cached_size_ = 0;
-  _unknown_fields_.UnsafeSetDefault(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  ::memset(_has_bits_, 0, sizeof(_has_bits_));
-}
-
-SourceAddressTokens::~SourceAddressTokens() {
-  // @@protoc_insertion_point(destructor:net.SourceAddressTokens)
-  SharedDtor();
-}
-
-void SourceAddressTokens::SharedDtor() {
-  _unknown_fields_.DestroyNoArena(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-  #ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  if (this != &default_instance()) {
-  #else
-  if (this != default_instance_) {
-  #endif
-  }
-}
-
-void SourceAddressTokens::SetCachedSize(int size) const {
-  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
-  _cached_size_ = size;
-  GOOGLE_SAFE_CONCURRENT_WRITES_END();
-}
-const SourceAddressTokens& SourceAddressTokens::default_instance() {
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-  protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-#else
-  if (default_instance_ == NULL) protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-#endif
-  return *default_instance_;
-}
-
-SourceAddressTokens* SourceAddressTokens::default_instance_ = NULL;
-
-SourceAddressTokens* SourceAddressTokens::New(::google::protobuf::Arena* arena) const {
-  SourceAddressTokens* n = new SourceAddressTokens;
-  if (arena != NULL) {
-    arena->Own(n);
-  }
-  return n;
-}
-
-void SourceAddressTokens::Clear() {
-// @@protoc_insertion_point(message_clear_start:net.SourceAddressTokens)
-  tokens_.Clear();
-  ::memset(_has_bits_, 0, sizeof(_has_bits_));
-  _unknown_fields_.ClearToEmptyNoArena(
-      &::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-bool SourceAddressTokens::MergePartialFromCodedStream(
-    ::google::protobuf::io::CodedInputStream* input) {
-#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
-  ::google::protobuf::uint32 tag;
-  ::google::protobuf::io::LazyStringOutputStream unknown_fields_string(
-      ::google::protobuf::internal::NewPermanentCallback(
-          &MutableUnknownFieldsForSourceAddressTokens, this));
-  ::google::protobuf::io::CodedOutputStream unknown_fields_stream(
-      &unknown_fields_string, false);
-  // @@protoc_insertion_point(parse_start:net.SourceAddressTokens)
-  for (;;) {
-    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
-    tag = p.first;
-    if (!p.second) goto handle_unusual;
-    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
-      // repeated .net.SourceAddressToken tokens = 4;
-      case 4: {
-        if (tag == 34) {
-          DO_(input->IncrementRecursionDepth());
-         parse_loop_tokens:
-          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
-                input, add_tokens()));
-        } else {
-          goto handle_unusual;
-        }
-        if (input->ExpectTag(34)) goto parse_loop_tokens;
-        input->UnsafeDecrementRecursionDepth();
-        if (input->ExpectAtEnd()) goto success;
-        break;
-      }
-
-      default: {
-      handle_unusual:
-        if (tag == 0 ||
-            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
-            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
-          goto success;
-        }
-        DO_(::google::protobuf::internal::WireFormatLite::SkipField(
-            input, tag, &unknown_fields_stream));
-        break;
-      }
-    }
-  }
-success:
-  // @@protoc_insertion_point(parse_success:net.SourceAddressTokens)
-  return true;
-failure:
-  // @@protoc_insertion_point(parse_failure:net.SourceAddressTokens)
-  return false;
-#undef DO_
-}
-
-void SourceAddressTokens::SerializeWithCachedSizes(
-    ::google::protobuf::io::CodedOutputStream* output) const {
-  // @@protoc_insertion_point(serialize_start:net.SourceAddressTokens)
-  // repeated .net.SourceAddressToken tokens = 4;
-  for (unsigned int i = 0, n = this->tokens_size(); i < n; i++) {
-    ::google::protobuf::internal::WireFormatLite::WriteMessage(
-      4, this->tokens(i), output);
-  }
-
-  output->WriteRaw(unknown_fields().data(),
-                   static_cast<int>(unknown_fields().size()));
-  // @@protoc_insertion_point(serialize_end:net.SourceAddressTokens)
-}
-
-int SourceAddressTokens::ByteSize() const {
-// @@protoc_insertion_point(message_byte_size_start:net.SourceAddressTokens)
-  int total_size = 0;
-
-  // repeated .net.SourceAddressToken tokens = 4;
-  total_size += 1 * this->tokens_size();
-  for (int i = 0; i < this->tokens_size(); i++) {
-    total_size +=
-      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
-        this->tokens(i));
-  }
-
-  total_size += unknown_fields().size();
-
-  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
-  _cached_size_ = total_size;
-  GOOGLE_SAFE_CONCURRENT_WRITES_END();
-  return total_size;
-}
-
-void SourceAddressTokens::CheckTypeAndMergeFrom(
-    const ::google::protobuf::MessageLite& from) {
-  MergeFrom(*::google::protobuf::down_cast<const SourceAddressTokens*>(&from));
-}
-
-void SourceAddressTokens::MergeFrom(const SourceAddressTokens& from) {
-// @@protoc_insertion_point(class_specific_merge_from_start:net.SourceAddressTokens)
-  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
-  tokens_.MergeFrom(from.tokens_);
-  if (!from.unknown_fields().empty()) {
-    mutable_unknown_fields()->append(from.unknown_fields());
-  }
-}
-
-void SourceAddressTokens::CopyFrom(const SourceAddressTokens& from) {
-// @@protoc_insertion_point(class_specific_copy_from_start:net.SourceAddressTokens)
-  if (&from == this) return;
-  Clear();
-  MergeFrom(from);
-}
-
-bool SourceAddressTokens::IsInitialized() const {
-
-  if (!::google::protobuf::internal::AllAreInitialized(this->tokens())) return false;
-  return true;
-}
-
-void SourceAddressTokens::Swap(SourceAddressTokens* other) {
-  if (other == this) return;
-  InternalSwap(other);
-}
-void SourceAddressTokens::InternalSwap(SourceAddressTokens* other) {
-  tokens_.UnsafeArenaSwap(&other->tokens_);
-  std::swap(_has_bits_[0], other->_has_bits_[0]);
-  _unknown_fields_.Swap(&other->_unknown_fields_);
-  std::swap(_cached_size_, other->_cached_size_);
-}
-
-::std::string SourceAddressTokens::GetTypeName() const {
-  return "net.SourceAddressTokens";
-}
-
-#if PROTOBUF_INLINE_NOT_IN_HEADERS
-// SourceAddressTokens
-
-// repeated .net.SourceAddressToken tokens = 4;
-int SourceAddressTokens::tokens_size() const {
-  return tokens_.size();
-}
-void SourceAddressTokens::clear_tokens() {
-  tokens_.Clear();
-}
-const ::net::SourceAddressToken& SourceAddressTokens::tokens(int index) const {
-  // @@protoc_insertion_point(field_get:net.SourceAddressTokens.tokens)
-  return tokens_.Get(index);
-}
-::net::SourceAddressToken* SourceAddressTokens::mutable_tokens(int index) {
-  // @@protoc_insertion_point(field_mutable:net.SourceAddressTokens.tokens)
-  return tokens_.Mutable(index);
-}
-::net::SourceAddressToken* SourceAddressTokens::add_tokens() {
-  // @@protoc_insertion_point(field_add:net.SourceAddressTokens.tokens)
-  return tokens_.Add();
-}
-::google::protobuf::RepeatedPtrField< ::net::SourceAddressToken >*
-SourceAddressTokens::mutable_tokens() {
-  // @@protoc_insertion_point(field_mutable_list:net.SourceAddressTokens.tokens)
-  return &tokens_;
-}
-const ::google::protobuf::RepeatedPtrField< ::net::SourceAddressToken >&
-SourceAddressTokens::tokens() const {
-  // @@protoc_insertion_point(field_list:net.SourceAddressTokens.tokens)
-  return tokens_;
-}
-
-#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS
-
-// @@protoc_insertion_point(namespace_scope)
-
-}  // namespace net
-
-// @@protoc_insertion_point(global_scope)
diff --git a/src/net/quic/core/proto/source_address_token.pb.h b/src/net/quic/core/proto/source_address_token.pb.h
deleted file mode 100644
index cea84e1..0000000
--- a/src/net/quic/core/proto/source_address_token.pb.h
+++ /dev/null
@@ -1,463 +0,0 @@
-// Generated by the protocol buffer compiler.  DO NOT EDIT!
-// source: source_address_token.proto
-
-#ifndef PROTOBUF_source_5faddress_5ftoken_2eproto__INCLUDED
-#define PROTOBUF_source_5faddress_5ftoken_2eproto__INCLUDED
-
-#include <string>
-
-#include <google/protobuf/stubs/common.h>
-
-#if GOOGLE_PROTOBUF_VERSION < 3000000
-#error This file was generated by a newer version of protoc which is
-#error incompatible with your Protocol Buffer headers.  Please update
-#error your headers.
-#endif
-#if 3000000 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
-#error This file was generated by an older version of protoc which is
-#error incompatible with your Protocol Buffer headers.  Please
-#error regenerate this file with a newer version of protoc.
-#endif
-
-#include <google/protobuf/arena.h>
-#include <google/protobuf/arenastring.h>
-#include <google/protobuf/generated_message_util.h>
-#include <google/protobuf/message_lite.h>
-#include <google/protobuf/repeated_field.h>
-#include <google/protobuf/extension_set.h>
-#include "cached_network_parameters.pb.h"
-// @@protoc_insertion_point(includes)
-#include "net/base/net_export.h"
-
-namespace net {
-
-// Internal implementation detail -- do not call these.
-void NET_EXPORT_PRIVATE protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-void protobuf_AssignDesc_source_5faddress_5ftoken_2eproto();
-void protobuf_ShutdownFile_source_5faddress_5ftoken_2eproto();
-
-class SourceAddressToken;
-class SourceAddressTokens;
-
-// ===================================================================
-
-class NET_EXPORT_PRIVATE SourceAddressToken : public ::google::protobuf::MessageLite {
-public:
-SourceAddressToken();
-virtual ~SourceAddressToken();
-
-SourceAddressToken(const SourceAddressToken& from);
-
-inline SourceAddressToken& operator=(const SourceAddressToken& from) {
-CopyFrom(from);
-return *this;
-}
-
-inline const ::std::string& unknown_fields() const {
-return _unknown_fields_.GetNoArena(
-&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-inline ::std::string* mutable_unknown_fields() {
-return _unknown_fields_.MutableNoArena(
-&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-static const SourceAddressToken& default_instance();
-
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-// Returns the internal default instance pointer. This function can
-// return NULL thus should not be used by the user. This is intended
-// for Protobuf internal code. Please use default_instance() declared
-// above instead.
-static inline const SourceAddressToken* internal_default_instance() {
-return default_instance_;
-}
-#endif
-
-GOOGLE_ATTRIBUTE_NOINLINE void Swap(SourceAddressToken* other);
-
-// implements Message ----------------------------------------------
-
-inline SourceAddressToken* New() const { return New(NULL); }
-
-SourceAddressToken* New(::google::protobuf::Arena* arena) const;
-void CheckTypeAndMergeFrom(const ::google::protobuf::MessageLite& from);
-void CopyFrom(const SourceAddressToken& from);
-void MergeFrom(const SourceAddressToken& from);
-void Clear();
-bool IsInitialized() const;
-
-int ByteSize() const;
-bool MergePartialFromCodedStream(
-::google::protobuf::io::CodedInputStream* input);
-void SerializeWithCachedSizes(
-::google::protobuf::io::CodedOutputStream* output) const;
-void DiscardUnknownFields();
-int GetCachedSize() const { return _cached_size_; }
-private:
-void SharedCtor();
-void SharedDtor();
-void SetCachedSize(int size) const;
-void InternalSwap(SourceAddressToken* other);
-private:
-inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
-return _arena_ptr_;
-}
-inline ::google::protobuf::Arena* MaybeArenaPtr() const {
-return _arena_ptr_;
-}
-public:
-
-::std::string GetTypeName() const;
-
-// nested types ----------------------------------------------------
-
-// accessors -------------------------------------------------------
-
-// required bytes ip = 1;
-bool has_ip() const;
-void clear_ip();
-static const int kIpFieldNumber = 1;
-const ::std::string& ip() const;
-void set_ip(const ::std::string& value);
-void set_ip(const char* value);
-void set_ip(const void* value, size_t size);
-::std::string* mutable_ip();
-::std::string* release_ip();
-void set_allocated_ip(::std::string* ip);
-
-// required int64 timestamp = 2;
-bool has_timestamp() const;
-void clear_timestamp();
-static const int kTimestampFieldNumber = 2;
-::google::protobuf::int64 timestamp() const;
-void set_timestamp(::google::protobuf::int64 value);
-
-// optional .net.CachedNetworkParameters cached_network_parameters = 3;
-bool has_cached_network_parameters() const;
-void clear_cached_network_parameters();
-static const int kCachedNetworkParametersFieldNumber = 3;
-const ::net::CachedNetworkParameters& cached_network_parameters() const;
-::net::CachedNetworkParameters* mutable_cached_network_parameters();
-::net::CachedNetworkParameters* release_cached_network_parameters();
-void set_allocated_cached_network_parameters(::net::CachedNetworkParameters* cached_network_parameters);
-
-// @@protoc_insertion_point(class_scope:net.SourceAddressToken)
-private:
-inline void set_has_ip();
-inline void clear_has_ip();
-inline void set_has_timestamp();
-inline void clear_has_timestamp();
-inline void set_has_cached_network_parameters();
-inline void clear_has_cached_network_parameters();
-
-// helper for ByteSize()
-int RequiredFieldsByteSizeFallback() const;
-
-::google::protobuf::internal::ArenaStringPtr _unknown_fields_;
-::google::protobuf::Arena* _arena_ptr_;
-
-::google::protobuf::uint32 _has_bits_[1];
-mutable int _cached_size_;
-::google::protobuf::internal::ArenaStringPtr ip_;
-::google::protobuf::int64 timestamp_;
-::net::CachedNetworkParameters* cached_network_parameters_;
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-friend void NET_EXPORT_PRIVATE protobuf_AddDesc_source_5faddress_5ftoken_2eproto_impl();
-#else
-friend void NET_EXPORT_PRIVATE protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-#endif
-friend void protobuf_AssignDesc_source_5faddress_5ftoken_2eproto();
-friend void protobuf_ShutdownFile_source_5faddress_5ftoken_2eproto();
-
-void InitAsDefaultInstance();
-static SourceAddressToken* default_instance_;
-};
-// -------------------------------------------------------------------
-
-class NET_EXPORT_PRIVATE SourceAddressTokens : public ::google::protobuf::MessageLite {
-public:
-SourceAddressTokens();
-virtual ~SourceAddressTokens();
-
-SourceAddressTokens(const SourceAddressTokens& from);
-
-inline SourceAddressTokens& operator=(const SourceAddressTokens& from) {
-CopyFrom(from);
-return *this;
-}
-
-inline const ::std::string& unknown_fields() const {
-return _unknown_fields_.GetNoArena(
-&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-inline ::std::string* mutable_unknown_fields() {
-return _unknown_fields_.MutableNoArena(
-&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-
-static const SourceAddressTokens& default_instance();
-
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-// Returns the internal default instance pointer. This function can
-// return NULL thus should not be used by the user. This is intended
-// for Protobuf internal code. Please use default_instance() declared
-// above instead.
-static inline const SourceAddressTokens* internal_default_instance() {
-return default_instance_;
-}
-#endif
-
-GOOGLE_ATTRIBUTE_NOINLINE void Swap(SourceAddressTokens* other);
-
-// implements Message ----------------------------------------------
-
-inline SourceAddressTokens* New() const { return New(NULL); }
-
-SourceAddressTokens* New(::google::protobuf::Arena* arena) const;
-void CheckTypeAndMergeFrom(const ::google::protobuf::MessageLite& from);
-void CopyFrom(const SourceAddressTokens& from);
-void MergeFrom(const SourceAddressTokens& from);
-void Clear();
-bool IsInitialized() const;
-
-int ByteSize() const;
-bool MergePartialFromCodedStream(
-::google::protobuf::io::CodedInputStream* input);
-void SerializeWithCachedSizes(
-::google::protobuf::io::CodedOutputStream* output) const;
-void DiscardUnknownFields();
-int GetCachedSize() const { return _cached_size_; }
-private:
-void SharedCtor();
-void SharedDtor();
-void SetCachedSize(int size) const;
-void InternalSwap(SourceAddressTokens* other);
-private:
-inline ::google::protobuf::Arena* GetArenaNoVirtual() const {
-return _arena_ptr_;
-}
-inline ::google::protobuf::Arena* MaybeArenaPtr() const {
-return _arena_ptr_;
-}
-public:
-
-::std::string GetTypeName() const;
-
-// nested types ----------------------------------------------------
-
-// accessors -------------------------------------------------------
-
-// repeated .net.SourceAddressToken tokens = 4;
-int tokens_size() const;
-void clear_tokens();
-static const int kTokensFieldNumber = 4;
-const ::net::SourceAddressToken& tokens(int index) const;
-::net::SourceAddressToken* mutable_tokens(int index);
-::net::SourceAddressToken* add_tokens();
-::google::protobuf::RepeatedPtrField< ::net::SourceAddressToken >*
-mutable_tokens();
-const ::google::protobuf::RepeatedPtrField< ::net::SourceAddressToken >&
-tokens() const;
-
-// @@protoc_insertion_point(class_scope:net.SourceAddressTokens)
-private:
-
-::google::protobuf::internal::ArenaStringPtr _unknown_fields_;
-::google::protobuf::Arena* _arena_ptr_;
-
-::google::protobuf::uint32 _has_bits_[1];
-mutable int _cached_size_;
-::google::protobuf::RepeatedPtrField< ::net::SourceAddressToken > tokens_;
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-friend void NET_EXPORT_PRIVATE protobuf_AddDesc_source_5faddress_5ftoken_2eproto_impl();
-#else
-friend void NET_EXPORT_PRIVATE protobuf_AddDesc_source_5faddress_5ftoken_2eproto();
-#endif
-friend void protobuf_AssignDesc_source_5faddress_5ftoken_2eproto();
-friend void protobuf_ShutdownFile_source_5faddress_5ftoken_2eproto();
-
-void InitAsDefaultInstance();
-static SourceAddressTokens* default_instance_;
-};
-// ===================================================================
-
-
-// ===================================================================
-
-#if !PROTOBUF_INLINE_NOT_IN_HEADERS
-// SourceAddressToken
-
-// required bytes ip = 1;
-inline bool SourceAddressToken::has_ip() const {
-return (_has_bits_[0] & 0x00000001u) != 0;
-}
-inline void SourceAddressToken::set_has_ip() {
-_has_bits_[0] |= 0x00000001u;
-}
-inline void SourceAddressToken::clear_has_ip() {
-_has_bits_[0] &= ~0x00000001u;
-}
-inline void SourceAddressToken::clear_ip() {
-ip_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-clear_has_ip();
-}
-inline const ::std::string& SourceAddressToken::ip() const {
-// @@protoc_insertion_point(field_get:net.SourceAddressToken.ip)
-return ip_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-inline void SourceAddressToken::set_ip(const ::std::string& value) {
-set_has_ip();
-ip_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
-// @@protoc_insertion_point(field_set:net.SourceAddressToken.ip)
-}
-inline void SourceAddressToken::set_ip(const char* value) {
-set_has_ip();
-ip_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
-// @@protoc_insertion_point(field_set_char:net.SourceAddressToken.ip)
-}
-inline void SourceAddressToken::set_ip(const void* value, size_t size) {
-set_has_ip();
-ip_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
-::std::string(reinterpret_cast<const char*>(value), size));
-// @@protoc_insertion_point(field_set_pointer:net.SourceAddressToken.ip)
-}
-inline ::std::string* SourceAddressToken::mutable_ip() {
-set_has_ip();
-// @@protoc_insertion_point(field_mutable:net.SourceAddressToken.ip)
-return ip_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-inline ::std::string* SourceAddressToken::release_ip() {
-// @@protoc_insertion_point(field_release:net.SourceAddressToken.ip)
-clear_has_ip();
-return ip_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
-}
-inline void SourceAddressToken::set_allocated_ip(::std::string* ip) {
-if (ip != NULL) {
-set_has_ip();
-} else {
-clear_has_ip();
-}
-ip_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ip);
-// @@protoc_insertion_point(field_set_allocated:net.SourceAddressToken.ip)
-}
-
-// required int64 timestamp = 2;
-inline bool SourceAddressToken::has_timestamp() const {
-return (_has_bits_[0] & 0x00000002u) != 0;
-}
-inline void SourceAddressToken::set_has_timestamp() {
-_has_bits_[0] |= 0x00000002u;
-}
-inline void SourceAddressToken::clear_has_timestamp() {
-_has_bits_[0] &= ~0x00000002u;
-}
-inline void SourceAddressToken::clear_timestamp() {
-timestamp_ = GOOGLE_LONGLONG(0);
-clear_has_timestamp();
-}
-inline ::google::protobuf::int64 SourceAddressToken::timestamp() const {
-// @@protoc_insertion_point(field_get:net.SourceAddressToken.timestamp)
-return timestamp_;
-}
-inline void SourceAddressToken::set_timestamp(::google::protobuf::int64 value) {
-set_has_timestamp();
-timestamp_ = value;
-// @@protoc_insertion_point(field_set:net.SourceAddressToken.timestamp)
-}
-
-// optional .net.CachedNetworkParameters cached_network_parameters = 3;
-inline bool SourceAddressToken::has_cached_network_parameters() const {
-return (_has_bits_[0] & 0x00000004u) != 0;
-}
-inline void SourceAddressToken::set_has_cached_network_parameters() {
-_has_bits_[0] |= 0x00000004u;
-}
-inline void SourceAddressToken::clear_has_cached_network_parameters() {
-_has_bits_[0] &= ~0x00000004u;
-}
-inline void SourceAddressToken::clear_cached_network_parameters() {
-if (cached_network_parameters_ != NULL) cached_network_parameters_->::net::CachedNetworkParameters::Clear();
-clear_has_cached_network_parameters();
-}
-inline const ::net::CachedNetworkParameters& SourceAddressToken::cached_network_parameters() const {
-// @@protoc_insertion_point(field_get:net.SourceAddressToken.cached_network_parameters)
-#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
-return cached_network_parameters_ != NULL ? *cached_network_parameters_ : *default_instance().cached_network_parameters_;
-#else
-return cached_network_parameters_ != NULL ? *cached_network_parameters_ : *default_instance_->cached_network_parameters_;
-#endif
-}
-inline ::net::CachedNetworkParameters* SourceAddressToken::mutable_cached_network_parameters() {
-set_has_cached_network_parameters();
-if (cached_network_parameters_ == NULL) {
-cached_network_parameters_ = new ::net::CachedNetworkParameters;
-}
-// @@protoc_insertion_point(field_mutable:net.SourceAddressToken.cached_network_parameters)
-return cached_network_parameters_;
-}
-inline ::net::CachedNetworkParameters* SourceAddressToken::release_cached_network_parameters() {
-// @@protoc_insertion_point(field_release:net.SourceAddressToken.cached_network_parameters)
-clear_has_cached_network_parameters();
-::net::CachedNetworkParameters* temp = cached_network_parameters_;
-cached_network_parameters_ = NULL;
-return temp;
-}
-inline void SourceAddressToken::set_allocated_cached_network_parameters(::net::CachedNetworkParameters* cached_network_parameters) {
-delete cached_network_parameters_;
-cached_network_parameters_ = cached_network_parameters;
-if (cached_network_parameters) {
-set_has_cached_network_parameters();
-} else {
-clear_has_cached_network_parameters();
-}
-// @@protoc_insertion_point(field_set_allocated:net.SourceAddressToken.cached_network_parameters)
-}
-
-// -------------------------------------------------------------------
-
-// SourceAddressTokens
-
-// repeated .net.SourceAddressToken tokens = 4;
-inline int SourceAddressTokens::tokens_size() const {
-return tokens_.size();
-}
-inline void SourceAddressTokens::clear_tokens() {
-tokens_.Clear();
-}
-inline const ::net::SourceAddressToken& SourceAddressTokens::tokens(int index) const {
-// @@protoc_insertion_point(field_get:net.SourceAddressTokens.tokens)
-return tokens_.Get(index);
-}
-inline ::net::SourceAddressToken* SourceAddressTokens::mutable_tokens(int index) {
-// @@protoc_insertion_point(field_mutable:net.SourceAddressTokens.tokens)
-return tokens_.Mutable(index);
-}
-inline ::net::SourceAddressToken* SourceAddressTokens::add_tokens() {
-// @@protoc_insertion_point(field_add:net.SourceAddressTokens.tokens)
-return tokens_.Add();
-}
-inline ::google::protobuf::RepeatedPtrField< ::net::SourceAddressToken >*
-SourceAddressTokens::mutable_tokens() {
-// @@protoc_insertion_point(field_mutable_list:net.SourceAddressTokens.tokens)
-return &tokens_;
-}
-inline const ::google::protobuf::RepeatedPtrField< ::net::SourceAddressToken >&
-SourceAddressTokens::tokens() const {
-// @@protoc_insertion_point(field_list:net.SourceAddressTokens.tokens)
-return tokens_;
-}
-
-#endif  // !PROTOBUF_INLINE_NOT_IN_HEADERS
-// -------------------------------------------------------------------
-
-
-// @@protoc_insertion_point(namespace_scope)
-
-}  // namespace net
-
-// @@protoc_insertion_point(global_scope)
-
-#endif  // PROTOBUF_source_5faddress_5ftoken_2eproto__INCLUDED
diff --git a/src/net/quic/core/quic_bandwidth.cc b/src/net/quic/core/quic_bandwidth.cc
index 9ba96f3..75ccc68 100644
--- a/src/net/quic/core/quic_bandwidth.cc
+++ b/src/net/quic/core/quic_bandwidth.cc
@@ -12,6 +12,7 @@
 #include "base/logging.h"
 #include "base/strings/stringprintf.h"
 #include "net/quic/core/quic_bug_tracker.h"
+#include "net/quic/core/quic_constants.h"
 #include "net/quic/core/quic_time.h"
 #include "net/quic/core/quic_types.h"
 
diff --git a/src/net/quic/core/quic_bandwidth.h b/src/net/quic/core/quic_bandwidth.h
index 780c55c..36e0f1a 100644
--- a/src/net/quic/core/quic_bandwidth.h
+++ b/src/net/quic/core/quic_bandwidth.h
@@ -13,13 +13,12 @@
 #include <ostream>
 
 #include "base/compiler_specific.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_time.h"
+#include "net/quic/core/quic_types.h"
 
 namespace net {
 
-typedef uint64_t QuicByteCount;
-typedef uint64_t QuicPacketCount;
-
 class NET_EXPORT_PRIVATE QuicBandwidth {
  public:
   // Creates a new QuicBandwidth with an internal value of 0.
diff --git a/src/net/quic/core/quic_buffered_packet_store.cc b/src/net/quic/core/quic_buffered_packet_store.cc
index 9024d22..779a9ff 100644
--- a/src/net/quic/core/quic_buffered_packet_store.cc
+++ b/src/net/quic/core/quic_buffered_packet_store.cc
@@ -8,8 +8,7 @@
 
 #include "base/stl_util.h"
 #include "net/quic/core/quic_bug_tracker.h"
-
-using std::list;
+#include "net/quic/core/quic_flags.h"
 
 namespace net {
 
@@ -44,8 +43,8 @@ class ConnectionExpireAlarm : public QuicAlarm::Delegate {
 }  // namespace
 
 BufferedPacket::BufferedPacket(std::unique_ptr<QuicReceivedPacket> packet,
-                               IPEndPoint server_address,
-                               IPEndPoint client_address)
+                               QuicSocketAddress server_address,
+                               QuicSocketAddress client_address)
     : packet(std::move(packet)),
       server_address(server_address),
       client_address(client_address) {}
@@ -81,9 +80,11 @@ QuicBufferedPacketStore::~QuicBufferedPacketStore() {}
 EnqueuePacketResult QuicBufferedPacketStore::EnqueuePacket(
     QuicConnectionId connection_id,
     const QuicReceivedPacket& packet,
-    IPEndPoint server_address,
-    IPEndPoint client_address,
+    QuicSocketAddress server_address,
+    QuicSocketAddress client_address,
     bool is_chlo) {
+  QUIC_BUG_IF(!FLAGS_quic_allow_chlo_buffering)
+      << "Shouldn't buffer packets if disabled via flag.";
   QUIC_BUG_IF(is_chlo &&
               base::ContainsKey(connections_with_chlo_, connection_id))
       << "Shouldn't buffer duplicated CHLO on connection " << connection_id;
@@ -145,9 +146,9 @@ bool QuicBufferedPacketStore::HasChlosBuffered() const {
   return !connections_with_chlo_.empty();
 }
 
-list<BufferedPacket> QuicBufferedPacketStore::DeliverPackets(
+std::list<BufferedPacket> QuicBufferedPacketStore::DeliverPackets(
     QuicConnectionId connection_id) {
-  list<BufferedPacket> packets_to_deliver;
+  std::list<BufferedPacket> packets_to_deliver;
   auto it = undecryptable_packets_.find(connection_id);
   if (it != undecryptable_packets_.end()) {
     packets_to_deliver = std::move(it->second.buffered_packets);
@@ -156,6 +157,11 @@ list<BufferedPacket> QuicBufferedPacketStore::DeliverPackets(
   return packets_to_deliver;
 }
 
+void QuicBufferedPacketStore::DiscardPackets(QuicConnectionId connection_id) {
+  undecryptable_packets_.erase(connection_id);
+  connections_with_chlo_.erase(connection_id);
+}
+
 void QuicBufferedPacketStore::OnExpirationTimeout() {
   QuicTime expiration_time = clock_->ApproximateNow() - connection_life_span_;
   while (!undecryptable_packets_.empty()) {
@@ -169,7 +175,7 @@ void QuicBufferedPacketStore::OnExpirationTimeout() {
     connections_with_chlo_.erase(connection_id);
   }
   if (!undecryptable_packets_.empty()) {
-    expiration_alarm_->Set(clock_->ApproximateNow() + connection_life_span_);
+    MaybeSetExpirationAlarm();
   }
 }
 
@@ -196,16 +202,17 @@ bool QuicBufferedPacketStore::ShouldBufferPacket(bool is_chlo) {
   return is_store_full || reach_non_chlo_limit;
 }
 
-list<BufferedPacket> QuicBufferedPacketStore::DeliverPacketsForNextConnection(
+std::list<BufferedPacket>
+QuicBufferedPacketStore::DeliverPacketsForNextConnection(
     QuicConnectionId* connection_id) {
   if (connections_with_chlo_.empty()) {
     // Returns empty list if no CHLO has been buffered.
-    return list<BufferedPacket>();
+    return std::list<BufferedPacket>();
   }
   *connection_id = connections_with_chlo_.front().first;
   connections_with_chlo_.erase(connections_with_chlo_.begin());
 
-  list<BufferedPacket> packets = DeliverPackets(*connection_id);
+  std::list<BufferedPacket> packets = DeliverPackets(*connection_id);
   DCHECK(!packets.empty()) << "Try to deliver connectons without CHLO";
   return packets;
 }
diff --git a/src/net/quic/core/quic_buffered_packet_store.h b/src/net/quic/core/quic_buffered_packet_store.h
index df72697..ad88253 100644
--- a/src/net/quic/core/quic_buffered_packet_store.h
+++ b/src/net/quic/core/quic_buffered_packet_store.h
@@ -5,13 +5,14 @@
 #ifndef NET_QUIC_QUIC_BUFFERED_PACKET_STORE_H_
 #define NET_QUIC_QUIC_BUFFERED_PACKET_STORE_H_
 
-#include "net/base/ip_address.h"
 #include "net/base/linked_hash_map.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_alarm.h"
 #include "net/quic/core/quic_alarm_factory.h"
-#include "net/quic/core/quic_clock.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
+#include "net/quic/platform/api/quic_clock.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 
 namespace net {
 
@@ -39,8 +40,8 @@ class NET_EXPORT_PRIVATE QuicBufferedPacketStore {
   // A packets with client/server address.
   struct NET_EXPORT_PRIVATE BufferedPacket {
     BufferedPacket(std::unique_ptr<QuicReceivedPacket> packet,
-                   IPEndPoint server_address,
-                   IPEndPoint client_address);
+                   QuicSocketAddress server_address,
+                   QuicSocketAddress client_address);
     BufferedPacket(BufferedPacket&& other);
 
     BufferedPacket& operator=(BufferedPacket&& other);
@@ -48,8 +49,8 @@ class NET_EXPORT_PRIVATE QuicBufferedPacketStore {
     ~BufferedPacket();
 
     std::unique_ptr<QuicReceivedPacket> packet;
-    IPEndPoint server_address;
-    IPEndPoint client_address;
+    QuicSocketAddress server_address;
+    QuicSocketAddress client_address;
   };
 
   // A queue of BufferedPackets for a connection.
@@ -90,8 +91,8 @@ class NET_EXPORT_PRIVATE QuicBufferedPacketStore {
   // Adds a copy of packet into packet queue for given connection.
   EnqueuePacketResult EnqueuePacket(QuicConnectionId connection_id,
                                     const QuicReceivedPacket& packet,
-                                    IPEndPoint server_address,
-                                    IPEndPoint client_address,
+                                    QuicSocketAddress server_address,
+                                    QuicSocketAddress client_address,
                                     bool is_chlo);
 
   // Returns true if there are any packets buffered for |connection_id|.
@@ -102,6 +103,9 @@ class NET_EXPORT_PRIVATE QuicBufferedPacketStore {
   // connection are present.
   std::list<BufferedPacket> DeliverPackets(QuicConnectionId connection_id);
 
+  // Discards packets buffered for |connection_id|, if any.
+  void DiscardPackets(QuicConnectionId connection_id);
+
   // Examines how long packets have been buffered in the store for each
   // connection. If they stay too long, removes them for new coming packets and
   // calls |visitor_|'s OnPotentialConnectionExpire().
@@ -137,7 +141,7 @@ class NET_EXPORT_PRIVATE QuicBufferedPacketStore {
   BufferedPacketMap undecryptable_packets_;
 
   // The max time the packets of a connection can be buffer in the store.
-  QuicTime::Delta connection_life_span_;
+  const QuicTime::Delta connection_life_span_;
 
   VisitorInterface* visitor_;  // Unowned.
 
diff --git a/src/net/quic/core/quic_client_promised_info.cc b/src/net/quic/core/quic_client_promised_info.cc
index 8c67038..186b192 100644
--- a/src/net/quic/core/quic_client_promised_info.cc
+++ b/src/net/quic/core/quic_client_promised_info.cc
@@ -25,7 +25,8 @@ QuicClientPromisedInfo::~QuicClientPromisedInfo() {}
 
 void QuicClientPromisedInfo::CleanupAlarm::OnAlarm() {
   DVLOG(1) << "self GC alarm for stream " << promised_->id_;
-  promised_->Reset(QUIC_STREAM_CANCELLED);
+  promised_->session()->OnPushStreamTimedOut(promised_->id_);
+  promised_->Reset(QUIC_PUSH_STREAM_TIMED_OUT);
 }
 
 void QuicClientPromisedInfo::Init() {
@@ -106,6 +107,15 @@ QuicAsyncStatus QuicClientPromisedInfo::HandleClientRequest(
     session_->DeletePromised(this);
     return QUIC_FAILURE;
   }
+
+  if (is_validating()) {
+    // The push promise has already been matched to another request though
+    // pending for validation. Returns QUIC_FAILURE to the caller as it couldn't
+    // match a new request any more. This will not affect the validation of the
+    // other request.
+    return QUIC_FAILURE;
+  }
+
   client_request_delegate_ = delegate;
   client_request_headers_.reset(new SpdyHeaderBlock(request_headers.Clone()));
   if (!response_headers_) {
diff --git a/src/net/quic/core/quic_client_promised_info.h b/src/net/quic/core/quic_client_promised_info.h
index 2ec6668..25238d7 100644
--- a/src/net/quic/core/quic_client_promised_info.h
+++ b/src/net/quic/core/quic_client_promised_info.h
@@ -8,18 +8,17 @@
 #include <sys/types.h>
 #include <string>
 
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_alarm.h"
 #include "net/quic/core/quic_client_push_promise_index.h"
 #include "net/quic/core/quic_client_session_base.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_spdy_stream.h"
 #include "net/spdy/spdy_framer.h"
 
 namespace net {
 
 class QuicClientSessionBase;
-class QuicDataToResend;
-class QuicConnectionHelperInterface;
 
 namespace test {
 class QuicClientPromisedInfoPeer;
@@ -77,6 +76,9 @@ class NET_EXPORT_PRIVATE QuicClientPromisedInfo
 
   const std::string url() const { return url_; }
 
+  // Return true if there's a request pending matching this push promise.
+  bool is_validating() const { return client_request_delegate_ != nullptr; }
+
  private:
   friend class test::QuicClientPromisedInfoPeer;
 
diff --git a/src/net/quic/core/quic_client_push_promise_index.h b/src/net/quic/core/quic_client_push_promise_index.h
index 63db73d..2049aac 100644
--- a/src/net/quic/core/quic_client_push_promise_index.h
+++ b/src/net/quic/core/quic_client_push_promise_index.h
@@ -7,6 +7,7 @@
 
 #include <string>
 
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_client_session_base.h"
 #include "net/quic/core/quic_types.h"
 
diff --git a/src/net/quic/core/quic_client_session_base.cc b/src/net/quic/core/quic_client_session_base.cc
index 2d3bb29..d0e6c4d 100644
--- a/src/net/quic/core/quic_client_session_base.cc
+++ b/src/net/quic/core/quic_client_session_base.cc
@@ -17,7 +17,7 @@ QuicClientSessionBase::QuicClientSessionBase(
     QuicConnection* connection,
     QuicClientPushPromiseIndex* push_promise_index,
     const QuicConfig& config)
-    : QuicSpdySession(connection, config),
+    : QuicSpdySession(connection, nullptr, config),
       push_promise_index_(push_promise_index),
       largest_promised_stream_id_(kInvalidStreamId) {}
 
@@ -35,17 +35,7 @@ void QuicClientSessionBase::OnConfigNegotiated() {
 }
 
 void QuicClientSessionBase::OnCryptoHandshakeEvent(CryptoHandshakeEvent event) {
-  QuicSession::OnCryptoHandshakeEvent(event);
-}
-
-void QuicClientSessionBase::OnPromiseHeaders(QuicStreamId stream_id,
-                                             StringPiece headers_data) {
-  QuicSpdyStream* stream = GetSpdyDataStream(stream_id);
-  if (!stream) {
-    // It's quite possible to receive headers after a stream has been reset.
-    return;
-  }
-  stream->OnPromiseHeaders(headers_data);
+  QuicSpdySession::OnCryptoHandshakeEvent(event);
 }
 
 void QuicClientSessionBase::OnInitialHeadersComplete(
@@ -63,29 +53,6 @@ void QuicClientSessionBase::OnInitialHeadersComplete(
   promised->OnResponseHeaders(response_headers);
 }
 
-void QuicClientSessionBase::OnPromiseHeadersComplete(
-    QuicStreamId stream_id,
-    QuicStreamId promised_stream_id,
-    size_t frame_len) {
-  if (promised_stream_id != kInvalidStreamId &&
-      promised_stream_id <= largest_promised_stream_id_) {
-    connection()->CloseConnection(
-        QUIC_INVALID_STREAM_ID,
-        "Received push stream id lesser or equal to the"
-        " last accepted before",
-        ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-    return;
-  }
-  largest_promised_stream_id_ = promised_stream_id;
-
-  QuicSpdyStream* stream = GetSpdyDataStream(stream_id);
-  if (!stream) {
-    // It's quite possible to receive headers after a stream has been reset.
-    return;
-  }
-  stream->OnPromiseHeadersComplete(promised_stream_id, frame_len);
-}
-
 void QuicClientSessionBase::OnPromiseHeaderList(
     QuicStreamId stream_id,
     QuicStreamId promised_stream_id,
@@ -110,7 +77,7 @@ void QuicClientSessionBase::OnPromiseHeaderList(
   stream->OnPromiseHeaderList(promised_stream_id, frame_len, header_list);
 }
 
-void QuicClientSessionBase::HandlePromised(QuicStreamId /* associated_id */,
+bool QuicClientSessionBase::HandlePromised(QuicStreamId /* associated_id */,
                                            QuicStreamId id,
                                            const SpdyHeaderBlock& headers) {
   // Due to pathalogical packet re-ordering, it is possible that
@@ -121,13 +88,13 @@ void QuicClientSessionBase::HandlePromised(QuicStreamId /* associated_id */,
     // QUIC_REFUSED_STREAM?
     DVLOG(1) << "Promise ignored for stream " << id
              << " that is already closed";
-    return;
+    return false;
   }
 
   if (push_promise_index_->promised_by_url()->size() >= get_max_promises()) {
     DVLOG(1) << "Too many promises, rejecting promise for stream " << id;
     ResetPromised(id, QUIC_REFUSED_STREAM);
-    return;
+    return false;
   }
 
   const string url = SpdyUtils::GetUrlFromHeaderBlock(headers);
@@ -136,14 +103,14 @@ void QuicClientSessionBase::HandlePromised(QuicStreamId /* associated_id */,
     DVLOG(1) << "Promise for stream " << id << " is duplicate URL " << url
              << " of previous promise for stream " << old_promised->id();
     ResetPromised(id, QUIC_DUPLICATE_PROMISE_URL);
-    return;
+    return false;
   }
 
   if (GetPromisedById(id)) {
     // OnPromiseHeadersComplete() would have closed the connection if
     // promised id is a duplicate.
     QUIC_BUG << "Duplicate promise for id " << id;
-    return;
+    return false;
   }
 
   QuicClientPromisedInfo* promised = new QuicClientPromisedInfo(this, id, url);
@@ -153,6 +120,7 @@ void QuicClientSessionBase::HandlePromised(QuicStreamId /* associated_id */,
   (*push_promise_index_->promised_by_url())[url] = promised;
   promised_by_id_[id] = std::move(promised_owner);
   promised->OnPromiseHeaders(headers);
+  return true;
 }
 
 QuicClientPromisedInfo* QuicClientSessionBase::GetPromisedByUrl(
@@ -176,14 +144,10 @@ QuicClientPromisedInfo* QuicClientSessionBase::GetPromisedById(
 
 QuicSpdyStream* QuicClientSessionBase::GetPromisedStream(
     const QuicStreamId id) {
-  if (IsClosedStream(id)) {
-    return nullptr;
-  }
   DynamicStreamMap::iterator it = dynamic_streams().find(id);
   if (it != dynamic_streams().end()) {
-    return static_cast<QuicSpdyStream*>(it->second);
+    return static_cast<QuicSpdyStream*>(it->second.get());
   }
-  QUIC_BUG << "Open promised stream " << id << " is missing!";
   return nullptr;
 }
 
@@ -192,15 +156,27 @@ void QuicClientSessionBase::DeletePromised(QuicClientPromisedInfo* promised) {
   // Since promised_by_id_ contains the unique_ptr, this will destroy
   // promised.
   promised_by_id_.erase(promised->id());
+  headers_stream()->MaybeReleaseSequencerBuffer();
 }
 
+void QuicClientSessionBase::OnPushStreamTimedOut(QuicStreamId stream_id) {}
+
 void QuicClientSessionBase::ResetPromised(QuicStreamId id,
                                           QuicRstStreamErrorCode error_code) {
   SendRstStream(id, error_code, 0);
   if (!IsOpenStream(id)) {
     MaybeIncreaseLargestPeerStreamId(id);
-    InsertLocallyClosedStreamsHighestOffset(id, 0);
   }
 }
 
+void QuicClientSessionBase::CloseStreamInner(QuicStreamId stream_id,
+                                             bool locally_reset) {
+  QuicSpdySession::CloseStreamInner(stream_id, locally_reset);
+  headers_stream()->MaybeReleaseSequencerBuffer();
+}
+
+bool QuicClientSessionBase::ShouldReleaseHeadersStreamSequencerBuffer() {
+  return num_active_requests() == 0 && promised_by_id_.empty();
+}
+
 }  // namespace net
diff --git a/src/net/quic/core/quic_client_session_base.h b/src/net/quic/core/quic_client_session_base.h
index 0fcf887..32d1ba8 100644
--- a/src/net/quic/core/quic_client_session_base.h
+++ b/src/net/quic/core/quic_client_session_base.h
@@ -8,6 +8,7 @@
 #include <string>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_crypto_client_stream.h"
 #include "net/quic/core/quic_spdy_session.h"
 
@@ -49,17 +50,6 @@ class NET_EXPORT_PRIVATE QuicClientSessionBase
   void OnCryptoHandshakeEvent(CryptoHandshakeEvent event) override;
 
   // Called by |headers_stream_| when push promise headers have been
-  // received for a stream.
-  void OnPromiseHeaders(QuicStreamId stream_id,
-                        base::StringPiece headers_data) override;
-
-  // Called by |headers_stream_| when push promise headers have been
-  // completely received.
-  void OnPromiseHeadersComplete(QuicStreamId stream_id,
-                                QuicStreamId promised_stream_id,
-                                size_t frame_len) override;
-
-  // Called by |headers_stream_| when push promise headers have been
   // completely received.
   void OnPromiseHeaderList(QuicStreamId stream_id,
                            QuicStreamId promised_stream_id,
@@ -75,8 +65,9 @@ class NET_EXPORT_PRIVATE QuicClientSessionBase
   // Called by |QuicSpdyClientStream| on receipt of PUSH_PROMISE, does
   // some session level validation and creates the
   // |QuicClientPromisedInfo| inserting into maps by (promised) id and
-  // url.
-  virtual void HandlePromised(QuicStreamId associated_id,
+  // url. Returns true if a new push promise is accepted. Reset the promised
+  // stream and returns false otherwiese.
+  virtual bool HandlePromised(QuicStreamId associated_id,
                               QuicStreamId promised_id,
                               const SpdyHeaderBlock& headers);
 
@@ -102,12 +93,20 @@ class NET_EXPORT_PRIVATE QuicClientSessionBase
   // promised.
   virtual void DeletePromised(QuicClientPromisedInfo* promised);
 
+  virtual void OnPushStreamTimedOut(QuicStreamId stream_id);
+
   // Sends Rst for the stream, and makes sure that future calls to
   // IsClosedStream(id) return true, which ensures that any subsequent
   // frames related to this stream will be ignored (modulo flow
   // control accounting).
   void ResetPromised(QuicStreamId id, QuicRstStreamErrorCode error_code);
 
+  // Release headers stream's sequencer buffer if it's empty.
+  void CloseStreamInner(QuicStreamId stream_id, bool locally_reset) override;
+
+  // Returns true if there are no active requests and no promised streams.
+  bool ShouldReleaseHeadersStreamSequencerBuffer() override;
+
   size_t get_max_promises() const {
     return max_open_incoming_streams() * kMaxPromisedStreamsMultiplier;
   }
@@ -123,7 +122,7 @@ class NET_EXPORT_PRIVATE QuicClientSessionBase
       std::unordered_map<QuicStreamId, std::unique_ptr<QuicClientPromisedInfo>>;
 
   // As per rfc7540, section 10.5: track promise streams in "reserved
-  // (remote)".  The primary key is URL from he promise request
+  // (remote)".  The primary key is URL from the promise request
   // headers.  The promised stream id is a secondary key used to get
   // promise info when the response headers of the promised stream
   // arrive.
diff --git a/src/net/quic/core/quic_clock.cc b/src/net/quic/core/quic_clock.cc
deleted file mode 100644
index 9eb4f71..0000000
--- a/src/net/quic/core/quic_clock.cc
+++ /dev/null
@@ -1,48 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "net/quic/core/quic_clock.h"
-
-#include "base/time/time.h"
-
-namespace net {
-
-QuicClock::QuicClock() {}
-
-QuicClock::~QuicClock() {}
-
-QuicTime QuicClock::ApproximateNow() const {
-  // At the moment, Chrome does not have a distinct notion of ApproximateNow().
-  // We should consider implementing this using MessageLoop::recent_time_.
-  return Now();
-}
-
-QuicTime QuicClock::Now() const {
-  return QuicTime(base::TimeTicks::Now());
-}
-
-QuicWallTime QuicClock::WallNow() const {
-  return QuicWallTime::FromUNIXMicroseconds(base::Time::Now().ToJavaTime() *
-                                            1000);
-}
-
-QuicTime QuicClock::ConvertWallTimeToQuicTime(
-    const QuicWallTime& walltime) const {
-  //     ..........................
-  //     |            |           |
-  // unix epoch   |walltime|   WallNow()
-  //     ..........................
-  //            |     |           |
-  //     clock epoch  |         Now()
-  //               result
-  //
-  // result = Now() - (WallNow() - walltime)
-  return Now() - QuicTime::Delta::FromMicroseconds(
-                     WallNow()
-                         .Subtract(QuicTime::Delta::FromMicroseconds(
-                             walltime.ToUNIXMicroseconds()))
-                         .ToUNIXMicroseconds());
-}
-
-}  // namespace net
diff --git a/src/net/quic/core/quic_clock.h b/src/net/quic/core/quic_clock.h
deleted file mode 100644
index 7c6878b..0000000
--- a/src/net/quic/core/quic_clock.h
+++ /dev/null
@@ -1,44 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef NET_QUIC_QUIC_CLOCK_H_
-#define NET_QUIC_QUIC_CLOCK_H_
-
-#include "base/macros.h"
-#include "net/base/net_export.h"
-#include "net/quic/core/quic_time.h"
-
-namespace net {
-
-typedef double WallTime;
-
-// Clock to efficiently retrieve an approximately accurate time from an
-// EpollServer.
-class NET_EXPORT_PRIVATE QuicClock {
- public:
-  QuicClock();
-  virtual ~QuicClock();
-
-  // Returns the approximate current time as a QuicTime object.
-  virtual QuicTime ApproximateNow() const;
-
-  // Returns the current time as a QuicTime object.
-  // Note: this use significant resources please use only if needed.
-  virtual QuicTime Now() const;
-
-  // WallNow returns the current wall-time - a time that is consistent across
-  // different clocks.
-  virtual QuicWallTime WallNow() const;
-
-  // Converts |walltime| to a QuicTime relative to this clock's epoch.
-  virtual QuicTime ConvertWallTimeToQuicTime(
-      const QuicWallTime& walltime) const;
-
- private:
-  DISALLOW_COPY_AND_ASSIGN(QuicClock);
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_QUIC_CLOCK_H_
diff --git a/src/net/quic/core/quic_config.cc b/src/net/quic/core/quic_config.cc
index 3697a97..6e1abef 100644
--- a/src/net/quic/core/quic_config.cc
+++ b/src/net/quic/core/quic_config.cc
@@ -10,10 +10,10 @@
 #include "net/quic/core/crypto/crypto_handshake_message.h"
 #include "net/quic/core/crypto/crypto_protocol.h"
 #include "net/quic/core/quic_bug_tracker.h"
+#include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_socket_address_coder.h"
 #include "net/quic/core/quic_utils.h"
 
-using std::min;
 using std::string;
 
 namespace net {
@@ -32,7 +32,7 @@ QuicErrorCode ReadUint32(const CryptoHandshakeMessage& msg,
   switch (error) {
     case QUIC_CRYPTO_MESSAGE_PARAMETER_NOT_FOUND:
       if (presence == PRESENCE_REQUIRED) {
-        *error_details = "Missing " + QuicUtils::TagToString(tag);
+        *error_details = "Missing " + QuicTagToString(tag);
         break;
       }
       error = QUIC_NO_ERROR;
@@ -41,7 +41,7 @@ QuicErrorCode ReadUint32(const CryptoHandshakeMessage& msg,
     case QUIC_NO_ERROR:
       break;
     default:
-      *error_details = "Bad " + QuicUtils::TagToString(tag);
+      *error_details = "Bad " + QuicTagToString(tag);
       break;
   }
   return error;
@@ -77,6 +77,11 @@ uint32_t QuicNegotiableUint32::GetUint32() const {
   return default_value_;
 }
 
+// Returns the maximum value negotiable.
+uint32_t QuicNegotiableUint32::GetMax() const {
+  return max_value_;
+}
+
 void QuicNegotiableUint32::ToHandshakeMessage(
     CryptoHandshakeMessage* out) const {
   if (negotiated()) {
@@ -99,98 +104,12 @@ QuicErrorCode QuicNegotiableUint32::ProcessPeerHello(
     return error;
   }
   if (hello_type == SERVER && value > max_value_) {
-    *error_details =
-        "Invalid value received for " + QuicUtils::TagToString(tag_);
+    *error_details = "Invalid value received for " + QuicTagToString(tag_);
     return QUIC_INVALID_NEGOTIATED_VALUE;
   }
 
   set_negotiated(true);
-  negotiated_value_ = min(value, max_value_);
-  return QUIC_NO_ERROR;
-}
-
-QuicNegotiableTag::QuicNegotiableTag(QuicTag tag, QuicConfigPresence presence)
-    : QuicNegotiableValue(tag, presence),
-      negotiated_tag_(0),
-      default_value_(0) {}
-
-QuicNegotiableTag::~QuicNegotiableTag() {}
-
-void QuicNegotiableTag::set(const QuicTagVector& possible,
-                            QuicTag default_value) {
-  DCHECK(ContainsQuicTag(possible, default_value));
-  possible_values_ = possible;
-  default_value_ = default_value;
-}
-
-void QuicNegotiableTag::ToHandshakeMessage(CryptoHandshakeMessage* out) const {
-  if (negotiated()) {
-    // Because of the way we serialize and parse handshake messages we can
-    // serialize this as value and still parse it as a vector.
-    out->SetValue(tag_, negotiated_tag_);
-  } else {
-    out->SetVector(tag_, possible_values_);
-  }
-}
-
-QuicErrorCode QuicNegotiableTag::ReadVector(const CryptoHandshakeMessage& msg,
-                                            const QuicTag** out,
-                                            size_t* out_length,
-                                            string* error_details) const {
-  DCHECK(error_details != nullptr);
-  QuicErrorCode error = msg.GetTaglist(tag_, out, out_length);
-  switch (error) {
-    case QUIC_CRYPTO_MESSAGE_PARAMETER_NOT_FOUND:
-      if (presence_ == PRESENCE_REQUIRED) {
-        *error_details = "Missing " + QuicUtils::TagToString(tag_);
-        break;
-      }
-      error = QUIC_NO_ERROR;
-      *out_length = 1;
-      *out = &default_value_;
-
-    case QUIC_NO_ERROR:
-      break;
-    default:
-      *error_details = "Bad " + QuicUtils::TagToString(tag_);
-      break;
-  }
-  return error;
-}
-
-QuicErrorCode QuicNegotiableTag::ProcessPeerHello(
-    const CryptoHandshakeMessage& peer_hello,
-    HelloType hello_type,
-    string* error_details) {
-  DCHECK(!negotiated());
-  DCHECK(error_details != nullptr);
-  const QuicTag* received_tags;
-  size_t received_tags_length;
-  QuicErrorCode error = ReadVector(peer_hello, &received_tags,
-                                   &received_tags_length, error_details);
-  if (error != QUIC_NO_ERROR) {
-    return error;
-  }
-
-  if (hello_type == SERVER) {
-    if (received_tags_length != 1 ||
-        !ContainsQuicTag(possible_values_, *received_tags)) {
-      *error_details = "Invalid " + QuicUtils::TagToString(tag_);
-      return QUIC_INVALID_NEGOTIATED_VALUE;
-    }
-    negotiated_tag_ = *received_tags;
-  } else {
-    QuicTag negotiated_tag;
-    if (!QuicUtils::FindMutualTag(
-            possible_values_, received_tags, received_tags_length,
-            QuicUtils::LOCAL_PRIORITY, &negotiated_tag, nullptr)) {
-      *error_details = "Unsupported " + QuicUtils::TagToString(tag_);
-      return QUIC_CRYPTO_MESSAGE_PARAMETER_NO_OVERLAP;
-    }
-    negotiated_tag_ = negotiated_tag;
-  }
-
-  set_negotiated(true);
+  negotiated_value_ = std::min(value, max_value_);
   return QUIC_NO_ERROR;
 }
 
@@ -206,7 +125,7 @@ bool QuicFixedUint32::HasSendValue() const {
 
 uint32_t QuicFixedUint32::GetSendValue() const {
   QUIC_BUG_IF(!has_send_value_) << "No send value to get for tag:"
-                                << QuicUtils::TagToString(tag_);
+                                << QuicTagToString(tag_);
   return send_value_;
 }
 
@@ -221,7 +140,7 @@ bool QuicFixedUint32::HasReceivedValue() const {
 
 uint32_t QuicFixedUint32::GetReceivedValue() const {
   QUIC_BUG_IF(!has_receive_value_) << "No receive value to get for tag:"
-                                   << QuicUtils::TagToString(tag_);
+                                   << QuicTagToString(tag_);
   return receive_value_;
 }
 
@@ -247,13 +166,13 @@ QuicErrorCode QuicFixedUint32::ProcessPeerHello(
       if (presence_ == PRESENCE_OPTIONAL) {
         return QUIC_NO_ERROR;
       }
-      *error_details = "Missing " + QuicUtils::TagToString(tag_);
+      *error_details = "Missing " + QuicTagToString(tag_);
       break;
     case QUIC_NO_ERROR:
       has_receive_value_ = true;
       break;
     default:
-      *error_details = "Bad " + QuicUtils::TagToString(tag_);
+      *error_details = "Bad " + QuicTagToString(tag_);
       break;
   }
   return error;
@@ -276,7 +195,7 @@ bool QuicFixedTagVector::HasSendValues() const {
 
 QuicTagVector QuicFixedTagVector::GetSendValues() const {
   QUIC_BUG_IF(!has_send_values_) << "No send values to get for tag:"
-                                 << QuicUtils::TagToString(tag_);
+                                 << QuicTagToString(tag_);
   return send_values_;
 }
 
@@ -291,7 +210,7 @@ bool QuicFixedTagVector::HasReceivedValues() const {
 
 QuicTagVector QuicFixedTagVector::GetReceivedValues() const {
   QUIC_BUG_IF(!has_receive_values_) << "No receive value to get for tag:"
-                                    << QuicUtils::TagToString(tag_);
+                                    << QuicTagToString(tag_);
   return receive_values_;
 }
 
@@ -320,7 +239,7 @@ QuicErrorCode QuicFixedTagVector::ProcessPeerHello(
       if (presence_ == PRESENCE_OPTIONAL) {
         return QUIC_NO_ERROR;
       }
-      *error_details = "Missing " + QuicUtils::TagToString(tag_);
+      *error_details = "Missing " + QuicTagToString(tag_);
       break;
     case QUIC_NO_ERROR:
       DVLOG(1) << "Received Connection Option tags from receiver.";
@@ -330,51 +249,51 @@ QuicErrorCode QuicFixedTagVector::ProcessPeerHello(
       }
       break;
     default:
-      *error_details = "Bad " + QuicUtils::TagToString(tag_);
+      *error_details = "Bad " + QuicTagToString(tag_);
       break;
   }
   return error;
 }
 
-QuicFixedIPEndPoint::QuicFixedIPEndPoint(QuicTag tag,
-                                         QuicConfigPresence presence)
+QuicFixedSocketAddress::QuicFixedSocketAddress(QuicTag tag,
+                                               QuicConfigPresence presence)
     : QuicConfigValue(tag, presence),
       has_send_value_(false),
       has_receive_value_(false) {}
 
-QuicFixedIPEndPoint::~QuicFixedIPEndPoint() {}
+QuicFixedSocketAddress::~QuicFixedSocketAddress() {}
 
-bool QuicFixedIPEndPoint::HasSendValue() const {
+bool QuicFixedSocketAddress::HasSendValue() const {
   return has_send_value_;
 }
 
-const IPEndPoint& QuicFixedIPEndPoint::GetSendValue() const {
+const QuicSocketAddress& QuicFixedSocketAddress::GetSendValue() const {
   QUIC_BUG_IF(!has_send_value_) << "No send value to get for tag:"
-                                << QuicUtils::TagToString(tag_);
+                                << QuicTagToString(tag_);
   return send_value_;
 }
 
-void QuicFixedIPEndPoint::SetSendValue(const IPEndPoint& value) {
+void QuicFixedSocketAddress::SetSendValue(const QuicSocketAddress& value) {
   has_send_value_ = true;
   send_value_ = value;
 }
 
-bool QuicFixedIPEndPoint::HasReceivedValue() const {
+bool QuicFixedSocketAddress::HasReceivedValue() const {
   return has_receive_value_;
 }
 
-const IPEndPoint& QuicFixedIPEndPoint::GetReceivedValue() const {
+const QuicSocketAddress& QuicFixedSocketAddress::GetReceivedValue() const {
   QUIC_BUG_IF(!has_receive_value_) << "No receive value to get for tag:"
-                                   << QuicUtils::TagToString(tag_);
+                                   << QuicTagToString(tag_);
   return receive_value_;
 }
 
-void QuicFixedIPEndPoint::SetReceivedValue(const IPEndPoint& value) {
+void QuicFixedSocketAddress::SetReceivedValue(const QuicSocketAddress& value) {
   has_receive_value_ = true;
   receive_value_ = value;
 }
 
-void QuicFixedIPEndPoint::ToHandshakeMessage(
+void QuicFixedSocketAddress::ToHandshakeMessage(
     CryptoHandshakeMessage* out) const {
   if (has_send_value_) {
     QuicSocketAddressCoder address_coder(send_value_);
@@ -382,20 +301,21 @@ void QuicFixedIPEndPoint::ToHandshakeMessage(
   }
 }
 
-QuicErrorCode QuicFixedIPEndPoint::ProcessPeerHello(
+QuicErrorCode QuicFixedSocketAddress::ProcessPeerHello(
     const CryptoHandshakeMessage& peer_hello,
     HelloType hello_type,
     string* error_details) {
   base::StringPiece address;
   if (!peer_hello.GetStringPiece(tag_, &address)) {
     if (presence_ == PRESENCE_REQUIRED) {
-      *error_details = "Missing " + QuicUtils::TagToString(tag_);
+      *error_details = "Missing " + QuicTagToString(tag_);
       return QUIC_CRYPTO_MESSAGE_PARAMETER_NOT_FOUND;
     }
   } else {
     QuicSocketAddressCoder address_coder;
     if (address_coder.Decode(address.data(), address.length())) {
-      SetReceivedValue(IPEndPoint(address_coder.ip(), address_coder.port()));
+      SetReceivedValue(
+          QuicSocketAddress(address_coder.ip(), address_coder.port()));
     }
   }
   return QUIC_NO_ERROR;
@@ -406,7 +326,8 @@ QuicConfig::QuicConfig()
       max_idle_time_before_crypto_handshake_(QuicTime::Delta::Zero()),
       max_undecryptable_packets_(0),
       connection_options_(kCOPT, PRESENCE_OPTIONAL),
-      idle_connection_state_lifetime_seconds_(kICSL, PRESENCE_REQUIRED),
+      client_connection_options_(kCLOP, PRESENCE_OPTIONAL),
+      idle_network_timeout_seconds_(kICSL, PRESENCE_REQUIRED),
       silent_close_(kSCLS, PRESENCE_OPTIONAL),
       max_streams_per_connection_(kMSPC, PRESENCE_OPTIONAL),
       max_incoming_dynamic_streams_(kMIDS, PRESENCE_OPTIONAL),
@@ -418,7 +339,8 @@ QuicConfig::QuicConfig()
       multipath_enabled_(kMPTH, PRESENCE_OPTIONAL),
       connection_migration_disabled_(kNCMR, PRESENCE_OPTIONAL),
       alternate_server_address_(kASAD, PRESENCE_OPTIONAL),
-      force_hol_blocking_(kFHOL, PRESENCE_OPTIONAL) {
+      force_hol_blocking_(kFHL2, PRESENCE_OPTIONAL),
+      support_max_header_list_size_(kSMHL, PRESENCE_OPTIONAL) {
   SetDefaults();
 }
 
@@ -429,8 +351,8 @@ QuicConfig::~QuicConfig() {}
 bool QuicConfig::SetInitialReceivedConnectionOptions(
     const QuicTagVector& tags) {
   if (HasReceivedConnectionOptions()) {
-    // If we have already received connection options (via handshake or due to a
-    // previous call), don't re-initialize.
+    // If we have already received connection options (via handshake or due to
+    // a previous call), don't re-initialize.
     return false;
   }
   connection_options_.SetReceivedValues(tags);
@@ -472,17 +394,34 @@ bool QuicConfig::HasClientSentConnectionOption(QuicTag tag,
   return false;
 }
 
-void QuicConfig::SetIdleConnectionStateLifetime(
-    QuicTime::Delta max_idle_connection_state_lifetime,
-    QuicTime::Delta default_idle_conection_state_lifetime) {
-  idle_connection_state_lifetime_seconds_.set(
-      static_cast<uint32_t>(max_idle_connection_state_lifetime.ToSeconds()),
-      static_cast<uint32_t>(default_idle_conection_state_lifetime.ToSeconds()));
+void QuicConfig::SetClientConnectionOptions(
+    const QuicTagVector& client_connection_options) {
+  client_connection_options_.SetSendValues(client_connection_options);
+}
+
+bool QuicConfig::HasClientRequestedIndependentOption(
+    QuicTag tag,
+    Perspective perspective) const {
+  if (perspective == Perspective::IS_SERVER) {
+    return (HasReceivedConnectionOptions() &&
+            ContainsQuicTag(ReceivedConnectionOptions(), tag));
+  }
+
+  return (client_connection_options_.HasSendValues() &&
+          ContainsQuicTag(client_connection_options_.GetSendValues(), tag));
+}
+
+void QuicConfig::SetIdleNetworkTimeout(
+    QuicTime::Delta max_idle_network_timeout,
+    QuicTime::Delta default_idle_network_timeout) {
+  idle_network_timeout_seconds_.set(
+      static_cast<uint32_t>(max_idle_network_timeout.ToSeconds()),
+      static_cast<uint32_t>(default_idle_network_timeout.ToSeconds()));
 }
 
-QuicTime::Delta QuicConfig::IdleConnectionStateLifetime() const {
+QuicTime::Delta QuicConfig::IdleNetworkTimeout() const {
   return QuicTime::Delta::FromSeconds(
-      idle_connection_state_lifetime_seconds_.GetUint32());
+      idle_network_timeout_seconds_.GetUint32());
 }
 
 // TODO(ianswett) Use this for silent close on mobile, or delete.
@@ -632,7 +571,7 @@ bool QuicConfig::DisableConnectionMigration() const {
 }
 
 void QuicConfig::SetAlternateServerAddressToSend(
-    const IPEndPoint& alternate_server_address) {
+    const QuicSocketAddress& alternate_server_address) {
   alternate_server_address_.SetSendValue(alternate_server_address);
 }
 
@@ -640,7 +579,7 @@ bool QuicConfig::HasReceivedAlternateServerAddress() const {
   return alternate_server_address_.HasReceivedValue();
 }
 
-const IPEndPoint& QuicConfig::ReceivedAlternateServerAddress() const {
+const QuicSocketAddress& QuicConfig::ReceivedAlternateServerAddress() const {
   return alternate_server_address_.GetReceivedValue();
 }
 
@@ -656,33 +595,46 @@ bool QuicConfig::ForceHolBlocking(Perspective perspective) const {
   }
 }
 
+void QuicConfig::SetSupportMaxHeaderListSize() {
+  support_max_header_list_size_.SetSendValue(1);
+}
+
+bool QuicConfig::SupportMaxHeaderListSize() const {
+  return support_max_header_list_size_.HasReceivedValue();
+}
+
 bool QuicConfig::negotiated() const {
   // TODO(ianswett): Add the negotiated parameters once and iterate over all
   // of them in negotiated, ToHandshakeMessage, ProcessClientHello, and
   // ProcessServerHello.
-  return idle_connection_state_lifetime_seconds_.negotiated() &&
+  return idle_network_timeout_seconds_.negotiated() &&
          max_streams_per_connection_.negotiated();
 }
 
 void QuicConfig::SetDefaults() {
-  idle_connection_state_lifetime_seconds_.set(kMaximumIdleTimeoutSecs,
-                                              kDefaultIdleTimeoutSecs);
+  idle_network_timeout_seconds_.set(kMaximumIdleTimeoutSecs,
+                                    kDefaultIdleTimeoutSecs);
   silent_close_.set(1, 0);
   SetMaxStreamsPerConnection(kDefaultMaxStreamsPerConnection,
                              kDefaultMaxStreamsPerConnection);
   SetMaxIncomingDynamicStreamsToSend(kDefaultMaxStreamsPerConnection);
   max_time_before_crypto_handshake_ =
-      QuicTime::Delta::FromSeconds(kMaxTimeForCryptoHandshakeSecs);
+      //QuicTime::Delta::FromSeconds(kMaxTimeForCryptoHandshakeSecs);
+      QuicTime::Delta::FromSeconds(600);
   max_idle_time_before_crypto_handshake_ =
-      QuicTime::Delta::FromSeconds(kInitialIdleTimeoutSecs);
+      //QuicTime::Delta::FromSeconds(kInitialIdleTimeoutSecs);
+      QuicTime::Delta::FromSeconds(600);
   max_undecryptable_packets_ = kDefaultMaxUndecryptablePackets;
 
   SetInitialStreamFlowControlWindowToSend(kMinimumFlowControlSendWindow);
   SetInitialSessionFlowControlWindowToSend(kMinimumFlowControlSendWindow);
+  if (FLAGS_quic_send_max_header_list_size) {
+    SetSupportMaxHeaderListSize();
+  }
 }
 
 void QuicConfig::ToHandshakeMessage(CryptoHandshakeMessage* out) const {
-  idle_connection_state_lifetime_seconds_.ToHandshakeMessage(out);
+  idle_network_timeout_seconds_.ToHandshakeMessage(out);
   silent_close_.ToHandshakeMessage(out);
   max_streams_per_connection_.ToHandshakeMessage(out);
   max_incoming_dynamic_streams_.ToHandshakeMessage(out);
@@ -695,6 +647,7 @@ void QuicConfig::ToHandshakeMessage(CryptoHandshakeMessage* out) const {
   connection_options_.ToHandshakeMessage(out);
   alternate_server_address_.ToHandshakeMessage(out);
   force_hol_blocking_.ToHandshakeMessage(out);
+  support_max_header_list_size_.ToHandshakeMessage(out);
 }
 
 QuicErrorCode QuicConfig::ProcessPeerHello(
@@ -705,7 +658,7 @@ QuicErrorCode QuicConfig::ProcessPeerHello(
 
   QuicErrorCode error = QUIC_NO_ERROR;
   if (error == QUIC_NO_ERROR) {
-    error = idle_connection_state_lifetime_seconds_.ProcessPeerHello(
+    error = idle_network_timeout_seconds_.ProcessPeerHello(
         peer_hello, hello_type, error_details);
   }
   if (error == QUIC_NO_ERROR) {
@@ -756,6 +709,10 @@ QuicErrorCode QuicConfig::ProcessPeerHello(
     error = force_hol_blocking_.ProcessPeerHello(peer_hello, hello_type,
                                                  error_details);
   }
+  if (error == QUIC_NO_ERROR) {
+    error = support_max_header_list_size_.ProcessPeerHello(
+        peer_hello, hello_type, error_details);
+  }
   return error;
 }
 
diff --git a/src/net/quic/core/quic_config.h b/src/net/quic/core/quic_config.h
index 2712e53..5e19bef 100644
--- a/src/net/quic/core/quic_config.h
+++ b/src/net/quic/core/quic_config.h
@@ -10,7 +10,8 @@
 
 #include <string>
 
-#include "net/quic/core/quic_protocol.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
@@ -92,6 +93,9 @@ class NET_EXPORT_PRIVATE QuicNegotiableUint32 : public QuicNegotiableValue {
   // default_value_ (used to set default values before negotiation finishes).
   uint32_t GetUint32() const;
 
+  // Returns the maximum value negotiable.
+  uint32_t GetMax() const;
+
   // Serialises |name_| and value to |out|. If |negotiated_| is true then
   // |negotiated_value_| is serialised, otherwise |max_value_| is serialised.
   void ToHandshakeMessage(CryptoHandshakeMessage* out) const override;
@@ -110,42 +114,6 @@ class NET_EXPORT_PRIVATE QuicNegotiableUint32 : public QuicNegotiableValue {
   uint32_t negotiated_value_;
 };
 
-class NET_EXPORT_PRIVATE QuicNegotiableTag : public QuicNegotiableValue {
- public:
-  QuicNegotiableTag(QuicTag name, QuicConfigPresence presence);
-  ~QuicNegotiableTag() override;
-
-  // Sets the possible values that |negotiated_tag_| can take after negotiation
-  // and the default value that |negotiated_tag_| takes if OPTIONAL and *HLO
-  // msg doesn't contain tag |name_|.
-  void set(const QuicTagVector& possible_values, QuicTag default_value);
-
-  // Serialises |name_| and vector (either possible or negotiated) to |out|. If
-  // |negotiated_| is true then |negotiated_tag_| is serialised, otherwise
-  // |possible_values_| is serialised.
-  void ToHandshakeMessage(CryptoHandshakeMessage* out) const override;
-
-  // Selects the tag common to both tags in |client_hello| for |name_| and
-  // |possible_values_| with preference to tag in |possible_values_|. The
-  // selected tag is set as |negotiated_tag_|.
-  QuicErrorCode ProcessPeerHello(const CryptoHandshakeMessage& peer_hello,
-                                 HelloType hello_type,
-                                 std::string* error_details) override;
-
- private:
-  // Reads the vector corresponding to |name_| from |msg| into |out|. If the
-  // |name_| is absent in |msg| and |presence_| is set to OPTIONAL |out| is set
-  // to |possible_values_|.
-  QuicErrorCode ReadVector(const CryptoHandshakeMessage& msg,
-                           const QuicTag** out,
-                           size_t* out_length,
-                           std::string* error_details) const;
-
-  QuicTag negotiated_tag_;
-  QuicTagVector possible_values_;
-  QuicTag default_value_;
-};
-
 // Stores uint32_t from CHLO or SHLO messages that are not negotiated.
 class NET_EXPORT_PRIVATE QuicFixedUint32 : public QuicConfigValue {
  public:
@@ -215,23 +183,23 @@ class NET_EXPORT_PRIVATE QuicFixedTagVector : public QuicConfigValue {
   bool has_receive_values_;
 };
 
-// Stores IPEndPoint from CHLO or SHLO messages that are not negotiated.
-class NET_EXPORT_PRIVATE QuicFixedIPEndPoint : public QuicConfigValue {
+// Stores QuicSocketAddress from CHLO or SHLO messages that are not negotiated.
+class NET_EXPORT_PRIVATE QuicFixedSocketAddress : public QuicConfigValue {
  public:
-  QuicFixedIPEndPoint(QuicTag tag, QuicConfigPresence presence);
-  ~QuicFixedIPEndPoint() override;
+  QuicFixedSocketAddress(QuicTag tag, QuicConfigPresence presence);
+  ~QuicFixedSocketAddress() override;
 
   bool HasSendValue() const;
 
-  const IPEndPoint& GetSendValue() const;
+  const QuicSocketAddress& GetSendValue() const;
 
-  void SetSendValue(const IPEndPoint& value);
+  void SetSendValue(const QuicSocketAddress& value);
 
   bool HasReceivedValue() const;
 
-  const IPEndPoint& GetReceivedValue() const;
+  const QuicSocketAddress& GetReceivedValue() const;
 
-  void SetReceivedValue(const IPEndPoint& value);
+  void SetReceivedValue(const QuicSocketAddress& value);
 
   void ToHandshakeMessage(CryptoHandshakeMessage* out) const override;
 
@@ -240,9 +208,9 @@ class NET_EXPORT_PRIVATE QuicFixedIPEndPoint : public QuicConfigValue {
                                  std::string* error_details) override;
 
  private:
-  IPEndPoint send_value_;
+  QuicSocketAddress send_value_;
   bool has_send_value_;
-  IPEndPoint receive_value_;
+  QuicSocketAddress receive_value_;
   bool has_receive_value_;
 };
 
@@ -273,14 +241,23 @@ class NET_EXPORT_PRIVATE QuicConfig {
 
   // Returns true if the client is sending or the server has received a
   // connection option.
+  // TODO(ianswett): Rename to HasClientRequestedSharedOption
   bool HasClientSentConnectionOption(QuicTag tag,
                                      Perspective perspective) const;
 
-  void SetIdleConnectionStateLifetime(
-      QuicTime::Delta max_idle_connection_state_lifetime,
-      QuicTime::Delta default_idle_conection_state_lifetime);
+  void SetClientConnectionOptions(
+      const QuicTagVector& client_connection_options);
+
+  // Returns true if the client has requested the specified connection option.
+  // Checks the client connection options if the |perspective| is client and
+  // connection options if the |perspective| is the server.
+  bool HasClientRequestedIndependentOption(QuicTag tag,
+                                           Perspective perspective) const;
+
+  void SetIdleNetworkTimeout(QuicTime::Delta max_idle_network_timeout,
+                             QuicTime::Delta default_idle_network_timeout);
 
-  QuicTime::Delta IdleConnectionStateLifetime() const;
+  QuicTime::Delta IdleNetworkTimeout() const;
 
   void SetSilentClose(bool silent_close);
 
@@ -318,6 +295,10 @@ class NET_EXPORT_PRIVATE QuicConfig {
     return max_idle_time_before_crypto_handshake_;
   }
 
+  QuicNegotiableUint32 idle_network_timeout_seconds() const {
+    return idle_network_timeout_seconds_;
+  }
+
   void set_max_undecryptable_packets(size_t max_undecryptable_packets) {
     max_undecryptable_packets_ = max_undecryptable_packets;
   }
@@ -380,16 +361,20 @@ class NET_EXPORT_PRIVATE QuicConfig {
   bool DisableConnectionMigration() const;
 
   void SetAlternateServerAddressToSend(
-      const IPEndPoint& alternate_server_address);
+      const QuicSocketAddress& alternate_server_address);
 
   bool HasReceivedAlternateServerAddress() const;
 
-  const IPEndPoint& ReceivedAlternateServerAddress() const;
+  const QuicSocketAddress& ReceivedAlternateServerAddress() const;
 
   void SetForceHolBlocking();
 
   bool ForceHolBlocking(Perspective perspective) const;
 
+  void SetSupportMaxHeaderListSize();
+
+  bool SupportMaxHeaderListSize() const;
+
   bool negotiated() const;
 
   // ToHandshakeMessage serialises the settings in this object as a series of
@@ -416,10 +401,13 @@ class NET_EXPORT_PRIVATE QuicConfig {
   // Maximum number of undecryptable packets stored before CHLO/SHLO.
   size_t max_undecryptable_packets_;
 
-  // Connection options.
+  // Connection options which affect the server side.  May also affect the
+  // client side in cases when identical behavior is desirable.
   QuicFixedTagVector connection_options_;
-  // Idle connection state lifetime
-  QuicNegotiableUint32 idle_connection_state_lifetime_seconds_;
+  // Connection options which only affect the client side.
+  QuicFixedTagVector client_connection_options_;
+  // Idle network timeout in seconds.
+  QuicNegotiableUint32 idle_network_timeout_seconds_;
   // Whether to use silent close.  Defaults to 0 (false) and is otherwise true.
   QuicNegotiableUint32 silent_close_;
   // Maximum number of streams that the connection can support.
@@ -448,10 +436,13 @@ class NET_EXPORT_PRIVATE QuicConfig {
   QuicFixedUint32 connection_migration_disabled_;
 
   // An alternate server address the client could connect to.
-  QuicFixedIPEndPoint alternate_server_address_;
+  QuicFixedSocketAddress alternate_server_address_;
 
   // Force HOL blocking for measurement purposes.
   QuicFixedUint32 force_hol_blocking_;
+
+  // Whether support HTTP/2 SETTINGS_MAX_HEADER_LIST_SIZE SETTINGS frame.
+  QuicFixedUint32 support_max_header_list_size_;
 };
 
 }  // namespace net
diff --git a/src/net/quic/core/quic_connection.cc b/src/net/quic/core/quic_connection.cc
index a3765d6..06c05f6 100644
--- a/src/net/quic/core/quic_connection.cc
+++ b/src/net/quic/core/quic_connection.cc
@@ -34,19 +34,13 @@
 #include "net/quic/core/quic_config.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_packet_generator.h"
+#include "net/quic/core/quic_pending_retransmission.h"
 #include "net/quic/core/quic_sent_packet_manager.h"
 #include "net/quic/core/quic_utils.h"
 
 using base::StringPiece;
 using base::StringPrintf;
-using std::list;
-using std::make_pair;
-using std::max;
-using std::min;
-using std::numeric_limits;
-using std::set;
 using std::string;
-using std::vector;
 
 namespace net {
 
@@ -84,11 +78,6 @@ bool Near(QuicPacketNumber a, QuicPacketNumber b) {
   return delta <= kMaxPacketGap;
 }
 
-bool IsInitializedIPEndPoint(const IPEndPoint& address) {
-  return net::GetAddressFamily(address.address()) !=
-         net::ADDRESS_FAMILY_UNSPECIFIED;
-}
-
 // An alarm that is scheduled to send an ack if a timeout occurs.
 class AckAlarmDelegate : public QuicAlarm::Delegate {
  public:
@@ -183,7 +172,7 @@ class MtuDiscoveryAlarmDelegate : public QuicAlarm::Delegate {
   (perspective_ == Perspective::IS_SERVER ? "Server: " : "Client: ")
 
 QuicConnection::QuicConnection(QuicConnectionId connection_id,
-                               IPEndPoint address,
+                               QuicSocketAddress address,
                                QuicConnectionHelperInterface* helper,
                                QuicAlarmFactory* alarm_factory,
                                QuicPacketWriter* writer,
@@ -210,6 +199,7 @@ QuicConnection::QuicConnection(QuicConnectionId connection_id,
       current_packet_data_(nullptr),
       last_decrypted_packet_level_(ENCRYPTION_NONE),
       should_last_packet_instigate_acks_(false),
+      was_last_packet_missing_(false),
       largest_seen_packet_with_ack_(0),
       largest_seen_packet_with_stop_waiting_(0),
       max_undecryptable_packets_(0),
@@ -255,7 +245,6 @@ QuicConnection::QuicConnection(QuicConnectionId connection_id,
       debug_visitor_(nullptr),
       packet_generator_(connection_id_,
                         &framer_,
-                        random_generator_,
                         helper->GetBufferAllocator(),
                         this),
       idle_network_timeout_(QuicTime::Delta::Infinite()),
@@ -268,7 +257,7 @@ QuicConnection::QuicConnection(QuicConnectionId connection_id,
                                                      kDefaultPathId,
                                                      clock_,
                                                      &stats_,
-                                                     kCubic,
+                                                     kCubicBytes,
                                                      kNack,
                                                      /*delegate=*/nullptr)),
       version_negotiation_state_(START_NEGOTIATION),
@@ -280,7 +269,6 @@ QuicConnection::QuicConnection(QuicConnectionId connection_id,
       packets_between_mtu_probes_(kPacketsBetweenMtuProbesBase),
       next_mtu_probe_at_(kPacketsBetweenMtuProbesBase),
       largest_received_packet_size_(0),
-      largest_packet_size_supported_(std::numeric_limits<QuicByteCount>::max()),
       goaway_sent_(false),
       goaway_received_(false),
       multipath_enabled_(false),
@@ -288,8 +276,9 @@ QuicConnection::QuicConnection(QuicConnectionId connection_id,
   DVLOG(1) << ENDPOINT
            << "Created connection with connection_id: " << connection_id;
   framer_.set_visitor(this);
-  framer_.set_received_entropy_calculator(&received_packet_manager_);
-  last_stop_waiting_frame_.least_unacked = 0;
+  if (!FLAGS_quic_receive_packet_once_decrypted) {
+    last_stop_waiting_frame_.least_unacked = 0;
+  }
   stats_.connection_creation_time = clock_->ApproximateNow();
   if (FLAGS_quic_enable_multipath) {
     sent_packet_manager_.reset(new QuicMultipathSentPacketManager(
@@ -303,14 +292,12 @@ QuicConnection::QuicConnection(QuicConnectionId connection_id,
   SetMaxPacketLength(perspective_ == Perspective::IS_SERVER
                          ? kDefaultServerMaxPacketSize
                          : kDefaultMaxPacketSize);
-  received_packet_manager_.SetVersion(version());
 }
 
 QuicConnection::~QuicConnection() {
   if (owns_writer_) {
     delete writer_;
   }
-  base::STLDeleteElements(&undecryptable_packets_);
   ClearQueuedPackets();
 }
 
@@ -320,7 +307,7 @@ void QuicConnection::ClearQueuedPackets() {
     // Delete the buffer before calling ClearSerializedPacket, which sets
     // encrypted_buffer to nullptr.
     delete[] it->encrypted_buffer;
-    QuicUtils::ClearSerializedPacket(&(*it));
+    ClearSerializedPacket(&(*it));
   }
   queued_packets_.clear();
 }
@@ -329,7 +316,7 @@ void QuicConnection::SetFromConfig(const QuicConfig& config) {
   if (config.negotiated()) {
     // Handshake complete, set handshake timeout to Infinite.
     SetNetworkTimeouts(QuicTime::Delta::Infinite(),
-                       config.IdleConnectionStateLifetime());
+                       config.IdleNetworkTimeout());
     if (config.SilentClose()) {
       idle_timeout_connection_close_behavior_ =
           ConnectionCloseBehavior::SILENT_CLOSE;
@@ -374,7 +361,10 @@ void QuicConnection::SetFromConfig(const QuicConfig& config) {
     ack_decimation_delay_ = kShortAckDecimationDelay;
   }
   if (config.HasClientSentConnectionOption(k5RTO, perspective_)) {
-    close_connection_after_five_rtos_ = true;
+    if (perspective_ == Perspective::IS_CLIENT ||
+        !FLAGS_quic_only_5rto_client_side) {
+      close_connection_after_five_rtos_ = true;
+    }
   }
 }
 
@@ -495,7 +485,6 @@ bool QuicConnection::OnProtocolVersionMismatch(QuicVersion received_version) {
   }
 
   version_negotiation_state_ = NEGOTIATED_VERSION;
-  received_packet_manager_.SetVersion(received_version);
   visitor_->OnSuccessfulVersionNegotiation(received_version);
   if (debug_visitor_ != nullptr) {
     debug_visitor_->OnSuccessfulVersionNegotiation(received_version);
@@ -558,7 +547,6 @@ void QuicConnection::OnVersionNegotiationPacket(
 
   DVLOG(1) << ENDPOINT
            << "Negotiated version: " << QuicVersionToString(version());
-  received_packet_manager_.SetVersion(version());
   server_supported_versions_ = packet.versions;
   version_negotiation_state_ = NEGOTIATION_IN_PROGRESS;
   RetransmitUnackedPackets(ALL_UNACKED_RETRANSMISSION);
@@ -593,18 +581,6 @@ bool QuicConnection::OnUnauthenticatedHeader(const QuicPacketHeader& header) {
   // here.
   DCHECK_EQ(connection_id_, header.public_header.connection_id);
 
-  if (!FLAGS_quic_postpone_multipath_flag_validation) {
-    // Multipath is not enabled, but a packet with multipath flag on is
-    // received.
-    if (!multipath_enabled_ && header.public_header.multipath_flag) {
-      const string error_details =
-          "Received a packet with multipath flag but multipath is not enabled.";
-      QUIC_BUG << error_details;
-      CloseConnection(QUIC_BAD_MULTIPATH_FLAG, error_details,
-                      ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-      return false;
-    }
-  }
   if (!packet_generator_.IsPendingPacketEmpty()) {
     // Incoming packets may change a queued ACK frame.
     const string error_details =
@@ -670,6 +646,17 @@ bool QuicConnection::OnPacketHeader(const QuicPacketHeader& header) {
   --stats_.packets_dropped;
   DVLOG(1) << ENDPOINT << "Received packet header: " << header;
   last_header_ = header;
+  if (FLAGS_quic_receive_packet_once_decrypted) {
+    // An ack will be sent if a missing retransmittable packet was received;
+    was_last_packet_missing_ =
+        received_packet_manager_.IsMissing(last_header_.packet_number);
+
+    // Record received to populate ack info correctly before processing stream
+    // frames, since the processing may result in a response packet with a
+    // bundled ack.
+    received_packet_manager_.RecordPacketReceived(
+        last_header_, time_of_last_received_packet_);
+  }
   DCHECK(connected_);
   return true;
 }
@@ -728,9 +715,6 @@ bool QuicConnection::OnAckFrame(const QuicAckFrame& incoming_ack) {
     send_alarm_->Cancel();
   }
   ProcessAckFrame(incoming_ack);
-  if (incoming_ack.is_truncated) {
-    should_last_packet_instigate_acks_ = true;
-  }
   // If the incoming ack's packets set expresses missing packets: peer is still
   // waiting for a packet lower than a packet that we are no longer planning to
   // send.
@@ -751,12 +735,6 @@ void QuicConnection::ProcessAckFrame(const QuicAckFrame& incoming_ack) {
   largest_seen_packet_with_ack_ = last_header_.packet_number;
   sent_packet_manager_->OnIncomingAck(incoming_ack,
                                       time_of_last_received_packet_);
-  if (version() <= QUIC_VERSION_33) {
-    sent_entropy_manager_.ClearEntropyBefore(
-        sent_packet_manager_->GetLeastPacketAwaitedByPeer(
-            incoming_ack.path_id) -
-        1);
-  }
   // Always reset the retransmission alarm when an ack comes in, since we now
   // have a better estimate of the current rtt than when it was set.
   SetRetransmissionAlarm();
@@ -787,7 +765,11 @@ bool QuicConnection::OnStopWaitingFrame(const QuicStopWaitingFrame& frame) {
     debug_visitor_->OnStopWaitingFrame(frame);
   }
 
-  last_stop_waiting_frame_ = frame;
+  if (FLAGS_quic_receive_packet_once_decrypted) {
+    ProcessStopWaitingFrame(frame);
+  } else {
+    last_stop_waiting_frame_ = frame;
+  }
   return connected_;
 }
 
@@ -830,44 +812,13 @@ const char* QuicConnection::ValidateAckFrame(const QuicAckFrame& incoming_ack) {
     return "Largest observed too low.";
   }
 
-  if (version() <= QUIC_VERSION_33) {
-    if (!incoming_ack.packets.Empty() &&
-        incoming_ack.packets.Max() > incoming_ack.largest_observed) {
-      LOG(WARNING) << ENDPOINT
-                   << "Peer sent missing packet: " << incoming_ack.packets.Max()
-                   << " which is greater than largest observed: "
-                   << incoming_ack.largest_observed;
-      return "Missing packet higher than largest observed.";
-    }
-
-    if (!incoming_ack.packets.Empty() &&
-        incoming_ack.packets.Min() <
-            sent_packet_manager_->GetLeastPacketAwaitedByPeer(
-                incoming_ack.path_id)) {
-      LOG(WARNING) << ENDPOINT
-                   << "Peer sent missing packet: " << incoming_ack.packets.Min()
-                   << " which is smaller than least_packet_awaited_by_peer_: "
-                   << sent_packet_manager_->GetLeastPacketAwaitedByPeer(
-                          incoming_ack.path_id);
-      return "Missing packet smaller than least awaited.";
-    }
-    if (!sent_entropy_manager_.IsValidEntropy(incoming_ack.largest_observed,
-                                              incoming_ack.packets,
-                                              incoming_ack.entropy_hash)) {
-      DLOG(WARNING) << ENDPOINT << "Peer sent invalid entropy."
-                    << " largest_observed:" << incoming_ack.largest_observed
-                    << " last_received:" << last_header_.packet_number;
-      return "Invalid entropy.";
-    }
-  } else {
-    if (!incoming_ack.packets.Empty() &&
-        incoming_ack.packets.Max() != incoming_ack.largest_observed) {
-      QUIC_BUG << ENDPOINT
-               << "Peer last received packet: " << incoming_ack.packets.Max()
-               << " which is not equal to largest observed: "
-               << incoming_ack.largest_observed;
-      return "Last received packet not equal to largest observed.";
-    }
+  if (!incoming_ack.packets.Empty() &&
+      incoming_ack.packets.Max() != incoming_ack.largest_observed) {
+    QUIC_BUG << ENDPOINT
+             << "Peer last received packet: " << incoming_ack.packets.Max()
+             << " which is not equal to largest observed: "
+             << incoming_ack.largest_observed;
+    return "Last received packet not equal to largest observed.";
   }
 
   return nullptr;
@@ -903,7 +854,7 @@ bool QuicConnection::OnRstStreamFrame(const QuicRstStreamFrame& frame) {
   DVLOG(1) << ENDPOINT
            << "RST_STREAM_FRAME received for stream: " << frame.stream_id
            << " with error: "
-           << QuicUtils::StreamErrorToString(frame.error_code);
+           << QuicRstStreamErrorCodeToString(frame.error_code);
   visitor_->OnRstStream(frame);
   visitor_->PostProcessAfterData();
   should_last_packet_instigate_acks_ = true;
@@ -918,10 +869,10 @@ bool QuicConnection::OnConnectionCloseFrame(
   }
   DVLOG(1) << ENDPOINT
            << "Received ConnectionClose for connection: " << connection_id()
-           << ", with error: " << QuicUtils::ErrorToString(frame.error_code)
+           << ", with error: " << QuicErrorCodeToString(frame.error_code)
            << " (" << frame.error_details << ")";
   if (frame.error_code == QUIC_BAD_MULTIPATH_FLAG) {
-    LOG(ERROR) << " quic_version: " << version()
+    LOG(ERROR) << "Unexpected QUIC_BAD_MULTIPATH_FLAG error."
                << " last_received_header: " << last_header_
                << " encryption_level: " << encryption_level_;
   }
@@ -937,7 +888,7 @@ bool QuicConnection::OnGoAwayFrame(const QuicGoAwayFrame& frame) {
   }
   DVLOG(1) << ENDPOINT << "GOAWAY_FRAME received with last good stream: "
            << frame.last_good_stream_id
-           << " and error: " << QuicUtils::ErrorToString(frame.error_code)
+           << " and error: " << QuicErrorCodeToString(frame.error_code)
            << " and reason: " << frame.reason_phrase;
 
   goaway_received_ = true;
@@ -970,6 +921,7 @@ bool QuicConnection::OnBlockedFrame(const QuicBlockedFrame& frame) {
            << "BLOCKED_FRAME received for stream: " << frame.stream_id;
   visitor_->OnBlockedFrame(frame);
   visitor_->PostProcessAfterData();
+  stats_.blocked_frames_received++;
   should_last_packet_instigate_acks_ = true;
   return connected_;
 }
@@ -995,30 +947,41 @@ void QuicConnection::OnPacketComplete() {
   DVLOG(1) << ENDPOINT << "Got packet " << last_header_.packet_number << " for "
            << last_header_.public_header.connection_id;
 
-  // An ack will be sent if a missing retransmittable packet was received;
-  const bool was_missing =
-      should_last_packet_instigate_acks_ &&
-      received_packet_manager_.IsMissing(last_header_.packet_number);
-
-  // Record received to populate ack info correctly before processing stream
-  // frames, since the processing may result in a response packet with a bundled
-  // ack.
-  received_packet_manager_.RecordPacketReceived(last_size_, last_header_,
-                                                time_of_last_received_packet_);
-
-  // Process stop waiting frames here, instead of inline, because the packet
-  // needs to be considered 'received' before the entropy can be updated.
-  if (last_stop_waiting_frame_.least_unacked > 0) {
-    ProcessStopWaitingFrame(last_stop_waiting_frame_);
-    if (!connected_) {
-      return;
+  if (FLAGS_quic_receive_packet_once_decrypted) {
+    // An ack will be sent if a missing retransmittable packet was received;
+    const bool was_missing =
+        should_last_packet_instigate_acks_ && was_last_packet_missing_;
+
+    // It's possible the ack frame was sent along with response data, so it
+    // no longer needs to be sent.
+    if (ack_frame_updated()) {
+      MaybeQueueAck(was_missing);
+    }
+  } else {
+    // An ack will be sent if a missing retransmittable packet was received;
+    const bool was_missing =
+        should_last_packet_instigate_acks_ &&
+        received_packet_manager_.IsMissing(last_header_.packet_number);
+
+    // Record received to populate ack info correctly before processing stream
+    // frames, since the processing may result in a response packet with a
+    // bundled ack.
+    received_packet_manager_.RecordPacketReceived(
+        last_header_, time_of_last_received_packet_);
+
+    // Process stop waiting frames here, instead of inline, because the packet
+    // needs to be considered 'received' before the entropy can be updated.
+    if (last_stop_waiting_frame_.least_unacked > 0) {
+      ProcessStopWaitingFrame(last_stop_waiting_frame_);
+      if (!connected_) {
+        return;
+      }
     }
-  }
 
-  MaybeQueueAck(was_missing);
+    MaybeQueueAck(was_missing);
+  }
 
   ClearLastFrames();
-  MaybeCloseIfTooManyOutstandingPackets();
 }
 
 void QuicConnection::MaybeQueueAck(bool was_missing) {
@@ -1087,30 +1050,8 @@ void QuicConnection::MaybeQueueAck(bool was_missing) {
 
 void QuicConnection::ClearLastFrames() {
   should_last_packet_instigate_acks_ = false;
-  last_stop_waiting_frame_.least_unacked = 0;
-}
-
-void QuicConnection::MaybeCloseIfTooManyOutstandingPackets() {
-  if (version() > QUIC_VERSION_33) {
-    return;
-  }
-  // This occurs if we don't discard old packets we've sent fast enough.
-  // It's possible largest observed is less than least unacked.
-  if (sent_packet_manager_->GetLargestObserved(last_header_.path_id) >
-      (sent_packet_manager_->GetLeastUnacked(last_header_.path_id) +
-       kMaxTrackedPackets)) {
-    CloseConnection(
-        QUIC_TOO_MANY_OUTSTANDING_SENT_PACKETS,
-        StringPrintf("More than %" PRIu64 " outstanding.", kMaxTrackedPackets),
-        ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-  }
-  // This occurs if there are received packet gaps and the peer does not raise
-  // the least unacked fast enough.
-  if (received_packet_manager_.NumTrackedPackets() > kMaxTrackedPackets) {
-    CloseConnection(
-        QUIC_TOO_MANY_OUTSTANDING_RECEIVED_PACKETS,
-        StringPrintf("More than %" PRIu64 " outstanding.", kMaxTrackedPackets),
-        ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
+  if (!FLAGS_quic_receive_packet_once_decrypted) {
+    last_stop_waiting_frame_.least_unacked = 0;
   }
 }
 
@@ -1121,10 +1062,6 @@ const QuicFrame QuicConnection::GetUpdatedAckFrame() {
 void QuicConnection::PopulateStopWaitingFrame(
     QuicStopWaitingFrame* stop_waiting) {
   stop_waiting->least_unacked = GetLeastUnacked(stop_waiting->path_id);
-  if (version() <= QUIC_VERSION_33) {
-    stop_waiting->entropy_hash = sent_entropy_manager_.GetCumulativeEntropy(
-        stop_waiting->least_unacked - 1);
-  }
 }
 
 QuicPacketNumber QuicConnection::GetLeastUnacked(QuicPathId path_id) const {
@@ -1156,8 +1093,8 @@ void QuicConnection::SendVersionNegotiationPacket() {
       packet_generator_.SerializeVersionNegotiationPacket(
           framer_.supported_versions()));
   WriteResult result = writer_->WritePacket(
-      version_packet->data(), version_packet->length(),
-      self_address().address(), peer_address(), per_packet_options_);
+      version_packet->data(), version_packet->length(), self_address().host(),
+      peer_address(), per_packet_options_);
 
   if (result.status == WRITE_STATUS_ERROR) {
     OnWriteError(result.error_code);
@@ -1208,8 +1145,8 @@ void QuicConnection::SendRstStream(QuicStreamId id,
                                    QuicStreamOffset bytes_written) {
   // Opportunistically bundle an ack with this outgoing packet.
   ScopedPacketBundler ack_bundler(this, SEND_ACK_IF_PENDING);
-  packet_generator_.AddControlFrame(QuicFrame(new QuicRstStreamFrame(
-      id, AdjustErrorForVersion(error, version()), bytes_written)));
+  packet_generator_.AddControlFrame(
+      QuicFrame(new QuicRstStreamFrame(id, error, bytes_written)));
 
   if (error == QUIC_STREAM_NO_ERROR) {
     // All data for streams which are reset with QUIC_STREAM_NO_ERROR must
@@ -1227,13 +1164,13 @@ void QuicConnection::SendRstStream(QuicStreamId id,
       ++packet_iterator;
       continue;
     }
-    QuicUtils::RemoveFramesForStream(retransmittable_frames, id);
+    RemoveFramesForStream(retransmittable_frames, id);
     if (!retransmittable_frames->empty()) {
       ++packet_iterator;
       continue;
     }
     delete[] packet_iterator->encrypted_buffer;
-    QuicUtils::ClearSerializedPacket(&(*packet_iterator));
+    ClearSerializedPacket(&(*packet_iterator));
     packet_iterator = queued_packets_.erase(packet_iterator);
   }
 }
@@ -1250,6 +1187,7 @@ void QuicConnection::SendBlocked(QuicStreamId id) {
   // Opportunistically bundle an ack with this outgoing packet.
   ScopedPacketBundler ack_bundler(this, SEND_ACK_IF_PENDING);
   packet_generator_.AddControlFrame(QuicFrame(new QuicBlockedFrame(id)));
+  stats_.blocked_frames_sent++;
 }
 
 void QuicConnection::SendPathClose(QuicPathId path_id) {
@@ -1283,8 +1221,8 @@ const QuicConnectionStats& QuicConnection::GetStats() {
   return stats_;
 }
 
-void QuicConnection::ProcessUdpPacket(const IPEndPoint& self_address,
-                                      const IPEndPoint& peer_address,
+void QuicConnection::ProcessUdpPacket(const QuicSocketAddress& self_address,
+                                      const QuicSocketAddress& peer_address,
                                       const QuicReceivedPacket& packet) {
   if (!connected_) {
     return;
@@ -1297,16 +1235,25 @@ void QuicConnection::ProcessUdpPacket(const IPEndPoint& self_address,
 
   last_packet_destination_address_ = self_address;
   last_packet_source_address_ = peer_address;
-  if (!IsInitializedIPEndPoint(self_address_)) {
+  if (!self_address_.IsInitialized()) {
     self_address_ = last_packet_destination_address_;
   }
-  if (!IsInitializedIPEndPoint(peer_address_)) {
+  if (!peer_address_.IsInitialized()) {
     peer_address_ = last_packet_source_address_;
   }
 
   stats_.bytes_received += packet.length();
   ++stats_.packets_received;
 
+  // Ensure the time coming from the packet reader is within a minute of now.
+  if (FLAGS_quic_allow_large_send_deltas &&
+      std::abs((packet.receipt_time() - clock_->ApproximateNow()).ToSeconds()) >
+          60) {
+    QUIC_BUG << "Packet receipt time:"
+             << packet.receipt_time().ToDebuggingValue()
+             << " too far from current time:"
+             << clock_->ApproximateNow().ToDebuggingValue();
+  }
   time_of_last_received_packet_ = packet.receipt_time();
   DVLOG(1) << ENDPOINT << "time of last received packet: "
            << time_of_last_received_packet_.ToDebuggingValue();
@@ -1386,34 +1333,13 @@ void QuicConnection::WriteAndBundleAcksIfNotBlocked() {
 }
 
 bool QuicConnection::ProcessValidatedPacket(const QuicPacketHeader& header) {
-  if (header.fec_flag) {
-    // Drop any FEC packet.
-    return false;
-  }
-
-  if (perspective_ == Perspective::IS_SERVER &&
-      IsInitializedIPEndPoint(self_address_) &&
-      IsInitializedIPEndPoint(last_packet_destination_address_) &&
-      (!(self_address_ == last_packet_destination_address_))) {
-    if (!FLAGS_quic_allow_server_address_change_for_mapped_ipv4) {
-      CloseConnection(QUIC_ERROR_MIGRATING_ADDRESS,
-                      "Self address migration is not supported at the server.",
-                      ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-      return false;
-    }
+  if (perspective_ == Perspective::IS_SERVER && self_address_.IsInitialized() &&
+      last_packet_destination_address_.IsInitialized() &&
+      self_address_ != last_packet_destination_address_) {
     // Allow change between pure IPv4 and equivalent mapped IPv4 address.
-    IPAddress self_ip = self_address_.address();
-    if (self_ip.IsIPv4MappedIPv6()) {
-      self_ip = ConvertIPv4MappedIPv6ToIPv4(self_ip);
-    }
-    IPAddress last_packet_destination_ip =
-        last_packet_destination_address_.address();
-    if (last_packet_destination_ip.IsIPv4MappedIPv6()) {
-      last_packet_destination_ip =
-          ConvertIPv4MappedIPv6ToIPv4(last_packet_destination_ip);
-    }
     if (self_address_.port() != last_packet_destination_address_.port() ||
-        self_ip != last_packet_destination_ip) {
+        self_address_.host().Normalized() !=
+            last_packet_destination_address_.host().Normalized()) {
       CloseConnection(QUIC_ERROR_MIGRATING_ADDRESS,
                       "Self address migration is not supported at the server.",
                       ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
@@ -1430,17 +1356,15 @@ bool QuicConnection::ProcessValidatedPacket(const QuicPacketHeader& header) {
     return false;
   }
 
-  if (FLAGS_quic_postpone_multipath_flag_validation) {
-    // Multipath is not enabled, but a packet with multipath flag on is
-    // received.
-    if (!multipath_enabled_ && header.public_header.multipath_flag) {
-      const string error_details =
-          "Received a packet with multipath flag but multipath is not enabled.";
-      QUIC_BUG << error_details;
-      CloseConnection(QUIC_BAD_MULTIPATH_FLAG, error_details,
-                      ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-      return false;
-    }
+  // Multipath is not enabled, but a packet with multipath flag on is
+  // received.
+  if (!multipath_enabled_ && header.public_header.multipath_flag) {
+    const string error_details =
+        "Received a packet with multipath flag but multipath is not enabled.";
+    QUIC_BUG << error_details;
+    CloseConnection(QUIC_BAD_MULTIPATH_FLAG, error_details,
+                    ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
+    return false;
   }
 
   if (version_negotiation_state_ != NEGOTIATED_VERSION) {
@@ -1460,7 +1384,6 @@ bool QuicConnection::ProcessValidatedPacket(const QuicPacketHeader& header) {
         DCHECK_EQ(1u, header.public_header.versions.size());
         DCHECK_EQ(header.public_header.versions[0], version());
         version_negotiation_state_ = NEGOTIATED_VERSION;
-        received_packet_manager_.SetVersion(version());
         visitor_->OnSuccessfulVersionNegotiation(version());
         if (debug_visitor_ != nullptr) {
           debug_visitor_->OnSuccessfulVersionNegotiation(version());
@@ -1472,7 +1395,6 @@ bool QuicConnection::ProcessValidatedPacket(const QuicPacketHeader& header) {
       // it should stop sending version since the version negotiation is done.
       packet_generator_.StopSendingVersion();
       version_negotiation_state_ = NEGOTIATED_VERSION;
-      received_packet_manager_.SetVersion(version());
       visitor_->OnSuccessfulVersionNegotiation(version());
       if (debug_visitor_ != nullptr) {
         debug_visitor_->OnSuccessfulVersionNegotiation(version());
@@ -1505,7 +1427,7 @@ void QuicConnection::WriteQueuedPackets() {
   while (packet_iterator != queued_packets_.end() &&
          WritePacket(&(*packet_iterator))) {
     delete[] packet_iterator->encrypted_buffer;
-    QuicUtils::ClearSerializedPacket(&(*packet_iterator));
+    ClearSerializedPacket(&(*packet_iterator));
     packet_iterator = queued_packets_.erase(packet_iterator);
   }
 }
@@ -1514,7 +1436,7 @@ void QuicConnection::WritePendingRetransmissions() {
   // Keep writing as long as there's a pending retransmission which can be
   // written.
   while (sent_packet_manager_->HasPendingRetransmissions()) {
-    const PendingRetransmission pending =
+    const QuicPendingRetransmission pending =
         sent_packet_manager_->NextPendingRetransmission();
     if (!CanWrite(HAS_RETRANSMITTABLE_DATA)) {
       break;
@@ -1618,6 +1540,9 @@ bool QuicConnection::WritePacket(SerializedPacket* packet) {
   }
 
   QuicPacketNumber packet_number = packet->packet_number;
+  // TODO(ianswett): Remove packet_number_of_last_sent_packet_ because it's
+  // redundant to SentPacketManager_->GetLargestPacket in most cases, and wrong
+  // for multipath.
   DCHECK_LE(packet_number_of_last_sent_packet_, packet_number);
   packet_number_of_last_sent_packet_ = packet_number;
 
@@ -1630,7 +1555,7 @@ bool QuicConnection::WritePacket(SerializedPacket* packet) {
           new std::vector<std::unique_ptr<QuicEncryptedPacket>>);
     }
     // Copy the buffer so it's owned in the future.
-    char* buffer_copy = QuicUtils::CopyBuffer(*packet);
+    char* buffer_copy = CopyBuffer(*packet);
     termination_packets_->push_back(std::unique_ptr<QuicEncryptedPacket>(
         new QuicEncryptedPacket(buffer_copy, encrypted_length, true)));
     // This assures we won't try to write *forced* packets when blocked.
@@ -1659,7 +1584,7 @@ bool QuicConnection::WritePacket(SerializedPacket* packet) {
   // during the WritePacket below.
   QuicTime packet_send_time = clock_->Now();
   WriteResult result = writer_->WritePacket(
-      packet->encrypted_buffer, encrypted_length, self_address().address(),
+      packet->encrypted_buffer, encrypted_length, self_address().host(),
       peer_address(), per_packet_options_);
   if (result.error_code == ERR_IO_PENDING) {
     DCHECK_EQ(WRITE_STATUS_BLOCKED, result.status);
@@ -1675,6 +1600,28 @@ bool QuicConnection::WritePacket(SerializedPacket* packet) {
       return false;
     }
   }
+
+  // In some cases, an MTU probe can cause EMSGSIZE. This indicates that the
+  // MTU discovery is permanently unsuccessful.
+  if (result.status == WRITE_STATUS_ERROR &&
+      result.error_code == kMessageTooBigErrorCode &&
+      packet->retransmittable_frames.empty() &&
+      packet->encrypted_length > long_term_mtu_) {
+    mtu_discovery_target_ = 0;
+    mtu_discovery_alarm_->Cancel();
+    // The write failed, but the writer is not blocked, so return true.
+    return true;
+  }
+
+  if (result.status == WRITE_STATUS_ERROR) {
+    OnWriteError(result.error_code);
+    DLOG(ERROR) << ENDPOINT << "failed writing " << encrypted_length
+                << " from host " << self_address().host().ToString()
+                << " to address " << peer_address().ToString()
+                << " with error code " << result.error_code;
+    return false;
+  }
+
   if (result.status != WRITE_STATUS_ERROR && debug_visitor_ != nullptr) {
     // Pass the write result to the visitor.
     debug_visitor_->OnPacketSent(*packet, packet->original_path_id,
@@ -1683,37 +1630,20 @@ bool QuicConnection::WritePacket(SerializedPacket* packet) {
   }
   if (packet->transmission_type == NOT_RETRANSMISSION) {
     time_of_last_sent_new_packet_ = packet_send_time;
-    if (!FLAGS_quic_better_last_send_for_timeout) {
-      if (IsRetransmittable(*packet) == HAS_RETRANSMITTABLE_DATA &&
-          last_send_for_timeout_ <= time_of_last_received_packet_) {
-        last_send_for_timeout_ = packet_send_time;
-      }
-    }
   }
-  if (FLAGS_quic_better_last_send_for_timeout) {
-    // Only adjust the last sent time (for the purpose of tracking the idle
-    // timeout) if this is the first retransmittable packet sent after a
-    // packet is received. If it were updated on every sent packet, then
-    // sending into a black hole might never timeout.
-    if (IsRetransmittable(*packet) == HAS_RETRANSMITTABLE_DATA &&
-        last_send_for_timeout_ <= time_of_last_received_packet_) {
-      last_send_for_timeout_ = packet_send_time;
-    }
+  // Only adjust the last sent time (for the purpose of tracking the idle
+  // timeout) if this is the first retransmittable packet sent after a
+  // packet is received. If it were updated on every sent packet, then
+  // sending into a black hole might never timeout.
+  if (IsRetransmittable(*packet) == HAS_RETRANSMITTABLE_DATA &&
+      last_send_for_timeout_ <= time_of_last_received_packet_) {
+    last_send_for_timeout_ = packet_send_time;
   }
   SetPingAlarm();
   MaybeSetMtuAlarm();
   DVLOG(1) << ENDPOINT << "time we began writing last sent packet: "
            << packet_send_time.ToDebuggingValue();
 
-  if (!FLAGS_quic_simple_packet_number_length_2) {
-    // TODO(ianswett): Change the packet number length and other packet creator
-    // options by a more explicit API than setting a struct value directly,
-    // perhaps via the NetworkChangeVisitor.
-    packet_generator_.UpdateSequenceNumberLength(
-        sent_packet_manager_->GetLeastUnacked(packet->path_id),
-        sent_packet_manager_->EstimateMaxPacketsInFlight(max_packet_length()));
-  }
-
   bool reset_retransmission_alarm = sent_packet_manager_->OnPacketSent(
       packet, packet->original_path_id, packet->original_packet_number,
       packet_send_time, packet->transmission_type, IsRetransmittable(*packet));
@@ -1722,13 +1652,11 @@ bool QuicConnection::WritePacket(SerializedPacket* packet) {
     SetRetransmissionAlarm();
   }
 
-  if (FLAGS_quic_simple_packet_number_length_2) {
-    // The packet number length must be updated after OnPacketSent, because it
-    // may change the packet number length in packet.
-    packet_generator_.UpdateSequenceNumberLength(
-        sent_packet_manager_->GetLeastUnacked(packet->path_id),
-        sent_packet_manager_->EstimateMaxPacketsInFlight(max_packet_length()));
-  }
+  // The packet number length must be updated after OnPacketSent, because it
+  // may change the packet number length in packet.
+  packet_generator_.UpdateSequenceNumberLength(
+      sent_packet_manager_->GetLeastUnacked(packet->path_id),
+      sent_packet_manager_->EstimateMaxPacketsInFlight(max_packet_length()));
 
   stats_.bytes_sent += result.bytes_written;
   ++stats_.packets_sent;
@@ -1737,30 +1665,6 @@ bool QuicConnection::WritePacket(SerializedPacket* packet) {
     ++stats_.packets_retransmitted;
   }
 
-  // In some cases, an MTU probe can cause ERR_MSG_TOO_BIG. This indicates that
-  // the MTU discovery is permanently unsuccessful.
-  if (FLAGS_graceful_emsgsize_on_mtu_probe &&
-      result.status == WRITE_STATUS_ERROR &&
-      result.error_code == kMessageTooBigErrorCode &&
-      packet->retransmittable_frames.empty() &&
-      packet->encrypted_length > long_term_mtu_) {
-    mtu_discovery_target_ = 0;
-    mtu_discovery_alarm_->Cancel();
-    return true;
-  }
-
-  if (result.status == WRITE_STATUS_ERROR) {
-    OnWriteError(result.error_code);
-    DLOG(ERROR) << ENDPOINT << "failed writing " << encrypted_length
-                << " bytes "
-                << " from host " << (self_address().address().empty()
-                                         ? " empty address "
-                                         : self_address().ToStringWithoutPort())
-                << " to address " << peer_address().ToString()
-                << " with error code " << result.error_code;
-    return false;
-  }
-
   return true;
 }
 
@@ -1784,7 +1688,7 @@ bool QuicConnection::ShouldDiscardPacket(const SerializedPacket& packet) {
 }
 
 void QuicConnection::OnWriteError(int error_code) {
-  if (FLAGS_quic_close_connection_on_packet_too_large && write_error_occured_) {
+  if (write_error_occured_) {
     // A write error already occurred. The connection is being closed.
     return;
   }
@@ -1797,15 +1701,10 @@ void QuicConnection::OnWriteError(int error_code) {
   // We can't send an error as the socket is presumably borked.
   switch (error_code) {
     case kMessageTooBigErrorCode:
-      if (FLAGS_quic_close_connection_on_packet_too_large) {  // NOLINT
-        CloseConnection(
-            QUIC_PACKET_WRITE_ERROR, error_details,
-            FLAGS_quic_do_not_send_ack_on_emsgsize
-                ? ConnectionCloseBehavior::
-                      SEND_CONNECTION_CLOSE_PACKET_WITH_NO_ACK
-                : ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-        break;
-      }
+      CloseConnection(
+          QUIC_PACKET_WRITE_ERROR, error_details,
+          ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET_WITH_NO_ACK);
+      break;
     default:
       // We can't send an error as the socket is presumably borked.
       TearDownLocalConnectionState(QUIC_PACKET_WRITE_ERROR, error_details,
@@ -1878,20 +1777,16 @@ void QuicConnection::SendOrQueuePacket(SerializedPacket* packet) {
     QUIC_BUG << "packet.encrypted_buffer == nullptr in to SendOrQueuePacket";
     return;
   }
-  if (version() <= QUIC_VERSION_33) {
-    sent_entropy_manager_.RecordPacketEntropyHash(packet->packet_number,
-                                                  packet->entropy_hash);
-  }
   // If there are already queued packets, queue this one immediately to ensure
   // it's written in sequence number order.
   if (!queued_packets_.empty() || !WritePacket(packet)) {
     // Take ownership of the underlying encrypted packet.
-    packet->encrypted_buffer = QuicUtils::CopyBuffer(*packet);
+    packet->encrypted_buffer = CopyBuffer(*packet);
     queued_packets_.push_back(*packet);
     packet->retransmittable_frames.clear();
   }
 
-  QuicUtils::ClearSerializedPacket(packet);
+  ClearSerializedPacket(packet);
 }
 
 void QuicConnection::OnPingTimeout() {
@@ -2005,7 +1900,7 @@ void QuicConnection::MaybeProcessUndecryptablePackets() {
 
   while (connected_ && !undecryptable_packets_.empty()) {
     DVLOG(1) << ENDPOINT << "Attempting to process undecryptable packet";
-    QuicEncryptedPacket* packet = undecryptable_packets_.front();
+    QuicEncryptedPacket* packet = undecryptable_packets_.front().get();
     if (!framer_.ProcessPacket(*packet) &&
         framer_.error() == QUIC_DECRYPTION_FAILURE) {
       DVLOG(1) << ENDPOINT << "Unable to process undecryptable packet...";
@@ -2013,7 +1908,6 @@ void QuicConnection::MaybeProcessUndecryptablePackets() {
     }
     DVLOG(1) << ENDPOINT << "Processed undecryptable packet!";
     ++stats_.packets_processed;
-    delete packet;
     undecryptable_packets_.pop_front();
   }
 
@@ -2029,7 +1923,7 @@ void QuicConnection::MaybeProcessUndecryptablePackets() {
         debug_visitor_->OnUndecryptablePacket();
       }
     }
-    base::STLDeleteElements(&undecryptable_packets_);
+    undecryptable_packets_.clear();
   }
 }
 
@@ -2044,8 +1938,8 @@ void QuicConnection::CloseConnection(
   }
 
   DVLOG(1) << ENDPOINT << "Closing connection: " << connection_id()
-           << ", with error: " << QuicUtils::ErrorToString(error) << " ("
-           << error << "), and details:  " << error_details;
+           << ", with error: " << QuicErrorCodeToString(error) << " (" << error
+           << "), and details:  " << error_details;
 
   if (connection_close_behavior ==
       ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET) {
@@ -2056,8 +1950,13 @@ void QuicConnection::CloseConnection(
     SendConnectionClosePacket(error, error_details, NO_ACK);
   }
 
-  TearDownLocalConnectionState(error, error_details,
-                               ConnectionCloseSource::FROM_SELF);
+  ConnectionCloseSource source = ConnectionCloseSource::FROM_SELF;
+  if (perspective_ == Perspective::IS_CLIENT &&
+      error == QUIC_CRYPTO_HANDSHAKE_STATELESS_REJECT) {
+    // Regard stateless rejected connection as closed by server.
+    source = ConnectionCloseSource::FROM_PEER;
+  }
+  TearDownLocalConnectionState(error, error_details, source);
 }
 
 void QuicConnection::SendConnectionClosePacket(QuicErrorCode error,
@@ -2100,6 +1999,8 @@ void QuicConnection::TearDownLocalConnectionState(
 }
 
 void QuicConnection::CancelAllAlarms() {
+  DVLOG(1) << "Cancelling all QuicConnection alarms.";
+
   ack_alarm_->Cancel();
   ping_alarm_->Cancel();
   resume_writes_alarm_->Cancel();
@@ -2118,7 +2019,7 @@ void QuicConnection::SendGoAway(QuicErrorCode error,
   goaway_sent_ = true;
 
   DVLOG(1) << ENDPOINT << "Going away with error "
-           << QuicUtils::ErrorToString(error) << " (" << error << ")";
+           << QuicErrorCodeToString(error) << " (" << error << ")";
 
   // Opportunistically bundle an ack with this outgoing packet.
   ScopedPacketBundler ack_bundler(this, SEND_ACK_IF_PENDING);
@@ -2181,7 +2082,7 @@ void QuicConnection::SetNetworkTimeouts(QuicTime::Delta handshake_timeout,
 void QuicConnection::CheckForTimeout() {
   QuicTime now = clock_->ApproximateNow();
   QuicTime time_of_last_packet =
-      max(time_of_last_received_packet_, last_send_for_timeout_);
+      std::max(time_of_last_received_packet_, last_send_for_timeout_);
 
   // |delta| can be < 0 as |now| is approximate time but |time_of_last_packet|
   // is accurate time. However, this should not change the behavior of
@@ -2220,16 +2121,14 @@ void QuicConnection::CheckForTimeout() {
 
 void QuicConnection::SetTimeoutAlarm() {
   QuicTime time_of_last_packet =
-      max(time_of_last_received_packet_, time_of_last_sent_new_packet_);
-  if (FLAGS_quic_better_last_send_for_timeout) {
-    time_of_last_packet =
-        max(time_of_last_received_packet_, last_send_for_timeout_);
-  }
+      std::max(time_of_last_received_packet_, time_of_last_sent_new_packet_);
+  time_of_last_packet =
+      std::max(time_of_last_received_packet_, last_send_for_timeout_);
 
   QuicTime deadline = time_of_last_packet + idle_network_timeout_;
   if (!handshake_timeout_.IsInfinite()) {
-    deadline =
-        min(deadline, stats_.connection_creation_time + handshake_timeout_);
+    deadline = std::min(deadline,
+                        stats_.connection_creation_time + handshake_timeout_);
   }
 
   timeout_alarm_->Update(deadline, QuicTime::Delta::Zero());
@@ -2410,15 +2309,21 @@ void QuicConnection::SetMtuDiscoveryTarget(QuicByteCount target) {
 
 QuicByteCount QuicConnection::GetLimitedMaxPacketSize(
     QuicByteCount suggested_max_packet_size) {
-  if (peer_address_.address().empty()) {
+  if (!peer_address_.IsInitialized()) {
     QUIC_BUG << "Attempted to use a connection without a valid peer address";
     return suggested_max_packet_size;
   }
 
   const QuicByteCount writer_limit = writer_->GetMaxPacketSize(peer_address());
 
-  return std::min({suggested_max_packet_size, writer_limit, kMaxPacketSize,
-                   largest_packet_size_supported_});
+  QuicByteCount max_packet_size = suggested_max_packet_size;
+  if (max_packet_size > writer_limit) {
+    max_packet_size = writer_limit;
+  }
+  if (max_packet_size > kMaxPacketSize) {
+    max_packet_size = kMaxPacketSize;
+  }
+  return max_packet_size;
 }
 
 void QuicConnection::SendMtuDiscoveryPacket(QuicByteCount target_mtu) {
@@ -2548,7 +2453,7 @@ bool QuicConnection::MaybeConsiderAsMemoryCorruption(
 // of (likely, tail) latency, then consider such a mechanism.
 const QuicTime::Delta QuicConnection::DelayedAckTime() {
   return QuicTime::Delta::FromMilliseconds(
-      min(kMaxDelayedAckTimeMs, kMinRetransmissionTimeMs / 2));
+      std::min(kMaxDelayedAckTimeMs, kMinRetransmissionTimeMs / 2));
 }
 
 void QuicConnection::CheckIfApplicationLimited() {
diff --git a/src/net/quic/core/quic_connection.h b/src/net/quic/core/quic_connection.h
index 16ef139..25108ac 100644
--- a/src/net/quic/core/quic_connection.h
+++ b/src/net/quic/core/quic_connection.h
@@ -30,8 +30,7 @@
 #include "base/logging.h"
 #include "base/macros.h"
 #include "base/strings/string_piece.h"
-#include "net/base/ip_address.h"
-#include "net/base/ip_endpoint.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/quic_decrypter.h"
 #include "net/quic/core/quic_alarm.h"
 #include "net/quic/core/quic_alarm_factory.h"
@@ -43,12 +42,12 @@
 #include "net/quic/core/quic_packet_creator.h"
 #include "net/quic/core/quic_packet_generator.h"
 #include "net/quic/core/quic_packet_writer.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_received_packet_manager.h"
-#include "net/quic/core/quic_sent_entropy_manager.h"
 #include "net/quic/core/quic_sent_packet_manager_interface.h"
 #include "net/quic/core/quic_time.h"
 #include "net/quic/core/quic_types.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 
 namespace net {
 
@@ -179,8 +178,8 @@ class NET_EXPORT_PRIVATE QuicConnectionDebugVisitor
 
   // Called when a packet has been received, but before it is
   // validated or parsed.
-  virtual void OnPacketReceived(const IPEndPoint& self_address,
-                                const IPEndPoint& peer_address,
+  virtual void OnPacketReceived(const QuicSocketAddress& self_address,
+                                const QuicSocketAddress& peer_address,
                                 const QuicEncryptedPacket& packet) {}
 
   // Called when the unauthenticated portion of the header has been parsed.
@@ -309,7 +308,7 @@ class NET_EXPORT_PRIVATE QuicConnection
   // |writer| to write packets. |owns_writer| specifies whether the connection
   // takes ownership of |writer|. |helper| must outlive this connection.
   QuicConnection(QuicConnectionId connection_id,
-                 IPEndPoint address,
+                 QuicSocketAddress address,
                  QuicConnectionHelperInterface* helper,
                  QuicAlarmFactory* alarm_factory,
                  QuicPacketWriter* writer,
@@ -388,8 +387,8 @@ class NET_EXPORT_PRIVATE QuicConnection
   // the peer.
   // In a client, the packet may be "stray" and have a different connection ID
   // than that of this connection.
-  virtual void ProcessUdpPacket(const IPEndPoint& self_address,
-                                const IPEndPoint& peer_address,
+  virtual void ProcessUdpPacket(const QuicSocketAddress& self_address,
+                                const QuicSocketAddress& peer_address,
                                 const QuicReceivedPacket& packet);
 
   // QuicBlockedWriterInterface
@@ -419,7 +418,7 @@ class NET_EXPORT_PRIVATE QuicConnection
   }
 
   // Set self address.
-  void SetSelfAddress(IPEndPoint address) { self_address_ = address; }
+  void SetSelfAddress(QuicSocketAddress address) { self_address_ = address; }
 
   // The version of the protocol this connection is using.
   QuicVersion version() const { return framer_.version(); }
@@ -494,8 +493,8 @@ class NET_EXPORT_PRIVATE QuicConnection
   void set_creator_debug_delegate(QuicPacketCreator::DebugDelegate* visitor) {
     packet_generator_.set_debug_delegate(visitor);
   }
-  const IPEndPoint& self_address() const { return self_address_; }
-  const IPEndPoint& peer_address() const { return peer_address_; }
+  const QuicSocketAddress& self_address() const { return self_address_; }
+  const QuicSocketAddress& peer_address() const { return peer_address_; }
   QuicConnectionId connection_id() const { return connection_id_; }
   const QuicClock* clock() const { return clock_; }
   QuicRandom* random_generator() const { return random_generator_; }
@@ -686,16 +685,16 @@ class NET_EXPORT_PRIVATE QuicConnection
     return packet_generator_;
   }
 
+  const QuicReceivedPacketManager& received_packet_manager() const {
+    return received_packet_manager_;
+  }
+
   EncryptionLevel encryption_level() const { return encryption_level_; }
 
-  const IPEndPoint& last_packet_source_address() const {
+  const QuicSocketAddress& last_packet_source_address() const {
     return last_packet_source_address_;
   }
 
-  void set_largest_packet_size_supported(QuicByteCount size) {
-    largest_packet_size_supported_ = size;
-  }
-
  protected:
   // Calls cancel() on all the alarms owned by this connection.
   void CancelAllAlarms();
@@ -783,10 +782,6 @@ class NET_EXPORT_PRIVATE QuicConnection
   // Deletes and clears any queued packets.
   void ClearQueuedPackets();
 
-  // Closes the connection if the sent or received packet manager are tracking
-  // too many outstanding packets.
-  void MaybeCloseIfTooManyOutstandingPackets();
-
   // Writes as many queued packets as possible.  The connection must not be
   // blocked when this is called.
   void WriteQueuedPackets();
@@ -832,11 +827,6 @@ class NET_EXPORT_PRIVATE QuicConnection
   // Sets the MTU discovery alarm if necessary.
   void MaybeSetMtuAlarm();
 
-  // On arrival of a new packet, checks to see if the socket addresses have
-  // changed since the last packet we saw on this connection.
-  void CheckForAddressMigration(const IPEndPoint& self_address,
-                                const IPEndPoint& peer_address);
-
   HasRetransmittableData IsRetransmittable(const SerializedPacket& packet);
   bool IsTerminationPacket(const SerializedPacket& packet);
 
@@ -886,8 +876,8 @@ class NET_EXPORT_PRIVATE QuicConnection
   const QuicConnectionId connection_id_;
   // Address on the last successfully processed packet received from the
   // client.
-  IPEndPoint self_address_;
-  IPEndPoint peer_address_;
+  QuicSocketAddress self_address_;
+  QuicSocketAddress peer_address_;
 
   // Records change type when the peer initiates migration to a new peer
   // address. Reset to NO_CHANGE after peer migration is validated.
@@ -905,8 +895,12 @@ class NET_EXPORT_PRIVATE QuicConnection
                                      // parsed or nullptr.
   EncryptionLevel last_decrypted_packet_level_;
   QuicPacketHeader last_header_;
+  // TODO(ianswett): Remove last_stop_waiting_frame_ once
+  // FLAGS_quic_receive_packet_once_decrypted is deprecated.
   QuicStopWaitingFrame last_stop_waiting_frame_;
   bool should_last_packet_instigate_acks_;
+  // Whether the most recent packet was missing before it was received.
+  bool was_last_packet_missing_;
 
   // Track some peer state so we can do less bookkeeping
   // Largest sequence sent by the peer which had an ack frame (latest ack info).
@@ -919,7 +913,7 @@ class NET_EXPORT_PRIVATE QuicConnection
   // established, but which could not be decrypted.  We buffer these on
   // the assumption that they could not be processed because they were
   // sent with the INITIAL encryption and the CHLO message was lost.
-  std::deque<QuicEncryptedPacket*> undecryptable_packets_;
+  std::deque<std::unique_ptr<QuicEncryptedPacket>> undecryptable_packets_;
 
   // Maximum number of undecryptable packets the connection will store.
   size_t max_undecryptable_packets_;
@@ -953,7 +947,6 @@ class NET_EXPORT_PRIVATE QuicConnection
   bool close_connection_after_five_rtos_;
 
   QuicReceivedPacketManager received_packet_manager_;
-  QuicSentEntropyManager sent_entropy_manager_;
 
   // Indicates whether an ack should be sent the next time we try to write.
   bool ack_queued_;
@@ -1042,6 +1035,19 @@ class NET_EXPORT_PRIVATE QuicConnection
   std::unique_ptr<QuicSentPacketManagerInterface> sent_packet_manager_;
 
   // The state of connection in version negotiation finite state machine.
+  enum QuicVersionNegotiationState {
+    START_NEGOTIATION = 0,
+    // Server-side this implies we've sent a version negotiation packet and are
+    // waiting on the client to select a compatible version.  Client-side this
+    // implies we've gotten a version negotiation packet, are retransmitting the
+    // initial packets with a supported version and are waiting for our first
+    // packet from the server.
+    NEGOTIATION_IN_PROGRESS,
+    // This indicates this endpoint has received a packet from the peer with a
+    // version this endpoint supports.  Version negotiation is complete, and the
+    // version number will no longer be sent with future packets.
+    NEGOTIATED_VERSION
+  };
   QuicVersionNegotiationState version_negotiation_state_;
 
   // Tracks if the connection was created by the server or the client.
@@ -1052,10 +1058,10 @@ class NET_EXPORT_PRIVATE QuicConnection
   bool connected_;
 
   // Destination address of the last received packet.
-  IPEndPoint last_packet_destination_address_;
+  QuicSocketAddress last_packet_destination_address_;
 
   // Source address of the last received packet.
-  IPEndPoint last_packet_source_address_;
+  QuicSocketAddress last_packet_source_address_;
 
   // Set to false if the connection should not send truncated connection IDs to
   // the peer, even if the peer supports it.
@@ -1088,9 +1094,6 @@ class NET_EXPORT_PRIVATE QuicConnection
   // The size of the largest packet received from peer.
   QuicByteCount largest_received_packet_size_;
 
-  // The maximum allowed packet size.
-  QuicByteCount largest_packet_size_supported_;
-
   // Whether a GoAway has been sent.
   bool goaway_sent_;
 
diff --git a/src/net/quic/core/quic_connection_stats.cc b/src/net/quic/core/quic_connection_stats.cc
index 5b231c6..759c462 100644
--- a/src/net/quic/core/quic_connection_stats.cc
+++ b/src/net/quic/core/quic_connection_stats.cc
@@ -4,8 +4,6 @@
 
 #include "net/quic/core/quic_connection_stats.h"
 
-using std::ostream;
-
 namespace net {
 
 QuicConnectionStats::QuicConnectionStats()
@@ -39,11 +37,53 @@ QuicConnectionStats::QuicConnectionStats()
       max_sequence_reordering(0),
       max_time_reordering_us(0),
       tcp_loss_events(0),
-      connection_creation_time(QuicTime::Zero()) {}
+      connection_creation_time(QuicTime::Zero()),
+      blocked_frames_received(0),
+      blocked_frames_sent(0) {}
 
 QuicConnectionStats::QuicConnectionStats(const QuicConnectionStats& other) =
     default;
 
 QuicConnectionStats::~QuicConnectionStats() {}
 
+std::ostream& operator<<(std::ostream& os, const QuicConnectionStats& s) {
+  os << "{ bytes_sent: " << s.bytes_sent;
+  os << " packets_sent: " << s.packets_sent;
+  os << " stream_bytes_sent: " << s.stream_bytes_sent;
+  os << " packets_discarded: " << s.packets_discarded;
+  os << " bytes_received: " << s.bytes_received;
+  os << " packets_received: " << s.packets_received;
+  os << " packets_processed: " << s.packets_processed;
+  os << " stream_bytes_received: " << s.stream_bytes_received;
+  os << " bytes_retransmitted: " << s.bytes_retransmitted;
+  os << " packets_retransmitted: " << s.packets_retransmitted;
+  os << " bytes_spuriously_retransmitted: " << s.bytes_spuriously_retransmitted;
+  os << " packets_spuriously_retransmitted: "
+     << s.packets_spuriously_retransmitted;
+  os << " packets_lost: " << s.packets_lost;
+  os << " slowstart_packets_sent: " << s.slowstart_packets_sent;
+  os << " slowstart_packets_lost: " << s.slowstart_packets_lost;
+  os << " slowstart_bytes_lost: " << s.slowstart_bytes_lost;
+  os << " packets_dropped: " << s.packets_dropped;
+  os << " crypto_retransmit_count: " << s.crypto_retransmit_count;
+  os << " loss_timeout_count: " << s.loss_timeout_count;
+  os << " tlp_count: " << s.tlp_count;
+  os << " rto_count: " << s.rto_count;
+  os << " min_rtt_us: " << s.min_rtt_us;
+  os << " srtt_us: " << s.srtt_us;
+  os << " max_packet_size: " << s.max_packet_size;
+  os << " max_received_packet_size: " << s.max_received_packet_size;
+  os << " estimated_bandwidth: " << s.estimated_bandwidth;
+  os << " packets_reordered: " << s.packets_reordered;
+  os << " max_sequence_reordering: " << s.max_sequence_reordering;
+  os << " max_time_reordering_us: " << s.max_time_reordering_us;
+  os << " tcp_loss_events: " << s.tcp_loss_events;
+  os << " connection_creation_time: "
+     << s.connection_creation_time.ToDebuggingValue();
+  os << " blocked_frames_received: " << s.blocked_frames_received;
+  os << " blocked_frames_sent: " << s.blocked_frames_sent << " }";
+
+  return os;
+}
+
 }  // namespace net
diff --git a/src/net/quic/core/quic_connection_stats.h b/src/net/quic/core/quic_connection_stats.h
index 1d0aaa3..1d7b9e6 100644
--- a/src/net/quic/core/quic_connection_stats.h
+++ b/src/net/quic/core/quic_connection_stats.h
@@ -12,7 +12,7 @@
 
 #include "net/base/net_export.h"
 #include "net/quic/core/quic_bandwidth.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_time.h"
 
 namespace net {
@@ -86,6 +86,9 @@ struct NET_EXPORT_PRIVATE QuicConnectionStats {
 
   // Creation time, as reported by the QuicClock.
   QuicTime connection_creation_time;
+
+  uint64_t blocked_frames_received;
+  uint64_t blocked_frames_sent;
 };
 
 }  // namespace net
diff --git a/src/net/quic/core/quic_crypto_client_stream.cc b/src/net/quic/core/quic_crypto_client_stream.cc
index 89fa590..b375a0c 100644
--- a/src/net/quic/core/quic_crypto_client_stream.cc
+++ b/src/net/quic/core/quic_crypto_client_stream.cc
@@ -14,12 +14,11 @@
 #include "net/quic/core/crypto/crypto_utils.h"
 #include "net/quic/core/crypto/null_encrypter.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_session.h"
 #include "net/quic/core/quic_utils.h"
 
 using std::string;
-using std::vector;
 
 namespace net {
 
@@ -171,8 +170,8 @@ void QuicCryptoClientStream::HandleServerConfigUpdateMessage(
       crypto_config_->LookupOrCreate(server_id_);
   QuicErrorCode error = crypto_config_->ProcessServerConfigUpdate(
       server_config_update, session()->connection()->clock()->WallNow(),
-      session()->connection()->version(), cached->chlo_hash(), cached,
-      &crypto_negotiated_params_, &error_details);
+      session()->connection()->version(), chlo_hash_, cached,
+      crypto_negotiated_params_, &error_details);
 
   if (error != QUIC_NO_ERROR) {
     CloseConnectionWithDetails(
@@ -298,7 +297,7 @@ void QuicCryptoClientStream::DoSendCHLO(
     crypto_config_->FillInchoateClientHello(
         server_id_, session()->connection()->supported_versions().front(),
         cached, session()->connection()->random_generator(),
-        /* demand_x509_proof= */ true, &crypto_negotiated_params_, &out);
+        /* demand_x509_proof= */ true, crypto_negotiated_params_, &out);
     // Pad the inchoate client hello to fill up a packet.
     const QuicByteCount kFramingOverhead = 50;  // A rough estimate.
     const QuicByteCount max_packet_size =
@@ -328,20 +327,19 @@ void QuicCryptoClientStream::DoSendCHLO(
   // If the server nonce is empty, copy over the server nonce from a previous
   // SREJ, if there is one.
   if (FLAGS_enable_quic_stateless_reject_support &&
-      crypto_negotiated_params_.server_nonce.empty() &&
+      crypto_negotiated_params_->server_nonce.empty() &&
       cached->has_server_nonce()) {
-    crypto_negotiated_params_.server_nonce = cached->GetNextServerNonce();
-    DCHECK(!crypto_negotiated_params_.server_nonce.empty());
+    crypto_negotiated_params_->server_nonce = cached->GetNextServerNonce();
+    DCHECK(!crypto_negotiated_params_->server_nonce.empty());
   }
 
   string error_details;
   QuicErrorCode error = crypto_config_->FillClientHello(
       server_id_, session()->connection()->connection_id(),
-      session()->connection()->version(),
       session()->connection()->supported_versions().front(), cached,
       session()->connection()->clock()->WallNow(),
       session()->connection()->random_generator(), channel_id_key_.get(),
-      &crypto_negotiated_params_, &out, &error_details);
+      crypto_negotiated_params_, &out, &error_details);
   if (error != QUIC_NO_ERROR) {
     // Flush the cached config so that, if it's bad, the server has a
     // chance to send us another in the future.
@@ -360,13 +358,13 @@ void QuicCryptoClientStream::DoSendCHLO(
   // Be prepared to decrypt with the new server write key.
   session()->connection()->SetAlternativeDecrypter(
       ENCRYPTION_INITIAL,
-      crypto_negotiated_params_.initial_crypters.decrypter.release(),
+      crypto_negotiated_params_->initial_crypters.decrypter.release(),
       true /* latch once used */);
   // Send subsequent packets under encryption on the assumption that the
   // server will accept the handshake.
   session()->connection()->SetEncrypter(
       ENCRYPTION_INITIAL,
-      crypto_negotiated_params_.initial_crypters.encrypter.release());
+      crypto_negotiated_params_->initial_crypters.encrypter.release());
   session()->connection()->SetDefaultEncryptionLevel(ENCRYPTION_INITIAL);
 
   // TODO(ianswett): Merge ENCRYPTION_REESTABLISHED and
@@ -422,7 +420,7 @@ void QuicCryptoClientStream::DoReceiveREJ(
   QuicErrorCode error = crypto_config_->ProcessRejection(
       *in, session()->connection()->clock()->WallNow(),
       session()->connection()->version(), chlo_hash_, cached,
-      &crypto_negotiated_params_, &error_details);
+      crypto_negotiated_params_, &error_details);
 
   if (error != QUIC_NO_ERROR) {
     next_state_ = STATE_NONE;
@@ -600,7 +598,7 @@ void QuicCryptoClientStream::DoReceiveSHLO(
       *in, session()->connection()->connection_id(),
       session()->connection()->version(),
       session()->connection()->server_supported_versions(), cached,
-      &crypto_negotiated_params_, &error_details);
+      crypto_negotiated_params_, &error_details);
 
   if (error != QUIC_NO_ERROR) {
     CloseConnectionWithDetails(error, "Server hello invalid: " + error_details);
@@ -613,7 +611,7 @@ void QuicCryptoClientStream::DoReceiveSHLO(
   }
   session()->OnConfigNegotiated();
 
-  CrypterPair* crypters = &crypto_negotiated_params_.forward_secure_crypters;
+  CrypterPair* crypters = &crypto_negotiated_params_->forward_secure_crypters;
   // TODO(agl): we don't currently latch this decrypter because the idea
   // has been floated that the server shouldn't send packets encrypted
   // with the FORWARD_SECURE key until it receives a FORWARD_SECURE
diff --git a/src/net/quic/core/quic_crypto_client_stream.h b/src/net/quic/core/quic_crypto_client_stream.h
index d1cb463..2017027 100644
--- a/src/net/quic/core/quic_crypto_client_stream.h
+++ b/src/net/quic/core/quic_crypto_client_stream.h
@@ -10,6 +10,7 @@
 #include <string>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/channel_id.h"
 #include "net/quic/core/crypto/proof_verifier.h"
 #include "net/quic/core/crypto/quic_crypto_client_config.h"
@@ -98,6 +99,8 @@ class NET_EXPORT_PRIVATE QuicCryptoClientStream
   // ChannelIDSource operated asynchronously. Intended for testing.
   bool WasChannelIDSourceCallbackRun() const;
 
+  std::string chlo_hash() const { return chlo_hash_; }
+
  private:
   // ChannelIDSourceCallbackImpl is passed as the callback method to
   // GetChannelIDKey. The ChannelIDSource calls this class with the result of
diff --git a/src/net/quic/core/quic_crypto_server_stream.cc b/src/net/quic/core/quic_crypto_server_stream.cc
index 6f43418..576d693 100644
--- a/src/net/quic/core/quic_crypto_server_stream.cc
+++ b/src/net/quic/core/quic_crypto_server_stream.cc
@@ -15,14 +15,51 @@
 #include "net/quic/core/proto/cached_network_parameters.pb.h"
 #include "net/quic/core/quic_config.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
-#include "net/quic/core/quic_server_session_base.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_session.h"
 
 using base::StringPiece;
 using std::string;
 
 namespace net {
 
+class QuicCryptoServerStream::ProcessClientHelloCallback
+    : public ProcessClientHelloResultCallback {
+ public:
+  ProcessClientHelloCallback(
+      QuicCryptoServerStream* stream,
+      const scoped_refptr<ValidateClientHelloResultCallback::Result>& result)
+      : stream_(stream), result_(result) {}
+
+  void Run(QuicErrorCode error,
+           const string& error_details,
+           std::unique_ptr<CryptoHandshakeMessage> message,
+           std::unique_ptr<DiversificationNonce> diversification_nonce,
+           std::unique_ptr<net::ProofSource::Details> proof_source_details)
+      override {
+    if (stream_ == nullptr) {
+      return;
+    }
+
+    // Note: set the parent's callback to nullptr here because
+    // FinishProcessingHandshakeMessageAfterProcessClientHello can be invoked
+    // from either synchronous or asynchronous codepaths.  When the synchronous
+    // codepaths are removed, this assignment should move to
+    // FinishProcessingHandshakeMessageAfterProcessClientHello.
+    stream_->process_client_hello_cb_ = nullptr;
+
+    stream_->FinishProcessingHandshakeMessageAfterProcessClientHello(
+        *result_, error, error_details, std::move(message),
+        std::move(diversification_nonce), std::move(proof_source_details));
+  }
+
+  void Cancel() { stream_ = nullptr; }
+
+ private:
+  QuicCryptoServerStream* stream_;
+  scoped_refptr<ValidateClientHelloResultCallback::Result> result_;
+};
+
 QuicCryptoServerStreamBase::QuicCryptoServerStreamBase(QuicSession* session)
     : QuicCryptoStream(session) {}
 
@@ -55,6 +92,7 @@ QuicCryptoServerStream::QuicCryptoServerStream(
     : QuicCryptoServerStreamBase(session),
       crypto_config_(crypto_config),
       compressed_certs_cache_(compressed_certs_cache),
+      signed_config_(new QuicSignedServerConfig),
       validate_client_hello_cb_(nullptr),
       helper_(helper),
       num_handshake_messages_(0),
@@ -64,7 +102,8 @@ QuicCryptoServerStream::QuicCryptoServerStream(
       use_stateless_rejects_if_peer_supported_(
           use_stateless_rejects_if_peer_supported),
       peer_supports_stateless_rejects_(false),
-      chlo_packet_size_(0) {
+      chlo_packet_size_(0),
+      process_client_hello_cb_(nullptr) {
   DCHECK_EQ(Perspective::IS_SERVER, session->connection()->perspective());
 }
 
@@ -82,6 +121,10 @@ void QuicCryptoServerStream::CancelOutstandingCallbacks() {
     send_server_config_update_cb_->Cancel();
     send_server_config_update_cb_ = nullptr;
   }
+  if (process_client_hello_cb_ != nullptr) {
+    process_client_hello_cb_->Cancel();
+    process_client_hello_cb_ = nullptr;
+  }
 }
 
 void QuicCryptoServerStream::OnHandshakeMessage(
@@ -118,15 +161,15 @@ void QuicCryptoServerStream::OnHandshakeMessage(
   std::unique_ptr<ValidateCallback> cb(new ValidateCallback(this));
   validate_client_hello_cb_ = cb.get();
   crypto_config_->ValidateClientHello(
-      message, session()->connection()->peer_address().address(),
-      session()->connection()->self_address().address(), version(),
-      session()->connection()->clock(), &crypto_proof_, std::move(cb));
+      message, session()->connection()->peer_address().host(),
+      session()->connection()->self_address(), version(),
+      session()->connection()->clock(), signed_config_, std::move(cb));
 }
 
 void QuicCryptoServerStream::FinishProcessingHandshakeMessage(
-    const ValidateClientHelloResultCallback::Result& result,
+    scoped_refptr<ValidateClientHelloResultCallback::Result> result,
     std::unique_ptr<ProofSource::Details> details) {
-  const CryptoHandshakeMessage& message = result.client_hello;
+  const CryptoHandshakeMessage& message = result->client_hello;
 
   // Clear the callback that got us here.
   DCHECK(validate_client_hello_cb_ != nullptr);
@@ -136,20 +179,28 @@ void QuicCryptoServerStream::FinishProcessingHandshakeMessage(
     peer_supports_stateless_rejects_ = DoesPeerSupportStatelessRejects(message);
   }
 
-  CryptoHandshakeMessage reply;
-  DiversificationNonce diversification_nonce;
-  string error_details;
-  QuicErrorCode error =
-      ProcessClientHello(result, std::move(details), &reply,
-                         &diversification_nonce, &error_details);
+  std::unique_ptr<ProcessClientHelloCallback> cb(
+      new ProcessClientHelloCallback(this, result));
+  process_client_hello_cb_ = cb.get();
+  ProcessClientHello(result, std::move(details), std::move(cb));
+}
 
+void QuicCryptoServerStream::
+    FinishProcessingHandshakeMessageAfterProcessClientHello(
+        const ValidateClientHelloResultCallback::Result& result,
+        QuicErrorCode error,
+        const string& error_details,
+        std::unique_ptr<CryptoHandshakeMessage> reply,
+        std::unique_ptr<DiversificationNonce> diversification_nonce,
+        std::unique_ptr<ProofSource::Details> proof_source_details) {
+  const CryptoHandshakeMessage& message = result.client_hello;
   if (error != QUIC_NO_ERROR) {
     CloseConnectionWithDetails(error, error_details);
     return;
   }
 
-  if (reply.tag() != kSHLO) {
-    if (reply.tag() == kSREJ) {
+  if (reply->tag() != kSHLO) {
+    if (reply->tag() == kSREJ) {
       DCHECK(use_stateless_rejects_if_peer_supported_);
       DCHECK(peer_supports_stateless_rejects_);
       // Before sending the SREJ, cause the connection to save crypto packets
@@ -157,9 +208,9 @@ void QuicCryptoServerStream::FinishProcessingHandshakeMessage(
       // retransmitted.
       session()->connection()->EnableSavingCryptoPackets();
     }
-    SendHandshakeMessage(reply);
+    SendHandshakeMessage(*reply);
 
-    if (reply.tag() == kSREJ) {
+    if (reply->tag() == kSREJ) {
       DCHECK(use_stateless_rejects_if_peer_supported_);
       DCHECK(peer_supports_stateless_rejects_);
       DCHECK(!handshake_confirmed());
@@ -178,15 +229,17 @@ void QuicCryptoServerStream::FinishProcessingHandshakeMessage(
   // session config.
   QuicConfig* config = session()->config();
   OverrideQuicConfigDefaults(config);
-  error = config->ProcessPeerHello(message, CLIENT, &error_details);
-  if (error != QUIC_NO_ERROR) {
-    CloseConnectionWithDetails(error, error_details);
+  string process_error_details;
+  const QuicErrorCode process_error =
+      config->ProcessPeerHello(message, CLIENT, &process_error_details);
+  if (process_error != QUIC_NO_ERROR) {
+    CloseConnectionWithDetails(process_error, process_error_details);
     return;
   }
 
   session()->OnConfigNegotiated();
 
-  config->ToHandshakeMessage(&reply);
+  config->ToHandshakeMessage(reply.get());
 
   // Receiving a full CHLO implies the client is prepared to decrypt with
   // the new server write key.  We can start to encrypt with the new server
@@ -195,27 +248,25 @@ void QuicCryptoServerStream::FinishProcessingHandshakeMessage(
   // NOTE: the SHLO will be encrypted with the new server write key.
   session()->connection()->SetEncrypter(
       ENCRYPTION_INITIAL,
-      crypto_negotiated_params_.initial_crypters.encrypter.release());
+      crypto_negotiated_params_->initial_crypters.encrypter.release());
   session()->connection()->SetDefaultEncryptionLevel(ENCRYPTION_INITIAL);
   // Set the decrypter immediately so that we no longer accept unencrypted
   // packets.
   session()->connection()->SetDecrypter(
       ENCRYPTION_INITIAL,
-      crypto_negotiated_params_.initial_crypters.decrypter.release());
-  if (version() > QUIC_VERSION_32) {
-    session()->connection()->SetDiversificationNonce(diversification_nonce);
-  }
+      crypto_negotiated_params_->initial_crypters.decrypter.release());
+  session()->connection()->SetDiversificationNonce(*diversification_nonce);
 
-  SendHandshakeMessage(reply);
+  SendHandshakeMessage(*reply);
 
   session()->connection()->SetEncrypter(
       ENCRYPTION_FORWARD_SECURE,
-      crypto_negotiated_params_.forward_secure_crypters.encrypter.release());
+      crypto_negotiated_params_->forward_secure_crypters.encrypter.release());
   session()->connection()->SetDefaultEncryptionLevel(ENCRYPTION_FORWARD_SECURE);
 
   session()->connection()->SetAlternativeDecrypter(
       ENCRYPTION_FORWARD_SECURE,
-      crypto_negotiated_params_.forward_secure_crypters.decrypter.release(),
+      crypto_negotiated_params_->forward_secure_crypters.decrypter.release(),
       false /* don't latch */);
 
   encryption_established_ = true;
@@ -239,14 +290,19 @@ void QuicCryptoServerStream::SendServerConfigUpdate(
     std::unique_ptr<SendServerConfigUpdateCallback> cb(
         new SendServerConfigUpdateCallback(this));
     send_server_config_update_cb_ = cb.get();
+
     crypto_config_->BuildServerConfigUpdateMessage(
         session()->connection()->version(), chlo_hash_,
         previous_source_address_tokens_,
-        session()->connection()->self_address().address(),
-        session()->connection()->peer_address().address(),
+        session()->connection()->self_address(),
+        session()->connection()->peer_address().host(),
         session()->connection()->clock(),
         session()->connection()->random_generator(), compressed_certs_cache_,
-        crypto_negotiated_params_, cached_network_params, std::move(cb));
+        *crypto_negotiated_params_, cached_network_params,
+        (session()->config()->HasReceivedConnectionOptions()
+             ? session()->config()->ReceivedConnectionOptions()
+             : QuicTagVector()),
+        std::move(cb));
     return;
   }
 
@@ -254,11 +310,14 @@ void QuicCryptoServerStream::SendServerConfigUpdate(
   if (!crypto_config_->BuildServerConfigUpdateMessage(
           session()->connection()->version(), chlo_hash_,
           previous_source_address_tokens_,
-          session()->connection()->self_address().address(),
-          session()->connection()->peer_address().address(),
+          session()->connection()->self_address(),
+          session()->connection()->peer_address().host(),
           session()->connection()->clock(),
           session()->connection()->random_generator(), compressed_certs_cache_,
-          crypto_negotiated_params_, cached_network_params,
+          *crypto_negotiated_params_, cached_network_params,
+          (session()->config()->HasReceivedConnectionOptions()
+               ? session()->config()->ReceivedConnectionOptions()
+               : QuicTagVector()),
           &server_config_update_message)) {
     DVLOG(1) << "Server: Failed to build server config update (SCUP)!";
     return;
@@ -309,10 +368,6 @@ void QuicCryptoServerStream::FinishSendServerConfigUpdate(
   ++num_server_config_update_messages_sent_;
 }
 
-void QuicCryptoServerStream::OnServerHelloAcked() {
-  session()->connection()->OnHandshakeComplete();
-}
-
 uint8_t QuicCryptoServerStream::NumHandshakeMessages() const {
   return num_handshake_messages_;
 }
@@ -352,11 +407,11 @@ void QuicCryptoServerStream::SetPreviousCachedNetworkParams(
 bool QuicCryptoServerStream::GetBase64SHA256ClientChannelID(
     string* output) const {
   if (!encryption_established_ ||
-      crypto_negotiated_params_.channel_id.empty()) {
+      crypto_negotiated_params_->channel_id.empty()) {
     return false;
   }
 
-  const string& channel_id(crypto_negotiated_params_.channel_id);
+  const string& channel_id(crypto_negotiated_params_->channel_id);
   std::unique_ptr<crypto::SecureHash> hash(
       crypto::SecureHash::Create(crypto::SecureHash::SHA256));
   hash->Update(channel_id.data(), channel_id.size());
@@ -379,27 +434,28 @@ bool QuicCryptoServerStream::GetBase64SHA256ClientChannelID(
   return true;
 }
 
-QuicErrorCode QuicCryptoServerStream::ProcessClientHello(
-    const ValidateClientHelloResultCallback::Result& result,
+void QuicCryptoServerStream::ProcessClientHello(
+    scoped_refptr<ValidateClientHelloResultCallback::Result> result,
     std::unique_ptr<ProofSource::Details> proof_source_details,
-    CryptoHandshakeMessage* reply,
-    DiversificationNonce* out_diversification_nonce,
-    string* error_details) {
-  const CryptoHandshakeMessage& message = result.client_hello;
+    std::unique_ptr<ProcessClientHelloResultCallback> done_cb) {
+  const CryptoHandshakeMessage& message = result->client_hello;
+  string error_details;
   if (!helper_->CanAcceptClientHello(
-          message, session()->connection()->self_address(), error_details)) {
-    return QUIC_HANDSHAKE_FAILED;
+          message, session()->connection()->self_address(), &error_details)) {
+    done_cb->Run(QUIC_HANDSHAKE_FAILED, error_details, nullptr, nullptr,
+                 nullptr);
+    return;
   }
 
-  if (!result.info.server_nonce.empty()) {
+  if (!result->info.server_nonce.empty()) {
     ++num_handshake_messages_with_server_nonces_;
   }
   // Store the bandwidth estimate from the client.
-  if (result.cached_network_params.bandwidth_estimate_bytes_per_second() > 0) {
+  if (result->cached_network_params.bandwidth_estimate_bytes_per_second() > 0) {
     previous_cached_network_params_.reset(
-        new CachedNetworkParameters(result.cached_network_params));
+        new CachedNetworkParameters(result->cached_network_params));
   }
-  previous_source_address_tokens_ = result.info.source_address_tokens;
+  previous_source_address_tokens_ = result->info.source_address_tokens;
 
   const bool use_stateless_rejects_in_crypto_config =
       use_stateless_rejects_if_peer_supported_ &&
@@ -407,15 +463,15 @@ QuicErrorCode QuicCryptoServerStream::ProcessClientHello(
   QuicConnection* connection = session()->connection();
   const QuicConnectionId server_designated_connection_id =
       GenerateConnectionIdForReject(use_stateless_rejects_in_crypto_config);
-  return crypto_config_->ProcessClientHello(
+  crypto_config_->ProcessClientHello(
       result, /*reject_only=*/false, connection->connection_id(),
-      connection->self_address().address(), connection->peer_address(),
-      version(), connection->supported_versions(),
-      use_stateless_rejects_in_crypto_config, server_designated_connection_id,
-      connection->clock(), connection->random_generator(),
-      compressed_certs_cache_, &crypto_negotiated_params_, &crypto_proof_,
+      connection->self_address(), connection->peer_address(), version(),
+      connection->supported_versions(), use_stateless_rejects_in_crypto_config,
+      server_designated_connection_id, connection->clock(),
+      connection->random_generator(), compressed_certs_cache_,
+      crypto_negotiated_params_, signed_config_,
       QuicCryptoStream::CryptoMessageFramingOverhead(version()),
-      chlo_packet_size_, reply, out_diversification_nonce, error_details);
+      chlo_packet_size_, std::move(done_cb));
 }
 
 void QuicCryptoServerStream::OverrideQuicConfigDefaults(QuicConfig* config) {}
@@ -429,10 +485,11 @@ void QuicCryptoServerStream::ValidateCallback::Cancel() {
 }
 
 void QuicCryptoServerStream::ValidateCallback::Run(
-    std::unique_ptr<Result> result,
+    scoped_refptr<Result> result,
     std::unique_ptr<ProofSource::Details> details) {
   if (parent_ != nullptr) {
-    parent_->FinishProcessingHandshakeMessage(*result, std::move(details));
+    parent_->FinishProcessingHandshakeMessage(std::move(result),
+                                              std::move(details));
   }
 }
 
diff --git a/src/net/quic/core/quic_crypto_server_stream.h b/src/net/quic/core/quic_crypto_server_stream.h
index 6b9da72..71e779b 100644
--- a/src/net/quic/core/quic_crypto_server_stream.h
+++ b/src/net/quic/core/quic_crypto_server_stream.h
@@ -10,6 +10,7 @@
 #include <string>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/crypto_handshake.h"
 #include "net/quic/core/crypto/quic_compressed_certs_cache.h"
 #include "net/quic/core/crypto/quic_crypto_server_config.h"
@@ -23,7 +24,6 @@ class CachedNetworkParameters;
 class CryptoHandshakeMessage;
 class QuicCryptoServerConfig;
 class QuicCryptoServerStreamBase;
-class QuicServerSessionBase;
 
 namespace test {
 class CryptoTestUtils;
@@ -53,10 +53,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStreamBase : public QuicCryptoStream {
   virtual void SendServerConfigUpdate(
       const CachedNetworkParameters* cached_network_params) = 0;
 
-  // Called by the ServerHello AckNotifier once the SHLO has been ACKed by the
-  // client.
-  virtual void OnServerHelloAcked() = 0;
-
   // These are all accessors and setters to their respective counters.
   virtual uint8_t NumHandshakeMessages() const = 0;
   virtual uint8_t NumHandshakeMessagesWithServerNonces() const = 0;
@@ -90,7 +86,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStream
     // acceptable according to the visitor's policy. Otherwise, returns false
     // and populates |error_details|.
     virtual bool CanAcceptClientHello(const CryptoHandshakeMessage& message,
-                                      const IPEndPoint& self_address,
+                                      const QuicSocketAddress& self_address,
                                       std::string* error_details) const = 0;
   };
 
@@ -111,7 +107,6 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStream
   bool GetBase64SHA256ClientChannelID(std::string* output) const override;
   void SendServerConfigUpdate(
       const CachedNetworkParameters* cached_network_params) override;
-  void OnServerHelloAcked() override;
   uint8_t NumHandshakeMessages() const override;
   uint8_t NumHandshakeMessagesWithServerNonces() const override;
   int NumServerConfigUpdateMessagesSent() const override;
@@ -123,13 +118,20 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStream
   void SetPreviousCachedNetworkParams(
       CachedNetworkParameters cached_network_params) override;
 
+  // NOTE: Indicating that the Expect-CT header should be sent here presents
+  // a layering violation to some extent. The Expect-CT header only applies to
+  // HTTP connections, while this class can be used for non-HTTP applications.
+  // However, it is exposed here because that is the only place where the
+  // configuration for the certificate used in the connection is accessible.
+  bool ShouldSendExpectCTHeader() const {
+    return signed_config_->proof.send_expect_ct_header;
+  }
+
  protected:
-  virtual QuicErrorCode ProcessClientHello(
-      const ValidateClientHelloResultCallback::Result& result,
+  virtual void ProcessClientHello(
+      scoped_refptr<ValidateClientHelloResultCallback::Result> result,
       std::unique_ptr<ProofSource::Details> proof_source_details,
-      CryptoHandshakeMessage* reply,
-      DiversificationNonce* out_diversification_nonce,
-      std::string* error_details);
+      std::unique_ptr<ProcessClientHelloResultCallback> done_cb);
 
   // Hook that allows the server to set QuicConfig defaults just
   // before going through the parameter negotiation step.
@@ -146,7 +148,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStream
     void Cancel();
 
     // From ValidateClientHelloResultCallback
-    void Run(std::unique_ptr<Result> result,
+    void Run(scoped_refptr<Result> result,
              std::unique_ptr<ProofSource::Details> details) override;
 
    private:
@@ -177,9 +179,22 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStream
   // the client hello is complete.  Finishes processing of the client
   // hello message and handles handshake success/failure.
   void FinishProcessingHandshakeMessage(
-      const ValidateClientHelloResultCallback::Result& result,
+      scoped_refptr<ValidateClientHelloResultCallback::Result> result,
       std::unique_ptr<ProofSource::Details> details);
 
+  class ProcessClientHelloCallback;
+  friend class ProcessClientHelloCallback;
+
+  // Portion of FinishProcessingHandshakeMessage which executes after
+  // ProcessClientHello has been called.
+  void FinishProcessingHandshakeMessageAfterProcessClientHello(
+      const ValidateClientHelloResultCallback::Result& result,
+      QuicErrorCode error,
+      const std::string& error_details,
+      std::unique_ptr<CryptoHandshakeMessage> reply,
+      std::unique_ptr<DiversificationNonce> diversification_nonce,
+      std::unique_ptr<ProofSource::Details> proof_source_details);
+
   // Invoked by SendServerConfigUpdateCallback::RunImpl once the proof has been
   // received.  |ok| indicates whether or not the proof was successfully
   // acquired, and |message| holds the partially-constructed message from
@@ -200,7 +215,7 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStream
 
   // Server's certificate chain and signature of the server config, as provided
   // by ProofSource::GetProof.
-  QuicCryptoProof crypto_proof_;
+  scoped_refptr<QuicSignedServerConfig> signed_config_;
 
   // Hash of the last received CHLO message which can be used for generating
   // server config update messages.
@@ -254,6 +269,11 @@ class NET_EXPORT_PRIVATE QuicCryptoServerStream
   // Size of the packet containing the most recently received CHLO.
   QuicByteCount chlo_packet_size_;
 
+  // Pointer to the active callback which will receive the results of
+  // ProcessClientHello and forward it to
+  // FinishProcessingHandshakeMessageAfterProcessClientHello.
+  ProcessClientHelloCallback* process_client_hello_cb_;
+
   DISALLOW_COPY_AND_ASSIGN(QuicCryptoServerStream);
 };
 
diff --git a/src/net/quic/core/quic_crypto_stream.cc b/src/net/quic/core/quic_crypto_stream.cc
index ed8e20c..9c4488f 100644
--- a/src/net/quic/core/quic_crypto_stream.cc
+++ b/src/net/quic/core/quic_crypto_stream.cc
@@ -25,14 +25,17 @@ namespace net {
                                                                      " ")
 
 QuicCryptoStream::QuicCryptoStream(QuicSession* session)
-    : ReliableQuicStream(kCryptoStreamId, session),
+    : QuicStream(kCryptoStreamId, session),
       encryption_established_(false),
-      handshake_confirmed_(false) {
+      handshake_confirmed_(false),
+      crypto_negotiated_params_(new QuicCryptoNegotiatedParameters) {
   crypto_framer_.set_visitor(this);
   // The crypto stream is exempt from connection level flow control.
   DisableConnectionFlowControlForThisStream();
 }
 
+QuicCryptoStream::~QuicCryptoStream() {}
+
 // static
 QuicByteCount QuicCryptoStream::CryptoMessageFramingOverhead(
     QuicVersion version) {
@@ -46,7 +49,7 @@ QuicByteCount QuicCryptoStream::CryptoMessageFramingOverhead(
 
 void QuicCryptoStream::OnError(CryptoFramer* framer) {
   DLOG(WARNING) << "Error processing crypto data: "
-                << QuicUtils::ErrorToString(framer->error());
+                << QuicErrorCodeToString(framer->error());
 }
 
 void QuicCryptoStream::OnHandshakeMessage(
@@ -69,6 +72,13 @@ void QuicCryptoStream::OnDataAvailable() {
       return;
     }
     sequencer()->MarkConsumed(iov.iov_len);
+    if (handshake_confirmed_ && crypto_framer_.InputBytesRemaining() == 0 &&
+        FLAGS_quic_release_crypto_stream_buffer) {
+      // If the handshake is complete and the current message has been fully
+      // processed then no more handshake messages are likely to arrive soon
+      // so release the memory in the stream sequencer.
+      sequencer()->ReleaseBufferIfEmpty();
+    }
   }
 }
 
@@ -91,7 +101,7 @@ bool QuicCryptoStream::ExportKeyingMaterial(StringPiece label,
     return false;
   }
   return CryptoUtils::ExportKeyingMaterial(
-      crypto_negotiated_params_.subkey_secret, label, context, result_len,
+      crypto_negotiated_params_->subkey_secret, label, context, result_len,
       result);
 }
 
@@ -102,13 +112,14 @@ bool QuicCryptoStream::ExportTokenBindingKeyingMaterial(string* result) const {
     return false;
   }
   return CryptoUtils::ExportKeyingMaterial(
-      crypto_negotiated_params_.initial_subkey_secret, "EXPORTER-Token-Binding",
+      crypto_negotiated_params_->initial_subkey_secret,
+      "EXPORTER-Token-Binding",
       /* context= */ "", 32, result);
 }
 
 const QuicCryptoNegotiatedParameters&
 QuicCryptoStream::crypto_negotiated_params() const {
-  return crypto_negotiated_params_;
+  return *crypto_negotiated_params_;
 }
 
 }  // namespace net
diff --git a/src/net/quic/core/quic_crypto_stream.h b/src/net/quic/core/quic_crypto_stream.h
index 225324f..90f5fce 100644
--- a/src/net/quic/core/quic_crypto_stream.h
+++ b/src/net/quic/core/quic_crypto_stream.h
@@ -8,33 +8,36 @@
 #include <stddef.h>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/crypto_framer.h"
 #include "net/quic/core/crypto/crypto_utils.h"
 #include "net/quic/core/quic_config.h"
-#include "net/quic/core/quic_protocol.h"
-#include "net/quic/core/reliable_quic_stream.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_stream.h"
 
 namespace net {
 
 class CryptoHandshakeMessage;
 class QuicSession;
 
-// Crypto handshake messages in QUIC take place over a reserved
-// reliable stream with the id 1.  Each endpoint (client and server)
-// will allocate an instance of a subclass of QuicCryptoStream
-// to send and receive handshake messages.  (In the normal 1-RTT
-// handshake, the client will send a client hello, CHLO, message.
-// The server will receive this message and respond with a server
-// hello message, SHLO.  At this point both sides will have established
-// a crypto context they can use to send encrypted messages.
+// Crypto handshake messages in QUIC take place over a reserved stream with the
+// id 1.  Each endpoint (client and server) will allocate an instance of a
+// subclass of QuicCryptoStream to send and receive handshake messages.  (In the
+// normal 1-RTT handshake, the client will send a client hello, CHLO, message.
+// The server will receive this message and respond with a server hello message,
+// SHLO.  At this point both sides will have established a crypto context they
+// can use to send encrypted messages.
 //
-// For more details: http://goto.google.com/quic-crypto
+// For more details:
+// https://docs.google.com/document/d/1g5nIXAIkN_Y-7XJW5K45IblHd_L2f5LTaDUDwvZ5L6g/edit?usp=sharing
 class NET_EXPORT_PRIVATE QuicCryptoStream
-    : public ReliableQuicStream,
+    : public QuicStream,
       public CryptoFramerVisitorInterface {
  public:
   explicit QuicCryptoStream(QuicSession* session);
 
+  ~QuicCryptoStream() override;
+
   // Returns the per-packet framing overhead associated with sending a
   // handshake message for |version|.
   static QuicByteCount CryptoMessageFramingOverhead(QuicVersion version);
@@ -43,7 +46,7 @@ class NET_EXPORT_PRIVATE QuicCryptoStream
   void OnError(CryptoFramer* framer) override;
   void OnHandshakeMessage(const CryptoHandshakeMessage& message) override;
 
-  // ReliableQuicStream implementation
+  // QuicStream implementation
   void OnDataAvailable() override;
 
   // Sends |message| to the peer.
@@ -78,7 +81,7 @@ class NET_EXPORT_PRIVATE QuicCryptoStream
   bool encryption_established_;
   bool handshake_confirmed_;
 
-  QuicCryptoNegotiatedParameters crypto_negotiated_params_;
+  scoped_refptr<QuicCryptoNegotiatedParameters> crypto_negotiated_params_;
 
  private:
   CryptoFramer crypto_framer_;
diff --git a/src/net/quic/core/quic_data_reader.cc b/src/net/quic/core/quic_data_reader.cc
index 72185cd..642a3c8 100644
--- a/src/net/quic/core/quic_data_reader.cc
+++ b/src/net/quic/core/quic_data_reader.cc
@@ -5,7 +5,7 @@
 #include "net/quic/core/quic_data_reader.h"
 
 #include "net/base/int128.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 using base::StringPiece;
 
diff --git a/src/net/quic/core/quic_data_writer.cc b/src/net/quic/core/quic_data_writer.cc
index f561458..6983553 100644
--- a/src/net/quic/core/quic_data_writer.cc
+++ b/src/net/quic/core/quic_data_writer.cc
@@ -9,7 +9,6 @@
 #include <limits>
 
 using base::StringPiece;
-using std::numeric_limits;
 
 namespace net {
 
@@ -52,7 +51,7 @@ bool QuicDataWriter::WriteUFloat16(uint64_t value) {
     result = static_cast<uint16_t>(value);
   } else if (value >= kUFloat16MaxValue) {
     // Value is out of range; clamp it to the maximum representable.
-    result = numeric_limits<uint16_t>::max();
+    result = std::numeric_limits<uint16_t>::max();
   } else {
     // The highest bit is between position 13 and 42 (zero-based), which
     // corresponds to exponent 1-30. In the output, mantissa is from 0 to 10,
@@ -84,7 +83,7 @@ bool QuicDataWriter::WriteUFloat16(uint64_t value) {
 }
 
 bool QuicDataWriter::WriteStringPiece16(StringPiece val) {
-  if (val.size() > numeric_limits<uint16_t>::max()) {
+  if (val.size() > std::numeric_limits<uint16_t>::max()) {
     return false;
   }
   if (!WriteUInt16(static_cast<uint16_t>(val.size()))) {
diff --git a/src/net/quic/core/quic_data_writer.h b/src/net/quic/core/quic_data_writer.h
index 8dcc74a..f796420 100644
--- a/src/net/quic/core/quic_data_writer.h
+++ b/src/net/quic/core/quic_data_writer.h
@@ -16,7 +16,7 @@
 #include "base/strings/string_piece.h"
 #include "net/base/int128.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/quic_flags_list.h b/src/net/quic/core/quic_flags_list.h
index bfad1e9..c1202a9 100644
--- a/src/net/quic/core/quic_flags_list.h
+++ b/src/net/quic/core/quic_flags_list.h
@@ -9,7 +9,7 @@
 
 // If true, QUIC BBR congestion control may be enabled via Finch and/or via QUIC
 // connection options.
-QUIC_FLAG(bool, FLAGS_quic_allow_bbr, false)
+QUIC_FLAG(bool, FLAGS_quic_allow_new_bbr, true)
 
 // Time period for which a given connection_id should live in the time-wait
 // state.
@@ -43,96 +43,111 @@ QUIC_FLAG(bool, FLAGS_quic_require_handshake_confirmation, false)
 // If true, disable pacing in QUIC.
 QUIC_FLAG(bool, FLAGS_quic_disable_pacing_for_perf_tests, false)
 
-// If true, QUIC connections can do bandwidth resumption with an initial window
-// of < 10 packets.
-QUIC_FLAG(bool, FLAGS_quic_no_lower_bw_resumption_limit, true)
-
 // If true, QUIC public reset packets will have the \"pre-v33\" public header
 // flags.
 QUIC_FLAG(bool, FLAGS_quic_use_old_public_reset_packets, true)
 
 // If true, QUIC will use cheap stateless rejects without creating a full
 // connection.
-QUIC_FLAG(bool, FLAGS_quic_use_cheap_stateless_rejects, false)
+QUIC_FLAG(bool, FLAGS_quic_use_cheap_stateless_rejects, true)
 
 // If true, QUIC respect HTTP2 SETTINGS frame rather than always close the
 // connection.
 QUIC_FLAG(bool, FLAGS_quic_respect_http2_settings_frame, true)
 
-// If true, enables QUIC_VERSION_35.
-QUIC_FLAG(bool, FLAGS_quic_enable_version_35, true)
-
 // If true, re-enables QUIC_VERSION_36.
-QUIC_FLAG(bool, FLAGS_quic_enable_version_36_v2, true)
+QUIC_FLAG(bool, FLAGS_quic_enable_version_36_v3, false)
 
 // If true, use async codepaths to invoke ProofSource::GetProof.
 QUIC_FLAG(bool, FLAGS_enable_async_get_proof, false)
 
-// If true, requires handshake confirmations for all QUIC handshakes with
-// versions less than 33.
-QUIC_FLAG(bool, FLAGS_quic_require_handshake_confirmation_pre33, false)
+// If true, only open limited number of quic sessions per epoll event. Leave the
+// rest to next event.
+QUIC_FLAG(bool, FLAGS_quic_limit_num_new_sessions_per_epoll_loop, true)
 
-// If true, close QUIC connection explicitly on write error due to packet being
-// too large.
-QUIC_FLAG(bool, FLAGS_quic_close_connection_on_packet_too_large, true)
+// Only close the connection on the 5th RTO client side when the 5RTO option
+// is enabled.
+QUIC_FLAG(bool, FLAGS_quic_only_5rto_client_side, false)
 
-// If true, v33 QUIC client uses 1 bit to specify 8-byte connection id in public
-// flag.
-QUIC_FLAG(bool, FLAGS_quic_remove_v33_hacks, true)
+// If true, QUIC server push will enabled by default.
+QUIC_FLAG(bool, FLAGS_quic_enable_server_push_by_default, true)
 
-// If true, use the CHLO packet size, not message size when determining how
-// large a REJ can be.
-QUIC_FLAG(bool, FLAGS_quic_use_chlo_packet_size, true)
+// If true, export reject reasons for all rejects, i.e., rejects,
+// stateless rejects and cheap stateless rejects.
+QUIC_FLAG(bool, FLAGS_quic_export_rej_for_all_rejects, true)
 
-// If true, defer creation of new connection till its CHLO arrives.
-QUIC_FLAG(bool, FLAGS_quic_buffer_packet_till_chlo, true)
+// Allow large send deltas to be used as RTT samples.
+QUIC_FLAG(bool, FLAGS_quic_allow_large_send_deltas, true)
 
-// Deprecate QuicPacketCreator::next_packet_number_length_ because it's no
-// longer necessary.
-QUIC_FLAG(bool, FLAGS_quic_simple_packet_number_length_2, true)
+// Engage early retransmit anytime the largest acked is greater than
+// or equal to the largest retransmittable packet.
+QUIC_FLAG(bool, FLAGS_quic_largest_sent_retransmittable, true)
 
-// If true, disables QUIC version less than 32.
-QUIC_FLAG(bool, FLAGS_quic_disable_pre_32, true)
+// If true, release QuicCryptoStream\'s read buffer when stream are less
+// frequently used.
+QUIC_FLAG(bool, FLAGS_quic_release_crypto_stream_buffer, false)
 
-// If true, QUIC will enforce the MTU limit for connections that may require a
-// small MTU.
-QUIC_FLAG(bool, FLAGS_quic_enforce_mtu_limit, false)
+// Use a more conservative backoff of 2x instead of 1.5x for handshake
+// retransmissions, as well as a larger minimum.
+QUIC_FLAG(bool, FLAGS_quic_conservative_handshake_retransmits, true)
 
-// Disable MTU probing if MTU probe causes ERR_MSG_TOO_BIG instead of aborting
-// the connection.
-QUIC_FLAG(bool, FLAGS_graceful_emsgsize_on_mtu_probe, true)
+// If true, buffer packets while parsing public headers instead of parsing down
+// if CHLO is already buffered.
+QUIC_FLAG(bool, FLAGS_quic_buffer_packets_after_chlo, false)
 
-// If true, do not force sending ack when connection is closed because of
-// message too long (EMSGSIZE) write error.
-QUIC_FLAG(bool, FLAGS_quic_do_not_send_ack_on_emsgsize, true)
+// Previously QUIC didn't register a packet as received until it was fully
+// processed, but now that flow control is implemented, it can be received once
+// decrypted.
+QUIC_FLAG(bool, FLAGS_quic_receive_packet_once_decrypted, false)
 
-// If true, postpone multipath flag validation to ProcessValidatedPacket.
-QUIC_FLAG(bool, FLAGS_quic_postpone_multipath_flag_validation, true)
+// If true, enable the Lazy FACK style loss detection in QUIC.
+QUIC_FLAG(bool, FLAGS_quic_enable_lazy_fack, true)
 
-// If true, set a QUIC connection's last_sent_for_timeout_ to the send time of
-// the first packet sent after receiving a packet, even if the sent packet is
-// a retransmission
-QUIC_FLAG(bool, FLAGS_quic_better_last_send_for_timeout, true)
+// If true, do not override a connection in global map if exists. Only create
+// QUIC session if it is successfully inserted to the global map. Toss the
+// packet if insertion fails.
+QUIC_FLAG(bool, FLAGS_quic_create_session_after_insertion, false)
 
-// If true, send an explicit TTL in QUIC REJ messages to mitigate client clock
-// skew.
-QUIC_FLAG(bool, FLAGS_quic_send_scfg_ttl, true)
+// If true, rejected packet number is removed from public reset packet.
+QUIC_FLAG(bool, FLAGS_quic_remove_packet_number_from_public_reset, false)
 
-// If true, only open limited number of quic sessions per epoll event. Leave the
-// rest to next event. This flag can be turned on only if
-// --quic_buffer_packet_till_chlo is true.
-QUIC_FLAG(bool, FLAGS_quic_limit_num_new_sessions_per_epoll_loop, false)
+// If true, v33 QUIC client uses 1 bit to specify 8-byte connection id in
+// public flag.
+QUIC_FLAG(bool, FLAGS_quic_remove_v33_hacks2, false)
+
+// If true, limits QUIC uncompressed headers to 16K.
+QUIC_FLAG(bool, FLAGS_quic_limit_uncompressed_headers, false)
+
+// If true, release headers stream\'s sequencer buffer when there is no active
+// stream.
+QUIC_FLAG(bool, FLAGS_quic_headers_stream_release_sequencer_buffer, false)
+
+// Set the retransmission alarm only when there are unacked
+// retransmittable packets.
+QUIC_FLAG(bool, FLAGS_quic_more_conservative_retransmission_alarm, true)
+
+// Enable QUIC force HOL blocking experiment.
+QUIC_FLAG(bool, FLAGS_quic_enable_force_hol_blocking, true)
+
+// If true, allows packets to be buffered in anticipation of a future CHLO, and
+// allow CHLO packets to be buffered until next iteration of the event loop.
+QUIC_FLAG(bool, FLAGS_quic_allow_chlo_buffering, true)
+
+// If true, fix version manager bug, in which version flag does not really
+// help.
+QUIC_FLAG(bool, FLAGS_quic_fix_version_manager, false)
 
-// If true, lazy allocate and early release memeory used in
-// QuicStreamSequencerBuffer to buffer incoming data.
-QUIC_FLAG(bool, FLAGS_quic_reduce_sequencer_buffer_memory_life_time, true)
+// Add a new client connection options field to QuicOptions which is only used
+// to configure client side features, such as congestion control.
+QUIC_FLAG(bool, FLAGS_quic_client_connection_options, true)
 
-// If true, allow server address change if it is because of mapped ipv4 address.
-QUIC_FLAG(bool, FLAGS_quic_allow_server_address_change_for_mapped_ipv4, true)
+// If true, fix some casts that were causing off-by-one errors in QUIC's cubic
+// "convex" increases.
+QUIC_FLAG(bool, FLAGS_quic_fix_cubic_convex_mode, false)
 
-// If true, disables QUIC version less than 34.
-QUIC_FLAG(bool, FLAGS_quic_disable_pre_34, false)
+// Ensure that BBR startup pacing rate does not drop below the initial one.
+QUIC_FLAG(bool, FLAGS_quic_bbr_faster_startup, false)
 
-// When true, decode the packet number from the largest received packet, rather
-// than the most recent.
-QUIC_FLAG(bool, FLAGS_quic_packet_numbers_largest_received, true)
+// If true, GFE sends SETTINGS_MAX_HEADER_LIST_SIZE to the client at the
+// beginning of a connection.
+QUIC_FLAG(bool, FLAGS_quic_send_max_header_list_size, true)
diff --git a/src/net/quic/core/quic_flow_controller.cc b/src/net/quic/core/quic_flow_controller.cc
index 3c556f3..7fd7b5a 100644
--- a/src/net/quic/core/quic_flow_controller.cc
+++ b/src/net/quic/core/quic_flow_controller.cc
@@ -8,7 +8,7 @@
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_connection.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/quic_flow_controller.h b/src/net/quic/core/quic_flow_controller.h
index 238b9b4..833e0ce 100644
--- a/src/net/quic/core/quic_flow_controller.h
+++ b/src/net/quic/core/quic_flow_controller.h
@@ -7,7 +7,7 @@
 
 #include "base/macros.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/quic_framer.cc b/src/net/quic/core/quic_framer.cc
index a678812..b7b1809 100644
--- a/src/net/quic/core/quic_framer.cc
+++ b/src/net/quic/core/quic_framer.cc
@@ -10,6 +10,7 @@
 
 #include "base/compiler_specific.h"
 #include "base/logging.h"
+#include "base/memory/ptr_util.h"
 #include "base/stl_util.h"
 #include "net/quic/core/crypto/crypto_framer.h"
 #include "net/quic/core/crypto/crypto_handshake_message.h"
@@ -25,18 +26,16 @@
 
 using base::ContainsKey;
 using base::StringPiece;
-using std::map;
-using std::max;
-using std::min;
-using std::numeric_limits;
 using std::string;
-using std::vector;
 #define PREDICT_FALSE(x) (x)
 
 namespace net {
 
 namespace {
 
+#define ENDPOINT \
+  (perspective_ == Perspective::IS_SERVER ? "Server: " : "Client: ")
+
 // Mask to select the lowest 48 bits of a packet number.
 const QuicPacketNumber k6ByteSequenceNumberMask = UINT64_C(0x0000FFFFFFFFFFFF);
 const QuicPacketNumber k4ByteSequenceNumberMask = UINT64_C(0x00000000FFFFFFFF);
@@ -93,12 +92,6 @@ const uint8_t kQuicStreamFinMask = 0x01;
 // packet number size shift used in AckFrames.
 const uint8_t kQuicSequenceNumberLengthShift = 2;
 
-// Acks may be truncated.
-const uint8_t kQuicAckTruncatedShift = 1;
-const uint8_t kQuicAckTruncatedMask = 0x01;
-
-// Acks may not have any nacks.
-const uint8_t kQuicHasNacksMask = 0x01;
 // Acks may have only one ack block.
 const uint8_t kQuicHasMultipleAckBlocksMask = 0x01;
 const uint8_t kQuicHasMultipleAckBlocksShift = 1;
@@ -140,7 +133,6 @@ QuicFramer::QuicFramer(const QuicVersionVector& supported_versions,
                        QuicTime creation_time,
                        Perspective perspective)
     : visitor_(nullptr),
-      entropy_calculator_(nullptr),
       error_(QUIC_NO_ERROR),
       last_packet_number_(0),
       largest_packet_number_(0),
@@ -177,9 +169,6 @@ size_t QuicFramer::GetMinAckFrameSize(
     QuicPacketNumberLength largest_observed_length) {
   size_t min_size = kQuicFrameTypeSize + largest_observed_length +
                     kQuicDeltaTimeLargestObservedSize;
-  if (version <= QUIC_VERSION_33) {
-    return min_size + kQuicEntropyHashSize;
-  }
   return min_size + kQuicNumTimestampsSize;
 }
 
@@ -188,9 +177,6 @@ size_t QuicFramer::GetStopWaitingFrameSize(
     QuicVersion version,
     QuicPacketNumberLength packet_number_length) {
   size_t min_size = kQuicFrameTypeSize + packet_number_length;
-  if (version <= QUIC_VERSION_33) {
-    return min_size + kQuicEntropyHashSize;
-  }
   return min_size;
 }
 
@@ -320,39 +306,20 @@ size_t QuicFramer::GetSerializedFrameLength(
   if (can_truncate) {
     // Truncate the frame so the packet will not exceed kMaxPacketSize.
     // Note that we may not use every byte of the writer in this case.
-    DVLOG(1) << "Truncating large frame, free bytes: " << free_bytes;
+    DVLOG(1) << ENDPOINT
+             << "Truncating large frame, free bytes: " << free_bytes;
     return free_bytes;
   }
   return 0;
 }
 
-QuicFramer::AckFrameInfo::AckFrameInfo() : max_delta(0) {}
+QuicFramer::AckFrameInfo::AckFrameInfo()
+    : max_block_length(0), first_block_length(0), num_ack_blocks(0) {}
 
 QuicFramer::AckFrameInfo::AckFrameInfo(const AckFrameInfo& other) = default;
 
 QuicFramer::AckFrameInfo::~AckFrameInfo() {}
 
-QuicFramer::AckBlock::AckBlock(uint8_t gap, QuicPacketNumber length)
-    : gap(gap), length(length) {}
-
-QuicFramer::AckBlock::AckBlock(const AckBlock& other) = default;
-
-QuicFramer::AckBlock::~AckBlock() {}
-
-QuicFramer::NewAckFrameInfo::NewAckFrameInfo()
-    : max_block_length(0), first_block_length(0), num_ack_blocks(0) {}
-
-QuicFramer::NewAckFrameInfo::NewAckFrameInfo(const NewAckFrameInfo& other) =
-    default;
-
-QuicFramer::NewAckFrameInfo::~NewAckFrameInfo() {}
-
-// static
-QuicPacketEntropyHash QuicFramer::GetPacketEntropyHash(
-    const QuicPacketHeader& header) {
-  return header.entropy_flag << (header.packet_number % 8);
-}
-
 size_t QuicFramer::BuildDataPacket(const QuicPacketHeader& header,
                                    const QuicFrames& frames,
                                    char* buffer,
@@ -384,18 +351,9 @@ size_t QuicFramer::BuildDataPacket(const QuicPacketHeader& header,
         }
         break;
       case ACK_FRAME:
-        if (quic_version_ <= QUIC_VERSION_33) {
-          if (!AppendAckFrameAndTypeByte(header, *frame.ack_frame, &writer)) {
-            QUIC_BUG << "AppendAckFrameAndTypeByte failed"
-                     << " header: " << header
-                     << " ack_fame: " << *frame.ack_frame;
-            return 0;
-          }
-        } else {
-          if (!AppendNewAckFrameAndTypeByte(*frame.ack_frame, &writer)) {
-            QUIC_BUG << "AppendNewAckFrameAndTypeByte failed";
-            return 0;
-          }
+        if (!AppendAckFrameAndTypeByte(*frame.ack_frame, &writer)) {
+          QUIC_BUG << "AppendAckFrameAndTypeByte failed";
+          return 0;
         }
         break;
       case STOP_WAITING_FRAME:
@@ -459,15 +417,18 @@ size_t QuicFramer::BuildDataPacket(const QuicPacketHeader& header,
 }
 
 // static
-QuicEncryptedPacket* QuicFramer::BuildPublicResetPacket(
+std::unique_ptr<QuicEncryptedPacket> QuicFramer::BuildPublicResetPacket(
     const QuicPublicResetPacket& packet) {
   DCHECK(packet.public_header.reset_flag);
 
   CryptoHandshakeMessage reset;
   reset.set_tag(kPRST);
   reset.SetValue(kRNON, packet.nonce_proof);
-  reset.SetValue(kRSEQ, packet.rejected_packet_number);
-  if (!packet.client_address.address().empty()) {
+  if (!FLAGS_quic_remove_packet_number_from_public_reset) {
+    reset.SetValue(kRSEQ, packet.rejected_packet_number);
+  }
+  if (packet.client_address.host().address_family() !=
+      IpAddressFamily::IP_UNSPEC) {
     // packet.client_address is non-empty.
     QuicSocketAddressCoder address_coder(packet.client_address);
     string serialized_address = address_coder.Encode();
@@ -501,11 +462,11 @@ QuicEncryptedPacket* QuicFramer::BuildPublicResetPacket(
     return nullptr;
   }
 
-  return new QuicEncryptedPacket(buffer.release(), len, true);
+  return base::MakeUnique<QuicEncryptedPacket>(buffer.release(), len, true);
 }
 
 // static
-QuicEncryptedPacket* QuicFramer::BuildVersionNegotiationPacket(
+std::unique_ptr<QuicEncryptedPacket> QuicFramer::BuildVersionNegotiationPacket(
     QuicConnectionId connection_id,
     const QuicVersionVector& versions) {
   DCHECK(!versions.empty());
@@ -531,7 +492,7 @@ QuicEncryptedPacket* QuicFramer::BuildVersionNegotiationPacket(
     }
   }
 
-  return new QuicEncryptedPacket(buffer.release(), len, true);
+  return base::MakeUnique<QuicEncryptedPacket>(buffer.release(), len, true);
 }
 
 bool QuicFramer::ProcessPacket(const QuicEncryptedPacket& packet) {
@@ -542,7 +503,9 @@ bool QuicFramer::ProcessPacket(const QuicEncryptedPacket& packet) {
   // First parse the public header.
   QuicPacketPublicHeader public_header;
   if (!ProcessPublicHeader(&reader, &public_header)) {
-    DLOG(WARNING) << "Unable to process public header.";
+    DCHECK_NE("", detailed_error_);
+    DVLOG(1) << ENDPOINT
+             << "Unable to process public header. Error: " << detailed_error_;
     DCHECK_NE("", detailed_error_);
     return RaiseError(QUIC_INVALID_PACKET_HEADER);
   }
@@ -609,7 +572,10 @@ bool QuicFramer::ProcessDataPacket(QuicDataReader* encrypted_reader,
                                    size_t buffer_length) {
   QuicPacketHeader header(public_header);
   if (!ProcessUnauthenticatedHeader(encrypted_reader, &header)) {
-    DLOG(WARNING) << "Unable to process packet header.  Stopping parsing.";
+    DCHECK_NE("", detailed_error_);
+    DVLOG(1) << ENDPOINT
+             << "Unable to process packet header. Stopping parsing. Error: "
+             << detailed_error_;
     return false;
   }
 
@@ -621,12 +587,6 @@ bool QuicFramer::ProcessDataPacket(QuicDataReader* encrypted_reader,
   }
 
   QuicDataReader reader(decrypted_buffer, decrypted_length);
-  if (quic_version_ <= QUIC_VERSION_33) {
-    if (!ProcessAuthenticatedHeader(&reader, &header)) {
-      DLOG(WARNING) << "Unable to process packet header.  Stopping parsing.";
-      return false;
-    }
-  }
 
   // Set the last packet number after we have decrypted the packet
   // so we are confident is not attacker controlled.
@@ -643,11 +603,12 @@ bool QuicFramer::ProcessDataPacket(QuicDataReader* encrypted_reader,
     return RaiseError(QUIC_PACKET_TOO_LARGE);
   }
 
-  DCHECK(!header.fec_flag);
   // Handle the payload.
   if (!ProcessFrameData(&reader, header)) {
     DCHECK_NE(QUIC_NO_ERROR, error_);  // ProcessFrameData sets the error.
-    DLOG(WARNING) << "Unable to process frame data.";
+    DCHECK_NE("", detailed_error_);
+    DLOG(WARNING) << ENDPOINT
+                  << "Unable to process frame data. Error: " << detailed_error_;
     return false;
   }
 
@@ -682,7 +643,7 @@ bool QuicFramer::ProcessPublicResetPacket(
     QuicSocketAddressCoder address_coder;
     if (address_coder.Decode(address.data(), address.length())) {
       packet.client_address =
-          IPEndPoint(address_coder.ip(), address_coder.port());
+          QuicSocketAddress(address_coder.ip(), address_coder.port());
     }
   }
 
@@ -692,7 +653,7 @@ bool QuicFramer::ProcessPublicResetPacket(
 
 bool QuicFramer::AppendPacketHeader(const QuicPacketHeader& header,
                                     QuicDataWriter* writer) {
-  DVLOG(1) << "Appending header: " << header;
+  DVLOG(1) << ENDPOINT << "Appending header: " << header;
   uint8_t public_flags = 0;
   if (header.public_header.reset_flag) {
     public_flags |= PACKET_PUBLIC_FLAGS_RST;
@@ -721,14 +682,9 @@ bool QuicFramer::AppendPacketHeader(const QuicPacketHeader& header,
       }
       break;
     case PACKET_8BYTE_CONNECTION_ID:
-      if (quic_version_ > QUIC_VERSION_32) {
-        public_flags |= PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID;
-        if (!FLAGS_quic_remove_v33_hacks &&
-            perspective_ == Perspective::IS_CLIENT) {
-          public_flags |= PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID_OLD;
-        }
-
-      } else {
+      public_flags |= PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID;
+      if (!FLAGS_quic_remove_v33_hacks2 &&
+          perspective_ == Perspective::IS_CLIENT) {
         public_flags |= PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID_OLD;
       }
       if (!writer->WriteUInt8(public_flags) ||
@@ -743,8 +699,8 @@ bool QuicFramer::AppendPacketHeader(const QuicPacketHeader& header,
     DCHECK_EQ(Perspective::IS_CLIENT, perspective_);
     QuicTag tag = QuicVersionToQuicTag(quic_version_);
     writer->WriteUInt32(tag);
-    DVLOG(1) << "version = " << quic_version_ << ", tag = '"
-             << QuicUtils::TagToString(tag) << "'";
+    DVLOG(1) << ENDPOINT << "version = " << quic_version_ << ", tag = '"
+             << QuicTagToString(tag) << "'";
   }
 
   if (header.public_header.multipath_flag &&
@@ -762,17 +718,6 @@ bool QuicFramer::AppendPacketHeader(const QuicPacketHeader& header,
                                   header.packet_number, writer)) {
     return false;
   }
-  if (quic_version_ > QUIC_VERSION_33) {
-    return true;
-  }
-
-  uint8_t private_flags = 0;
-  if (header.entropy_flag) {
-    private_flags |= PACKET_PRIVATE_FLAGS_ENTROPY;
-  }
-  if (!writer->WriteUInt8(private_flags)) {
-    return false;
-  }
 
   return true;
 }
@@ -807,28 +752,15 @@ bool QuicFramer::IsValidPath(QuicPathId path_id,
     return false;
   }
 
-  if (FLAGS_quic_packet_numbers_largest_received) {
-    if (path_id == last_path_id_) {
-      *base_packet_number = largest_packet_number_;
-      return true;
-    }
+  if (path_id == last_path_id_) {
+    *base_packet_number = largest_packet_number_;
+    return true;
+  }
 
-    if (ContainsKey(largest_packet_numbers_, path_id)) {
-      *base_packet_number = largest_packet_numbers_[path_id];
-    } else {
-      *base_packet_number = 0;
-    }
+  if (ContainsKey(largest_packet_numbers_, path_id)) {
+    *base_packet_number = largest_packet_numbers_[path_id];
   } else {
-    if (path_id == last_path_id_) {
-      *base_packet_number = last_packet_number_;
-      return true;
-    }
-
-    if (ContainsKey(last_packet_numbers_, path_id)) {
-      *base_packet_number = last_packet_numbers_[path_id];
-    } else {
-      *base_packet_number = 0;
-    }
+    *base_packet_number = 0;
   }
 
   return true;
@@ -838,23 +770,19 @@ void QuicFramer::SetLastPacketNumber(const QuicPacketHeader& header) {
   if (header.public_header.multipath_flag && header.path_id != last_path_id_) {
     if (last_path_id_ != kInvalidPathId) {
       // Save current last packet number before changing path.
-      last_packet_numbers_[last_path_id_] = last_packet_number_;
-      if (FLAGS_quic_packet_numbers_largest_received) {
-        largest_packet_numbers_[last_path_id_] = largest_packet_number_;
-      }
+      largest_packet_numbers_[last_path_id_] = largest_packet_number_;
     }
     // Change path.
     last_path_id_ = header.path_id;
   }
   last_packet_number_ = header.packet_number;
-  if (FLAGS_quic_packet_numbers_largest_received) {
-    largest_packet_number_ = max(header.packet_number, largest_packet_number_);
-  }
+  largest_packet_number_ =
+      std::max(header.packet_number, largest_packet_number_);
 }
 
 void QuicFramer::OnPathClosed(QuicPathId path_id) {
   closed_paths_.insert(path_id);
-  last_packet_numbers_.erase(path_id);
+  largest_packet_numbers_.erase(path_id);
 }
 
 QuicPacketNumber QuicFramer::CalculatePacketNumberFromWire(
@@ -945,12 +873,8 @@ bool QuicFramer::ProcessPublicHeader(QuicDataReader* reader,
   }
 
   // A nonce should only be present in packets from the server to the client,
-  // which are neither version negotiation nor public reset packets
-  // and only for versions after QUIC_VERSION_32. Earlier versions will
-  // set this bit when indicating an 8-byte connection ID, which should
-  // not be interpreted as indicating a nonce is present.
-  if (quic_version_ > QUIC_VERSION_32 &&
-      public_flags & PACKET_PUBLIC_FLAGS_NONCE &&
+  // which are neither version negotiation nor public reset packets.
+  if (public_flags & PACKET_PUBLIC_FLAGS_NONCE &&
       !(public_flags & PACKET_PUBLIC_FLAGS_VERSION) &&
       !(public_flags & PACKET_PUBLIC_FLAGS_RST) &&
       // The nonce flag from a client is ignored and is assumed to be an older
@@ -1004,38 +928,7 @@ uint8_t QuicFramer::GetSequenceNumberFlags(
 // static
 QuicFramer::AckFrameInfo QuicFramer::GetAckFrameInfo(
     const QuicAckFrame& frame) {
-  AckFrameInfo ack_info;
-  if (frame.packets.Empty()) {
-    return ack_info;
-  }
-  DCHECK_GE(frame.largest_observed, frame.packets.Max());
-  QuicPacketNumber last_largest_missing = 0;
-  for (const Interval<QuicPacketNumber>& interval : frame.packets) {
-    for (QuicPacketNumber interval_start = interval.min();
-         interval_start < interval.max();
-         interval_start += (1ull + numeric_limits<uint8_t>::max())) {
-      uint8_t cur_range_length =
-          interval.max() - interval_start > numeric_limits<uint8_t>::max()
-              ? numeric_limits<uint8_t>::max()
-              : (interval.max() - interval_start) - 1;
-      ack_info.nack_ranges[interval_start] = cur_range_length;
-    }
-    ack_info.max_delta =
-        max(ack_info.max_delta, last_largest_missing == 0
-                                    ? QuicPacketNumber{0}
-                                    : (interval.min() - last_largest_missing));
-    last_largest_missing = interval.max() - 1;
-  }
-  // Include the range to the largest observed.
-  ack_info.max_delta =
-      max(ack_info.max_delta, frame.largest_observed - last_largest_missing);
-  return ack_info;
-}
-
-// static
-QuicFramer::NewAckFrameInfo QuicFramer::GetNewAckFrameInfo(
-    const QuicAckFrame& frame) {
-  NewAckFrameInfo new_ack_info;
+  AckFrameInfo new_ack_info;
   if (frame.packets.Empty()) {
     return new_ack_info;
   }
@@ -1050,15 +943,15 @@ QuicFramer::NewAckFrameInfo QuicFramer::GetNewAckFrameInfo(
   // Don't do any more work after getting information for 256 ACK blocks; any
   // more can't be encoded anyway.
   for (; itr != frame.packets.rend() &&
-         new_ack_info.num_ack_blocks < numeric_limits<uint8_t>::max();
+         new_ack_info.num_ack_blocks < std::numeric_limits<uint8_t>::max();
        previous_start = itr->min(), ++itr) {
     const auto& interval = *itr;
     const QuicPacketNumber total_gap = previous_start - interval.max();
     new_ack_info.num_ack_blocks +=
-        (total_gap + numeric_limits<uint8_t>::max() - 1) /
-        numeric_limits<uint8_t>::max();
+        (total_gap + std::numeric_limits<uint8_t>::max() - 1) /
+        std::numeric_limits<uint8_t>::max();
     new_ack_info.max_block_length =
-        max(new_ack_info.max_block_length, interval.Length());
+        std::max(new_ack_info.max_block_length, interval.Length());
   }
   return new_ack_info;
 }
@@ -1072,12 +965,11 @@ bool QuicFramer::ProcessUnauthenticatedHeader(QuicDataReader* encrypted_reader,
     return RaiseError(QUIC_INVALID_PACKET_HEADER);
   }
 
-  QuicPacketNumber base_packet_number =
-      FLAGS_quic_packet_numbers_largest_received ? largest_packet_number_
-                                                 : last_packet_number_;
+  QuicPacketNumber base_packet_number = largest_packet_number_;
   if (header->public_header.multipath_flag &&
       !IsValidPath(header->path_id, &base_packet_number)) {
     // Stop processing because path is closed.
+    set_detailed_error("Path is closed.");
     return false;
   }
 
@@ -1094,52 +986,13 @@ bool QuicFramer::ProcessUnauthenticatedHeader(QuicDataReader* encrypted_reader,
   }
 
   if (!visitor_->OnUnauthenticatedHeader(*header)) {
+    set_detailed_error(
+        "Visitor asked to stop processing of unauthenticated header.");
     return false;
   }
   return true;
 }
 
-bool QuicFramer::ProcessAuthenticatedHeader(QuicDataReader* reader,
-                                            QuicPacketHeader* header) {
-  uint8_t private_flags;
-  if (!reader->ReadBytes(&private_flags, 1)) {
-    set_detailed_error("Unable to read private flags.");
-    return RaiseError(QUIC_INVALID_PACKET_HEADER);
-  }
-
-  if (quic_version_ > QUIC_VERSION_31) {
-    if (private_flags > PACKET_PRIVATE_FLAGS_MAX_VERSION_32) {
-      set_detailed_error("Illegal private flags value.");
-      return RaiseError(QUIC_INVALID_PACKET_HEADER);
-    }
-  } else {
-    if (private_flags > PACKET_PRIVATE_FLAGS_MAX) {
-      set_detailed_error("Illegal private flags value.");
-      return RaiseError(QUIC_INVALID_PACKET_HEADER);
-    }
-  }
-
-  header->entropy_flag = (private_flags & PACKET_PRIVATE_FLAGS_ENTROPY) != 0;
-  header->fec_flag = (private_flags & PACKET_PRIVATE_FLAGS_FEC) != 0;
-
-  if ((private_flags & PACKET_PRIVATE_FLAGS_FEC_GROUP) != 0) {
-    uint8_t first_fec_protected_packet_offset;
-    if (!reader->ReadBytes(&first_fec_protected_packet_offset, 1)) {
-      set_detailed_error("Unable to read first fec protected packet offset.");
-      return RaiseError(QUIC_INVALID_PACKET_HEADER);
-    }
-    if (first_fec_protected_packet_offset >= header->packet_number) {
-      set_detailed_error(
-          "First fec protected packet offset must be less "
-          "than the packet number.");
-      return RaiseError(QUIC_INVALID_PACKET_HEADER);
-    }
-  }
-
-  header->entropy_hash = GetPacketEntropyHash(*header);
-  return true;
-}
-
 bool QuicFramer::ProcessPathId(QuicDataReader* reader, QuicPathId* path_id) {
   if (!reader->ReadBytes(path_id, 1)) {
     return false;
@@ -1186,7 +1039,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
           return RaiseError(QUIC_INVALID_STREAM_DATA);
         }
         if (!visitor_->OnStreamFrame(frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1196,17 +1049,11 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
       // Ack Frame
       if (frame_type & kQuicFrameTypeAckMask) {
         QuicAckFrame frame;
-        if (quic_version_ <= QUIC_VERSION_33) {
-          if (!ProcessAckFrame(reader, frame_type, &frame)) {
-            return RaiseError(QUIC_INVALID_ACK_DATA);
-          }
-        } else {
-          if (!ProcessNewAckFrame(reader, frame_type, &frame)) {
-            return RaiseError(QUIC_INVALID_ACK_DATA);
-          }
+        if (!ProcessAckFrame(reader, frame_type, &frame)) {
+          return RaiseError(QUIC_INVALID_ACK_DATA);
         }
         if (!visitor_->OnAckFrame(frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1216,7 +1063,8 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
       // This was a special frame type that did not match any
       // of the known ones. Error.
       set_detailed_error("Illegal frame type.");
-      DLOG(WARNING) << "Illegal frame type: " << static_cast<int>(frame_type);
+      DLOG(WARNING) << ENDPOINT
+                    << "Illegal frame type: " << static_cast<int>(frame_type);
       return RaiseError(QUIC_INVALID_FRAME_DATA);
     }
 
@@ -1250,7 +1098,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
         }
 
         if (!visitor_->OnConnectionCloseFrame(frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1263,7 +1111,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
           return RaiseError(QUIC_INVALID_GOAWAY_DATA);
         }
         if (!visitor_->OnGoAwayFrame(goaway_frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1276,7 +1124,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
           return RaiseError(QUIC_INVALID_WINDOW_UPDATE_DATA);
         }
         if (!visitor_->OnWindowUpdateFrame(window_update_frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1289,7 +1137,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
           return RaiseError(QUIC_INVALID_BLOCKED_DATA);
         }
         if (!visitor_->OnBlockedFrame(blocked_frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1302,7 +1150,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
           return RaiseError(QUIC_INVALID_STOP_WAITING_DATA);
         }
         if (!visitor_->OnStopWaitingFrame(stop_waiting_frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1312,7 +1160,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
         // Ping has no payload.
         QuicPingFrame ping_frame;
         if (!visitor_->OnPingFrame(ping_frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1324,7 +1172,7 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
           return RaiseError(QUIC_INVALID_PATH_CLOSE_DATA);
         }
         if (!visitor_->OnPathCloseFrame(path_close_frame)) {
-          DVLOG(1) << "Visitor asked to stop further processing.";
+          DVLOG(1) << ENDPOINT << "Visitor asked to stop further processing.";
           // Returning true since there was no parsing error.
           return true;
         }
@@ -1333,7 +1181,8 @@ bool QuicFramer::ProcessFrameData(QuicDataReader* reader,
 
       default:
         set_detailed_error("Illegal frame type.");
-        DLOG(WARNING) << "Illegal frame type: " << static_cast<int>(frame_type);
+        DLOG(WARNING) << ENDPOINT
+                      << "Illegal frame type: " << static_cast<int>(frame_type);
         return RaiseError(QUIC_INVALID_FRAME_DATA);
     }
   }
@@ -1399,104 +1248,6 @@ bool QuicFramer::ProcessStreamFrame(QuicDataReader* reader,
 bool QuicFramer::ProcessAckFrame(QuicDataReader* reader,
                                  uint8_t frame_type,
                                  QuicAckFrame* ack_frame) {
-  // Determine the three lengths from the frame type: largest observed length,
-  // missing packet number length, and missing range length.
-  const QuicPacketNumberLength missing_packet_number_length =
-      ReadSequenceNumberLength(frame_type);
-  frame_type >>= kQuicSequenceNumberLengthShift;
-  const QuicPacketNumberLength largest_observed_packet_number_length =
-      ReadSequenceNumberLength(frame_type);
-  frame_type >>= kQuicSequenceNumberLengthShift;
-  ack_frame->is_truncated = frame_type & kQuicAckTruncatedMask;
-  frame_type >>= kQuicAckTruncatedShift;
-  bool has_nacks = frame_type & kQuicHasNacksMask;
-
-  if (!reader->ReadBytes(&ack_frame->entropy_hash, 1)) {
-    set_detailed_error("Unable to read entropy hash for received packets.");
-    return false;
-  }
-
-  if (!reader->ReadBytes(&ack_frame->largest_observed,
-                         largest_observed_packet_number_length)) {
-    set_detailed_error("Unable to read largest observed.");
-    return false;
-  }
-
-  uint64_t ack_delay_time_us;
-  if (!reader->ReadUFloat16(&ack_delay_time_us)) {
-    set_detailed_error("Unable to read ack delay time.");
-    return false;
-  }
-
-  if (ack_delay_time_us == kUFloat16MaxValue) {
-    ack_frame->ack_delay_time = QuicTime::Delta::Infinite();
-  } else {
-    ack_frame->ack_delay_time =
-        QuicTime::Delta::FromMicroseconds(ack_delay_time_us);
-  }
-
-  if (!ProcessTimestampsInAckFrame(reader, ack_frame)) {
-    return false;
-  }
-
-  if (!has_nacks) {
-    return true;
-  }
-
-  uint8_t num_missing_ranges;
-  if (!reader->ReadBytes(&num_missing_ranges, 1)) {
-    set_detailed_error("Unable to read num missing packet ranges.");
-    return false;
-  }
-
-  QuicPacketNumber last_packet_number = ack_frame->largest_observed;
-  for (size_t i = 0; i < num_missing_ranges; ++i) {
-    QuicPacketNumber missing_delta = 0;
-    if (!reader->ReadBytes(&missing_delta, missing_packet_number_length)) {
-      set_detailed_error("Unable to read missing packet number delta.");
-      return false;
-    }
-    last_packet_number -= missing_delta;
-    QuicPacketNumber range_length = 0;
-    if (!reader->ReadBytes(&range_length, PACKET_1BYTE_PACKET_NUMBER)) {
-      set_detailed_error("Unable to read missing packet number range.");
-      return false;
-    }
-    ack_frame->packets.Add(last_packet_number - range_length,
-                           last_packet_number + 1);
-    // Subtract an extra 1 to ensure ranges are represented efficiently and
-    // can't overlap by 1 packet number.  This allows a missing_delta of 0
-    // to represent an adjacent nack range.
-    last_packet_number -= (range_length + 1);
-  }
-
-  if (quic_version_ > QUIC_VERSION_31) {
-    return true;
-  }
-
-  // Parse the revived packets list.
-  // TODO(ianswett): Change the ack frame so it only expresses one revived.
-  uint8_t num_revived_packets;
-  if (!reader->ReadBytes(&num_revived_packets, 1)) {
-    set_detailed_error("Unable to read num revived packets.");
-    return false;
-  }
-
-  for (size_t i = 0; i < num_revived_packets; ++i) {
-    QuicPacketNumber revived_packet = 0;
-    if (!reader->ReadBytes(&revived_packet,
-                           largest_observed_packet_number_length)) {
-      set_detailed_error("Unable to read revived packet.");
-      return false;
-    }
-  }
-
-  return true;
-}
-
-bool QuicFramer::ProcessNewAckFrame(QuicDataReader* reader,
-                                    uint8_t frame_type,
-                                    QuicAckFrame* ack_frame) {
   // Determine the two lengths from the frame type: largest acked length,
   // ack block length.
   const QuicPacketNumberLength ack_block_length =
@@ -1507,7 +1258,6 @@ bool QuicFramer::ProcessNewAckFrame(QuicDataReader* reader,
   frame_type >>= kQuicSequenceNumberLengthShift;
   frame_type >>= kQuicHasMultipleAckBlocksShift;
   bool has_ack_blocks = frame_type & kQuicHasMultipleAckBlocksMask;
-  ack_frame->missing = false;
 
   if (!reader->ReadBytes(&ack_frame->largest_observed, largest_acked_length)) {
     set_detailed_error("Unable to read largest acked.");
@@ -1573,9 +1323,6 @@ bool QuicFramer::ProcessNewAckFrame(QuicDataReader* reader,
 
 bool QuicFramer::ProcessTimestampsInAckFrame(QuicDataReader* reader,
                                              QuicAckFrame* ack_frame) {
-  if (ack_frame->is_truncated) {
-    return true;
-  }
   uint8_t num_received_packets;
   if (!reader->ReadBytes(&num_received_packets, 1)) {
     set_detailed_error("Unable to read num received packets.");
@@ -1634,13 +1381,6 @@ bool QuicFramer::ProcessTimestampsInAckFrame(QuicDataReader* reader,
 bool QuicFramer::ProcessStopWaitingFrame(QuicDataReader* reader,
                                          const QuicPacketHeader& header,
                                          QuicStopWaitingFrame* stop_waiting) {
-  if (quic_version_ <= QUIC_VERSION_33) {
-    if (!reader->ReadBytes(&stop_waiting->entropy_hash, 1)) {
-      set_detailed_error("Unable to read entropy hash for sent packets.");
-      return false;
-    }
-  }
-
   QuicPacketNumber least_unacked_delta = 0;
   if (!reader->ReadBytes(&least_unacked_delta,
                          header.public_header.packet_number_length)) {
@@ -1908,8 +1648,7 @@ bool QuicFramer::DecryptPayload(QuicDataReader* encrypted_reader,
     }
     bool try_alternative_decryption = true;
     if (alternative_decrypter_level_ == ENCRYPTION_INITIAL) {
-      if (perspective_ == Perspective::IS_CLIENT &&
-          quic_version_ > QUIC_VERSION_32) {
+      if (perspective_ == Perspective::IS_CLIENT) {
         if (header.public_header.nonce == nullptr) {
           // Can not use INITIAL decryption without a diversification nonce.
           try_alternative_decryption = false;
@@ -1929,7 +1668,7 @@ bool QuicFramer::DecryptPayload(QuicDataReader* encrypted_reader,
       if (alternative_decrypter_latch_) {
         // Switch to the alternative decrypter and latch so that we cannot
         // switch back.
-        decrypter_.reset(alternative_decrypter_.release());
+        decrypter_ = std::move(alternative_decrypter_);
         decrypter_level_ = alternative_decrypter_level_;
         alternative_decrypter_level_ = ENCRYPTION_NONE;
       } else {
@@ -1943,8 +1682,8 @@ bool QuicFramer::DecryptPayload(QuicDataReader* encrypted_reader,
   }
 
   if (!success) {
-    DLOG(WARNING) << "DecryptPacket failed for packet_number:"
-                  << header.packet_number;
+    DVLOG(1) << ENDPOINT << "DecryptPacket failed for packet_number:"
+             << header.packet_number;
     return false;
   }
 
@@ -1963,35 +1702,8 @@ size_t QuicFramer::GetAckFrameSize(
     const QuicAckFrame& ack,
     QuicPacketNumberLength packet_number_length) {
   size_t ack_size = 0;
-  if (quic_version_ <= QUIC_VERSION_33) {
-    AckFrameInfo ack_info = GetAckFrameInfo(ack);
-    QuicPacketNumberLength largest_observed_length =
-        GetMinSequenceNumberLength(ack.largest_observed);
-    QuicPacketNumberLength missing_packet_number_length =
-        GetMinSequenceNumberLength(ack_info.max_delta);
-
-    ack_size = GetMinAckFrameSize(quic_version_, largest_observed_length);
-    if (!ack_info.nack_ranges.empty()) {
-      ack_size += kNumberOfNackRangesSize;
-      if (quic_version_ <= QUIC_VERSION_31) {
-        ack_size += kNumberOfRevivedPacketsSize;
-      }
-      ack_size += min(ack_info.nack_ranges.size(), kMaxNackRanges) *
-                  (missing_packet_number_length + PACKET_1BYTE_PACKET_NUMBER);
-    }
-
-    // In version 23, if the ack will be truncated due to too many nack ranges,
-    // then do not include the number of timestamps (1 byte).
-    if (ack_info.nack_ranges.size() <= kMaxNackRanges) {
-      // 1 byte for the number of timestamps.
-      ack_size += 1;
-      ack_size += GetAckFrameTimeStampSize(ack);
-    }
-
-    return ack_size;
-  }
 
-  NewAckFrameInfo ack_info = GetNewAckFrameInfo(ack);
+  AckFrameInfo ack_info = GetAckFrameInfo(ack);
   QuicPacketNumberLength largest_acked_length =
       GetMinSequenceNumberLength(ack.largest_observed);
   QuicPacketNumberLength ack_block_length =
@@ -2002,7 +1714,7 @@ size_t QuicFramer::GetAckFrameSize(
   ack_size += ack_block_length;
   if (ack_info.num_ack_blocks != 0) {
     ack_size += kNumberOfAckBlocksSize;
-    ack_size += min(ack_info.num_ack_blocks, kMaxAckBlocks) *
+    ack_size += std::min(ack_info.num_ack_blocks, kMaxAckBlocks) *
                 (ack_block_length + PACKET_1BYTE_PACKET_NUMBER);
   }
 
@@ -2150,7 +1862,7 @@ bool QuicFramer::AppendStreamFrame(const QuicStreamFrame& frame,
     return false;
   }
   if (!no_stream_frame_length) {
-    if ((frame.data_length > numeric_limits<uint16_t>::max()) ||
+    if ((frame.data_length > std::numeric_limits<uint16_t>::max()) ||
         !writer->WriteUInt16(static_cast<uint16_t>(frame.data_length))) {
       QUIC_BUG << "Writing stream frame length failed";
       return false;
@@ -2169,159 +1881,9 @@ void QuicFramer::set_version(const QuicVersion version) {
   quic_version_ = version;
 }
 
-bool QuicFramer::AppendAckFrameAndTypeByte(const QuicPacketHeader& header,
-                                           const QuicAckFrame& frame,
+bool QuicFramer::AppendAckFrameAndTypeByte(const QuicAckFrame& frame,
                                            QuicDataWriter* writer) {
-  AckFrameInfo ack_info = GetAckFrameInfo(frame);
-  QuicPacketNumber ack_largest_observed = frame.largest_observed;
-  QuicPacketNumberLength largest_observed_length =
-      GetMinSequenceNumberLength(ack_largest_observed);
-  QuicPacketNumberLength missing_packet_number_length =
-      GetMinSequenceNumberLength(ack_info.max_delta);
-  // Determine whether we need to truncate ranges.
-  size_t available_range_bytes =
-      writer->capacity() - writer->length() - kNumberOfNackRangesSize -
-      GetMinAckFrameSize(quic_version_, largest_observed_length);
-  if (quic_version_ <= QUIC_VERSION_31) {
-    available_range_bytes -= kNumberOfRevivedPacketsSize;
-  }
-  size_t max_num_ranges =
-      available_range_bytes /
-      (missing_packet_number_length + PACKET_1BYTE_PACKET_NUMBER);
-  max_num_ranges = min(kMaxNackRanges, max_num_ranges);
-  bool truncated = ack_info.nack_ranges.size() > max_num_ranges;
-  DVLOG_IF(1, truncated) << "Truncating ack from "
-                         << ack_info.nack_ranges.size() << " ranges to "
-                         << max_num_ranges;
-  // Write out the type byte by setting the low order bits and doing shifts
-  // to make room for the next bit flags to be set.
-  // Whether there are any nacks.
-  uint8_t type_byte = ack_info.nack_ranges.empty() ? 0 : kQuicHasNacksMask;
-
-  // truncating bit.
-  type_byte <<= kQuicAckTruncatedShift;
-  type_byte |= truncated ? kQuicAckTruncatedMask : 0;
-
-  // Largest observed packet number length.
-  type_byte <<= kQuicSequenceNumberLengthShift;
-  type_byte |= GetSequenceNumberFlags(largest_observed_length);
-
-  // Missing packet number length.
-  type_byte <<= kQuicSequenceNumberLengthShift;
-  type_byte |= GetSequenceNumberFlags(missing_packet_number_length);
-
-  type_byte |= kQuicFrameTypeAckMask;
-
-  if (!writer->WriteUInt8(type_byte)) {
-    QUIC_BUG << "type byte failed";
-    return false;
-  }
-
-  QuicPacketEntropyHash ack_entropy_hash = frame.entropy_hash;
-  NackRangeMap::reverse_iterator ack_iter = ack_info.nack_ranges.rbegin();
-  if (truncated) {
-    // Skip the nack ranges which the truncated ack won't include and set
-    // a correct largest observed for the truncated ack.
-    for (size_t i = 1; i < (ack_info.nack_ranges.size() - max_num_ranges);
-         ++i) {
-      ++ack_iter;
-    }
-    // If the last range is followed by acks, include them.
-    // If the last range is followed by another range, specify the end of the
-    // range as the largest_observed.
-    ack_largest_observed = ack_iter->first - 1;
-    // Also update the entropy so it matches the largest observed.
-    ack_entropy_hash = entropy_calculator_->EntropyHash(ack_largest_observed);
-    ++ack_iter;
-  }
-
-  if (!writer->WriteUInt8(ack_entropy_hash)) {
-    QUIC_BUG << "hash failed.";
-    return false;
-  }
-
-  if (!AppendPacketSequenceNumber(largest_observed_length, ack_largest_observed,
-                                  writer)) {
-    QUIC_BUG << "AppendPacketSequenceNumber failed. "
-             << "largest_observed_length: " << largest_observed_length
-             << " ack_largest_observed: " << ack_largest_observed;
-    return false;
-  }
-
-  uint64_t ack_delay_time_us = kUFloat16MaxValue;
-  if (!frame.ack_delay_time.IsInfinite()) {
-    DCHECK_LE(0u, frame.ack_delay_time.ToMicroseconds());
-    ack_delay_time_us = frame.ack_delay_time.ToMicroseconds();
-  }
-
-  if (!writer->WriteUFloat16(ack_delay_time_us)) {
-    QUIC_BUG << "ack delay time failed.";
-    return false;
-  }
-
-  // Timestamp goes at the end of the required fields.
-  if (!truncated) {
-    if (!AppendTimestampToAckFrame(frame, writer)) {
-      QUIC_BUG << "AppendTimestampToAckFrame failed";
-      return false;
-    }
-  }
-
-  if (ack_info.nack_ranges.empty()) {
-    return true;
-  }
-
-  const uint8_t num_missing_ranges =
-      static_cast<uint8_t>(min(ack_info.nack_ranges.size(), max_num_ranges));
-  if (!writer->WriteBytes(&num_missing_ranges, 1)) {
-    QUIC_BUG << "num_missing_ranges failed: "
-             << static_cast<uint32_t>(num_missing_ranges);
-    return false;
-  }
-
-  int num_ranges_written = 0;
-  QuicPacketNumber last_sequence_written = ack_largest_observed;
-  for (; ack_iter != ack_info.nack_ranges.rend(); ++ack_iter) {
-    // Calculate the delta to the last number in the range.
-    QuicPacketNumber missing_delta =
-        last_sequence_written - (ack_iter->first + ack_iter->second);
-    if (!AppendPacketSequenceNumber(missing_packet_number_length, missing_delta,
-                                    writer)) {
-      QUIC_BUG << "AppendPacketSequenceNumber failed: "
-               << "missing_packet_number_length: "
-               << missing_packet_number_length << " missing_delta "
-               << missing_delta;
-      return false;
-    }
-    if (!AppendPacketSequenceNumber(PACKET_1BYTE_PACKET_NUMBER,
-                                    ack_iter->second, writer)) {
-      QUIC_BUG << "AppendPacketSequenceNumber failed";
-      return false;
-    }
-    // Subtract 1 so a missing_delta of 0 means an adjacent range.
-    last_sequence_written = ack_iter->first - 1;
-    ++num_ranges_written;
-  }
-  DCHECK_EQ(num_missing_ranges, num_ranges_written);
-
-  if (quic_version_ > QUIC_VERSION_31) {
-    return true;
-  }
-
-  // Append revived packets.
-  // FEC is not supported.
-  uint8_t num_revived_packets = 0;
-  if (!writer->WriteBytes(&num_revived_packets, 1)) {
-    QUIC_BUG << "num_revived_packets failed: " << num_revived_packets;
-    return false;
-  }
-
-  return true;
-}
-
-bool QuicFramer::AppendNewAckFrameAndTypeByte(const QuicAckFrame& frame,
-                                              QuicDataWriter* writer) {
-  const NewAckFrameInfo new_ack_info = GetNewAckFrameInfo(frame);
+  const AckFrameInfo new_ack_info = GetAckFrameInfo(frame);
   QuicPacketNumber largest_acked = frame.largest_observed;
   QuicPacketNumberLength largest_acked_length =
       GetMinSequenceNumberLength(largest_acked);
@@ -2375,9 +1937,10 @@ bool QuicFramer::AppendNewAckFrameAndTypeByte(const QuicAckFrame& frame,
                               (ack_block_length + PACKET_1BYTE_PACKET_NUMBER);
 
   // Number of ack blocks.
-  size_t num_ack_blocks = min(new_ack_info.num_ack_blocks, max_num_ack_blocks);
-  if (num_ack_blocks > numeric_limits<uint8_t>::max()) {
-    num_ack_blocks = numeric_limits<uint8_t>::max();
+  size_t num_ack_blocks =
+      std::min(new_ack_info.num_ack_blocks, max_num_ack_blocks);
+  if (num_ack_blocks > std::numeric_limits<uint8_t>::max()) {
+    num_ack_blocks = std::numeric_limits<uint8_t>::max();
   }
 
   if (num_ack_blocks > 0) {
@@ -2413,16 +1976,16 @@ bool QuicFramer::AppendNewAckFrameAndTypeByte(const QuicAckFrame& frame,
       const auto& interval = *itr;
       const QuicPacketNumber total_gap = previous_start - interval.max();
       const size_t num_encoded_gaps =
-          (total_gap + numeric_limits<uint8_t>::max() - 1) /
-          numeric_limits<uint8_t>::max();
+          (total_gap + std::numeric_limits<uint8_t>::max() - 1) /
+          std::numeric_limits<uint8_t>::max();
       DCHECK_GT(num_encoded_gaps, 0u);
 
       // Append empty ACK blocks because the gap is longer than a single gap.
       for (size_t i = 1;
            i < num_encoded_gaps && num_ack_blocks_written < num_ack_blocks;
            ++i) {
-        if (!AppendAckBlock(numeric_limits<uint8_t>::max(), ack_block_length, 0,
-                            writer)) {
+        if (!AppendAckBlock(std::numeric_limits<uint8_t>::max(),
+                            ack_block_length, 0, writer)) {
           return false;
         }
         ++num_ack_blocks_written;
@@ -2436,7 +1999,8 @@ bool QuicFramer::AppendNewAckFrameAndTypeByte(const QuicAckFrame& frame,
       }
 
       const uint8_t last_gap =
-          total_gap - (num_encoded_gaps - 1) * numeric_limits<uint8_t>::max();
+          total_gap -
+          (num_encoded_gaps - 1) * std::numeric_limits<uint8_t>::max();
       // Append the final ACK block with a non-empty size.
       if (!AppendAckBlock(last_gap, ack_block_length, interval.Length(),
                           writer)) {
@@ -2467,9 +2031,11 @@ bool QuicFramer::AppendNewAckFrameAndTypeByte(const QuicAckFrame& frame,
 
 bool QuicFramer::AppendTimestampToAckFrame(const QuicAckFrame& frame,
                                            QuicDataWriter* writer) {
-  DCHECK_GE(numeric_limits<uint8_t>::max(), frame.received_packet_times.size());
+  DCHECK_GE(std::numeric_limits<uint8_t>::max(),
+            frame.received_packet_times.size());
   // num_received_packets is only 1 byte.
-  if (frame.received_packet_times.size() > numeric_limits<uint8_t>::max()) {
+  if (frame.received_packet_times.size() >
+      std::numeric_limits<uint8_t>::max()) {
     return false;
   }
 
@@ -2486,8 +2052,8 @@ bool QuicFramer::AppendTimestampToAckFrame(const QuicAckFrame& frame,
   QuicPacketNumber delta_from_largest_observed =
       frame.largest_observed - packet_number;
 
-  DCHECK_GE(numeric_limits<uint8_t>::max(), delta_from_largest_observed);
-  if (delta_from_largest_observed > numeric_limits<uint8_t>::max()) {
+  DCHECK_GE(std::numeric_limits<uint8_t>::max(), delta_from_largest_observed);
+  if (delta_from_largest_observed > std::numeric_limits<uint8_t>::max()) {
     return false;
   }
 
@@ -2511,7 +2077,7 @@ bool QuicFramer::AppendTimestampToAckFrame(const QuicAckFrame& frame,
     packet_number = it->first;
     delta_from_largest_observed = frame.largest_observed - packet_number;
 
-    if (delta_from_largest_observed > numeric_limits<uint8_t>::max()) {
+    if (delta_from_largest_observed > std::numeric_limits<uint8_t>::max()) {
       return false;
     }
 
@@ -2537,12 +2103,6 @@ bool QuicFramer::AppendStopWaitingFrame(const QuicPacketHeader& header,
       header.packet_number - frame.least_unacked;
   const QuicPacketNumber length_shift =
       header.public_header.packet_number_length * 8;
-  if (quic_version_ <= QUIC_VERSION_33) {
-    if (!writer->WriteUInt8(frame.entropy_hash)) {
-      QUIC_BUG << " hash failed";
-      return false;
-    }
-  }
 
   if (least_unacked_delta >> length_shift > 0) {
     QUIC_BUG << "packet_number_length "
@@ -2640,7 +2200,7 @@ bool QuicFramer::AppendPathCloseFrame(const QuicPathCloseFrame& frame,
 }
 
 bool QuicFramer::RaiseError(QuicErrorCode error) {
-  DVLOG(1) << "Error: " << QuicUtils::ErrorToString(error)
+  DVLOG(1) << ENDPOINT << "Error: " << QuicErrorCodeToString(error)
            << " detail: " << detailed_error_;
   set_error(error);
   visitor_->OnError(this);
diff --git a/src/net/quic/core/quic_framer.h b/src/net/quic/core/quic_framer.h
index 55d3226..60d71d8 100644
--- a/src/net/quic/core/quic_framer.h
+++ b/src/net/quic/core/quic_framer.h
@@ -18,7 +18,7 @@
 #include "base/macros.h"
 #include "base/strings/string_piece.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
@@ -46,8 +46,6 @@ const size_t kQuicMaxStreamOffsetSize = 8;
 // Number of bytes reserved to store payload length in stream frame.
 const size_t kQuicStreamPayloadLengthSize = 2;
 
-// Size in bytes of the entropy hash sent in ack frames.
-const size_t kQuicEntropyHashSize = 1;
 // Size in bytes reserved for the delta time of the largest observed
 // packet number in ack frames.
 const size_t kQuicDeltaTimeLargestObservedSize = 2;
@@ -61,8 +59,6 @@ const size_t kNumberOfAckBlocksSize = 1;
 const size_t kMaxNackRanges = (1 << (kNumberOfNackRangesSize * 8)) - 1;
 // Maximum number of ack blocks that can fit within an ack frame.
 const size_t kMaxAckBlocks = (1 << (kNumberOfAckBlocksSize * 8)) - 1;
-// Size in bytes reserved for the number of revived packets in ack frames.
-const size_t kNumberOfRevivedPacketsSize = 1;
 
 // This class receives callbacks from the framer when packets
 // are processed.
@@ -150,21 +146,6 @@ class NET_EXPORT_PRIVATE QuicFramerVisitorInterface {
   virtual void OnPacketComplete() = 0;
 };
 
-// This class calculates the received entropy of the ack packet being
-// framed, should it get truncated.
-class NET_EXPORT_PRIVATE QuicReceivedEntropyHashCalculatorInterface {
- public:
-  virtual ~QuicReceivedEntropyHashCalculatorInterface() {}
-
-  // When an ack frame gets truncated while being framed the received
-  // entropy of the ack frame needs to be calculated since the some of the
-  // missing packets are not added and the largest observed might be lowered.
-  // This should return the received entropy hash of the packets received up to
-  // and including |packet_number|.
-  virtual QuicPacketEntropyHash EntropyHash(
-      QuicPacketNumber packet_number) const = 0;
-};
-
 // Class for parsing and constructing QUIC packets.  It has a
 // QuicFramerVisitorInterface that is called when packets are parsed.
 class NET_EXPORT_PRIVATE QuicFramer {
@@ -202,15 +183,6 @@ class NET_EXPORT_PRIVATE QuicFramer {
     quic_version_ = version;
   }
 
-  // Set entropy calculator to be called from the framer when it needs the
-  // entropy of a truncated ack frame. An entropy calculator must be set or else
-  // the framer will likely crash. If this is called multiple times, only the
-  // last calculator will be used.
-  void set_received_entropy_calculator(
-      QuicReceivedEntropyHashCalculatorInterface* entropy_calculator) {
-    entropy_calculator_ = entropy_calculator;
-  }
-
   QuicErrorCode error() const { return error_; }
 
   // Pass a UDP packet into the framer for parsing.
@@ -281,12 +253,12 @@ class NET_EXPORT_PRIVATE QuicFramer {
                          char* buffer,
                          size_t packet_length);
 
-  // Returns a new public reset packet, owned by the caller.
-  static QuicEncryptedPacket* BuildPublicResetPacket(
+  // Returns a new public reset packet.
+  static std::unique_ptr<QuicEncryptedPacket> BuildPublicResetPacket(
       const QuicPublicResetPacket& packet);
 
-  // Returns a new version negotiation packet, owned by the caller.
-  static QuicEncryptedPacket* BuildVersionNegotiationPacket(
+  // Returns a new version negotiation packet.
+  static std::unique_ptr<QuicEncryptedPacket> BuildVersionNegotiationPacket(
       QuicConnectionId connection_id,
       const QuicVersionVector& versions);
 
@@ -365,9 +337,6 @@ class NET_EXPORT_PRIVATE QuicFramer {
 
   Perspective perspective() const { return perspective_; }
 
-  static QuicPacketEntropyHash GetPacketEntropyHash(
-      const QuicPacketHeader& header);
-
   // Called when a PATH_CLOSED frame has been sent/received on |path_id|.
   void OnPathClosed(QuicPathId path_id);
 
@@ -383,28 +352,6 @@ class NET_EXPORT_PRIVATE QuicFramer {
     AckFrameInfo(const AckFrameInfo& other);
     ~AckFrameInfo();
 
-    // The maximum delta between ranges.
-    QuicPacketNumber max_delta;
-    // Nack ranges starting with start packet numbers and lengths.
-    NackRangeMap nack_ranges;
-  };
-
-  struct AckBlock {
-    AckBlock(uint8_t gap, QuicPacketNumber length);
-    AckBlock(const AckBlock& other);
-    ~AckBlock();
-
-    // Gap to the next ack block.
-    uint8_t gap;
-    // Length of this ack block.
-    QuicPacketNumber length;
-  };
-
-  struct NewAckFrameInfo {
-    NewAckFrameInfo();
-    NewAckFrameInfo(const NewAckFrameInfo& other);
-    ~NewAckFrameInfo();
-
     // The maximum ack block length.
     QuicPacketNumber max_block_length;
     // Length of first ack block.
@@ -433,11 +380,6 @@ class NET_EXPORT_PRIVATE QuicFramer {
   bool ProcessUnauthenticatedHeader(QuicDataReader* encrypted_reader,
                                     QuicPacketHeader* header);
 
-  // Processes the authenticated portion of the header into |header| from
-  // the current QuicDataReader.  Returns true on success, false on failure.
-  bool ProcessAuthenticatedHeader(QuicDataReader* reader,
-                                  QuicPacketHeader* header);
-
   bool ProcessPathId(QuicDataReader* reader, QuicPathId* path_id);
   bool ProcessPacketSequenceNumber(QuicDataReader* reader,
                                    QuicPacketNumberLength packet_number_length,
@@ -450,9 +392,6 @@ class NET_EXPORT_PRIVATE QuicFramer {
   bool ProcessAckFrame(QuicDataReader* reader,
                        uint8_t frame_type,
                        QuicAckFrame* frame);
-  bool ProcessNewAckFrame(QuicDataReader* reader,
-                          uint8_t frame_type,
-                          QuicAckFrame* frame);
   bool ProcessTimestampsInAckFrame(QuicDataReader* reader, QuicAckFrame* frame);
   bool ProcessStopWaitingFrame(QuicDataReader* reader,
                                const QuicPacketHeader& public_header,
@@ -497,12 +436,12 @@ class NET_EXPORT_PRIVATE QuicFramer {
   // Computes the wire size in bytes of time stamps in |ack|.
   size_t GetAckFrameTimeStampSize(const QuicAckFrame& ack);
 
-  // Computes the wire size in bytes of the |ack| frame, assuming no truncation.
+  // Computes the wire size in bytes of the |ack| frame.
   size_t GetAckFrameSize(const QuicAckFrame& ack,
                          QuicPacketNumberLength packet_number_length);
 
   // Computes the wire size in bytes of the |ack| frame.
-  size_t GetNewAckFrameSize(const QuicAckFrame& ack);
+  size_t GetAckFrameSize(const QuicAckFrame& ack);
 
   // Computes the wire size in bytes of the payload of |frame|.
   size_t ComputeFrameLength(const QuicFrame& frame,
@@ -526,16 +465,11 @@ class NET_EXPORT_PRIVATE QuicFramer {
 
   static AckFrameInfo GetAckFrameInfo(const QuicAckFrame& frame);
 
-  static NewAckFrameInfo GetNewAckFrameInfo(const QuicAckFrame& frame);
-
   // The Append* methods attempt to write the provided header or frame using the
   // |writer|, and return true if successful.
 
-  bool AppendAckFrameAndTypeByte(const QuicPacketHeader& header,
-                                 const QuicAckFrame& frame,
+  bool AppendAckFrameAndTypeByte(const QuicAckFrame& frame,
                                  QuicDataWriter* builder);
-  bool AppendNewAckFrameAndTypeByte(const QuicAckFrame& frame,
-                                    QuicDataWriter* builder);
   bool AppendTimestampToAckFrame(const QuicAckFrame& frame,
                                  QuicDataWriter* builder);
   bool AppendStopWaitingFrame(const QuicPacketHeader& header,
@@ -561,18 +495,12 @@ class NET_EXPORT_PRIVATE QuicFramer {
 
   std::string detailed_error_;
   QuicFramerVisitorInterface* visitor_;
-  QuicReceivedEntropyHashCalculatorInterface* entropy_calculator_;
   QuicErrorCode error_;
   // Set of closed paths. A path is considered as closed if a PATH_CLOSED frame
   // has been sent/received.
   // TODO(fayang): this set is never cleaned up. A possible improvement is to
   // use intervals.
   std::unordered_set<QuicPathId> closed_paths_;
-  // Map mapping path id to packet number of last successfully decrypted
-  // received packet.
-  // TODO(ianswett): Remove when
-  // gfe2_reloadable_flag_quic_packet_numbers_largest_received is deprecated.
-  std::unordered_map<QuicPathId, QuicPacketNumber> last_packet_numbers_;
   // Updated by ProcessPacketHeader when it succeeds.
   QuicPacketNumber last_packet_number_;
   // Map mapping path id to packet number of largest successfully decrypted
diff --git a/src/net/quic/core/quic_header_list.cc b/src/net/quic/core/quic_header_list.cc
index 15cd5ad..269b439 100644
--- a/src/net/quic/core/quic_header_list.cc
+++ b/src/net/quic/core/quic_header_list.cc
@@ -6,9 +6,14 @@
 
 using std::string;
 
+#include "net/quic/core/quic_flags.h"
+#include "net/quic/core/quic_packets.h"
+
 namespace net {
 
-QuicHeaderList::QuicHeaderList() : uncompressed_header_bytes_(0) {}
+QuicHeaderList::QuicHeaderList()
+    : max_uncompressed_header_bytes_(kDefaultMaxUncompressedHeaderSize),
+      uncompressed_header_bytes_(0) {}
 
 QuicHeaderList::QuicHeaderList(QuicHeaderList&& other) = default;
 
@@ -27,11 +32,26 @@ void QuicHeaderList::OnHeaderBlockStart() {
 }
 
 void QuicHeaderList::OnHeader(base::StringPiece name, base::StringPiece value) {
-  header_list_.emplace_back(name.as_string(), value.as_string());
+  // Avoid infinte buffering of headers. No longer store headers
+  // once the current headers are over the limit.
+  if (!FLAGS_quic_limit_uncompressed_headers ||
+      uncompressed_header_bytes_ == 0 || !header_list_.empty()) {
+    header_list_.emplace_back(name.as_string(), value.as_string());
+  }
 }
 
 void QuicHeaderList::OnHeaderBlockEnd(size_t uncompressed_header_bytes) {
+  OnHeaderBlockEnd(uncompressed_header_bytes, uncompressed_header_bytes);
+}
+
+void QuicHeaderList::OnHeaderBlockEnd(size_t uncompressed_header_bytes,
+                                      size_t compressed_header_bytes) {
   uncompressed_header_bytes_ = uncompressed_header_bytes;
+  compressed_header_bytes_ = compressed_header_bytes;
+  if (FLAGS_quic_limit_uncompressed_headers &&
+      uncompressed_header_bytes_ > max_uncompressed_header_bytes_) {
+    Clear();
+  }
 }
 
 void QuicHeaderList::Clear() {
diff --git a/src/net/quic/core/quic_header_list.h b/src/net/quic/core/quic_header_list.h
index 7949965..e74275b 100644
--- a/src/net/quic/core/quic_header_list.h
+++ b/src/net/quic/core/quic_header_list.h
@@ -5,6 +5,7 @@
 #ifndef NET_QUIC_QUIC_HEADER_LIST_H_
 #define NET_QUIC_QUIC_HEADER_LIST_H_
 
+#include <algorithm>
 #include <deque>
 #include <functional>
 
@@ -33,7 +34,8 @@ class NET_EXPORT_PRIVATE QuicHeaderList : public SpdyHeadersHandlerInterface {
   void OnHeaderBlockStart() override;
   void OnHeader(base::StringPiece name, base::StringPiece value) override;
   void OnHeaderBlockEnd(size_t uncompressed_header_bytes) override;
-
+  void OnHeaderBlockEnd(size_t uncompressed_header_bytes,
+                        size_t compressed_header_bytes) override;
   void Clear();
 
   const_iterator begin() const { return header_list_.begin(); }
@@ -44,13 +46,29 @@ class NET_EXPORT_PRIVATE QuicHeaderList : public SpdyHeadersHandlerInterface {
     return uncompressed_header_bytes_;
   }
 
+  size_t compressed_header_bytes() const { return compressed_header_bytes_; }
+
+  void set_max_uncompressed_header_bytes(size_t max_uncompressed_header_bytes) {
+    max_uncompressed_header_bytes_ = max_uncompressed_header_bytes;
+  }
+
   std::string DebugString() const;
 
  private:
   std::deque<std::pair<std::string, std::string>> header_list_;
+  size_t max_uncompressed_header_bytes_;
   size_t uncompressed_header_bytes_;
+  size_t compressed_header_bytes_;
 };
 
+inline bool operator==(const QuicHeaderList& l1, const QuicHeaderList& l2) {
+  auto pred = [](const std::pair<std::string, std::string>& p1,
+                 const std::pair<std::string, std::string>& p2) {
+    return p1.first == p2.first && p1.second == p2.second;
+  };
+  return std::equal(l1.begin(), l1.end(), l2.begin(), pred);
+}
+
 }  // namespace net
 
 #endif  // NET_QUIC_QUIC_HEADER_LIST_H_
diff --git a/src/net/quic/core/quic_headers_stream.cc b/src/net/quic/core/quic_headers_stream.cc
index 5b011e8..7f890f6 100644
--- a/src/net/quic/core/quic_headers_stream.cc
+++ b/src/net/quic/core/quic_headers_stream.cc
@@ -4,6 +4,8 @@
 
 #include "net/quic/core/quic_headers_stream.h"
 
+#include <algorithm>
+#include <string>
 #include <utility>
 
 #include "base/macros.h"
@@ -13,12 +15,12 @@
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_header_list.h"
+#include "net/quic/core/quic_server_session_base.h"
 #include "net/quic/core/quic_spdy_session.h"
 #include "net/quic/core/quic_time.h"
 #include "net/spdy/spdy_protocol.h"
 
 using base::StringPiece;
-using net::HTTP2;
 using net::SpdyFrameType;
 using std::string;
 
@@ -102,38 +104,14 @@ QuicHeadersStream::HpackDebugVisitor::HpackDebugVisitor() {}
 
 QuicHeadersStream::HpackDebugVisitor::~HpackDebugVisitor() {}
 
-// A SpdyFramer visitor which passed SYN_STREAM and SYN_REPLY frames to
-// the QuicSpdyStream, and closes the connection if any unexpected frames
-// are received.
+// A SpdyFramerVisitor that passes HEADERS frames to the QuicSpdyStream, and
+// closes the connection if any unexpected frames are received.
 class QuicHeadersStream::SpdyFramerVisitor
     : public SpdyFramerVisitorInterface,
       public SpdyFramerDebugVisitorInterface {
  public:
   explicit SpdyFramerVisitor(QuicHeadersStream* stream) : stream_(stream) {}
 
-  // SpdyFramerVisitorInterface implementation
-  void OnSynStream(SpdyStreamId stream_id,
-                   SpdyStreamId associated_stream_id,
-                   SpdyPriority priority,
-                   bool fin,
-                   bool unidirectional) override {
-    CloseConnection("SPDY SYN_STREAM frame received.");
-  }
-
-  void OnSynReply(SpdyStreamId stream_id, bool fin) override {
-    CloseConnection("SPDY SYN_REPLY frame received.");
-  }
-
-  bool OnControlFrameHeaderData(SpdyStreamId stream_id,
-                                const char* header_data,
-                                size_t len) override {
-    if (!stream_->IsConnected()) {
-      return false;
-    }
-    stream_->OnControlFrameHeaderData(stream_id, header_data, len);
-    return true;
-  }
-
   void OnStreamFrameData(SpdyStreamId stream_id,
                          const char* data,
                          size_t len) override {
@@ -144,8 +122,8 @@ class QuicHeadersStream::SpdyFramerVisitor
   }
 
   void OnStreamEnd(SpdyStreamId stream_id) override {
-    // The framer invokes OnStreamEnd after processing a SYN_STREAM
-    // or SYN_REPLY frame that had the fin bit set.
+    // The framer invokes OnStreamEnd after processing a frame that had the fin
+    // bit set.
   }
 
   void OnStreamPadding(SpdyStreamId stream_id, size_t len) override {
@@ -196,8 +174,28 @@ class QuicHeadersStream::SpdyFramerVisitor
       case SETTINGS_HEADER_TABLE_SIZE:
         stream_->UpdateHeaderEncoderTableSize(value);
         break;
+      case SETTINGS_ENABLE_PUSH:
+        if (FLAGS_quic_enable_server_push_by_default &&
+            stream_->session()->perspective() == Perspective::IS_SERVER) {
+          // See rfc7540, Section 6.5.2.
+          if (value > 1) {
+            CloseConnection("Invalid value for SETTINGS_ENABLE_PUSH: " +
+                            base::IntToString(value));
+            return;
+          }
+          stream_->UpdateEnableServerPush(value > 0);
+          break;
+        } else {
+          CloseConnection("Unsupported field of HTTP/2 SETTINGS frame: " +
+                          base::IntToString(id));
+        }
+        break;
       // TODO(fayang): Need to support SETTINGS_MAX_HEADER_LIST_SIZE when
       // clients are actually sending it.
+      case SETTINGS_MAX_HEADER_LIST_SIZE:
+        if (FLAGS_quic_send_max_header_list_size) {
+          break;
+        }
       default:
         CloseConnection("Unsupported field of HTTP/2 SETTINGS frame: " +
                         base::IntToString(id));
@@ -297,6 +295,12 @@ class QuicHeadersStream::SpdyFramerVisitor
     }
   }
 
+  void set_max_uncompressed_header_bytes(
+      size_t set_max_uncompressed_header_bytes) {
+    header_list_.set_max_uncompressed_header_bytes(
+        set_max_uncompressed_header_bytes);
+  }
+
  private:
   void CloseConnection(const string& details) {
     if (stream_->IsConnected()) {
@@ -313,7 +317,7 @@ class QuicHeadersStream::SpdyFramerVisitor
 };
 
 QuicHeadersStream::QuicHeadersStream(QuicSpdySession* session)
-    : ReliableQuicStream(kHeadersStreamId, session),
+    : QuicStream(kHeadersStreamId, session),
       spdy_session_(session),
       stream_id_(kInvalidStreamId),
       promised_stream_id_(kInvalidStreamId),
@@ -323,7 +327,6 @@ QuicHeadersStream::QuicHeadersStream(QuicSpdySession* session)
       supports_push_promise_(session->perspective() == Perspective::IS_CLIENT),
       cur_max_timestamp_(QuicTime::Zero()),
       prev_max_timestamp_(QuicTime::Zero()),
-      spdy_framer_(HTTP2),
       spdy_framer_visitor_(new SpdyFramerVisitor(this)) {
   spdy_framer_.set_visitor(spdy_framer_visitor_.get());
   spdy_framer_.set_debug_visitor(spdy_framer_visitor_.get());
@@ -370,60 +373,79 @@ size_t QuicHeadersStream::WritePushPromise(QuicStreamId original_stream_id,
   return frame.size();
 }
 
+void QuicHeadersStream::WriteDataFrame(
+    QuicStreamId id,
+    StringPiece data,
+    bool fin,
+    QuicAckListenerInterface* ack_notifier_delegate) {
+  SpdyDataIR spdy_data(id, data);
+  spdy_data.set_fin(fin);
+  SpdySerializedFrame frame(spdy_framer_.SerializeFrame(spdy_data));
+  scoped_refptr<ForceHolAckListener> ack_listener;
+  if (ack_notifier_delegate != nullptr) {
+    ack_listener = new ForceHolAckListener(ack_notifier_delegate,
+                                           frame.size() - data.length());
+  }
+  // Use buffered writes so that coherence of framing is preserved
+  // between streams.
+  WriteOrBufferData(StringPiece(frame.data(), frame.size()), false,
+                    ack_listener.get());
+}
+
 QuicConsumedData QuicHeadersStream::WritevStreamData(
     QuicStreamId id,
     QuicIOVector iov,
     QuicStreamOffset offset,
     bool fin,
     QuicAckListenerInterface* ack_notifier_delegate) {
-  const size_t max_len = kSpdyInitialFrameSizeLimit -
-                         SpdyConstants::GetDataFrameMinimumSize(HTTP2);
+  const size_t max_len =
+      kSpdyInitialFrameSizeLimit - SpdyConstants::kDataFrameMinimumSize;
 
   QuicConsumedData result(0, false);
   size_t total_length = iov.total_length;
 
+  if (total_length == 0 && fin) {
+    WriteDataFrame(id, StringPiece(), true, ack_notifier_delegate);
+    result.fin_consumed = true;
+    return result;
+  }
+
   // Encapsulate the data into HTTP/2 DATA frames.  The outer loop
   // handles each element of the source iov, the inner loop handles
-  // the possibility of fragmenting eacho of those into multiple DATA
+  // the possibility of fragmenting each of those into multiple DATA
   // frames, as the DATA frames have a max size of 16KB.
   for (int i = 0; i < iov.iov_count; i++) {
-    size_t offset = 0;
+    size_t src_iov_offset = 0;
     const struct iovec* src_iov = &iov.iov[i];
     do {
-      size_t len =
-          std::min(std::min(src_iov->iov_len - offset, max_len), total_length);
-      char* data = static_cast<char*>(src_iov->iov_base) + offset;
-      SpdyDataIR spdy_data(id, StringPiece(data, len));
+      if (queued_data_bytes() > 0) {
+        // Limit the amount of buffering to the minimum needed to
+        // preserve framing.
+        return result;
+      }
+      size_t len = std::min(
+          std::min(src_iov->iov_len - src_iov_offset, max_len), total_length);
+      char* data = static_cast<char*>(src_iov->iov_base) + src_iov_offset;
+      src_iov_offset += len;
       offset += len;
-      // fin handling, set it only it only very last generated HTTP/2
-      // DATA frame.
+      // fin handling, only set it for the final HTTP/2 DATA frame.
       bool last_iov = i == iov.iov_count - 1;
-      bool last_fragment_within_iov = offset >= src_iov->iov_len;
+      bool last_fragment_within_iov = src_iov_offset >= src_iov->iov_len;
       bool frame_fin = (last_iov && last_fragment_within_iov) ? fin : false;
-      spdy_data.set_fin(frame_fin);
+      WriteDataFrame(id, StringPiece(data, len), frame_fin,
+                     ack_notifier_delegate);
+      result.bytes_consumed += len;
       if (frame_fin) {
         result.fin_consumed = true;
       }
-      SpdySerializedFrame frame(spdy_framer_.SerializeFrame(spdy_data));
-      DVLOG(1) << "Encapsulating in DATA frame for stream " << id << " len "
-               << len << " fin " << spdy_data.fin() << " remaining "
-               << src_iov->iov_len - offset;
-
-      scoped_refptr<ForceHolAckListener> ack_listener;
-      if (ack_notifier_delegate != nullptr) {
-        ack_listener =
-            new ForceHolAckListener(ack_notifier_delegate, frame.size() - len);
-      }
-
-      WriteOrBufferData(StringPiece(frame.data(), frame.size()), false,
-                        ack_listener.get());
-      result.bytes_consumed += len;
+      DCHECK_GE(total_length, len);
       total_length -= len;
       if (total_length <= 0) {
         return result;
       }
-    } while (offset < src_iov->iov_len);
+    } while (src_iov_offset < src_iov->iov_len);
   }
+
   return result;
 }
 
@@ -446,9 +468,16 @@ void QuicHeadersStream::OnDataAvailable() {
       return;
     }
     sequencer()->MarkConsumed(iov.iov_len);
+    MaybeReleaseSequencerBuffer();
   }
 }
 
+void QuicHeadersStream::set_max_uncompressed_header_bytes(
+    size_t set_max_uncompressed_header_bytes) {
+  spdy_framer_visitor_->set_max_uncompressed_header_bytes(
+      set_max_uncompressed_header_bytes);
+}
+
 void QuicHeadersStream::OnHeaders(SpdyStreamId stream_id,
                                   bool has_priority,
                                   SpdyPriority priority,
@@ -482,55 +511,6 @@ void QuicHeadersStream::OnPushPromise(SpdyStreamId stream_id,
   promised_stream_id_ = promised_stream_id;
 }
 
-void QuicHeadersStream::OnControlFrameHeaderData(SpdyStreamId stream_id,
-                                                 const char* header_data,
-                                                 size_t len) {
-  DCHECK_EQ(stream_id_, stream_id);
-  if (len == 0) {
-    DCHECK_NE(0u, stream_id_);
-    DCHECK_NE(0u, frame_len_);
-    if (prev_max_timestamp_ > cur_max_timestamp_) {
-      // prev_max_timestamp_ > cur_max_timestamp_ implies that
-      // headers from lower numbered streams actually came off the
-      // wire after headers for the current stream, hence there was
-      // HOL blocking.
-      QuicTime::Delta delta = prev_max_timestamp_ - cur_max_timestamp_;
-      DVLOG(1) << "stream " << stream_id
-               << ": Net.QuicSession.HeadersHOLBlockedTime "
-               << delta.ToMilliseconds();
-      spdy_session_->OnHeadersHeadOfLineBlocking(delta);
-    }
-    prev_max_timestamp_ = std::max(prev_max_timestamp_, cur_max_timestamp_);
-    cur_max_timestamp_ = QuicTime::Zero();
-    if (promised_stream_id_ == kInvalidStreamId) {
-      spdy_session_->OnStreamHeadersComplete(stream_id_, fin_, frame_len_);
-    } else {
-      spdy_session_->OnPromiseHeadersComplete(stream_id_, promised_stream_id_,
-                                              frame_len_);
-    }
-    if (uncompressed_frame_len_ != 0) {
-      int compression_pct = 100 - (100 * frame_len_) / uncompressed_frame_len_;
-      DVLOG(1) << "Net.QuicHpackDecompressionPercentage: " << compression_pct;
-      UMA_HISTOGRAM_PERCENTAGE("Net.QuicHpackDecompressionPercentage",
-                               compression_pct);
-    }
-    // Reset state for the next frame.
-    promised_stream_id_ = kInvalidStreamId;
-    stream_id_ = kInvalidStreamId;
-    fin_ = false;
-    frame_len_ = 0;
-    uncompressed_frame_len_ = 0;
-  } else {
-    uncompressed_frame_len_ += len;
-    if (promised_stream_id_ == kInvalidStreamId) {
-      spdy_session_->OnStreamHeaders(stream_id_, StringPiece(header_data, len));
-    } else {
-      spdy_session_->OnPromiseHeaders(stream_id_,
-                                      StringPiece(header_data, len));
-    }
-  }
-}
-
 void QuicHeadersStream::OnHeaderList(const QuicHeaderList& header_list) {
   DVLOG(1) << "Received header list for stream " << stream_id_ << ": "
            << header_list.DebugString();
@@ -593,6 +573,26 @@ void QuicHeadersStream::UpdateHeaderEncoderTableSize(uint32_t value) {
   spdy_framer_.UpdateHeaderEncoderTableSize(value);
 }
 
+void QuicHeadersStream::UpdateEnableServerPush(bool value) {
+  spdy_session_->set_server_push_enabled(value);
+}
+
+void QuicHeadersStream::MaybeReleaseSequencerBuffer() {
+  if (FLAGS_quic_headers_stream_release_sequencer_buffer &&
+      spdy_session_->ShouldReleaseHeadersStreamSequencerBuffer()) {
+    sequencer()->ReleaseBufferIfEmpty();
+  }
+}
+
+size_t QuicHeadersStream::SendMaxHeaderListSize(size_t value) {
+  SpdySettingsIR settings_frame;
+  settings_frame.AddSetting(SETTINGS_MAX_HEADER_LIST_SIZE, false, false, value);
+
+  SpdySerializedFrame frame(spdy_framer_.SerializeFrame(settings_frame));
+  WriteOrBufferData(StringPiece(frame.data(), frame.size()), false, nullptr);
+  return frame.size();
+}
+
 bool QuicHeadersStream::OnDataFrameHeader(QuicStreamId stream_id,
                                           size_t length,
                                           bool fin) {
diff --git a/src/net/quic/core/quic_headers_stream.h b/src/net/quic/core/quic_headers_stream.h
index db1b123..9790766 100644
--- a/src/net/quic/core/quic_headers_stream.h
+++ b/src/net/quic/core/quic_headers_stream.h
@@ -2,8 +2,8 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 
-#ifndef NET_QUIC_QUIC_HEADERS_STREAM_H_
-#define NET_QUIC_QUIC_HEADERS_STREAM_H_
+#ifndef NET_QUIC_CORE_QUIC_HEADERS_STREAM_H_
+#define NET_QUIC_CORE_QUIC_HEADERS_STREAM_H_
 
 #include <stddef.h>
 
@@ -12,8 +12,8 @@
 #include "base/macros.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/quic_header_list.h"
-#include "net/quic/core/quic_protocol.h"
-#include "net/quic/core/reliable_quic_stream.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_stream.h"
 #include "net/spdy/spdy_framer.h"
 
 namespace net {
@@ -28,7 +28,7 @@ class QuicHeadersStreamPeer;
 // over a reserved reliable stream with the id 3.  Each endpoint
 // (client and server) will allocate an instance of QuicHeadersStream
 // to send and receive headers.
-class NET_EXPORT_PRIVATE QuicHeadersStream : public ReliableQuicStream {
+class NET_EXPORT_PRIVATE QuicHeadersStream : public QuicStream {
  public:
   class NET_EXPORT_PRIVATE HpackDebugVisitor {
    public:
@@ -73,7 +73,7 @@ class NET_EXPORT_PRIVATE QuicHeadersStream : public ReliableQuicStream {
       bool fin,
       QuicAckListenerInterface* ack_notifier_delegate);
 
-  // ReliableQuicStream implementation
+  // QuicStream implementation
   void OnDataAvailable() override;
 
   bool supports_push_promise() { return supports_push_promise_; }
@@ -91,12 +91,25 @@ class NET_EXPORT_PRIVATE QuicHeadersStream : public ReliableQuicStream {
   // willing to use to decode header blocks.
   void UpdateHeaderEncoderTableSize(uint32_t value);
 
+  // Called when SETTINGS_ENABLE_PUSH is received, only supported on
+  // server side.
+  void UpdateEnableServerPush(bool value);
+
+  // Release underlying buffer if allowed.
+  void MaybeReleaseSequencerBuffer();
+
+  // Sends SETTINGS_MAX_HEADER_LIST_SIZE SETTINGS frame.
+  size_t SendMaxHeaderListSize(size_t value);
+
   // Sets how much encoded data the hpack decoder of spdy_framer_ is willing to
   // buffer.
   void set_max_decode_buffer_size_bytes(size_t max_decode_buffer_size_bytes) {
     spdy_framer_.set_max_decode_buffer_size_bytes(max_decode_buffer_size_bytes);
   }
 
+  void set_max_uncompressed_header_bytes(
+      size_t set_max_uncompressed_header_bytes);
+
  private:
   friend class test::QuicHeadersStreamPeer;
 
@@ -115,16 +128,6 @@ class NET_EXPORT_PRIVATE QuicHeadersStream : public ReliableQuicStream {
                      SpdyStreamId promised_stream_id,
                      bool end);
 
-  // Called when a chunk of header data is available. This is called
-  // after OnHeaders.
-  // |stream_id| The stream receiving the header data.
-  // |header_data| A buffer containing the header data chunk received.
-  // |len| The length of the header data buffer. A length of zero indicates
-  //       that the header data block has been completely sent.
-  void OnControlFrameHeaderData(SpdyStreamId stream_id,
-                                const char* header_data,
-                                size_t len);
-
   // Called when the complete list of headers is available.
   void OnHeaderList(const QuicHeaderList& header_list);
 
@@ -132,10 +135,15 @@ class NET_EXPORT_PRIVATE QuicHeadersStream : public ReliableQuicStream {
   void OnCompressedFrameSize(size_t frame_len);
 
   // For force HOL blocking, where stream frames from all streams are
-  // plumbed through headers stream as HTTP/2 data frames.  Return false
-  // if force_hol_blocking_ is false;
+  // plumbed through headers stream as HTTP/2 data frames.
+  // The following two return false if force_hol_blocking_ is false.
   bool OnDataFrameHeader(QuicStreamId stream_id, size_t length, bool fin);
   bool OnStreamFrameData(QuicStreamId stream_id, const char* data, size_t len);
+  // Helper for |WritevStreamData()|.
+  void WriteDataFrame(QuicStreamId stream_id,
+                      base::StringPiece data,
+                      bool fin,
+                      QuicAckListenerInterface* ack_notifier_delegate);
 
   // Returns true if the session is still connected.
   bool IsConnected();
@@ -163,12 +171,9 @@ class NET_EXPORT_PRIVATE QuicHeadersStream : public ReliableQuicStream {
   SpdyFramer spdy_framer_;
   std::unique_ptr<SpdyFramerVisitor> spdy_framer_visitor_;
 
-  // Either empty, or contains the complete list of headers.
-  QuicHeaderList header_list_;
-
   DISALLOW_COPY_AND_ASSIGN(QuicHeadersStream);
 };
 
 }  // namespace net
 
-#endif  // NET_QUIC_QUIC_HEADERS_STREAM_H_
+#endif  // NET_QUIC_CORE_QUIC_HEADERS_STREAM_H_
diff --git a/src/net/quic/core/quic_multipath_sent_packet_manager.cc b/src/net/quic/core/quic_multipath_sent_packet_manager.cc
index 0800a6a..45c8805 100644
--- a/src/net/quic/core/quic_multipath_sent_packet_manager.cc
+++ b/src/net/quic/core/quic_multipath_sent_packet_manager.cc
@@ -10,7 +10,6 @@
 #include "net/quic/core/quic_bug_tracker.h"
 
 using std::string;
-using std::max;
 
 namespace net {
 
@@ -129,7 +128,7 @@ bool QuicMultipathSentPacketManager::HasPendingRetransmissions() const {
   return path_manager != nullptr && path_manager->HasPendingRetransmissions();
 }
 
-PendingRetransmission
+QuicPendingRetransmission
 QuicMultipathSentPacketManager::NextPendingRetransmission() {
   // TODO(fayang): Move pending_retransmissions_ from path sent packet manager
   // to multipath sent packet manager.
@@ -138,9 +137,9 @@ QuicMultipathSentPacketManager::NextPendingRetransmission() {
   if (path_manager == nullptr) {
     OnUnrecoverablePathError(kDefaultPathId);
     QuicFrames retransmittable_frames;
-    return PendingRetransmission(kInvalidPathId, 0u, NOT_RETRANSMISSION,
-                                 retransmittable_frames, false, 0,
-                                 ENCRYPTION_NONE, PACKET_1BYTE_PACKET_NUMBER);
+    return QuicPendingRetransmission(
+        kInvalidPathId, 0u, NOT_RETRANSMISSION, retransmittable_frames, false,
+        0, ENCRYPTION_NONE, PACKET_1BYTE_PACKET_NUMBER);
   }
   return path_manager->NextPendingRetransmission();
 }
@@ -287,9 +286,9 @@ QuicPacketCount QuicMultipathSentPacketManager::EstimateMaxPacketsInFlight(
   for (PathSentPacketManagerInfo path_manager_info : path_managers_info_) {
     if (path_manager_info.manager != nullptr) {
       max_packets_in_flight =
-          max(max_packets_in_flight,
-              path_manager_info.manager->EstimateMaxPacketsInFlight(
-                  max_packet_length));
+          std::max(max_packets_in_flight,
+                   path_manager_info.manager->EstimateMaxPacketsInFlight(
+                       max_packet_length));
     }
   }
   DCHECK_LT(0u, max_packets_in_flight);
@@ -354,12 +353,6 @@ void QuicMultipathSentPacketManager::OnConnectionMigration(
   path_manager->OnConnectionMigration(path_id, type);
 }
 
-bool QuicMultipathSentPacketManager::IsHandshakeConfirmed() const {
-  QuicSentPacketManagerInterface* path_manager =
-      MaybeGetSentPacketManagerForActivePath(kDefaultPathId);
-  return path_manager != nullptr && path_manager->IsHandshakeConfirmed();
-}
-
 void QuicMultipathSentPacketManager::SetDebugDelegate(
     DebugDelegate* debug_delegate) {
   for (PathSentPacketManagerInfo path_manager_info : path_managers_info_) {
@@ -527,4 +520,14 @@ void QuicMultipathSentPacketManager::OnApplicationLimited() {
   }
 }
 
+const SendAlgorithmInterface* QuicMultipathSentPacketManager::GetSendAlgorithm()
+    const {
+  QuicSentPacketManagerInterface* path_manager =
+      MaybeGetSentPacketManagerForActivePath(kDefaultPathId);
+  if (path_manager == nullptr) {
+    return nullptr;
+  }
+  return path_manager->GetSendAlgorithm();
+}
+
 }  // namespace net
diff --git a/src/net/quic/core/quic_multipath_sent_packet_manager.h b/src/net/quic/core/quic_multipath_sent_packet_manager.h
index c805280..b516248 100644
--- a/src/net/quic/core/quic_multipath_sent_packet_manager.h
+++ b/src/net/quic/core/quic_multipath_sent_packet_manager.h
@@ -8,7 +8,8 @@
 #include <vector>
 
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_connection_close_delegate_interface.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_sent_packet_manager.h"
 #include "net/quic/core/quic_sent_packet_manager_interface.h"
 
@@ -30,7 +31,7 @@ class NET_EXPORT_PRIVATE QuicMultipathSentPacketManager
     : public QuicSentPacketManagerInterface {
  public:
   // Multipath sent packet manager takes ownership of |manager|.
-  explicit QuicMultipathSentPacketManager(
+  QuicMultipathSentPacketManager(
       QuicSentPacketManagerInterface* manager,
       QuicConnectionCloseDelegateInterface* delegate);
   ~QuicMultipathSentPacketManager() override;
@@ -73,7 +74,7 @@ class NET_EXPORT_PRIVATE QuicMultipathSentPacketManager
 
   // Retrieves the next pending retransmission.  Caller must ensure that
   // there are pending retransmissions prior to calling this function.
-  PendingRetransmission NextPendingRetransmission() override;
+  QuicPendingRetransmission NextPendingRetransmission() override;
 
   // Returns true if the any path has unacked packets.
   bool HasUnackedPackets() const override;
@@ -143,8 +144,6 @@ class NET_EXPORT_PRIVATE QuicMultipathSentPacketManager
   void OnConnectionMigration(QuicPathId path_id,
                              PeerAddressChangeType type) override;
 
-  bool IsHandshakeConfirmed() const override;
-
   // Sets debug delegate for all active paths.
   void SetDebugDelegate(DebugDelegate* debug_delegate) override;
 
@@ -168,6 +167,8 @@ class NET_EXPORT_PRIVATE QuicMultipathSentPacketManager
 
   void OnApplicationLimited() override;
 
+  const SendAlgorithmInterface* GetSendAlgorithm() const override;
+
  private:
   friend class test::QuicConnectionPeer;
   friend class test::QuicMultipathSentPacketManagerPeer;
diff --git a/src/net/quic/core/quic_packet_creator.cc b/src/net/quic/core/quic_packet_creator.cc
index a98afd2..9049c24 100644
--- a/src/net/quic/core/quic_packet_creator.cc
+++ b/src/net/quic/core/quic_packet_creator.cc
@@ -9,31 +9,26 @@
 #include "base/logging.h"
 #include "base/macros.h"
 #include "net/quic/core/crypto/crypto_protocol.h"
-#include "net/quic/core/crypto/quic_random.h"
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_data_writer.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_utils.h"
 
 using base::StringPiece;
-using std::make_pair;
-using std::max;
-using std::min;
-using std::pair;
 using std::string;
-using std::vector;
+
+// If true, enforce that QUIC CHLOs fit in one packet.
+bool FLAGS_quic_enforce_single_packet_chlo = true;
 
 namespace net {
 
 QuicPacketCreator::QuicPacketCreator(QuicConnectionId connection_id,
                                      QuicFramer* framer,
-                                     QuicRandom* random_generator,
                                      QuicBufferAllocator* buffer_allocator,
                                      DelegateInterface* delegate)
     : delegate_(delegate),
       debug_delegate_(nullptr),
       framer_(framer),
-      random_bool_source_(random_generator),
       buffer_allocator_(buffer_allocator),
       send_version_in_packet_(framer->perspective() == Perspective::IS_CLIENT),
       send_path_id_in_packet_(false),
@@ -48,14 +43,13 @@ QuicPacketCreator::QuicPacketCreator(QuicConnectionId connection_id,
               PACKET_1BYTE_PACKET_NUMBER,
               nullptr,
               0,
-              0,
               false,
               false) {
   SetMaxPacketLength(kDefaultMaxPacketSize);
 }
 
 QuicPacketCreator::~QuicPacketCreator() {
-  QuicUtils::DeleteFrames(&packet_.retransmittable_frames);
+  DeleteFrames(&packet_.retransmittable_frames);
 }
 
 void QuicPacketCreator::SetEncrypter(EncryptionLevel level,
@@ -82,17 +76,6 @@ void QuicPacketCreator::SetMaxPacketLength(QuicByteCount length) {
   max_plaintext_size_ = framer_->GetMaxPlaintextSize(max_packet_length_);
 }
 
-void QuicPacketCreator::MaybeUpdatePacketNumberLength() {
-  DCHECK(!FLAGS_quic_simple_packet_number_length_2);
-  if (!queued_frames_.empty()) {
-    // Don't change creator state if there are frames queued.
-    return;
-  }
-
-  // Update packet number length only on packet boundary.
-  packet_.packet_number_length = next_packet_number_length_;
-}
-
 // Stops serializing version of the protocol in packets sent after this call.
 // A packet that is already open might send kQuicVersionSize bytes less than the
 // maximum packet size if we stop sending version before it is serialized.
@@ -115,7 +98,7 @@ void QuicPacketCreator::SetDiversificationNonce(
 void QuicPacketCreator::UpdatePacketNumberLength(
     QuicPacketNumber least_packet_awaited_by_peer,
     QuicPacketCount max_packets_in_flight) {
-  if (FLAGS_quic_simple_packet_number_length_2 && !queued_frames_.empty()) {
+  if (!queued_frames_.empty()) {
     // Don't change creator state if there are frames queued.
     QUIC_BUG << "Called UpdatePacketNumberLength with " << queued_frames_.size()
              << " queued_frames.  First frame type:"
@@ -127,14 +110,9 @@ void QuicPacketCreator::UpdatePacketNumberLength(
   DCHECK_LE(least_packet_awaited_by_peer, packet_.packet_number + 1);
   const QuicPacketNumber current_delta =
       packet_.packet_number + 1 - least_packet_awaited_by_peer;
-  const uint64_t delta = max(current_delta, max_packets_in_flight);
-  if (FLAGS_quic_simple_packet_number_length_2) {
-    packet_.packet_number_length =
-        QuicFramer::GetMinSequenceNumberLength(delta * 4);
-  } else {
-    next_packet_number_length_ =
-        QuicFramer::GetMinSequenceNumberLength(delta * 4);
-  }
+  const uint64_t delta = std::max(current_delta, max_packets_in_flight);
+  packet_.packet_number_length =
+      QuicFramer::GetMinSequenceNumberLength(delta * 4);
 }
 
 bool QuicPacketCreator::ConsumeData(QuicStreamId id,
@@ -154,7 +132,8 @@ bool QuicPacketCreator::ConsumeData(QuicStreamId id,
       strncmp(frame->stream_frame->data_buffer,
               reinterpret_cast<const char*>(&kCHLO), sizeof(kCHLO)) == 0) {
     DCHECK_EQ(static_cast<size_t>(0), iov_offset);
-    if (frame->stream_frame->data_length < iov.iov->iov_len) {
+    if (FLAGS_quic_enforce_single_packet_chlo &&
+        frame->stream_frame->data_length < iov.iov->iov_len) {
       const string error_details = "Client hello won't fit in a single packet.";
       QUIC_BUG << error_details << " Constructed stream frame length: "
                << frame->stream_frame->data_length
@@ -209,9 +188,6 @@ void QuicPacketCreator::CreateStreamFrame(QuicStreamId id,
                                       IncludeNonceInPublicHeader(),
                                       PACKET_6BYTE_PACKET_NUMBER, offset));
 
-  if (!FLAGS_quic_simple_packet_number_length_2) {
-    MaybeUpdatePacketNumberLength();
-  }
   QUIC_BUG_IF(!HasRoomForStreamFrame(id, offset))
       << "No room for Stream frame, BytesFree: " << BytesFree()
       << " MinStreamFrameSize: "
@@ -227,7 +203,8 @@ void QuicPacketCreator::CreateStreamFrame(QuicStreamId id,
   const size_t data_size = iov.total_length - iov_offset;
   size_t min_frame_size = QuicFramer::GetMinStreamFrameSize(
       id, offset, /* last_frame_in_packet= */ true);
-  size_t bytes_consumed = min<size_t>(BytesFree() - min_frame_size, data_size);
+  size_t bytes_consumed =
+      std::min<size_t>(BytesFree() - min_frame_size, data_size);
 
   bool set_fin = fin && bytes_consumed == data_size;  // Last frame.
   UniqueStreamBuffer buffer =
@@ -255,7 +232,7 @@ void QuicPacketCreator::CopyToBuffer(QuicIOVector iov,
 
   // Unroll the first iteration that handles iov_offset.
   const size_t iov_available = iov.iov[iovnum].iov_len - iov_offset;
-  size_t copy_len = min(length, iov_available);
+  size_t copy_len = std::min(length, iov_available);
 
   // Try to prefetch the next iov if there is at least one more after the
   // current. Otherwise, it looks like an irregular access that the hardware
@@ -285,28 +262,23 @@ void QuicPacketCreator::CopyToBuffer(QuicIOVector iov,
       break;
     }
     src = static_cast<char*>(iov.iov[iovnum].iov_base);
-    copy_len = min(length, iov.iov[iovnum].iov_len);
+    copy_len = std::min(length, iov.iov[iovnum].iov_len);
   }
   QUIC_BUG_IF(length > 0) << "Failed to copy entire length to buffer.";
 }
 
 void QuicPacketCreator::ReserializeAllFrames(
-    const PendingRetransmission& retransmission,
+    const QuicPendingRetransmission& retransmission,
     char* buffer,
     size_t buffer_len) {
   DCHECK(queued_frames_.empty());
   DCHECK_EQ(0, packet_.num_padding_bytes);
   QUIC_BUG_IF(retransmission.retransmittable_frames.empty())
       << "Attempt to serialize empty packet";
-  const QuicPacketNumberLength saved_length = packet_.packet_number_length;
-  const QuicPacketNumberLength saved_next_length = next_packet_number_length_;
   const EncryptionLevel default_encryption_level = packet_.encryption_level;
 
   // Temporarily set the packet number length and change the encryption level.
   packet_.packet_number_length = retransmission.packet_number_length;
-  if (!FLAGS_quic_simple_packet_number_length_2) {
-    next_packet_number_length_ = retransmission.packet_number_length;
-  }
   packet_.num_padding_bytes = retransmission.num_padding_bytes;
   // Only preserve the original encryption level if it's a handshake packet or
   // if we haven't gone forward secure.
@@ -332,12 +304,6 @@ void QuicPacketCreator::ReserializeAllFrames(
   packet_.transmission_type = retransmission.transmission_type;
   OnSerializedPacket();
   // Restore old values.
-  if (!FLAGS_quic_simple_packet_number_length_2) {
-    // OnSerializedPacket updates the packet_number_length, so it's incorrect to
-    // restore it here.
-    packet_.packet_number_length = saved_length;
-    next_packet_number_length_ = saved_next_length;
-  }
   packet_.encryption_level = default_encryption_level;
 }
 
@@ -365,11 +331,6 @@ void QuicPacketCreator::OnSerializedPacket() {
 
   delegate_->OnSerializedPacket(&packet_);
   ClearPacket();
-  // Maximum packet size may be only enacted while no packet is currently being
-  // constructed, so here we have a good opportunity to actually change it.
-  if (CanSetMaxPacketLength()) {
-    SetMaxPacketLength(max_packet_length_);
-  }
 }
 
 void QuicPacketCreator::ClearPacket() {
@@ -414,7 +375,7 @@ void QuicPacketCreator::CreateAndSerializeStreamFrame(
   const size_t available_size =
       max_plaintext_size_ - writer.length() - min_frame_size;
   const size_t bytes_consumed =
-      min<size_t>(available_size, remaining_data_size);
+      std::min<size_t>(available_size, remaining_data_size);
 
   const bool set_fin = fin && (bytes_consumed == remaining_data_size);
   UniqueStreamBuffer stream_buffer =
@@ -449,7 +410,6 @@ void QuicPacketCreator::CreateAndSerializeStreamFrame(
   // unioned with a QuicStreamFrame and a UniqueStreamBuffer.
   *num_bytes_consumed = bytes_consumed;
   packet_size_ = 0;
-  packet_.entropy_hash = QuicFramer::GetPacketEntropyHash(header);
   packet_.encrypted_buffer = encrypted_buffer;
   packet_.encrypted_length = encrypted_length;
   if (listener != nullptr) {
@@ -478,17 +438,13 @@ size_t QuicPacketCreator::ExpansionOnNewFrame() const {
 size_t QuicPacketCreator::BytesFree() {
   DCHECK_GE(max_plaintext_size_, PacketSize());
   return max_plaintext_size_ -
-         min(max_plaintext_size_, PacketSize() + ExpansionOnNewFrame());
+         std::min(max_plaintext_size_, PacketSize() + ExpansionOnNewFrame());
 }
 
 size_t QuicPacketCreator::PacketSize() {
   if (!queued_frames_.empty()) {
     return packet_size_;
   }
-  // Update packet number length on packet boundary.
-  if (!FLAGS_quic_simple_packet_number_length_2) {
-    packet_.packet_number_length = next_packet_number_length_;
-  }
   packet_size_ = GetPacketHeaderSize(
       framer_->version(), connection_id_length_, send_version_in_packet_,
       send_path_id_in_packet_, IncludeNonceInPublicHeader(),
@@ -557,16 +513,17 @@ void QuicPacketCreator::SerializePacket(char* encrypted_buffer,
 
   packet_size_ = 0;
   queued_frames_.clear();
-  packet_.entropy_hash = QuicFramer::GetPacketEntropyHash(header);
   packet_.encrypted_buffer = encrypted_buffer;
   packet_.encrypted_length = encrypted_length;
 }
 
-QuicEncryptedPacket* QuicPacketCreator::SerializeVersionNegotiationPacket(
+std::unique_ptr<QuicEncryptedPacket>
+QuicPacketCreator::SerializeVersionNegotiationPacket(
     const QuicVersionVector& supported_versions) {
   DCHECK_EQ(Perspective::IS_SERVER, framer_->perspective());
-  QuicEncryptedPacket* encrypted = QuicFramer::BuildVersionNegotiationPacket(
-      connection_id_, supported_versions);
+  std::unique_ptr<QuicEncryptedPacket> encrypted =
+      QuicFramer::BuildVersionNegotiationPacket(connection_id_,
+                                                supported_versions);
   DCHECK(encrypted);
   DCHECK_GE(max_packet_length_, encrypted->length());
   return encrypted;
@@ -575,7 +532,7 @@ QuicEncryptedPacket* QuicPacketCreator::SerializeVersionNegotiationPacket(
 // TODO(jri): Make this a public method of framer?
 SerializedPacket QuicPacketCreator::NoPacket() {
   return SerializedPacket(kInvalidPathId, 0, PACKET_1BYTE_PACKET_NUMBER,
-                          nullptr, 0, 0, false, false);
+                          nullptr, 0, false, false);
 }
 
 void QuicPacketCreator::FillPacketHeader(QuicPacketHeader* header) {
@@ -593,7 +550,6 @@ void QuicPacketCreator::FillPacketHeader(QuicPacketHeader* header) {
   header->path_id = packet_.path_id;
   header->packet_number = ++packet_.packet_number;
   header->public_header.packet_number_length = packet_.packet_number_length;
-  header->entropy_flag = random_bool_source_.RandBool();
 }
 
 bool QuicPacketCreator::ShouldRetransmit(const QuicFrame& frame) {
@@ -621,9 +577,6 @@ bool QuicPacketCreator::AddFrame(const QuicFrame& frame,
         ConnectionCloseSource::FROM_SELF);
     return false;
   }
-  if (!FLAGS_quic_simple_packet_number_length_2) {
-    MaybeUpdatePacketNumberLength();
-  }
   size_t frame_len = framer_->GetSerializedFrameLength(
       frame, BytesFree(), queued_frames_.empty(), true,
       packet_.packet_number_length);
@@ -708,20 +661,4 @@ bool QuicPacketCreator::IncludeNonceInPublicHeader() {
          packet_.encryption_level == ENCRYPTION_INITIAL;
 }
 
-QuicPacketCreator::QuicRandomBoolSource::QuicRandomBoolSource(
-    QuicRandom* random)
-    : random_(random), bit_bucket_(0), bit_mask_(0) {}
-
-QuicPacketCreator::QuicRandomBoolSource::~QuicRandomBoolSource() {}
-
-bool QuicPacketCreator::QuicRandomBoolSource::RandBool() {
-  if (bit_mask_ == 0) {
-    bit_bucket_ = random_->RandUint64();
-    bit_mask_ = 1;
-  }
-  bool result = ((bit_bucket_ & bit_mask_) != 0);
-  bit_mask_ <<= 1;
-  return result;
-}
-
 }  // namespace net
diff --git a/src/net/quic/core/quic_packet_creator.h b/src/net/quic/core/quic_packet_creator.h
index fc623b3..573e083 100644
--- a/src/net/quic/core/quic_packet_creator.h
+++ b/src/net/quic/core/quic_packet_creator.h
@@ -20,16 +20,18 @@
 
 #include "base/macros.h"
 #include "base/strings/string_piece.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/quic_connection_close_delegate_interface.h"
 #include "net/quic/core/quic_framer.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_iovector.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_pending_retransmission.h"
 
 namespace net {
 namespace test {
 class QuicPacketCreatorPeer;
 }
 
-class QuicRandom;
-
 class NET_EXPORT_PRIVATE QuicPacketCreator {
  public:
   // A delegate interface for further processing serialized packet.
@@ -54,10 +56,8 @@ class NET_EXPORT_PRIVATE QuicPacketCreator {
     virtual void OnFrameAddedToPacket(const QuicFrame& frame) {}
   };
 
-  // QuicRandom* required for packet entropy.
   QuicPacketCreator(QuicConnectionId connection_id,
                     QuicFramer* framer,
-                    QuicRandom* random_generator,
                     QuicBufferAllocator* buffer_allocator,
                     DelegateInterface* delegate);
 
@@ -107,7 +107,7 @@ class NET_EXPORT_PRIVATE QuicPacketCreator {
 
   // Re-serializes frames with the original packet's packet number length.
   // Used for retransmitting packets to ensure they aren't too long.
-  void ReserializeAllFrames(const PendingRetransmission& retransmission,
+  void ReserializeAllFrames(const QuicPendingRetransmission& retransmission,
                             char* buffer,
                             size_t buffer_len);
 
@@ -165,10 +165,7 @@ class NET_EXPORT_PRIVATE QuicPacketCreator {
                       QuicPacketLength length);
 
   // Creates a version negotiation packet which supports |supported_versions|.
-  // Caller owns the created  packet. Also, sets the entropy hash of the
-  // serialized packet to a random bool and returns that value as a member of
-  // SerializedPacket.
-  QuicEncryptedPacket* SerializeVersionNegotiationPacket(
+  std::unique_ptr<QuicEncryptedPacket> SerializeVersionNegotiationPacket(
       const QuicVersionVector& supported_versions);
 
   // Returns a dummy packet that is valid but contains no useful information.
@@ -223,30 +220,6 @@ class NET_EXPORT_PRIVATE QuicPacketCreator {
  private:
   friend class test::QuicPacketCreatorPeer;
 
-  // A QuicRandom wrapper that gets a bucket of entropy and distributes it
-  // bit-by-bit. Replenishes the bucket as needed. Not thread-safe. Expose this
-  // class if single bit randomness is needed elsewhere.
-  class QuicRandomBoolSource {
-   public:
-    // random: Source of entropy. Not owned.
-    explicit QuicRandomBoolSource(QuicRandom* random);
-
-    ~QuicRandomBoolSource();
-
-    // Returns the next random bit from the bucket.
-    bool RandBool();
-
-   private:
-    // Source of entropy.
-    QuicRandom* random_;
-    // Stored random bits.
-    uint64_t bit_bucket_;
-    // The next available bit has "1" in the mask. Zero means empty bucket.
-    uint64_t bit_mask_;
-
-    DISALLOW_COPY_AND_ASSIGN(QuicRandomBoolSource);
-  };
-
   static bool ShouldRetransmit(const QuicFrame& frame);
 
   // Converts a raw payload to a frame which fits into the current open
@@ -269,9 +242,6 @@ class NET_EXPORT_PRIVATE QuicPacketCreator {
                            size_t length,
                            char* buffer);
 
-  // Updates packet number length on packet boundary.
-  void MaybeUpdatePacketNumberLength();
-
   void FillPacketHeader(QuicPacketHeader* header);
 
   // Adds a |frame| if there is space and returns false and flushes all pending
@@ -286,8 +256,7 @@ class NET_EXPORT_PRIVATE QuicPacketCreator {
 
   // Serializes all frames which have been added and adds any which should be
   // retransmitted to packet_.retransmittable_frames. All frames must fit into
-  // a single packet. Sets the entropy hash of the serialized packet to a
-  // random bool.
+  // a single packet.
   // Fails if |buffer_len| isn't long enough for the encrypted packet.
   void SerializePacket(char* encrypted_buffer, size_t buffer_len);
 
@@ -307,7 +276,6 @@ class NET_EXPORT_PRIVATE QuicPacketCreator {
   DebugDelegate* debug_delegate_;
   QuicFramer* framer_;
 
-  QuicRandomBoolSource random_bool_source_;
   QuicBufferAllocator* const buffer_allocator_;
 
   // Controls whether version should be included while serializing the packet.
diff --git a/src/net/quic/core/quic_packet_generator.cc b/src/net/quic/core/quic_packet_generator.cc
index 84f6bb6..fc7bbbb 100644
--- a/src/net/quic/core/quic_packet_generator.cc
+++ b/src/net/quic/core/quic_packet_generator.cc
@@ -15,21 +15,16 @@ namespace net {
 
 QuicPacketGenerator::QuicPacketGenerator(QuicConnectionId connection_id,
                                          QuicFramer* framer,
-                                         QuicRandom* random_generator,
                                          QuicBufferAllocator* buffer_allocator,
                                          DelegateInterface* delegate)
     : delegate_(delegate),
-      packet_creator_(connection_id,
-                      framer,
-                      random_generator,
-                      buffer_allocator,
-                      delegate),
+      packet_creator_(connection_id, framer, buffer_allocator, delegate),
       batch_mode_(false),
       should_send_ack_(false),
       should_send_stop_waiting_(false) {}
 
 QuicPacketGenerator::~QuicPacketGenerator() {
-  QuicUtils::DeleteFrames(&queued_control_frames_);
+  DeleteFrames(&queued_control_frames_);
 }
 
 void QuicPacketGenerator::SetShouldSendAck(bool also_send_stop_waiting) {
@@ -195,7 +190,22 @@ void QuicPacketGenerator::SendQueuedFrames(bool flush) {
   // Only add pending frames if we are SURE we can then send the whole packet.
   while (HasPendingFrames() &&
          (flush || CanSendWithNextPendingFrameAddition())) {
-    AddNextPendingFrame();
+    bool first_frame = packet_creator_.CanSetMaxPacketLength();
+    if (!AddNextPendingFrame() && first_frame) {
+      // A single frame cannot fit into the packet, tear down the connection.
+      QUIC_BUG << "A single frame cannot fit into packet."
+               << " should_send_ack: " << should_send_ack_
+               << " should_send_stop_waiting: " << should_send_stop_waiting_
+               << " number of queued_control_frames: "
+               << queued_control_frames_.size();
+      if (!queued_control_frames_.empty()) {
+        DVLOG(1) << queued_control_frames_[0];
+      }
+      delegate_->OnUnrecoverableError(QUIC_FAILED_TO_SERIALIZE_PACKET,
+                                      "Single frame cannot fit into a packet",
+                                      ConnectionCloseSource::FROM_SELF);
+      return;
+    }
   }
   if (flush || !InBatchMode()) {
     packet_creator_.Flush();
@@ -281,13 +291,14 @@ void QuicPacketGenerator::SetMaxPacketLength(QuicByteCount length) {
   packet_creator_.SetMaxPacketLength(length);
 }
 
-QuicEncryptedPacket* QuicPacketGenerator::SerializeVersionNegotiationPacket(
+std::unique_ptr<QuicEncryptedPacket>
+QuicPacketGenerator::SerializeVersionNegotiationPacket(
     const QuicVersionVector& supported_versions) {
   return packet_creator_.SerializeVersionNegotiationPacket(supported_versions);
 }
 
 void QuicPacketGenerator::ReserializeAllFrames(
-    const PendingRetransmission& retransmission,
+    const QuicPendingRetransmission& retransmission,
     char* buffer,
     size_t buffer_len) {
   packet_creator_.ReserializeAllFrames(retransmission, buffer, buffer_len);
diff --git a/src/net/quic/core/quic_packet_generator.h b/src/net/quic/core/quic_packet_generator.h
index c90e022..cdb9840 100644
--- a/src/net/quic/core/quic_packet_generator.h
+++ b/src/net/quic/core/quic_packet_generator.h
@@ -46,7 +46,9 @@
 #include <list>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_packet_creator.h"
+#include "net/quic/core/quic_pending_retransmission.h"
 #include "net/quic/core/quic_sent_packet_manager.h"
 #include "net/quic/core/quic_types.h"
 
@@ -72,7 +74,6 @@ class NET_EXPORT_PRIVATE QuicPacketGenerator {
 
   QuicPacketGenerator(QuicConnectionId connection_id,
                       QuicFramer* framer,
-                      QuicRandom* random_generator,
                       QuicBufferAllocator* buffer_allocator,
                       DelegateInterface* delegate);
 
@@ -135,15 +136,12 @@ class NET_EXPORT_PRIVATE QuicPacketGenerator {
   void SetDiversificationNonce(const DiversificationNonce& nonce);
 
   // Creates a version negotiation packet which supports |supported_versions|.
-  // Caller owns the created  packet. Also, sets the entropy hash of the
-  // serialized packet to a random bool and returns that value as a member of
-  // SerializedPacket.
-  QuicEncryptedPacket* SerializeVersionNegotiationPacket(
+  std::unique_ptr<QuicEncryptedPacket> SerializeVersionNegotiationPacket(
       const QuicVersionVector& supported_versions);
 
   // Re-serializes frames with the original packet's packet number length.
   // Used for retransmitting packets to ensure they aren't too long.
-  void ReserializeAllFrames(const PendingRetransmission& retransmission,
+  void ReserializeAllFrames(const QuicPendingRetransmission& retransmission,
                             char* buffer,
                             size_t buffer_len);
 
@@ -181,8 +179,6 @@ class NET_EXPORT_PRIVATE QuicPacketGenerator {
     packet_creator_.set_debug_delegate(debug_delegate);
   }
 
-  const QuicAckFrame& pending_ack_frame() const { return pending_ack_frame_; }
-
  private:
   friend class test::QuicPacketGeneratorPeer;
 
@@ -214,7 +210,6 @@ class NET_EXPORT_PRIVATE QuicPacketGenerator {
   // a reference to it until we flush (and serialize it). Retransmittable frames
   // are referenced elsewhere so that they can later be (optionally)
   // retransmitted.
-  QuicAckFrame pending_ack_frame_;
   QuicStopWaitingFrame pending_stop_waiting_frame_;
 
   DISALLOW_COPY_AND_ASSIGN(QuicPacketGenerator);
diff --git a/src/net/quic/core/quic_packet_writer.h b/src/net/quic/core/quic_packet_writer.h
index cf3ee19..a4002af 100644
--- a/src/net/quic/core/quic_packet_writer.h
+++ b/src/net/quic/core/quic_packet_writer.h
@@ -7,12 +7,12 @@
 
 #include <stddef.h>
 
-#include "net/base/ip_endpoint.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 
 namespace net {
 
-class IPAddress;
 struct WriteResult;
 
 class NET_EXPORT_PRIVATE PerPacketOptions {
@@ -45,8 +45,8 @@ class NET_EXPORT_PRIVATE QuicPacketWriter {
   // implementation. Options may be ignored, depending on the implementation.
   virtual WriteResult WritePacket(const char* buffer,
                                   size_t buf_len,
-                                  const IPAddress& self_address,
-                                  const IPEndPoint& peer_address,
+                                  const QuicIpAddress& self_address,
+                                  const QuicSocketAddress& peer_address,
                                   PerPacketOptions* options) = 0;
 
   // Returns true if the writer buffers and subsequently rewrites data
@@ -65,7 +65,7 @@ class NET_EXPORT_PRIVATE QuicPacketWriter {
   // writer for the supplied peer address.  This size may actually exceed the
   // size of a valid QUIC packet.
   virtual QuicByteCount GetMaxPacketSize(
-      const IPEndPoint& peer_address) const = 0;
+      const QuicSocketAddress& peer_address) const = 0;
 };
 
 }  // namespace net
diff --git a/src/net/quic/core/quic_protocol.cc b/src/net/quic/core/quic_protocol.cc
deleted file mode 100644
index 4053dc0..0000000
--- a/src/net/quic/core/quic_protocol.cc
+++ /dev/null
@@ -1,884 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "net/quic/core/quic_protocol.h"
-
-#include "base/stl_util.h"
-#include "base/strings/string_number_conversions.h"
-#include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_utils.h"
-
-using base::StringPiece;
-using std::map;
-using std::numeric_limits;
-using std::ostream;
-using std::string;
-
-namespace net {
-
-const char* const kFinalOffsetHeaderKey = ":final-offset";
-
-size_t GetPacketHeaderSize(QuicVersion version,
-                           const QuicPacketHeader& header) {
-  return GetPacketHeaderSize(version, header.public_header.connection_id_length,
-                             header.public_header.version_flag,
-                             header.public_header.multipath_flag,
-                             header.public_header.nonce != nullptr,
-                             header.public_header.packet_number_length);
-}
-
-size_t GetPacketHeaderSize(QuicVersion version,
-                           QuicConnectionIdLength connection_id_length,
-                           bool include_version,
-                           bool include_path_id,
-                           bool include_diversification_nonce,
-                           QuicPacketNumberLength packet_number_length) {
-  return kPublicFlagsSize + connection_id_length +
-         (include_version ? kQuicVersionSize : 0) +
-         (include_path_id ? kQuicPathIdSize : 0) + packet_number_length +
-         (include_diversification_nonce ? kDiversificationNonceSize : 0) +
-         (version <= QUIC_VERSION_33 ? kPrivateFlagsSize : 0);
-}
-
-size_t GetStartOfEncryptedData(QuicVersion version,
-                               const QuicPacketHeader& header) {
-  return GetPacketHeaderSize(version, header) -
-         (version <= QUIC_VERSION_33 ? kPrivateFlagsSize : 0);
-}
-
-size_t GetStartOfEncryptedData(QuicVersion version,
-                               QuicConnectionIdLength connection_id_length,
-                               bool include_version,
-                               bool include_path_id,
-                               bool include_diversification_nonce,
-                               QuicPacketNumberLength packet_number_length) {
-  // Encryption starts before private flags.
-  return GetPacketHeaderSize(version, connection_id_length, include_version,
-                             include_path_id, include_diversification_nonce,
-                             packet_number_length) -
-         (version <= QUIC_VERSION_33 ? kPrivateFlagsSize : 0);
-}
-
-QuicPacketPublicHeader::QuicPacketPublicHeader()
-    : connection_id(0),
-      connection_id_length(PACKET_8BYTE_CONNECTION_ID),
-      multipath_flag(false),
-      reset_flag(false),
-      version_flag(false),
-      packet_number_length(PACKET_6BYTE_PACKET_NUMBER),
-      nonce(nullptr) {}
-
-QuicPacketPublicHeader::QuicPacketPublicHeader(
-    const QuicPacketPublicHeader& other) = default;
-
-QuicPacketPublicHeader::~QuicPacketPublicHeader() {}
-
-QuicPacketHeader::QuicPacketHeader()
-    : packet_number(0),
-      path_id(kDefaultPathId),
-      entropy_flag(false),
-      entropy_hash(0),
-      fec_flag(false) {}
-
-QuicPacketHeader::QuicPacketHeader(const QuicPacketPublicHeader& header)
-    : public_header(header),
-      packet_number(0),
-      path_id(kDefaultPathId),
-      entropy_flag(false),
-      entropy_hash(0),
-      fec_flag(false) {}
-
-QuicPacketHeader::QuicPacketHeader(const QuicPacketHeader& other) = default;
-
-QuicPublicResetPacket::QuicPublicResetPacket()
-    : nonce_proof(0), rejected_packet_number(0) {}
-
-QuicPublicResetPacket::QuicPublicResetPacket(
-    const QuicPacketPublicHeader& header)
-    : public_header(header), nonce_proof(0), rejected_packet_number(0) {}
-
-QuicBufferAllocator::~QuicBufferAllocator() = default;
-
-void StreamBufferDeleter::operator()(char* buffer) const {
-  if (allocator_ != nullptr && buffer != nullptr) {
-    allocator_->Delete(buffer);
-  }
-}
-
-UniqueStreamBuffer NewStreamBuffer(QuicBufferAllocator* allocator,
-                                   size_t size) {
-  return UniqueStreamBuffer(allocator->New(size),
-                            StreamBufferDeleter(allocator));
-}
-
-QuicStreamFrame::QuicStreamFrame()
-    : QuicStreamFrame(0, false, 0, nullptr, 0, nullptr) {}
-
-QuicStreamFrame::QuicStreamFrame(QuicStreamId stream_id,
-                                 bool fin,
-                                 QuicStreamOffset offset,
-                                 StringPiece data)
-    : QuicStreamFrame(stream_id,
-                      fin,
-                      offset,
-                      data.data(),
-                      data.length(),
-                      nullptr) {}
-
-QuicStreamFrame::QuicStreamFrame(QuicStreamId stream_id,
-                                 bool fin,
-                                 QuicStreamOffset offset,
-                                 QuicPacketLength data_length,
-                                 UniqueStreamBuffer buffer)
-    : QuicStreamFrame(stream_id,
-                      fin,
-                      offset,
-                      nullptr,
-                      data_length,
-                      std::move(buffer)) {
-  DCHECK(this->buffer != nullptr);
-  DCHECK_EQ(data_buffer, this->buffer.get());
-}
-
-QuicStreamFrame::QuicStreamFrame(QuicStreamId stream_id,
-                                 bool fin,
-                                 QuicStreamOffset offset,
-                                 const char* data_buffer,
-                                 QuicPacketLength data_length,
-                                 UniqueStreamBuffer buffer)
-    : stream_id(stream_id),
-      fin(fin),
-      data_length(data_length),
-      data_buffer(data_buffer),
-      offset(offset),
-      buffer(std::move(buffer)) {
-  if (this->buffer != nullptr) {
-    DCHECK(data_buffer == nullptr);
-    this->data_buffer = this->buffer.get();
-  }
-}
-
-QuicStreamFrame::~QuicStreamFrame() {}
-
-uint32_t MakeQuicTag(char a, char b, char c, char d) {
-  return static_cast<uint32_t>(a) | static_cast<uint32_t>(b) << 8 |
-         static_cast<uint32_t>(c) << 16 | static_cast<uint32_t>(d) << 24;
-}
-
-bool ContainsQuicTag(const QuicTagVector& tag_vector, QuicTag tag) {
-  return std::find(tag_vector.begin(), tag_vector.end(), tag) !=
-         tag_vector.end();
-}
-
-QuicVersionVector AllSupportedVersions() {
-  QuicVersionVector supported_versions;
-  for (size_t i = 0; i < arraysize(kSupportedQuicVersions); ++i) {
-    supported_versions.push_back(kSupportedQuicVersions[i]);
-  }
-  return supported_versions;
-}
-
-QuicVersionVector CurrentSupportedVersions() {
-  return FilterSupportedVersions(AllSupportedVersions());
-}
-
-QuicVersionVector FilterSupportedVersions(QuicVersionVector versions) {
-  QuicVersionVector filtered_versions(versions.size());
-  filtered_versions.clear();  // Guaranteed by spec not to change capacity.
-  for (QuicVersion version : versions) {
-    if (version < QUIC_VERSION_32) {
-      if (!FLAGS_quic_disable_pre_32 && !FLAGS_quic_disable_pre_34) {
-        filtered_versions.push_back(version);
-      }
-    } else if (version < QUIC_VERSION_34) {
-      if (!FLAGS_quic_disable_pre_34) {
-        filtered_versions.push_back(version);
-      }
-    } else if (version == QUIC_VERSION_35) {
-      if (FLAGS_quic_enable_version_35) {
-        filtered_versions.push_back(version);
-      }
-    } else if (version == QUIC_VERSION_36) {
-      if (FLAGS_quic_enable_version_35 && FLAGS_quic_enable_version_36_v2) {
-        filtered_versions.push_back(version);
-      }
-    } else {
-      filtered_versions.push_back(version);
-    }
-  }
-  return filtered_versions;
-}
-
-QuicVersionVector VersionOfIndex(const QuicVersionVector& versions, int index) {
-  QuicVersionVector version;
-  int version_count = versions.size();
-  if (index >= 0 && index < version_count) {
-    version.push_back(versions[index]);
-  } else {
-    version.push_back(QUIC_VERSION_UNSUPPORTED);
-  }
-  return version;
-}
-
-QuicTag QuicVersionToQuicTag(const QuicVersion version) {
-  switch (version) {
-    case QUIC_VERSION_30:
-      return MakeQuicTag('Q', '0', '3', '0');
-    case QUIC_VERSION_31:
-      return MakeQuicTag('Q', '0', '3', '1');
-    case QUIC_VERSION_32:
-      return MakeQuicTag('Q', '0', '3', '2');
-    case QUIC_VERSION_33:
-      return MakeQuicTag('Q', '0', '3', '3');
-    case QUIC_VERSION_34:
-      return MakeQuicTag('Q', '0', '3', '4');
-    case QUIC_VERSION_35:
-      return MakeQuicTag('Q', '0', '3', '5');
-    case QUIC_VERSION_36:
-      return MakeQuicTag('Q', '0', '3', '6');
-    default:
-      // This shold be an ERROR because we should never attempt to convert an
-      // invalid QuicVersion to be written to the wire.
-      LOG(ERROR) << "Unsupported QuicVersion: " << version;
-      return 0;
-  }
-}
-
-QuicVersion QuicTagToQuicVersion(const QuicTag version_tag) {
-  for (size_t i = 0; i < arraysize(kSupportedQuicVersions); ++i) {
-    if (version_tag == QuicVersionToQuicTag(kSupportedQuicVersions[i])) {
-      return kSupportedQuicVersions[i];
-    }
-  }
-  // Reading from the client so this should not be considered an ERROR.
-  DVLOG(1) << "Unsupported QuicTag version: "
-           << QuicUtils::TagToString(version_tag);
-  return QUIC_VERSION_UNSUPPORTED;
-}
-
-#define RETURN_STRING_LITERAL(x) \
-  case x:                        \
-    return #x
-
-string QuicVersionToString(const QuicVersion version) {
-  switch (version) {
-    RETURN_STRING_LITERAL(QUIC_VERSION_30);
-    RETURN_STRING_LITERAL(QUIC_VERSION_31);
-    RETURN_STRING_LITERAL(QUIC_VERSION_32);
-    RETURN_STRING_LITERAL(QUIC_VERSION_33);
-    RETURN_STRING_LITERAL(QUIC_VERSION_34);
-    RETURN_STRING_LITERAL(QUIC_VERSION_35);
-    RETURN_STRING_LITERAL(QUIC_VERSION_36);
-    default:
-      return "QUIC_VERSION_UNSUPPORTED";
-  }
-}
-
-string QuicVersionVectorToString(const QuicVersionVector& versions) {
-  string result = "";
-  for (size_t i = 0; i < versions.size(); ++i) {
-    if (i != 0) {
-      result.append(",");
-    }
-    result.append(QuicVersionToString(versions[i]));
-  }
-  return result;
-}
-
-ostream& operator<<(ostream& os, const Perspective& s) {
-  if (s == Perspective::IS_SERVER) {
-    os << "IS_SERVER";
-  } else {
-    os << "IS_CLIENT";
-  }
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicPacketHeader& header) {
-  os << "{ connection_id: " << header.public_header.connection_id
-     << ", connection_id_length: " << header.public_header.connection_id_length
-     << ", packet_number_length: " << header.public_header.packet_number_length
-     << ", multipath_flag: " << header.public_header.multipath_flag
-     << ", reset_flag: " << header.public_header.reset_flag
-     << ", version_flag: " << header.public_header.version_flag;
-  if (header.public_header.version_flag) {
-    os << ", version:";
-    for (size_t i = 0; i < header.public_header.versions.size(); ++i) {
-      os << " ";
-      os << QuicVersionToString(header.public_header.versions[i]);
-    }
-  }
-  if (header.public_header.nonce != nullptr) {
-    os << ", diversification_nonce: "
-       << QuicUtils::HexEncode(StringPiece(header.public_header.nonce->data(),
-                                           header.public_header.nonce->size()));
-  }
-  os << ", fec_flag: " << header.fec_flag
-     << ", entropy_flag: " << header.entropy_flag
-     << ", entropy hash: " << static_cast<int>(header.entropy_hash)
-     << ", path_id: " << static_cast<int>(header.path_id)
-     << ", packet_number: " << header.packet_number << " }\n";
-  return os;
-}
-
-bool IsAwaitingPacket(const QuicAckFrame& ack_frame,
-                      QuicPacketNumber packet_number,
-                      QuicPacketNumber peer_least_packet_awaiting_ack) {
-  if (ack_frame.missing) {
-    return packet_number > ack_frame.largest_observed ||
-           ack_frame.packets.Contains(packet_number);
-  }
-  return packet_number >= peer_least_packet_awaiting_ack &&
-         !ack_frame.packets.Contains(packet_number);
-}
-
-QuicStopWaitingFrame::QuicStopWaitingFrame()
-    : path_id(kDefaultPathId), entropy_hash(0), least_unacked(0) {}
-
-QuicStopWaitingFrame::~QuicStopWaitingFrame() {}
-
-QuicAckFrame::QuicAckFrame()
-    : largest_observed(0),
-      ack_delay_time(QuicTime::Delta::Infinite()),
-      path_id(kDefaultPathId),
-      entropy_hash(0),
-      is_truncated(false),
-      missing(true) {}
-
-QuicAckFrame::QuicAckFrame(const QuicAckFrame& other) = default;
-
-QuicAckFrame::~QuicAckFrame() {}
-
-QuicRstStreamErrorCode AdjustErrorForVersion(QuicRstStreamErrorCode error_code,
-                                             QuicVersion /*version*/) {
-  return error_code;
-}
-
-QuicRstStreamFrame::QuicRstStreamFrame()
-    : stream_id(0), error_code(QUIC_STREAM_NO_ERROR), byte_offset(0) {}
-
-QuicRstStreamFrame::QuicRstStreamFrame(QuicStreamId stream_id,
-                                       QuicRstStreamErrorCode error_code,
-                                       QuicStreamOffset bytes_written)
-    : stream_id(stream_id),
-      error_code(error_code),
-      byte_offset(bytes_written) {}
-
-QuicConnectionCloseFrame::QuicConnectionCloseFrame()
-    : error_code(QUIC_NO_ERROR) {}
-
-QuicFrame::QuicFrame() {}
-
-QuicFrame::QuicFrame(QuicPaddingFrame padding_frame)
-    : type(PADDING_FRAME), padding_frame(padding_frame) {}
-
-QuicFrame::QuicFrame(QuicStreamFrame* stream_frame)
-    : type(STREAM_FRAME), stream_frame(stream_frame) {}
-
-QuicFrame::QuicFrame(QuicAckFrame* frame) : type(ACK_FRAME), ack_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicMtuDiscoveryFrame frame)
-    : type(MTU_DISCOVERY_FRAME), mtu_discovery_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicStopWaitingFrame* frame)
-    : type(STOP_WAITING_FRAME), stop_waiting_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicPingFrame frame)
-    : type(PING_FRAME), ping_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicRstStreamFrame* frame)
-    : type(RST_STREAM_FRAME), rst_stream_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicConnectionCloseFrame* frame)
-    : type(CONNECTION_CLOSE_FRAME), connection_close_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicGoAwayFrame* frame)
-    : type(GOAWAY_FRAME), goaway_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicWindowUpdateFrame* frame)
-    : type(WINDOW_UPDATE_FRAME), window_update_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicBlockedFrame* frame)
-    : type(BLOCKED_FRAME), blocked_frame(frame) {}
-
-QuicFrame::QuicFrame(QuicPathCloseFrame* frame)
-    : type(PATH_CLOSE_FRAME), path_close_frame(frame) {}
-
-ostream& operator<<(ostream& os, const QuicStopWaitingFrame& sent_info) {
-  os << "{ entropy_hash: " << static_cast<int>(sent_info.entropy_hash)
-     << ", least_unacked: " << sent_info.least_unacked << " }\n";
-  return os;
-}
-
-PacketNumberQueue::PacketNumberQueue() = default;
-PacketNumberQueue::PacketNumberQueue(const PacketNumberQueue& other) = default;
-// TODO(rtenneti): on windows RValue reference gives errors.
-// PacketNumberQueue::PacketNumberQueue(PacketNumberQueue&& other) = default;
-PacketNumberQueue::~PacketNumberQueue() {}
-
-PacketNumberQueue& PacketNumberQueue::operator=(
-    const PacketNumberQueue& other) = default;
-// TODO(rtenneti): on windows RValue reference gives errors.
-// PacketNumberQueue& PacketNumberQueue::operator=(PacketNumberQueue&& other) =
-//    default;
-
-void PacketNumberQueue::Add(QuicPacketNumber packet_number) {
-  packet_number_intervals_.Add(packet_number, packet_number + 1);
-}
-
-void PacketNumberQueue::Add(QuicPacketNumber lower, QuicPacketNumber higher) {
-  packet_number_intervals_.Add(lower, higher);
-}
-
-void PacketNumberQueue::Remove(QuicPacketNumber packet_number) {
-  packet_number_intervals_.Difference(packet_number, packet_number + 1);
-}
-
-void PacketNumberQueue::Remove(QuicPacketNumber lower,
-                               QuicPacketNumber higher) {
-  packet_number_intervals_.Difference(lower, higher);
-}
-
-bool PacketNumberQueue::RemoveUpTo(QuicPacketNumber higher) {
-  if (Empty()) {
-    return false;
-  }
-  const QuicPacketNumber old_min = Min();
-  packet_number_intervals_.Difference(0, higher);
-  return Empty() || old_min != Min();
-}
-
-void PacketNumberQueue::Complement() {
-  if (Empty()) {
-    return;
-  }
-  packet_number_intervals_.Complement(Min(), Max() + 1);
-}
-
-bool PacketNumberQueue::Contains(QuicPacketNumber packet_number) const {
-  return packet_number_intervals_.Contains(packet_number);
-}
-
-bool PacketNumberQueue::Empty() const {
-  return packet_number_intervals_.Empty();
-}
-
-QuicPacketNumber PacketNumberQueue::Min() const {
-  DCHECK(!Empty());
-  return packet_number_intervals_.begin()->min();
-}
-
-QuicPacketNumber PacketNumberQueue::Max() const {
-  DCHECK(!Empty());
-  return packet_number_intervals_.rbegin()->max() - 1;
-}
-
-size_t PacketNumberQueue::NumPacketsSlow() const {
-  size_t num_packets = 0;
-  for (const auto& interval : packet_number_intervals_) {
-    num_packets += interval.Length();
-  }
-  return num_packets;
-}
-
-size_t PacketNumberQueue::NumIntervals() const {
-  return packet_number_intervals_.Size();
-}
-
-QuicPacketNumber PacketNumberQueue::LastIntervalLength() const {
-  DCHECK(!Empty());
-  return packet_number_intervals_.rbegin()->Length();
-}
-
-PacketNumberQueue::const_iterator PacketNumberQueue::lower_bound(
-    QuicPacketNumber packet_number) const {
-  // lower_bound returns the first interval that contains |packet_number| or the
-  // first interval after |packet_number|.
-  auto itr = packet_number_intervals_.Find(packet_number);
-  if (itr != packet_number_intervals_.end()) {
-    return itr;
-  }
-  for (itr = packet_number_intervals_.begin();
-       itr != packet_number_intervals_.end(); ++itr) {
-    if (packet_number < itr->min()) {
-      return itr;
-    }
-  }
-  return packet_number_intervals_.end();
-}
-
-PacketNumberQueue::const_iterator PacketNumberQueue::begin() const {
-  return packet_number_intervals_.begin();
-}
-
-PacketNumberQueue::const_iterator PacketNumberQueue::end() const {
-  return packet_number_intervals_.end();
-}
-
-PacketNumberQueue::const_reverse_iterator PacketNumberQueue::rbegin() const {
-  return packet_number_intervals_.rbegin();
-}
-
-PacketNumberQueue::const_reverse_iterator PacketNumberQueue::rend() const {
-  return packet_number_intervals_.rend();
-}
-
-ostream& operator<<(ostream& os, const PacketNumberQueue& q) {
-  for (const Interval<QuicPacketNumber>& interval : q) {
-    for (QuicPacketNumber packet_number = interval.min();
-         packet_number < interval.max(); ++packet_number) {
-      os << packet_number << " ";
-    }
-  }
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicAckFrame& ack_frame) {
-  os << "{ entropy_hash: " << static_cast<int>(ack_frame.entropy_hash)
-     << ", largest_observed: " << ack_frame.largest_observed
-     << ", ack_delay_time: " << ack_frame.ack_delay_time.ToMicroseconds()
-     << ", packets: [ " << ack_frame.packets << " ]"
-     << ", is_truncated: " << ack_frame.is_truncated
-     << ", received_packets: [ ";
-  for (const std::pair<QuicPacketNumber, QuicTime>& p :
-       ack_frame.received_packet_times) {
-    os << p.first << " at " << p.second.ToDebuggingValue() << " ";
-  }
-  os << " ] }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicFrame& frame) {
-  switch (frame.type) {
-    case PADDING_FRAME: {
-      os << "type { PADDING_FRAME } " << frame.padding_frame;
-      break;
-    }
-    case RST_STREAM_FRAME: {
-      os << "type { RST_STREAM_FRAME } " << *(frame.rst_stream_frame);
-      break;
-    }
-    case CONNECTION_CLOSE_FRAME: {
-      os << "type { CONNECTION_CLOSE_FRAME } "
-         << *(frame.connection_close_frame);
-      break;
-    }
-    case GOAWAY_FRAME: {
-      os << "type { GOAWAY_FRAME } " << *(frame.goaway_frame);
-      break;
-    }
-    case WINDOW_UPDATE_FRAME: {
-      os << "type { WINDOW_UPDATE_FRAME } " << *(frame.window_update_frame);
-      break;
-    }
-    case BLOCKED_FRAME: {
-      os << "type { BLOCKED_FRAME } " << *(frame.blocked_frame);
-      break;
-    }
-    case STREAM_FRAME: {
-      os << "type { STREAM_FRAME } " << *(frame.stream_frame);
-      break;
-    }
-    case ACK_FRAME: {
-      os << "type { ACK_FRAME } " << *(frame.ack_frame);
-      break;
-    }
-    case STOP_WAITING_FRAME: {
-      os << "type { STOP_WAITING_FRAME } " << *(frame.stop_waiting_frame);
-      break;
-    }
-    case PING_FRAME: {
-      os << "type { PING_FRAME } ";
-      break;
-    }
-    case MTU_DISCOVERY_FRAME: {
-      os << "type { MTU_DISCOVERY_FRAME } ";
-      break;
-    }
-    case PATH_CLOSE_FRAME: {
-      os << "type { PATH_CLOSE_FRAME } " << *(frame.path_close_frame);
-      break;
-    }
-    default: {
-      LOG(ERROR) << "Unknown frame type: " << frame.type;
-      break;
-    }
-  }
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicPaddingFrame& padding_frame) {
-  os << "{ num_padding_bytes: " << padding_frame.num_padding_bytes << " }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicRstStreamFrame& rst_frame) {
-  os << "{ stream_id: " << rst_frame.stream_id
-     << ", error_code: " << rst_frame.error_code << " }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os,
-                    const QuicConnectionCloseFrame& connection_close_frame) {
-  os << "{ error_code: " << connection_close_frame.error_code
-     << ", error_details: '" << connection_close_frame.error_details << "' }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicGoAwayFrame& goaway_frame) {
-  os << "{ error_code: " << goaway_frame.error_code
-     << ", last_good_stream_id: " << goaway_frame.last_good_stream_id
-     << ", reason_phrase: '" << goaway_frame.reason_phrase << "' }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os,
-                    const QuicWindowUpdateFrame& window_update_frame) {
-  os << "{ stream_id: " << window_update_frame.stream_id
-     << ", byte_offset: " << window_update_frame.byte_offset << " }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicBlockedFrame& blocked_frame) {
-  os << "{ stream_id: " << blocked_frame.stream_id << " }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicPathCloseFrame& path_close_frame) {
-  os << "{ path_id: " << static_cast<int>(path_close_frame.path_id) << " }\n";
-  return os;
-}
-
-ostream& operator<<(ostream& os, const QuicStreamFrame& stream_frame) {
-  os << "{ stream_id: " << stream_frame.stream_id
-     << ", fin: " << stream_frame.fin << ", offset: " << stream_frame.offset
-     << ", length: " << stream_frame.data_length << " }\n";
-  return os;
-}
-
-QuicGoAwayFrame::QuicGoAwayFrame()
-    : error_code(QUIC_NO_ERROR), last_good_stream_id(0) {}
-
-QuicGoAwayFrame::QuicGoAwayFrame(QuicErrorCode error_code,
-                                 QuicStreamId last_good_stream_id,
-                                 const string& reason)
-    : error_code(error_code),
-      last_good_stream_id(last_good_stream_id),
-      reason_phrase(reason) {}
-
-QuicData::QuicData(const char* buffer, size_t length)
-    : buffer_(buffer), length_(length), owns_buffer_(false) {}
-
-QuicData::QuicData(const char* buffer, size_t length, bool owns_buffer)
-    : buffer_(buffer), length_(length), owns_buffer_(owns_buffer) {}
-
-QuicData::~QuicData() {
-  if (owns_buffer_) {
-    delete[] const_cast<char*>(buffer_);
-  }
-}
-
-QuicWindowUpdateFrame::QuicWindowUpdateFrame(QuicStreamId stream_id,
-                                             QuicStreamOffset byte_offset)
-    : stream_id(stream_id), byte_offset(byte_offset) {}
-
-QuicBlockedFrame::QuicBlockedFrame(QuicStreamId stream_id)
-    : stream_id(stream_id) {}
-
-QuicPathCloseFrame::QuicPathCloseFrame(QuicPathId path_id) : path_id(path_id) {}
-
-QuicPacket::QuicPacket(char* buffer,
-                       size_t length,
-                       bool owns_buffer,
-                       QuicConnectionIdLength connection_id_length,
-                       bool includes_version,
-                       bool includes_path_id,
-                       bool includes_diversification_nonce,
-                       QuicPacketNumberLength packet_number_length)
-    : QuicData(buffer, length, owns_buffer),
-      buffer_(buffer),
-      connection_id_length_(connection_id_length),
-      includes_version_(includes_version),
-      includes_path_id_(includes_path_id),
-      includes_diversification_nonce_(includes_diversification_nonce),
-      packet_number_length_(packet_number_length) {}
-
-QuicEncryptedPacket::QuicEncryptedPacket(const char* buffer, size_t length)
-    : QuicData(buffer, length) {}
-
-QuicEncryptedPacket::QuicEncryptedPacket(const char* buffer,
-                                         size_t length,
-                                         bool owns_buffer)
-    : QuicData(buffer, length, owns_buffer) {}
-
-QuicEncryptedPacket* QuicEncryptedPacket::Clone() const {
-  char* buffer = new char[this->length()];
-  memcpy(buffer, this->data(), this->length());
-  return new QuicEncryptedPacket(buffer, this->length(), true);
-}
-
-ostream& operator<<(ostream& os, const QuicEncryptedPacket& s) {
-  os << s.length() << "-byte data";
-  return os;
-}
-
-QuicReceivedPacket::QuicReceivedPacket(const char* buffer,
-                                       size_t length,
-                                       QuicTime receipt_time)
-    : QuicReceivedPacket(buffer,
-                         length,
-                         receipt_time,
-                         false /* owns_buffer */) {}
-
-QuicReceivedPacket::QuicReceivedPacket(const char* buffer,
-                                       size_t length,
-                                       QuicTime receipt_time,
-                                       bool owns_buffer)
-    : QuicReceivedPacket(buffer,
-                         length,
-                         receipt_time,
-                         owns_buffer,
-                         false /* potentially_small_mtu */,
-                         -1 /* ttl */,
-                         false /* ttl_valid */) {}
-
-QuicReceivedPacket::QuicReceivedPacket(const char* buffer,
-                                       size_t length,
-                                       QuicTime receipt_time,
-                                       bool owns_buffer,
-                                       bool potentially_small_mtu,
-                                       int ttl,
-                                       bool ttl_valid)
-    : QuicEncryptedPacket(buffer, length, owns_buffer),
-      receipt_time_(receipt_time),
-      ttl_(ttl_valid ? ttl : -1),
-      potentially_small_mtu_(potentially_small_mtu) {}
-
-QuicReceivedPacket* QuicReceivedPacket::Clone() const {
-  char* buffer = new char[this->length()];
-  memcpy(buffer, this->data(), this->length());
-  return new QuicReceivedPacket(buffer, this->length(), receipt_time(), true,
-                                potentially_small_mtu(), ttl(), ttl() >= 0);
-}
-
-ostream& operator<<(ostream& os, const QuicReceivedPacket& s) {
-  os << s.length() << "-byte data";
-  return os;
-}
-
-StringPiece QuicPacket::AssociatedData(QuicVersion version) const {
-  return StringPiece(
-      data(), GetStartOfEncryptedData(version, connection_id_length_,
-                                      includes_version_, includes_path_id_,
-                                      includes_diversification_nonce_,
-                                      packet_number_length_));
-}
-
-StringPiece QuicPacket::Plaintext(QuicVersion version) const {
-  const size_t start_of_encrypted_data = GetStartOfEncryptedData(
-      version, connection_id_length_, includes_version_, includes_path_id_,
-      includes_diversification_nonce_, packet_number_length_);
-  return StringPiece(data() + start_of_encrypted_data,
-                     length() - start_of_encrypted_data);
-}
-
-QuicVersionManager::QuicVersionManager(QuicVersionVector supported_versions)
-    : disable_pre_32_(FLAGS_quic_disable_pre_32),
-      disable_pre_34_(FLAGS_quic_disable_pre_34),
-      enable_version_35_(FLAGS_quic_enable_version_35),
-      enable_version_36_(FLAGS_quic_enable_version_36_v2),
-      allowed_supported_versions_(supported_versions),
-      filtered_supported_versions_(
-          FilterSupportedVersions(supported_versions)) {}
-
-QuicVersionManager::~QuicVersionManager() {}
-
-const QuicVersionVector& QuicVersionManager::GetSupportedVersions() {
-  if (disable_pre_32_ != FLAGS_quic_disable_pre_32 ||
-      disable_pre_34_ != FLAGS_quic_disable_pre_34 ||
-      enable_version_35_ != FLAGS_quic_enable_version_35 ||
-      enable_version_36_ != FLAGS_quic_enable_version_36_v2) {
-    disable_pre_32_ = FLAGS_quic_disable_pre_32;
-    disable_pre_34_ = FLAGS_quic_disable_pre_34;
-    enable_version_35_ = FLAGS_quic_enable_version_35;
-    enable_version_36_ = FLAGS_quic_enable_version_36_v2;
-    filtered_supported_versions_ =
-        FilterSupportedVersions(allowed_supported_versions_);
-  }
-  return filtered_supported_versions_;
-}
-
-AckListenerWrapper::AckListenerWrapper(QuicAckListenerInterface* listener,
-                                       QuicPacketLength data_length)
-    : ack_listener(listener), length(data_length) {
-  DCHECK(listener != nullptr);
-}
-
-AckListenerWrapper::AckListenerWrapper(const AckListenerWrapper& other) =
-    default;
-
-AckListenerWrapper::~AckListenerWrapper() {}
-
-SerializedPacket::SerializedPacket(QuicPathId path_id,
-                                   QuicPacketNumber packet_number,
-                                   QuicPacketNumberLength packet_number_length,
-                                   const char* encrypted_buffer,
-                                   QuicPacketLength encrypted_length,
-                                   QuicPacketEntropyHash entropy_hash,
-                                   bool has_ack,
-                                   bool has_stop_waiting)
-    : encrypted_buffer(encrypted_buffer),
-      encrypted_length(encrypted_length),
-      has_crypto_handshake(NOT_HANDSHAKE),
-      num_padding_bytes(0),
-      path_id(path_id),
-      packet_number(packet_number),
-      packet_number_length(packet_number_length),
-      encryption_level(ENCRYPTION_NONE),
-      entropy_hash(entropy_hash),
-      has_ack(has_ack),
-      has_stop_waiting(has_stop_waiting),
-      transmission_type(NOT_RETRANSMISSION),
-      original_path_id(kInvalidPathId),
-      original_packet_number(0) {}
-
-SerializedPacket::SerializedPacket(const SerializedPacket& other) = default;
-
-SerializedPacket::~SerializedPacket() {}
-
-TransmissionInfo::TransmissionInfo()
-    : encryption_level(ENCRYPTION_NONE),
-      packet_number_length(PACKET_1BYTE_PACKET_NUMBER),
-      bytes_sent(0),
-      sent_time(QuicTime::Zero()),
-      transmission_type(NOT_RETRANSMISSION),
-      in_flight(false),
-      is_unackable(false),
-      has_crypto_handshake(false),
-      num_padding_bytes(0),
-      retransmission(0) {}
-
-TransmissionInfo::TransmissionInfo(EncryptionLevel level,
-                                   QuicPacketNumberLength packet_number_length,
-                                   TransmissionType transmission_type,
-                                   QuicTime sent_time,
-                                   QuicPacketLength bytes_sent,
-                                   bool has_crypto_handshake,
-                                   int num_padding_bytes)
-    : encryption_level(level),
-      packet_number_length(packet_number_length),
-      bytes_sent(bytes_sent),
-      sent_time(sent_time),
-      transmission_type(transmission_type),
-      in_flight(false),
-      is_unackable(false),
-      has_crypto_handshake(has_crypto_handshake),
-      num_padding_bytes(num_padding_bytes),
-      retransmission(0) {}
-
-TransmissionInfo::TransmissionInfo(const TransmissionInfo& other) = default;
-
-TransmissionInfo::~TransmissionInfo() {}
-
-}  // namespace net
diff --git a/src/net/quic/core/quic_protocol.h b/src/net/quic/core/quic_protocol.h
deleted file mode 100644
index 72a5b69..0000000
--- a/src/net/quic/core/quic_protocol.h
+++ /dev/null
@@ -1,1545 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#ifndef NET_QUIC_QUIC_PROTOCOL_H_
-#define NET_QUIC_QUIC_PROTOCOL_H_
-
-#include <stddef.h>
-#include <stdint.h>
-
-#include <array>
-#include <limits>
-#include <list>
-#include <map>
-#include <memory>
-#include <ostream>
-#include <set>
-#include <string>
-#include <utility>
-#include <vector>
-
-#include "base/logging.h"
-#include "base/macros.h"
-#include "base/memory/ref_counted.h"
-#include "base/strings/string_piece.h"
-#include "net/base/int128.h"
-#include "net/base/iovec.h"
-#include "net/base/ip_endpoint.h"
-#include "net/base/net_export.h"
-#include "net/quic/core/interval_set.h"
-#include "net/quic/core/quic_bandwidth.h"
-#include "net/quic/core/quic_time.h"
-#include "net/quic/core/quic_types.h"
-
-namespace net {
-
-class QuicPacket;
-struct QuicPacketHeader;
-class QuicAckListenerInterface;
-
-typedef uint64_t QuicConnectionId;
-typedef uint32_t QuicStreamId;
-typedef uint64_t QuicStreamOffset;
-typedef uint64_t QuicPacketNumber;
-typedef uint8_t QuicPathId;
-typedef uint64_t QuicPublicResetNonceProof;
-typedef uint8_t QuicPacketEntropyHash;
-typedef uint32_t QuicHeaderId;
-// QuicTag is the type of a tag in the wire protocol.
-typedef uint32_t QuicTag;
-typedef std::vector<QuicTag> QuicTagVector;
-typedef std::map<QuicTag, std::string> QuicTagValueMap;
-typedef uint16_t QuicPacketLength;
-
-// Default initial maximum size in bytes of a QUIC packet.
-const QuicByteCount kDefaultMaxPacketSize = 1350;
-// Default initial maximum size in bytes of a QUIC packet for servers.
-const QuicByteCount kDefaultServerMaxPacketSize = 1000;
-// Minimum size of a QUIC packet, used if a server receives packets from a
-// client with unusual network headers. 1280 - sizeof(eth) - sizeof(ipv6).
-const QuicByteCount kMinimumSupportedPacketSize = 1214;
-// The maximum packet size of any QUIC packet, based on ethernet's max size,
-// minus the IP and UDP headers. IPv6 has a 40 byte header, UDP adds an
-// additional 8 bytes.  This is a total overhead of 48 bytes.  Ethernet's
-// max packet size is 1500 bytes,  1500 - 48 = 1452.
-const QuicByteCount kMaxPacketSize = 1452;
-// Default maximum packet size used in the Linux TCP implementation.
-// Used in QUIC for congestion window computations in bytes.
-const QuicByteCount kDefaultTCPMSS = 1460;
-
-// We match SPDY's use of 32 (since we'd compete with SPDY).
-const QuicPacketCount kInitialCongestionWindow = 32;
-
-// Minimum size of initial flow control window, for both stream and session.
-const uint32_t kMinimumFlowControlSendWindow = 16 * 1024;  // 16 KB
-
-// Maximum flow control receive window limits for connection and stream.
-const QuicByteCount kStreamReceiveWindowLimit = 16 * 1024 * 1024;   // 16 MB
-const QuicByteCount kSessionReceiveWindowLimit = 24 * 1024 * 1024;  // 24 MB
-
-// Minimum size of the CWND, in packets, when doing bandwidth resumption.
-const QuicPacketCount kMinCongestionWindowForBandwidthResumption = 10;
-
-// Maximum number of tracked packets.
-const QuicPacketCount kMaxTrackedPackets = 10000;
-
-// Default size of the socket receive buffer in bytes.
-const QuicByteCount kDefaultSocketReceiveBuffer = 1024 * 1024;
-// Minimum size of the socket receive buffer in bytes.
-// Smaller values are ignored.
-const QuicByteCount kMinSocketReceiveBuffer = 16 * 1024;
-
-// Fraction of the receive buffer that can be used, based on conservative
-// estimates and testing on Linux.
-// An alternative to kUsableRecieveBufferFraction.
-static const float kConservativeReceiveBufferFraction = 0.6f;
-
-// Don't allow a client to suggest an RTT shorter than 10ms.
-const uint32_t kMinInitialRoundTripTimeUs = 10 * kNumMicrosPerMilli;
-
-// Don't allow a client to suggest an RTT longer than 15 seconds.
-const uint32_t kMaxInitialRoundTripTimeUs = 15 * kNumMicrosPerSecond;
-
-// Maximum number of open streams per connection.
-const size_t kDefaultMaxStreamsPerConnection = 100;
-
-// Number of bytes reserved for public flags in the packet header.
-const size_t kPublicFlagsSize = 1;
-// Number of bytes reserved for version number in the packet header.
-const size_t kQuicVersionSize = 4;
-// Number of bytes reserved for path id in the packet header.
-const size_t kQuicPathIdSize = 1;
-// Number of bytes reserved for private flags in the packet header.
-const size_t kPrivateFlagsSize = 1;
-
-// Signifies that the QuicPacket will contain version of the protocol.
-const bool kIncludeVersion = true;
-// Signifies that the QuicPacket will contain path id.
-const bool kIncludePathId = true;
-// Signifies that the QuicPacket will include a diversification nonce.
-const bool kIncludeDiversificationNonce = true;
-
-// Stream ID is reserved to denote an invalid ID.
-const QuicStreamId kInvalidStreamId = 0;
-
-// Reserved ID for the crypto stream.
-const QuicStreamId kCryptoStreamId = 1;
-
-// Reserved ID for the headers stream.
-const QuicStreamId kHeadersStreamId = 3;
-
-// Header key used to identify final offset on data stream when sending HTTP/2
-// trailing headers over QUIC.
-NET_EXPORT_PRIVATE extern const char* const kFinalOffsetHeaderKey;
-
-// Maximum delayed ack time, in ms.
-const int64_t kMaxDelayedAckTimeMs = 25;
-
-// Minimum tail loss probe time in ms.
-static const int64_t kMinTailLossProbeTimeoutMs = 10;
-
-// The timeout before the handshake succeeds.
-const int64_t kInitialIdleTimeoutSecs = 5;
-// The default idle timeout.
-const int64_t kDefaultIdleTimeoutSecs = 30;
-// The maximum idle timeout that can be negotiated.
-const int64_t kMaximumIdleTimeoutSecs = 60 * 10;  // 10 minutes.
-// The default timeout for a connection until the crypto handshake succeeds.
-const int64_t kMaxTimeForCryptoHandshakeSecs = 10;  // 10 secs.
-
-// Default limit on the number of undecryptable packets the connection buffers
-// before the CHLO/SHLO arrive.
-const size_t kDefaultMaxUndecryptablePackets = 10;
-
-// Default ping timeout.
-const int64_t kPingTimeoutSecs = 15;  // 15 secs.
-
-// Minimum number of RTTs between Server Config Updates (SCUP) sent to client.
-const int kMinIntervalBetweenServerConfigUpdatesRTTs = 10;
-
-// Minimum time between Server Config Updates (SCUP) sent to client.
-const int kMinIntervalBetweenServerConfigUpdatesMs = 1000;
-
-// Minimum number of packets between Server Config Updates (SCUP).
-const int kMinPacketsBetweenServerConfigUpdates = 100;
-
-// The number of open streams that a server will accept is set to be slightly
-// larger than the negotiated limit. Immediately closing the connection if the
-// client opens slightly too many streams is not ideal: the client may have sent
-// a FIN that was lost, and simultaneously opened a new stream. The number of
-// streams a server accepts is a fixed increment over the negotiated limit, or a
-// percentage increase, whichever is larger.
-const float kMaxStreamsMultiplier = 1.1f;
-const int kMaxStreamsMinimumIncrement = 10;
-
-// Available streams are ones with IDs less than the highest stream that has
-// been opened which have neither been opened or reset. The limit on the number
-// of available streams is 10 times the limit on the number of open streams.
-const int kMaxAvailableStreamsMultiplier = 10;
-
-// Track the number of promises that are not yet claimed by a
-// corresponding get.  This must be smaller than
-// kMaxAvailableStreamsMultiplier, because RST on a promised stream my
-// create available streams entries.
-const int kMaxPromisedStreamsMultiplier = kMaxAvailableStreamsMultiplier - 1;
-
-// TCP RFC calls for 1 second RTO however Linux differs from this default and
-// define the minimum RTO to 200ms, we will use the same until we have data to
-// support a higher or lower value.
-static const int64_t kMinRetransmissionTimeMs = 200;
-
-// We define an unsigned 16-bit floating point value, inspired by IEEE floats
-// (http://en.wikipedia.org/wiki/Half_precision_floating-point_format),
-// with 5-bit exponent (bias 1), 11-bit mantissa (effective 12 with hidden
-// bit) and denormals, but without signs, transfinites or fractions. Wire format
-// 16 bits (little-endian byte order) are split into exponent (high 5) and
-// mantissa (low 11) and decoded as:
-//   uint64_t value;
-//   if (exponent == 0) value = mantissa;
-//   else value = (mantissa | 1 << 11) << (exponent - 1)
-const int kUFloat16ExponentBits = 5;
-const int kUFloat16MaxExponent = (1 << kUFloat16ExponentBits) - 2;     // 30
-const int kUFloat16MantissaBits = 16 - kUFloat16ExponentBits;          // 11
-const int kUFloat16MantissaEffectiveBits = kUFloat16MantissaBits + 1;  // 12
-const uint64_t kUFloat16MaxValue =  // 0x3FFC0000000
-    ((UINT64_C(1) << kUFloat16MantissaEffectiveBits) - 1)
-    << kUFloat16MaxExponent;
-
-// Default path ID.
-const QuicPathId kDefaultPathId = 0;
-// Invalid path ID.
-const QuicPathId kInvalidPathId = 0xff;
-
-// kDiversificationNonceSize is the size, in bytes, of the nonce that a server
-// may set in the packet header to ensure that its INITIAL keys are not
-// duplicated.
-const size_t kDiversificationNonceSize = 32;
-
-// The largest gap in packets we'll accept without closing the connection.
-// This will likely have to be tuned.
-const QuicPacketNumber kMaxPacketGap = 5000;
-
-enum TransmissionType : int8_t {
-  NOT_RETRANSMISSION,
-  FIRST_TRANSMISSION_TYPE = NOT_RETRANSMISSION,
-  HANDSHAKE_RETRANSMISSION,    // Retransmits due to handshake timeouts.
-  ALL_UNACKED_RETRANSMISSION,  // Retransmits all unacked packets.
-  ALL_INITIAL_RETRANSMISSION,  // Retransmits all initially encrypted packets.
-  LOSS_RETRANSMISSION,         // Retransmits due to loss detection.
-  RTO_RETRANSMISSION,          // Retransmits due to retransmit time out.
-  TLP_RETRANSMISSION,          // Tail loss probes.
-  LAST_TRANSMISSION_TYPE = TLP_RETRANSMISSION,
-};
-
-enum HasRetransmittableData : int8_t {
-  NO_RETRANSMITTABLE_DATA,
-  HAS_RETRANSMITTABLE_DATA,
-};
-
-enum IsHandshake : int8_t { NOT_HANDSHAKE, IS_HANDSHAKE };
-
-enum class Perspective { IS_SERVER, IS_CLIENT };
-
-// Describes whether a ConnectionClose was originated by the peer.
-enum class ConnectionCloseSource { FROM_PEER, FROM_SELF };
-
-// Should a connection be closed silently or not.
-enum class ConnectionCloseBehavior {
-  SILENT_CLOSE,
-  SEND_CONNECTION_CLOSE_PACKET,
-  SEND_CONNECTION_CLOSE_PACKET_WITH_NO_ACK
-};
-
-NET_EXPORT_PRIVATE std::ostream& operator<<(std::ostream& os,
-                                            const Perspective& s);
-enum QuicFrameType {
-  // Regular frame types. The values set here cannot change without the
-  // introduction of a new QUIC version.
-  PADDING_FRAME = 0,
-  RST_STREAM_FRAME = 1,
-  CONNECTION_CLOSE_FRAME = 2,
-  GOAWAY_FRAME = 3,
-  WINDOW_UPDATE_FRAME = 4,
-  BLOCKED_FRAME = 5,
-  STOP_WAITING_FRAME = 6,
-  PING_FRAME = 7,
-  PATH_CLOSE_FRAME = 8,
-
-  // STREAM and ACK frames are special frames. They are encoded differently on
-  // the wire and their values do not need to be stable.
-  STREAM_FRAME,
-  ACK_FRAME,
-  // The path MTU discovery frame is encoded as a PING frame on the wire.
-  MTU_DISCOVERY_FRAME,
-  NUM_FRAME_TYPES
-};
-
-enum QuicConnectionIdLength {
-  PACKET_0BYTE_CONNECTION_ID = 0,
-  PACKET_8BYTE_CONNECTION_ID = 8
-};
-
-enum QuicPacketNumberLength : int8_t {
-  PACKET_1BYTE_PACKET_NUMBER = 1,
-  PACKET_2BYTE_PACKET_NUMBER = 2,
-  PACKET_4BYTE_PACKET_NUMBER = 4,
-  PACKET_6BYTE_PACKET_NUMBER = 6
-};
-
-// Used to indicate a QuicSequenceNumberLength using two flag bits.
-enum QuicPacketNumberLengthFlags {
-  PACKET_FLAGS_1BYTE_PACKET = 0,           // 00
-  PACKET_FLAGS_2BYTE_PACKET = 1,           // 01
-  PACKET_FLAGS_4BYTE_PACKET = 1 << 1,      // 10
-  PACKET_FLAGS_6BYTE_PACKET = 1 << 1 | 1,  // 11
-};
-
-// The public flags are specified in one byte.
-enum QuicPacketPublicFlags {
-  PACKET_PUBLIC_FLAGS_NONE = 0,
-
-  // Bit 0: Does the packet header contains version info?
-  PACKET_PUBLIC_FLAGS_VERSION = 1 << 0,
-
-  // Bit 1: Is this packet a public reset packet?
-  PACKET_PUBLIC_FLAGS_RST = 1 << 1,
-
-  // Bit 2: indicates the that public header includes a nonce.
-  PACKET_PUBLIC_FLAGS_NONCE = 1 << 2,
-
-  // Bit 3: indicates whether a ConnectionID is included.
-  PACKET_PUBLIC_FLAGS_0BYTE_CONNECTION_ID = 0,
-  PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID = 1 << 3,
-
-  // QUIC_VERSION_32 and earlier use two bits for an 8 byte
-  // connection id.
-  PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID_OLD = 1 << 3 | 1 << 2,
-
-  // Bits 4 and 5 describe the packet number length as follows:
-  // --00----: 1 byte
-  // --01----: 2 bytes
-  // --10----: 4 bytes
-  // --11----: 6 bytes
-  PACKET_PUBLIC_FLAGS_1BYTE_PACKET = PACKET_FLAGS_1BYTE_PACKET << 4,
-  PACKET_PUBLIC_FLAGS_2BYTE_PACKET = PACKET_FLAGS_2BYTE_PACKET << 4,
-  PACKET_PUBLIC_FLAGS_4BYTE_PACKET = PACKET_FLAGS_4BYTE_PACKET << 4,
-  PACKET_PUBLIC_FLAGS_6BYTE_PACKET = PACKET_FLAGS_6BYTE_PACKET << 4,
-
-  // Bit 6: Does the packet header contain a path id?
-  PACKET_PUBLIC_FLAGS_MULTIPATH = 1 << 6,
-
-  // Reserved, unimplemented flags:
-
-  // Bit 7: indicates the presence of a second flags byte.
-  PACKET_PUBLIC_FLAGS_TWO_OR_MORE_BYTES = 1 << 7,
-
-  // All bits set (bit 7 is not currently used): 01111111
-  PACKET_PUBLIC_FLAGS_MAX = (1 << 7) - 1,
-};
-
-// The private flags are specified in one byte.
-enum QuicPacketPrivateFlags {
-  PACKET_PRIVATE_FLAGS_NONE = 0,
-
-  // Bit 0: Does this packet contain an entropy bit?
-  PACKET_PRIVATE_FLAGS_ENTROPY = 1 << 0,
-
-  // Bit 1: Payload is part of an FEC group?
-  PACKET_PRIVATE_FLAGS_FEC_GROUP = 1 << 1,
-
-  // Bit 2: Payload is FEC as opposed to frames?
-  PACKET_PRIVATE_FLAGS_FEC = 1 << 2,
-
-  // All bits set (bits 3-7 are not currently used): 00000111
-  PACKET_PRIVATE_FLAGS_MAX = (1 << 3) - 1,
-
-  // For version 32 (bits 1-7 are not used): 00000001
-  PACKET_PRIVATE_FLAGS_MAX_VERSION_32 = (1 << 1) - 1
-};
-
-// The available versions of QUIC. Guaranteed that the integer value of the enum
-// will match the version number.
-// When adding a new version to this enum you should add it to
-// kSupportedQuicVersions (if appropriate), and also add a new case to the
-// helper methods QuicVersionToQuicTag, QuicTagToQuicVersion, and
-// QuicVersionToString.
-enum QuicVersion {
-  // Special case to indicate unknown/unsupported QUIC version.
-  QUIC_VERSION_UNSUPPORTED = 0,
-
-  QUIC_VERSION_30 = 30,  // Add server side support of cert transparency.
-  QUIC_VERSION_31 = 31,  // Adds a hash of the client hello to crypto proof.
-  QUIC_VERSION_32 = 32,  // FEC related fields are removed from wire format.
-  QUIC_VERSION_33 = 33,  // Adds diversification nonces.
-  QUIC_VERSION_34 = 34,  // Deprecates entropy, removes private flag from packet
-                         // header, uses new ack and stop waiting wire format.
-  QUIC_VERSION_35 = 35,  // Allows endpoints to independently set stream limit.
-  QUIC_VERSION_36 = 36,  // Add support to force HOL blocking.
-
-  // IMPORTANT: if you are adding to this std::list, follow the instructions at
-  // http://sites/quic/adding-and-removing-versions
-};
-
-// This vector contains QUIC versions which we currently support.
-// This should be ordered such that the highest supported version is the first
-// element, with subsequent elements in descending order (versions can be
-// skipped as necessary).
-//
-// IMPORTANT: if you are adding to this list, follow the instructions at
-// http://sites/quic/adding-and-removing-versions
-static const QuicVersion kSupportedQuicVersions[] = {
-    QUIC_VERSION_36, QUIC_VERSION_35, QUIC_VERSION_34, QUIC_VERSION_33,
-    QUIC_VERSION_32, QUIC_VERSION_31, QUIC_VERSION_30};
-
-typedef std::vector<QuicVersion> QuicVersionVector;
-
-// Returns a vector of QUIC versions in kSupportedQuicVersions.
-NET_EXPORT_PRIVATE QuicVersionVector AllSupportedVersions();
-
-// Returns a vector of QUIC versions from kSupportedQuicVersions which exclude
-// any versions which are disabled by flags.
-NET_EXPORT_PRIVATE QuicVersionVector CurrentSupportedVersions();
-
-// Returns a vector of QUIC versions from |versions| which exclude any versions
-// which are disabled by flags.
-NET_EXPORT_PRIVATE QuicVersionVector
-FilterSupportedVersions(QuicVersionVector versions);
-
-// Returns QUIC version of |index| in result of |versions|. Returns
-// QUIC_VERSION_UNSUPPORTED if |index| is out of bounds.
-NET_EXPORT_PRIVATE QuicVersionVector
-VersionOfIndex(const QuicVersionVector& versions, int index);
-
-// QuicTag is written to and read from the wire, but we prefer to use
-// the more readable QuicVersion at other levels.
-// Helper function which translates from a QuicVersion to a QuicTag. Returns 0
-// if QuicVersion is unsupported.
-NET_EXPORT_PRIVATE QuicTag QuicVersionToQuicTag(const QuicVersion version);
-
-// Returns appropriate QuicVersion from a QuicTag.
-// Returns QUIC_VERSION_UNSUPPORTED if version_tag cannot be understood.
-NET_EXPORT_PRIVATE QuicVersion QuicTagToQuicVersion(const QuicTag version_tag);
-
-// Helper function which translates from a QuicVersion to a string.
-// Returns strings corresponding to enum names (e.g. QUIC_VERSION_6).
-NET_EXPORT_PRIVATE std::string QuicVersionToString(const QuicVersion version);
-
-// Returns comma separated list of string representations of QuicVersion enum
-// values in the supplied |versions| vector.
-NET_EXPORT_PRIVATE std::string QuicVersionVectorToString(
-    const QuicVersionVector& versions);
-
-// Version and Crypto tags are written to the wire with a big-endian
-// representation of the name of the tag.  For example
-// the client hello tag (CHLO) will be written as the
-// following 4 bytes: 'C' 'H' 'L' 'O'.  Since it is
-// stored in memory as a little endian uint32_t, we need
-// to reverse the order of the bytes.
-
-// MakeQuicTag returns a value given the four bytes. For example:
-//   MakeQuicTag('C', 'H', 'L', 'O');
-NET_EXPORT_PRIVATE QuicTag MakeQuicTag(char a, char b, char c, char d);
-
-// Returns true if the tag vector contains the specified tag.
-NET_EXPORT_PRIVATE bool ContainsQuicTag(const QuicTagVector& tag_vector,
-                                        QuicTag tag);
-
-// Size in bytes of the data packet header.
-NET_EXPORT_PRIVATE size_t GetPacketHeaderSize(QuicVersion version,
-                                              const QuicPacketHeader& header);
-
-NET_EXPORT_PRIVATE size_t
-GetPacketHeaderSize(QuicVersion version,
-                    QuicConnectionIdLength connection_id_length,
-                    bool include_version,
-                    bool include_path_id,
-                    bool include_diversification_nonce,
-                    QuicPacketNumberLength packet_number_length);
-
-// Index of the first byte in a QUIC packet of encrypted data.
-NET_EXPORT_PRIVATE size_t
-GetStartOfEncryptedData(QuicVersion version, const QuicPacketHeader& header);
-
-NET_EXPORT_PRIVATE size_t
-GetStartOfEncryptedData(QuicVersion version,
-                        QuicConnectionIdLength connection_id_length,
-                        bool include_version,
-                        bool include_path_id,
-                        bool include_diversification_nonce,
-                        QuicPacketNumberLength packet_number_length);
-
-enum QuicRstStreamErrorCode {
-  // Complete response has been sent, sending a RST to ask the other endpoint
-  // to stop sending request data without discarding the response.
-  QUIC_STREAM_NO_ERROR = 0,
-
-  // There was some error which halted stream processing.
-  QUIC_ERROR_PROCESSING_STREAM,
-  // We got two fin or reset offsets which did not match.
-  QUIC_MULTIPLE_TERMINATION_OFFSETS,
-  // We got bad payload and can not respond to it at the protocol level.
-  QUIC_BAD_APPLICATION_PAYLOAD,
-  // Stream closed due to connection error. No reset frame is sent when this
-  // happens.
-  QUIC_STREAM_CONNECTION_ERROR,
-  // GoAway frame sent. No more stream can be created.
-  QUIC_STREAM_PEER_GOING_AWAY,
-  // The stream has been cancelled.
-  QUIC_STREAM_CANCELLED,
-  // Closing stream locally, sending a RST to allow for proper flow control
-  // accounting. Sent in response to a RST from the peer.
-  QUIC_RST_ACKNOWLEDGEMENT,
-  // Receiver refused to create the stream (because its limit on open streams
-  // has been reached).  The sender should retry the request later (using
-  // another stream).
-  QUIC_REFUSED_STREAM,
-  // Invalid URL in PUSH_PROMISE request header.
-  QUIC_INVALID_PROMISE_URL,
-  // Server is not authoritative for this URL.
-  QUIC_UNAUTHORIZED_PROMISE_URL,
-  // Can't have more than one active PUSH_PROMISE per URL.
-  QUIC_DUPLICATE_PROMISE_URL,
-  // Vary check failed.
-  QUIC_PROMISE_VARY_MISMATCH,
-  // Only GET and HEAD methods allowed.
-  QUIC_INVALID_PROMISE_METHOD,
-  // No error. Used as bound while iterating.
-  QUIC_STREAM_LAST_ERROR,
-};
-// QUIC error codes are encoded to a single octet on-the-wire.
-static_assert(static_cast<int>(QUIC_STREAM_LAST_ERROR) <=
-                  std::numeric_limits<uint8_t>::max(),
-              "QuicErrorCode exceeds single octet");
-
-// Because receiving an unknown QuicRstStreamErrorCode results in connection
-// teardown, we use this to make sure any errors predating a given version are
-// downgraded to the most appropriate existing error.
-NET_EXPORT_PRIVATE QuicRstStreamErrorCode
-AdjustErrorForVersion(QuicRstStreamErrorCode error_code, QuicVersion version);
-
-// These values must remain stable as they are uploaded to UMA histograms.
-// To add a new error code, use the current value of QUIC_LAST_ERROR and
-// increment QUIC_LAST_ERROR.
-enum QuicErrorCode {
-  QUIC_NO_ERROR = 0,
-
-  // Connection has reached an invalid state.
-  QUIC_INTERNAL_ERROR = 1,
-  // There were data frames after the a fin or reset.
-  QUIC_STREAM_DATA_AFTER_TERMINATION = 2,
-  // Control frame is malformed.
-  QUIC_INVALID_PACKET_HEADER = 3,
-  // Frame data is malformed.
-  QUIC_INVALID_FRAME_DATA = 4,
-  // The packet contained no payload.
-  QUIC_MISSING_PAYLOAD = 48,
-  // FEC data is malformed.
-  QUIC_INVALID_FEC_DATA = 5,
-  // STREAM frame data is malformed.
-  QUIC_INVALID_STREAM_DATA = 46,
-  // STREAM frame data overlaps with buffered data.
-  QUIC_OVERLAPPING_STREAM_DATA = 87,
-  // Received STREAM frame data is not encrypted.
-  QUIC_UNENCRYPTED_STREAM_DATA = 61,
-  // Attempt to send unencrypted STREAM frame.
-  QUIC_ATTEMPT_TO_SEND_UNENCRYPTED_STREAM_DATA = 88,
-  // Received a frame which is likely the result of memory corruption.
-  QUIC_MAYBE_CORRUPTED_MEMORY = 89,
-  // FEC frame data is not encrypted.
-  QUIC_UNENCRYPTED_FEC_DATA = 77,
-  // RST_STREAM frame data is malformed.
-  QUIC_INVALID_RST_STREAM_DATA = 6,
-  // CONNECTION_CLOSE frame data is malformed.
-  QUIC_INVALID_CONNECTION_CLOSE_DATA = 7,
-  // GOAWAY frame data is malformed.
-  QUIC_INVALID_GOAWAY_DATA = 8,
-  // WINDOW_UPDATE frame data is malformed.
-  QUIC_INVALID_WINDOW_UPDATE_DATA = 57,
-  // BLOCKED frame data is malformed.
-  QUIC_INVALID_BLOCKED_DATA = 58,
-  // STOP_WAITING frame data is malformed.
-  QUIC_INVALID_STOP_WAITING_DATA = 60,
-  // PATH_CLOSE frame data is malformed.
-  QUIC_INVALID_PATH_CLOSE_DATA = 78,
-  // ACK frame data is malformed.
-  QUIC_INVALID_ACK_DATA = 9,
-
-  // Version negotiation packet is malformed.
-  QUIC_INVALID_VERSION_NEGOTIATION_PACKET = 10,
-  // Public RST packet is malformed.
-  QUIC_INVALID_PUBLIC_RST_PACKET = 11,
-  // There was an error decrypting.
-  QUIC_DECRYPTION_FAILURE = 12,
-  // There was an error encrypting.
-  QUIC_ENCRYPTION_FAILURE = 13,
-  // The packet exceeded kMaxPacketSize.
-  QUIC_PACKET_TOO_LARGE = 14,
-  // The peer is going away.  May be a client or server.
-  QUIC_PEER_GOING_AWAY = 16,
-  // A stream ID was invalid.
-  QUIC_INVALID_STREAM_ID = 17,
-  // A priority was invalid.
-  QUIC_INVALID_PRIORITY = 49,
-  // Too many streams already open.
-  QUIC_TOO_MANY_OPEN_STREAMS = 18,
-  // The peer created too many available streams.
-  QUIC_TOO_MANY_AVAILABLE_STREAMS = 76,
-  // Received public reset for this connection.
-  QUIC_PUBLIC_RESET = 19,
-  // Invalid protocol version.
-  QUIC_INVALID_VERSION = 20,
-
-  // The Header ID for a stream was too far from the previous.
-  QUIC_INVALID_HEADER_ID = 22,
-  // Negotiable parameter received during handshake had invalid value.
-  QUIC_INVALID_NEGOTIATED_VALUE = 23,
-  // There was an error decompressing data.
-  QUIC_DECOMPRESSION_FAILURE = 24,
-  // The connection timed out due to no network activity.
-  QUIC_NETWORK_IDLE_TIMEOUT = 25,
-  // The connection timed out waiting for the handshake to complete.
-  QUIC_HANDSHAKE_TIMEOUT = 67,
-  // There was an error encountered migrating addresses.
-  QUIC_ERROR_MIGRATING_ADDRESS = 26,
-  // There was an error encountered migrating port only.
-  QUIC_ERROR_MIGRATING_PORT = 86,
-  // There was an error while writing to the socket.
-  QUIC_PACKET_WRITE_ERROR = 27,
-  // There was an error while reading from the socket.
-  QUIC_PACKET_READ_ERROR = 51,
-  // We received a STREAM_FRAME with no data and no fin flag set.
-  QUIC_EMPTY_STREAM_FRAME_NO_FIN = 50,
-  // We received invalid data on the headers stream.
-  QUIC_INVALID_HEADERS_STREAM_DATA = 56,
-  // The peer received too much data, violating flow control.
-  QUIC_FLOW_CONTROL_RECEIVED_TOO_MUCH_DATA = 59,
-  // The peer sent too much data, violating flow control.
-  QUIC_FLOW_CONTROL_SENT_TOO_MUCH_DATA = 63,
-  // The peer received an invalid flow control window.
-  QUIC_FLOW_CONTROL_INVALID_WINDOW = 64,
-  // The connection has been IP pooled into an existing connection.
-  QUIC_CONNECTION_IP_POOLED = 62,
-  // The connection has too many outstanding sent packets.
-  QUIC_TOO_MANY_OUTSTANDING_SENT_PACKETS = 68,
-  // The connection has too many outstanding received packets.
-  QUIC_TOO_MANY_OUTSTANDING_RECEIVED_PACKETS = 69,
-  // The quic connection has been cancelled.
-  QUIC_CONNECTION_CANCELLED = 70,
-  // Disabled QUIC because of high packet loss rate.
-  QUIC_BAD_PACKET_LOSS_RATE = 71,
-  // Disabled QUIC because of too many PUBLIC_RESETs post handshake.
-  QUIC_PUBLIC_RESETS_POST_HANDSHAKE = 73,
-  // Disabled QUIC because of too many timeouts with streams open.
-  QUIC_TIMEOUTS_WITH_OPEN_STREAMS = 74,
-  // Closed because we failed to serialize a packet.
-  QUIC_FAILED_TO_SERIALIZE_PACKET = 75,
-  // QUIC timed out after too many RTOs.
-  QUIC_TOO_MANY_RTOS = 85,
-
-  // Crypto errors.
-
-  // Hanshake failed.
-  QUIC_HANDSHAKE_FAILED = 28,
-  // Handshake message contained out of order tags.
-  QUIC_CRYPTO_TAGS_OUT_OF_ORDER = 29,
-  // Handshake message contained too many entries.
-  QUIC_CRYPTO_TOO_MANY_ENTRIES = 30,
-  // Handshake message contained an invalid value length.
-  QUIC_CRYPTO_INVALID_VALUE_LENGTH = 31,
-  // A crypto message was received after the handshake was complete.
-  QUIC_CRYPTO_MESSAGE_AFTER_HANDSHAKE_COMPLETE = 32,
-  // A crypto message was received with an illegal message tag.
-  QUIC_INVALID_CRYPTO_MESSAGE_TYPE = 33,
-  // A crypto message was received with an illegal parameter.
-  QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER = 34,
-  // An invalid channel id signature was supplied.
-  QUIC_INVALID_CHANNEL_ID_SIGNATURE = 52,
-  // A crypto message was received with a mandatory parameter missing.
-  QUIC_CRYPTO_MESSAGE_PARAMETER_NOT_FOUND = 35,
-  // A crypto message was received with a parameter that has no overlap
-  // with the local parameter.
-  QUIC_CRYPTO_MESSAGE_PARAMETER_NO_OVERLAP = 36,
-  // A crypto message was received that contained a parameter with too few
-  // values.
-  QUIC_CRYPTO_MESSAGE_INDEX_NOT_FOUND = 37,
-  // A demand for an unsupport proof type was received.
-  QUIC_UNSUPPORTED_PROOF_DEMAND = 94,
-  // An internal error occured in crypto processing.
-  QUIC_CRYPTO_INTERNAL_ERROR = 38,
-  // A crypto handshake message specified an unsupported version.
-  QUIC_CRYPTO_VERSION_NOT_SUPPORTED = 39,
-  // A crypto handshake message resulted in a stateless reject.
-  QUIC_CRYPTO_HANDSHAKE_STATELESS_REJECT = 72,
-  // There was no intersection between the crypto primitives supported by the
-  // peer and ourselves.
-  QUIC_CRYPTO_NO_SUPPORT = 40,
-  // The server rejected our client hello messages too many times.
-  QUIC_CRYPTO_TOO_MANY_REJECTS = 41,
-  // The client rejected the server's certificate chain or signature.
-  QUIC_PROOF_INVALID = 42,
-  // A crypto message was received with a duplicate tag.
-  QUIC_CRYPTO_DUPLICATE_TAG = 43,
-  // A crypto message was received with the wrong encryption level (i.e. it
-  // should have been encrypted but was not.)
-  QUIC_CRYPTO_ENCRYPTION_LEVEL_INCORRECT = 44,
-  // The server config for a server has expired.
-  QUIC_CRYPTO_SERVER_CONFIG_EXPIRED = 45,
-  // We failed to setup the symmetric keys for a connection.
-  QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED = 53,
-  // A handshake message arrived, but we are still validating the
-  // previous handshake message.
-  QUIC_CRYPTO_MESSAGE_WHILE_VALIDATING_CLIENT_HELLO = 54,
-  // A server config update arrived before the handshake is complete.
-  QUIC_CRYPTO_UPDATE_BEFORE_HANDSHAKE_COMPLETE = 65,
-  // CHLO cannot fit in one packet.
-  QUIC_CRYPTO_CHLO_TOO_LARGE = 90,
-  // This connection involved a version negotiation which appears to have been
-  // tampered with.
-  QUIC_VERSION_NEGOTIATION_MISMATCH = 55,
-
-  // Multipath errors.
-  // Multipath is not enabled, but a packet with multipath flag on is received.
-  QUIC_BAD_MULTIPATH_FLAG = 79,
-  // A path is supposed to exist but does not.
-  QUIC_MULTIPATH_PATH_DOES_NOT_EXIST = 91,
-  // A path is supposed to be active but is not.
-  QUIC_MULTIPATH_PATH_NOT_ACTIVE = 92,
-
-  // IP address changed causing connection close.
-  QUIC_IP_ADDRESS_CHANGED = 80,
-
-  // Connection migration errors.
-  // Network changed, but connection had no migratable streams.
-  QUIC_CONNECTION_MIGRATION_NO_MIGRATABLE_STREAMS = 81,
-  // Connection changed networks too many times.
-  QUIC_CONNECTION_MIGRATION_TOO_MANY_CHANGES = 82,
-  // Connection migration was attempted, but there was no new network to
-  // migrate to.
-  QUIC_CONNECTION_MIGRATION_NO_NEW_NETWORK = 83,
-  // Network changed, but connection had one or more non-migratable streams.
-  QUIC_CONNECTION_MIGRATION_NON_MIGRATABLE_STREAM = 84,
-
-  // Stream frames arrived too discontiguously so that stream sequencer buffer
-  // maintains too many gaps.
-  QUIC_TOO_MANY_FRAME_GAPS = 93,
-
-  // No error. Used as bound while iterating.
-  QUIC_LAST_ERROR = 95,
-};
-
-typedef std::array<char, 32> DiversificationNonce;
-
-struct NET_EXPORT_PRIVATE QuicPacketPublicHeader {
-  QuicPacketPublicHeader();
-  explicit QuicPacketPublicHeader(const QuicPacketPublicHeader& other);
-  ~QuicPacketPublicHeader();
-
-  // Universal header. All QuicPacket headers will have a connection_id and
-  // public flags.
-  QuicConnectionId connection_id;
-  QuicConnectionIdLength connection_id_length;
-  bool multipath_flag;
-  bool reset_flag;
-  bool version_flag;
-  QuicPacketNumberLength packet_number_length;
-  QuicVersionVector versions;
-  // nonce contains an optional, 32-byte nonce value. If not included in the
-  // packet, |nonce| will be empty.
-  DiversificationNonce* nonce;
-};
-
-// An integer which cannot be a packet number.
-const QuicPacketNumber kInvalidPacketNumber = 0;
-
-// Header for Data packets.
-struct NET_EXPORT_PRIVATE QuicPacketHeader {
-  QuicPacketHeader();
-  explicit QuicPacketHeader(const QuicPacketPublicHeader& header);
-  QuicPacketHeader(const QuicPacketHeader& other);
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(std::ostream& os,
-                                                     const QuicPacketHeader& s);
-
-  QuicPacketPublicHeader public_header;
-  QuicPacketNumber packet_number;
-  QuicPathId path_id;
-  bool entropy_flag;
-  QuicPacketEntropyHash entropy_hash;
-  bool fec_flag;
-};
-
-struct NET_EXPORT_PRIVATE QuicPublicResetPacket {
-  QuicPublicResetPacket();
-  explicit QuicPublicResetPacket(const QuicPacketPublicHeader& header);
-
-  QuicPacketPublicHeader public_header;
-  QuicPublicResetNonceProof nonce_proof;
-  QuicPacketNumber rejected_packet_number;
-  IPEndPoint client_address;
-};
-
-enum QuicVersionNegotiationState {
-  START_NEGOTIATION = 0,
-  // Server-side this implies we've sent a version negotiation packet and are
-  // waiting on the client to select a compatible version.  Client-side this
-  // implies we've gotten a version negotiation packet, are retransmitting the
-  // initial packets with a supported version and are waiting for our first
-  // packet from the server.
-  NEGOTIATION_IN_PROGRESS,
-  // This indicates this endpoint has received a packet from the peer with a
-  // version this endpoint supports.  Version negotiation is complete, and the
-  // version number will no longer be sent with future packets.
-  NEGOTIATED_VERSION
-};
-
-typedef QuicPacketPublicHeader QuicVersionNegotiationPacket;
-
-// A padding frame contains no payload.
-struct NET_EXPORT_PRIVATE QuicPaddingFrame {
-  QuicPaddingFrame() : num_padding_bytes(-1) {}
-  explicit QuicPaddingFrame(int num_padding_bytes)
-      : num_padding_bytes(num_padding_bytes) {}
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(std::ostream& os,
-                                                     const QuicPaddingFrame& s);
-
-  // -1: full padding to the end of a max-sized packet
-  // otherwise: only pad up to num_padding_bytes bytes
-  int num_padding_bytes;
-};
-
-// A ping frame contains no payload, though it is retransmittable,
-// and ACK'd just like other normal frames.
-struct NET_EXPORT_PRIVATE QuicPingFrame {};
-
-// A path MTU discovery frame contains no payload and is serialized as a ping
-// frame.
-struct NET_EXPORT_PRIVATE QuicMtuDiscoveryFrame {};
-
-class NET_EXPORT_PRIVATE QuicBufferAllocator {
- public:
-  virtual ~QuicBufferAllocator();
-
-  // Returns or allocates a new buffer of |size|. Never returns null.
-  virtual char* New(size_t size) = 0;
-
-  // Returns or allocates a new buffer of |size| if |flag_enable| is true.
-  // Otherwise, returns a buffer that is compatible with this class directly
-  // with operator new. Never returns null.
-  virtual char* New(size_t size, bool flag_enable) = 0;
-
-  // Releases a buffer.
-  virtual void Delete(char* buffer) = 0;
-
-  // Marks the allocator as being idle. Serves as a hint to notify the allocator
-  // that it should release any resources it's still holding on to.
-  virtual void MarkAllocatorIdle() {}
-};
-
-// Deleter for stream buffers. Copyable to support platforms where the deleter
-// of a unique_ptr must be copyable. Otherwise it would be nice for this to be
-// move-only.
-class NET_EXPORT_PRIVATE StreamBufferDeleter {
- public:
-  StreamBufferDeleter() : allocator_(nullptr) {}
-  explicit StreamBufferDeleter(QuicBufferAllocator* allocator)
-      : allocator_(allocator) {}
-
-  // Deletes |buffer| using |allocator_|.
-  void operator()(char* buffer) const;
-
- private:
-  // Not owned; must be valid so long as the buffer stored in the unique_ptr
-  // that owns |this| is valid.
-  QuicBufferAllocator* allocator_;
-};
-
-using UniqueStreamBuffer = std::unique_ptr<char[], StreamBufferDeleter>;
-
-// Allocates memory of size |size| using |allocator| for a QUIC stream buffer.
-NET_EXPORT_PRIVATE UniqueStreamBuffer
-NewStreamBuffer(QuicBufferAllocator* allocator, size_t size);
-
-struct NET_EXPORT_PRIVATE QuicStreamFrame {
-  QuicStreamFrame();
-  QuicStreamFrame(QuicStreamId stream_id,
-                  bool fin,
-                  QuicStreamOffset offset,
-                  base::StringPiece data);
-  QuicStreamFrame(QuicStreamId stream_id,
-                  bool fin,
-                  QuicStreamOffset offset,
-                  QuicPacketLength data_length,
-                  UniqueStreamBuffer buffer);
-  ~QuicStreamFrame();
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(std::ostream& os,
-                                                     const QuicStreamFrame& s);
-
-  QuicStreamId stream_id;
-  bool fin;
-  QuicPacketLength data_length;
-  const char* data_buffer;
-  QuicStreamOffset offset;  // Location of this data in the stream.
-  // nullptr when the QuicStreamFrame is received, and non-null when sent.
-  UniqueStreamBuffer buffer;
-
- private:
-  QuicStreamFrame(QuicStreamId stream_id,
-                  bool fin,
-                  QuicStreamOffset offset,
-                  const char* data_buffer,
-                  QuicPacketLength data_length,
-                  UniqueStreamBuffer buffer);
-
-  DISALLOW_COPY_AND_ASSIGN(QuicStreamFrame);
-};
-static_assert(sizeof(QuicStreamFrame) <= 64,
-              "Keep the QuicStreamFrame size to a cacheline.");
-
-typedef std::vector<std::pair<QuicPacketNumber, QuicTime>> PacketTimeVector;
-
-struct NET_EXPORT_PRIVATE QuicStopWaitingFrame {
-  QuicStopWaitingFrame();
-  ~QuicStopWaitingFrame();
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const QuicStopWaitingFrame& s);
-  // Path which this stop waiting frame belongs to.
-  QuicPathId path_id;
-  // Entropy hash of all packets up to, but not including, the least unacked
-  // packet.
-  QuicPacketEntropyHash entropy_hash;
-  // The lowest packet we've sent which is unacked, and we expect an ack for.
-  QuicPacketNumber least_unacked;
-};
-
-// A sequence of packet numbers where each number is unique. Intended to be used
-// in a sliding window fashion, where smaller old packet numbers are removed and
-// larger new packet numbers are added, with the occasional random access.
-class NET_EXPORT_PRIVATE PacketNumberQueue {
- public:
-  using const_iterator = IntervalSet<QuicPacketNumber>::const_iterator;
-  using const_reverse_iterator =
-      IntervalSet<QuicPacketNumber>::const_reverse_iterator;
-
-  PacketNumberQueue();
-  PacketNumberQueue(const PacketNumberQueue& other);
-  // TODO(rtenneti): on windows RValue reference gives errors.
-  // PacketNumberQueue(PacketNumberQueue&& other);
-  ~PacketNumberQueue();
-
-  PacketNumberQueue& operator=(const PacketNumberQueue& other);
-  // PacketNumberQueue& operator=(PacketNumberQueue&& other);
-
-  // Adds |packet_number| to the set of packets in the queue.
-  void Add(QuicPacketNumber packet_number);
-
-  // Adds packets between [lower, higher) to the set of packets in the queue. It
-  // is undefined behavior to call this with |higher| < |lower|.
-  void Add(QuicPacketNumber lower, QuicPacketNumber higher);
-
-  // Removes |packet_number| from the set of packets in the queue.
-  void Remove(QuicPacketNumber packet_number);
-
-  // Removes packets numbers between [lower, higher) to the set of packets in
-  // the queue. It is undefined behavior to call this with |higher| < |lower|.
-  void Remove(QuicPacketNumber lower, QuicPacketNumber higher);
-
-  // Removes packets with values less than |higher| from the set of packets in
-  // the queue. Returns true if packets were removed.
-  bool RemoveUpTo(QuicPacketNumber higher);
-
-  // Mutates packet number set so that it contains only those packet numbers
-  // from minimum to maximum packet number not currently in the set. Do nothing
-  // if packet number set is empty.
-  void Complement();
-
-  // Returns true if the queue contains |packet_number|.
-  bool Contains(QuicPacketNumber packet_number) const;
-
-  // Returns true if the queue is empty.
-  bool Empty() const;
-
-  // Returns the minimum packet number stored in the queue. It is undefined
-  // behavior to call this if the queue is empty.
-  QuicPacketNumber Min() const;
-
-  // Returns the maximum packet number stored in the queue. It is undefined
-  // behavior to call this if the queue is empty.
-  QuicPacketNumber Max() const;
-
-  // Returns the number of unique packets stored in the queue. Inefficient; only
-  // exposed for testing.
-  size_t NumPacketsSlow() const;
-
-  // Returns the number of disjoint packet number intervals contained in the
-  // queue.
-  size_t NumIntervals() const;
-
-  // Returns the length of last interval.
-  QuicPacketNumber LastIntervalLength() const;
-
-  // Returns iterators over the packet number intervals.
-  const_iterator begin() const;
-  const_iterator end() const;
-  const_reverse_iterator rbegin() const;
-  const_reverse_iterator rend() const;
-  const_iterator lower_bound(QuicPacketNumber packet_number) const;
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const PacketNumberQueue& q);
-
- private:
-  IntervalSet<QuicPacketNumber> packet_number_intervals_;
-};
-
-struct NET_EXPORT_PRIVATE QuicAckFrame {
-  QuicAckFrame();
-  QuicAckFrame(const QuicAckFrame& other);
-  ~QuicAckFrame();
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(std::ostream& os,
-                                                     const QuicAckFrame& s);
-
-  // The highest packet number we've observed from the peer.
-  //
-  // In general, this should be the largest packet number we've received.  In
-  // the case of truncated acks, we may have to advertise a lower "upper bound"
-  // than largest received, to avoid implicitly acking missing packets that
-  // don't fit in the missing packet list due to size limitations.  In this
-  // case, largest_observed may be a packet which is also in the missing packets
-  // list.
-  QuicPacketNumber largest_observed;
-
-  // Time elapsed since largest_observed was received until this Ack frame was
-  // sent.
-  QuicTime::Delta ack_delay_time;
-
-  // Vector of <packet_number, time> for when packets arrived.
-  PacketTimeVector received_packet_times;
-
-  // Set of packets.
-  PacketNumberQueue packets;
-
-  // Path which this ack belongs to.
-  QuicPathId path_id;
-
-  // Entropy hash of all packets up to largest observed not including missing
-  // packets.
-  QuicPacketEntropyHash entropy_hash;
-
-  // Whether the ack had to be truncated when sent.
-  bool is_truncated;
-
-  // If true, |packets| express missing packets. Otherwise, |packets| express
-  // received packets.
-  bool missing;
-};
-
-// True if the packet number is greater than largest_observed or is listed
-// as missing.
-// Always returns false for packet numbers less than least_unacked.
-bool NET_EXPORT_PRIVATE
-IsAwaitingPacket(const QuicAckFrame& ack_frame,
-                 QuicPacketNumber packet_number,
-                 QuicPacketNumber peer_least_packet_awaiting_ack);
-
-// Defines for all types of congestion control algorithms that can be used in
-// QUIC. Note that this is separate from the congestion feedback type -
-// some congestion control algorithms may use the same feedback type
-// (Reno and Cubic are the classic example for that).
-enum CongestionControlType {
-  kCubic,
-  kCubicBytes,
-  kReno,
-  kRenoBytes,
-  kBBR,
-};
-
-enum LossDetectionType {
-  kNack,          // Used to mimic TCP's loss detection.
-  kTime,          // Time based loss detection.
-  kAdaptiveTime,  // Adaptive time based loss detection.
-};
-
-struct NET_EXPORT_PRIVATE QuicRstStreamFrame {
-  QuicRstStreamFrame();
-  QuicRstStreamFrame(QuicStreamId stream_id,
-                     QuicRstStreamErrorCode error_code,
-                     QuicStreamOffset bytes_written);
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const QuicRstStreamFrame& r);
-
-  QuicStreamId stream_id;
-  QuicRstStreamErrorCode error_code;
-
-  // Used to update flow control windows. On termination of a stream, both
-  // endpoints must inform the peer of the number of bytes they have sent on
-  // that stream. This can be done through normal termination (data packet with
-  // FIN) or through a RST.
-  QuicStreamOffset byte_offset;
-};
-
-struct NET_EXPORT_PRIVATE QuicConnectionCloseFrame {
-  QuicConnectionCloseFrame();
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const QuicConnectionCloseFrame& c);
-
-  QuicErrorCode error_code;
-  std::string error_details;
-};
-
-struct NET_EXPORT_PRIVATE QuicGoAwayFrame {
-  QuicGoAwayFrame();
-  QuicGoAwayFrame(QuicErrorCode error_code,
-                  QuicStreamId last_good_stream_id,
-                  const std::string& reason);
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(std::ostream& os,
-                                                     const QuicGoAwayFrame& g);
-
-  QuicErrorCode error_code;
-  QuicStreamId last_good_stream_id;
-  std::string reason_phrase;
-};
-
-// Flow control updates per-stream and at the connection levoel.
-// Based on SPDY's WINDOW_UPDATE frame, but uses an absolute byte offset rather
-// than a window delta.
-// TODO(rjshade): A possible future optimization is to make stream_id and
-//                byte_offset variable length, similar to stream frames.
-struct NET_EXPORT_PRIVATE QuicWindowUpdateFrame {
-  QuicWindowUpdateFrame() {}
-  QuicWindowUpdateFrame(QuicStreamId stream_id, QuicStreamOffset byte_offset);
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const QuicWindowUpdateFrame& w);
-
-  // The stream this frame applies to.  0 is a special case meaning the overall
-  // connection rather than a specific stream.
-  QuicStreamId stream_id;
-
-  // Byte offset in the stream or connection. The receiver of this frame must
-  // not send data which would result in this offset being exceeded.
-  QuicStreamOffset byte_offset;
-};
-
-// The BLOCKED frame is used to indicate to the remote endpoint that this
-// endpoint believes itself to be flow-control blocked but otherwise ready to
-// send data. The BLOCKED frame is purely advisory and optional.
-// Based on SPDY's BLOCKED frame (undocumented as of 2014-01-28).
-struct NET_EXPORT_PRIVATE QuicBlockedFrame {
-  QuicBlockedFrame() {}
-  explicit QuicBlockedFrame(QuicStreamId stream_id);
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(std::ostream& os,
-                                                     const QuicBlockedFrame& b);
-
-  // The stream this frame applies to.  0 is a special case meaning the overall
-  // connection rather than a specific stream.
-  QuicStreamId stream_id;
-};
-
-// The PATH_CLOSE frame is used to explicitly close a path. Both endpoints can
-// send a PATH_CLOSE frame to initiate a path termination. A path is considered
-// to be closed either a PATH_CLOSE frame is sent or received. An endpoint drops
-// receive side of a closed path, and packets with retransmittable frames on a
-// closed path are marked as retransmissions which will be transmitted on other
-// paths.
-struct NET_EXPORT_PRIVATE QuicPathCloseFrame {
-  QuicPathCloseFrame() {}
-  explicit QuicPathCloseFrame(QuicPathId path_id);
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const QuicPathCloseFrame& p);
-
-  QuicPathId path_id;
-};
-
-// EncryptionLevel enumerates the stages of encryption that a QUIC connection
-// progresses through. When retransmitting a packet, the encryption level needs
-// to be specified so that it is retransmitted at a level which the peer can
-// understand.
-enum EncryptionLevel : int8_t {
-  ENCRYPTION_NONE = 0,
-  ENCRYPTION_INITIAL = 1,
-  ENCRYPTION_FORWARD_SECURE = 2,
-
-  NUM_ENCRYPTION_LEVELS,
-};
-
-enum PeerAddressChangeType {
-  // IP address and port remain unchanged.
-  NO_CHANGE,
-  // Port changed, but IP address remains unchanged.
-  PORT_CHANGE,
-  // IPv4 address changed, but within the /24 subnet (port may have changed.)
-  IPV4_SUBNET_CHANGE,
-  // IPv4 address changed, excluding /24 subnet change (port may have changed.)
-  IPV4_TO_IPV4_CHANGE,
-  // IP address change from an IPv4 to an IPv6 address (port may have changed.)
-  IPV4_TO_IPV6_CHANGE,
-  // IP address change from an IPv6 to an IPv4 address (port may have changed.)
-  IPV6_TO_IPV4_CHANGE,
-  // IP address change from an IPv6 to an IPv6 address (port may have changed.)
-  IPV6_TO_IPV6_CHANGE,
-};
-
-struct NET_EXPORT_PRIVATE QuicFrame {
-  QuicFrame();
-  explicit QuicFrame(QuicPaddingFrame padding_frame);
-  explicit QuicFrame(QuicMtuDiscoveryFrame frame);
-  explicit QuicFrame(QuicPingFrame frame);
-
-  explicit QuicFrame(QuicStreamFrame* stream_frame);
-  explicit QuicFrame(QuicAckFrame* frame);
-  explicit QuicFrame(QuicRstStreamFrame* frame);
-  explicit QuicFrame(QuicConnectionCloseFrame* frame);
-  explicit QuicFrame(QuicStopWaitingFrame* frame);
-  explicit QuicFrame(QuicGoAwayFrame* frame);
-  explicit QuicFrame(QuicWindowUpdateFrame* frame);
-  explicit QuicFrame(QuicBlockedFrame* frame);
-  explicit QuicFrame(QuicPathCloseFrame* frame);
-
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(std::ostream& os,
-                                                     const QuicFrame& frame);
-
-  QuicFrameType type;
-  union {
-    // Frames smaller than a pointer are inline.
-    QuicPaddingFrame padding_frame;
-    QuicMtuDiscoveryFrame mtu_discovery_frame;
-    QuicPingFrame ping_frame;
-
-    // Frames larger than a pointer.
-    QuicStreamFrame* stream_frame;
-    QuicAckFrame* ack_frame;
-    QuicStopWaitingFrame* stop_waiting_frame;
-    QuicRstStreamFrame* rst_stream_frame;
-    QuicConnectionCloseFrame* connection_close_frame;
-    QuicGoAwayFrame* goaway_frame;
-    QuicWindowUpdateFrame* window_update_frame;
-    QuicBlockedFrame* blocked_frame;
-    QuicPathCloseFrame* path_close_frame;
-  };
-};
-// QuicFrameType consumes 8 bytes with padding.
-static_assert(sizeof(QuicFrame) <= 16,
-              "Frames larger than 8 bytes should be referenced by pointer.");
-
-typedef std::vector<QuicFrame> QuicFrames;
-
-class NET_EXPORT_PRIVATE QuicData {
- public:
-  QuicData(const char* buffer, size_t length);
-  QuicData(const char* buffer, size_t length, bool owns_buffer);
-  virtual ~QuicData();
-
-  base::StringPiece AsStringPiece() const {
-    return base::StringPiece(data(), length());
-  }
-
-  const char* data() const { return buffer_; }
-  size_t length() const { return length_; }
-  bool owns_buffer() const { return owns_buffer_; }
-
- private:
-  const char* buffer_;
-  size_t length_;
-  bool owns_buffer_;
-
-  DISALLOW_COPY_AND_ASSIGN(QuicData);
-};
-
-class NET_EXPORT_PRIVATE QuicPacket : public QuicData {
- public:
-  // TODO(fayang): 4 fields from public header are passed in as arguments.
-  // Consider to add a convenience method which directly accepts the entire
-  // public header.
-  QuicPacket(char* buffer,
-             size_t length,
-             bool owns_buffer,
-             QuicConnectionIdLength connection_id_length,
-             bool includes_version,
-             bool includes_path_id,
-             bool includes_diversification_nonce,
-             QuicPacketNumberLength packet_number_length);
-
-  base::StringPiece AssociatedData(QuicVersion version) const;
-  base::StringPiece Plaintext(QuicVersion version) const;
-
-  char* mutable_data() { return buffer_; }
-
- private:
-  char* buffer_;
-  const QuicConnectionIdLength connection_id_length_;
-  const bool includes_version_;
-  const bool includes_path_id_;
-  const bool includes_diversification_nonce_;
-  const QuicPacketNumberLength packet_number_length_;
-
-  DISALLOW_COPY_AND_ASSIGN(QuicPacket);
-};
-
-class NET_EXPORT_PRIVATE QuicEncryptedPacket : public QuicData {
- public:
-  QuicEncryptedPacket(const char* buffer, size_t length);
-  QuicEncryptedPacket(const char* buffer, size_t length, bool owns_buffer);
-
-  // Clones the packet into a new packet which owns the buffer.
-  QuicEncryptedPacket* Clone() const;
-
-  // By default, gtest prints the raw bytes of an object. The bool data
-  // member (in the base class QuicData) causes this object to have padding
-  // bytes, which causes the default gtest object printer to read
-  // uninitialize memory. So we need to teach gtest how to print this object.
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const QuicEncryptedPacket& s);
-
- private:
-  DISALLOW_COPY_AND_ASSIGN(QuicEncryptedPacket);
-};
-
-// A received encrypted QUIC packet, with a recorded time of receipt.
-class NET_EXPORT_PRIVATE QuicReceivedPacket : public QuicEncryptedPacket {
- public:
-  QuicReceivedPacket(const char* buffer, size_t length, QuicTime receipt_time);
-  QuicReceivedPacket(const char* buffer,
-                     size_t length,
-                     QuicTime receipt_time,
-                     bool owns_buffer);
-  QuicReceivedPacket(const char* buffer,
-                     size_t length,
-                     QuicTime receipt_time,
-                     bool owns_buffer,
-                     bool potentially_small_mtu,
-                     int ttl,
-                     bool ttl_valid);
-
-  // Clones the packet into a new packet which owns the buffer.
-  QuicReceivedPacket* Clone() const;
-
-  // Returns the time at which the packet was received.
-  QuicTime receipt_time() const { return receipt_time_; }
-
-  // This is the TTL of the packet, assuming ttl_vaild_ is true.
-  int ttl() const { return ttl_; }
-
-  bool potentially_small_mtu() const { return potentially_small_mtu_; }
-
-  // By default, gtest prints the raw bytes of an object. The bool data
-  // member (in the base class QuicData) causes this object to have padding
-  // bytes, which causes the default gtest object printer to read
-  // uninitialize memory. So we need to teach gtest how to print this object.
-  NET_EXPORT_PRIVATE friend std::ostream& operator<<(
-      std::ostream& os,
-      const QuicReceivedPacket& s);
-
- private:
-  const QuicTime receipt_time_;
-  int ttl_;
-  bool potentially_small_mtu_;
-
-  DISALLOW_COPY_AND_ASSIGN(QuicReceivedPacket);
-};
-
-// Pure virtual class to listen for packet acknowledgements.
-class NET_EXPORT_PRIVATE QuicAckListenerInterface
-    : public base::RefCounted<QuicAckListenerInterface> {
- public:
-  QuicAckListenerInterface() {}
-
-  // Called when a packet is acked.  Called once per packet.
-  // |acked_bytes| is the number of data bytes acked.
-  virtual void OnPacketAcked(int acked_bytes,
-                             QuicTime::Delta ack_delay_time) = 0;
-
-  // Called when a packet is retransmitted.  Called once per packet.
-  // |retransmitted_bytes| is the number of data bytes retransmitted.
-  virtual void OnPacketRetransmitted(int retransmitted_bytes) = 0;
-
- protected:
-  friend class base::RefCounted<QuicAckListenerInterface>;
-
-  // Delegates are ref counted.
-  virtual ~QuicAckListenerInterface() {}
-};
-
-// Pure virtual class to close connection on unrecoverable errors.
-class NET_EXPORT_PRIVATE QuicConnectionCloseDelegateInterface {
- public:
-  virtual ~QuicConnectionCloseDelegateInterface() {}
-
-  // Called when an unrecoverable error is encountered.
-  virtual void OnUnrecoverableError(QuicErrorCode error,
-                                    const std::string& error_details,
-                                    ConnectionCloseSource source) = 0;
-};
-
-// Used to generate filtered supported versions based on flags.
-class NET_EXPORT_PRIVATE QuicVersionManager {
- public:
-  explicit QuicVersionManager(QuicVersionVector supported_versions);
-  ~QuicVersionManager();
-
-  // Returns supported versions based on flags.
-  const QuicVersionVector& GetSupportedVersions();
-
- private:
-  // FLAGS_quic_disable_pre_32
-  bool disable_pre_32_;
-  // FLAGS_quic_disable_pre_34
-  bool disable_pre_34_;
-  // FLAGS_quic_enable_version_35
-  bool enable_version_35_;
-  // FLAGS_quic_enable_version_36_v2
-  bool enable_version_36_;
-  // The list of versions that may be supported.
-  QuicVersionVector allowed_supported_versions_;
-  // This vector contains QUIC versions which are currently supported based
-  // on flags.
-  QuicVersionVector filtered_supported_versions_;
-};
-
-struct NET_EXPORT_PRIVATE AckListenerWrapper {
-  AckListenerWrapper(QuicAckListenerInterface* listener,
-                     QuicPacketLength data_length);
-  AckListenerWrapper(const AckListenerWrapper& other);
-  ~AckListenerWrapper();
-
-  scoped_refptr<QuicAckListenerInterface> ack_listener;
-  QuicPacketLength length;
-};
-
-struct NET_EXPORT_PRIVATE SerializedPacket {
-  SerializedPacket(QuicPathId path_id,
-                   QuicPacketNumber packet_number,
-                   QuicPacketNumberLength packet_number_length,
-                   const char* encrypted_buffer,
-                   QuicPacketLength encrypted_length,
-                   QuicPacketEntropyHash entropy_hash,
-                   bool has_ack,
-                   bool has_stop_waiting);
-  SerializedPacket(const SerializedPacket& other);
-  ~SerializedPacket();
-
-  // Not owned.
-  const char* encrypted_buffer;
-  QuicPacketLength encrypted_length;
-  QuicFrames retransmittable_frames;
-  IsHandshake has_crypto_handshake;
-  // -1: full padding to the end of a max-sized packet
-  //  0: no padding
-  //  otherwise: only pad up to num_padding_bytes bytes
-  int16_t num_padding_bytes;
-  QuicPathId path_id;
-  QuicPacketNumber packet_number;
-  QuicPacketNumberLength packet_number_length;
-  EncryptionLevel encryption_level;
-  QuicPacketEntropyHash entropy_hash;
-  bool has_ack;
-  bool has_stop_waiting;
-  TransmissionType transmission_type;
-  QuicPathId original_path_id;
-  QuicPacketNumber original_packet_number;
-
-  // Optional notifiers which will be informed when this packet has been ACKed.
-  std::list<AckListenerWrapper> listeners;
-};
-
-struct NET_EXPORT_PRIVATE TransmissionInfo {
-  // Used by STL when assigning into a map.
-  TransmissionInfo();
-
-  // Constructs a Transmission with a new all_transmissions set
-  // containing |packet_number|.
-  TransmissionInfo(EncryptionLevel level,
-                   QuicPacketNumberLength packet_number_length,
-                   TransmissionType transmission_type,
-                   QuicTime sent_time,
-                   QuicPacketLength bytes_sent,
-                   bool has_crypto_handshake,
-                   int num_padding_bytes);
-
-  TransmissionInfo(const TransmissionInfo& other);
-
-  ~TransmissionInfo();
-
-  QuicFrames retransmittable_frames;
-  EncryptionLevel encryption_level;
-  QuicPacketNumberLength packet_number_length;
-  QuicPacketLength bytes_sent;
-  QuicTime sent_time;
-  // Reason why this packet was transmitted.
-  TransmissionType transmission_type;
-  // In flight packets have not been abandoned or lost.
-  bool in_flight;
-  // True if the packet can never be acked, so it can be removed.  Occurs when
-  // a packet is never sent, after it is acknowledged once, or if it's a crypto
-  // packet we never expect to receive an ack for.
-  bool is_unackable;
-  // True if the packet contains stream data from the crypto stream.
-  bool has_crypto_handshake;
-  // Non-zero if the packet needs padding if it's retransmitted.
-  int16_t num_padding_bytes;
-  // Stores the packet number of the next retransmission of this packet.
-  // Zero if the packet has not been retransmitted.
-  QuicPacketNumber retransmission;
-  // Non-empty if there is a listener for this packet.
-  std::list<AckListenerWrapper> ack_listeners;
-};
-
-// Struct to store the pending retransmission information.
-struct PendingRetransmission {
-  PendingRetransmission(QuicPathId path_id,
-                        QuicPacketNumber packet_number,
-                        TransmissionType transmission_type,
-                        const QuicFrames& retransmittable_frames,
-                        bool has_crypto_handshake,
-                        int num_padding_bytes,
-                        EncryptionLevel encryption_level,
-                        QuicPacketNumberLength packet_number_length)
-      : packet_number(packet_number),
-        retransmittable_frames(retransmittable_frames),
-        transmission_type(transmission_type),
-        path_id(path_id),
-        has_crypto_handshake(has_crypto_handshake),
-        num_padding_bytes(num_padding_bytes),
-        encryption_level(encryption_level),
-        packet_number_length(packet_number_length) {}
-
-  QuicPacketNumber packet_number;
-  const QuicFrames& retransmittable_frames;
-  TransmissionType transmission_type;
-  QuicPathId path_id;
-  bool has_crypto_handshake;
-  int num_padding_bytes;
-  EncryptionLevel encryption_level;
-  QuicPacketNumberLength packet_number_length;
-};
-
-// Convenience wrapper to wrap an iovec array and the total length, which must
-// be less than or equal to the actual total length of the iovecs.
-struct NET_EXPORT_PRIVATE QuicIOVector {
-  QuicIOVector(const struct iovec* iov, int iov_count, size_t total_length)
-      : iov(iov), iov_count(iov_count), total_length(total_length) {}
-
-  const struct iovec* iov;
-  const int iov_count;
-  const size_t total_length;
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_QUIC_PROTOCOL_H_
diff --git a/src/net/quic/core/quic_received_packet_manager.cc b/src/net/quic/core/quic_received_packet_manager.cc
index 1f5c36d..2c8fce0 100644
--- a/src/net/quic/core/quic_received_packet_manager.cc
+++ b/src/net/quic/core/quic_received_packet_manager.cc
@@ -9,16 +9,12 @@
 
 #include "base/logging.h"
 #include "base/stl_util.h"
-#include "base/strings/stringprintf.h"
 #include "net/base/linked_hash_map.h"
 #include "net/quic/core/crypto/crypto_protocol.h"
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_connection_stats.h"
 #include "net/quic/core/quic_flags.h"
 
-using std::max;
-using std::min;
-using std::numeric_limits;
 
 namespace net {
 
@@ -32,170 +28,48 @@ namespace {
 const size_t kMaxPacketsAfterNewMissing = 4;
 }
 
-QuicReceivedPacketManager::EntropyTracker::EntropyTracker()
-    : packets_entropy_hash_(0), first_gap_(1), largest_observed_(0) {}
-
-QuicReceivedPacketManager::EntropyTracker::~EntropyTracker() {}
-
-QuicPacketEntropyHash QuicReceivedPacketManager::EntropyTracker::EntropyHash(
-    QuicPacketNumber packet_number) const {
-  DCHECK_LE(packet_number, largest_observed_);
-  if (packet_number == largest_observed_) {
-    return packets_entropy_hash_;
-  }
-
-  DCHECK_GE(packet_number, first_gap_);
-  DCHECK_EQ(first_gap_ + packets_entropy_.size() - 1, largest_observed_);
-  QuicPacketEntropyHash hash = packets_entropy_hash_;
-  ReceivedEntropyHashes::const_reverse_iterator it = packets_entropy_.rbegin();
-  for (QuicPacketNumber i = 0; i < (largest_observed_ - packet_number);
-       ++i, ++it) {
-    hash ^= it->first;
-  }
-  return hash;
-}
-
-void QuicReceivedPacketManager::EntropyTracker::RecordPacketEntropyHash(
-    QuicPacketNumber packet_number,
-    QuicPacketEntropyHash entropy_hash) {
-  if (packet_number < first_gap_) {
-    DVLOG(1) << "Ignoring received packet entropy for packet_number:"
-             << packet_number
-             << " less than largest_peer_packet_number:" << first_gap_;
-    return;
-  }
-  // RecordPacketEntropyHash is only intended to be called once per packet.
-  DCHECK(packet_number > largest_observed_ ||
-         !packets_entropy_[packet_number - first_gap_].second);
-
-  packets_entropy_hash_ ^= entropy_hash;
-
-  // Optimize the typical case of no gaps.
-  if (packet_number == largest_observed_ + 1 && packets_entropy_.empty()) {
-    ++first_gap_;
-    largest_observed_ = packet_number;
-    return;
-  }
-  if (packet_number > largest_observed_) {
-    for (QuicPacketNumber i = 0; i < (packet_number - largest_observed_ - 1);
-         ++i) {
-      packets_entropy_.push_back(std::make_pair(0, false));
-    }
-    packets_entropy_.push_back(std::make_pair(entropy_hash, true));
-    largest_observed_ = packet_number;
-  } else {
-    packets_entropy_[packet_number - first_gap_] =
-        std::make_pair(entropy_hash, true);
-    AdvanceFirstGapAndGarbageCollectEntropyMap();
-  }
-
-  DVLOG(2) << "setting cumulative received entropy hash to: "
-           << static_cast<int>(packets_entropy_hash_)
-           << " updated with packet number " << packet_number
-           << " entropy hash: " << static_cast<int>(entropy_hash);
-}
-
-void QuicReceivedPacketManager::EntropyTracker::SetCumulativeEntropyUpTo(
-    QuicPacketNumber packet_number,
-    QuicPacketEntropyHash entropy_hash) {
-  DCHECK_LE(packet_number, largest_observed_);
-  if (packet_number < first_gap_) {
-    DVLOG(1) << "Ignoring set entropy at:" << packet_number
-             << " less than first_gap_:" << first_gap_;
-    return;
-  }
-  while (first_gap_ < packet_number) {
-    ++first_gap_;
-    if (!packets_entropy_.empty()) {
-      packets_entropy_.pop_front();
-    }
-  }
-  // Compute the current entropy by XORing in all entropies received including
-  // and since packet_number.
-  packets_entropy_hash_ = entropy_hash;
-  for (ReceivedEntropyHashes::const_iterator it = packets_entropy_.begin();
-       it != packets_entropy_.end(); ++it) {
-    packets_entropy_hash_ ^= it->first;
-  }
-
-  // Garbage collect entries from the beginning of the map.
-  AdvanceFirstGapAndGarbageCollectEntropyMap();
-}
-
-void QuicReceivedPacketManager::EntropyTracker::
-    AdvanceFirstGapAndGarbageCollectEntropyMap() {
-  while (!packets_entropy_.empty() && packets_entropy_.front().second) {
-    ++first_gap_;
-    packets_entropy_.pop_front();
-  }
-}
-
 QuicReceivedPacketManager::QuicReceivedPacketManager(QuicConnectionStats* stats)
     : peer_least_packet_awaiting_ack_(0),
       ack_frame_updated_(false),
       time_largest_observed_(QuicTime::Zero()),
       stats_(stats) {
   ack_frame_.largest_observed = 0;
-  ack_frame_.entropy_hash = 0;
 }
 
 QuicReceivedPacketManager::~QuicReceivedPacketManager() {}
 
 void QuicReceivedPacketManager::RecordPacketReceived(
-    QuicByteCount bytes,
     const QuicPacketHeader& header,
     QuicTime receipt_time) {
   QuicPacketNumber packet_number = header.packet_number;
-  DCHECK(IsAwaitingPacket(packet_number));
+  DCHECK(IsAwaitingPacket(packet_number)) << " packet_number:" << packet_number;
   if (!ack_frame_updated_) {
     ack_frame_.received_packet_times.clear();
   }
   ack_frame_updated_ = true;
-  if (ack_frame_.missing) {
-    // Adds the range of packet numbers from max(largest observed + 1, least
-    // awaiting ack) up to packet_number not including packet_number.
-    ack_frame_.packets.Add(
-        max(ack_frame_.largest_observed + 1, peer_least_packet_awaiting_ack_),
-        packet_number);
-  } else {
-    ack_frame_.packets.Add(header.packet_number);
-  }
+  ack_frame_.packets.Add(header.packet_number);
 
   if (ack_frame_.largest_observed > packet_number) {
-    if (ack_frame_.missing) {
-      // We've gotten one of the out of order packets - remove it from our
-      // "missing packets" list.
-      DVLOG(1) << "Removing " << packet_number << " from missing list";
-      ack_frame_.packets.Remove(packet_number);
-    }
-
     // Record how out of order stats.
     ++stats_->packets_reordered;
     stats_->max_sequence_reordering =
-        max(stats_->max_sequence_reordering,
-            ack_frame_.largest_observed - packet_number);
+        std::max(stats_->max_sequence_reordering,
+                 ack_frame_.largest_observed - packet_number);
     int64_t reordering_time_us =
         (receipt_time - time_largest_observed_).ToMicroseconds();
     stats_->max_time_reordering_us =
-        max(stats_->max_time_reordering_us, reordering_time_us);
+        std::max(stats_->max_time_reordering_us, reordering_time_us);
   }
   if (packet_number > ack_frame_.largest_observed) {
     ack_frame_.largest_observed = packet_number;
     time_largest_observed_ = receipt_time;
   }
-  if (ack_frame_.missing) {
-    entropy_tracker_.RecordPacketEntropyHash(packet_number,
-                                             header.entropy_hash);
-  }
 
   ack_frame_.received_packet_times.push_back(
       std::make_pair(packet_number, receipt_time));
 }
 
 bool QuicReceivedPacketManager::IsMissing(QuicPacketNumber packet_number) {
-  if (ack_frame_.missing) {
-    return ack_frame_.packets.Contains(packet_number);
-  }
   return packet_number < ack_frame_.largest_observed &&
          !ack_frame_.packets.Contains(packet_number);
 }
@@ -214,7 +88,7 @@ struct isTooLarge {
   // Return true if the packet in p is too different from largest_observed_
   // to express.
   bool operator()(const std::pair<QuicPacketNumber, QuicTime>& p) const {
-    return largest_observed_ - p.first >= numeric_limits<uint8_t>::max();
+    return largest_observed_ - p.first >= std::numeric_limits<uint8_t>::max();
   }
 };
 }  // namespace
@@ -222,10 +96,6 @@ struct isTooLarge {
 const QuicFrame QuicReceivedPacketManager::GetUpdatedAckFrame(
     QuicTime approximate_now) {
   ack_frame_updated_ = false;
-  if (ack_frame_.missing) {
-    ack_frame_.entropy_hash = EntropyHash(ack_frame_.largest_observed);
-  }
-
   if (time_largest_observed_ == QuicTime::Zero()) {
     // We have received no packets.
     ack_frame_.ack_delay_time = QuicTime::Delta::Infinite();
@@ -241,7 +111,7 @@ const QuicFrame QuicReceivedPacketManager::GetUpdatedAckFrame(
   for (PacketTimeVector::iterator it = ack_frame_.received_packet_times.begin();
        it != ack_frame_.received_packet_times.end();) {
     if (ack_frame_.largest_observed - it->first >=
-        numeric_limits<uint8_t>::max()) {
+        std::numeric_limits<uint8_t>::max()) {
       it = ack_frame_.received_packet_times.erase(it);
     } else {
       ++it;
@@ -251,11 +121,6 @@ const QuicFrame QuicReceivedPacketManager::GetUpdatedAckFrame(
   return QuicFrame(&ack_frame_);
 }
 
-QuicPacketEntropyHash QuicReceivedPacketManager::EntropyHash(
-    QuicPacketNumber packet_number) const {
-  return entropy_tracker_.EntropyHash(packet_number);
-}
-
 bool QuicReceivedPacketManager::DontWaitForPacketsBefore(
     QuicPacketNumber least_unacked) {
   peer_least_packet_awaiting_ack_ = least_unacked;
@@ -269,13 +134,6 @@ void QuicReceivedPacketManager::UpdatePacketInformationSentByPeer(
   if (stop_waiting.least_unacked > peer_least_packet_awaiting_ack_) {
     bool packets_updated = DontWaitForPacketsBefore(stop_waiting.least_unacked);
     if (packets_updated) {
-      if (ack_frame_.missing) {
-        DVLOG(1) << "Updating entropy hashed since we missed packets";
-        // There were some missing packets that we won't ever get now.
-        // Recalculate the received entropy hash.
-        entropy_tracker_.SetCumulativeEntropyUpTo(stop_waiting.least_unacked,
-                                                  stop_waiting.entropy_hash);
-      }
       // Ack frame gets updated because packets set is updated because of stop
       // waiting frame.
       ack_frame_updated_ = true;
@@ -286,35 +144,17 @@ void QuicReceivedPacketManager::UpdatePacketInformationSentByPeer(
 }
 
 bool QuicReceivedPacketManager::HasMissingPackets() const {
-  if (ack_frame_.missing) {
-    return !ack_frame_.packets.Empty();
-  }
-
   return ack_frame_.packets.NumIntervals() > 1 ||
          (!ack_frame_.packets.Empty() &&
           ack_frame_.packets.Min() >
-              max(QuicPacketNumber(1), peer_least_packet_awaiting_ack_));
+              std::max(QuicPacketNumber(1), peer_least_packet_awaiting_ack_));
 }
 
 bool QuicReceivedPacketManager::HasNewMissingPackets() const {
-  if (ack_frame_.missing) {
-    return !ack_frame_.packets.Empty() &&
-           (ack_frame_.largest_observed - ack_frame_.packets.Max()) <=
-               kMaxPacketsAfterNewMissing;
-  }
-
   return HasMissingPackets() &&
          ack_frame_.packets.LastIntervalLength() <= kMaxPacketsAfterNewMissing;
 }
 
-size_t QuicReceivedPacketManager::NumTrackedPackets() const {
-  return entropy_tracker_.size();
-}
-
-void QuicReceivedPacketManager::SetVersion(QuicVersion version) {
-  ack_frame_.missing = version <= QUIC_VERSION_33;
-}
-
 bool QuicReceivedPacketManager::ack_frame_updated() const {
   return ack_frame_updated_;
 }
diff --git a/src/net/quic/core/quic_received_packet_manager.h b/src/net/quic/core/quic_received_packet_manager.h
index dbfcf3f..06ab94f 100644
--- a/src/net/quic/core/quic_received_packet_manager.h
+++ b/src/net/quic/core/quic_received_packet_manager.h
@@ -1,9 +1,6 @@
 // Copyright 2013 The Chromium Authors. All rights reserved.
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
-//
-// Manages the packet entropy calculation for both sent and received packets
-// for a connection.
 
 #ifndef NET_QUIC_QUIC_RECEIVED_PACKET_MANAGER_H_
 #define NET_QUIC_QUIC_RECEIVED_PACKET_MANAGER_H_
@@ -13,100 +10,30 @@
 #include <deque>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_config.h"
 #include "net/quic/core/quic_framer.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
 namespace test {
-class EntropyTrackerPeer;
 class QuicConnectionPeer;
 class QuicReceivedPacketManagerPeer;
 }  // namespace test
 
 struct QuicConnectionStats;
 
-// Records all received packets by a connection and tracks their entropy.
-// Also calculates the correct entropy for the framer when it truncates an ack
-// frame being serialized.
-class NET_EXPORT_PRIVATE QuicReceivedPacketManager
-    : public QuicReceivedEntropyHashCalculatorInterface {
+// Records all received packets by a connection.
+class NET_EXPORT_PRIVATE QuicReceivedPacketManager {
  public:
-  class NET_EXPORT_PRIVATE EntropyTracker {
-   public:
-    EntropyTracker();
-    ~EntropyTracker();
-
-    // Compute the XOR of the entropy of all received packets up to
-    // and including packet_number.
-    // Requires that either:
-    //   packet_number == largest_observed_
-    // or:
-    //   packet_number > first_gap_ &&
-    //   packet_number < largest_observed_ &&
-    //   packet_number in packets_entropy_
-    QuicPacketEntropyHash EntropyHash(QuicPacketNumber packet_number) const;
-
-    // Record the received entropy hash against |packet_number|.
-    // Performs garbage collection to advance first_gap_ if
-    // packet_number == first_gap_.
-    void RecordPacketEntropyHash(QuicPacketNumber packet_number,
-                                 QuicPacketEntropyHash entropy_hash);
-
-    // Sets the entropy hash up to but not including a packet number based
-    // on the hash provided by a StopWaiting frame.  Clears older packet
-    // entropy entries and performs garbage collection up to the first gap.
-    void SetCumulativeEntropyUpTo(QuicPacketNumber packet_number,
-                                  QuicPacketEntropyHash entropy_hash);
-
-    size_t size() const { return packets_entropy_.size(); }
-
-   private:
-    friend class test::EntropyTrackerPeer;
-
-    // A deque indexed by packet number storing the packet's hash and whether
-    // a hash was recorded for that packet number.
-    typedef std::deque<std::pair<QuicPacketEntropyHash, bool>>
-        ReceivedEntropyHashes;
-
-    // Recomputes first_gap_ and removes packets_entropy_ entries that are no
-    // longer needed to compute EntropyHash.
-    void AdvanceFirstGapAndGarbageCollectEntropyMap();
-
-    // Map of received packet numbers to their corresponding entropy.
-    // Stores an entry for every received packet whose packet_number is larger
-    // than first_gap_.  Packets without the entropy bit set have an entropy
-    // value of 0.
-    ReceivedEntropyHashes packets_entropy_;
-
-    // Cumulative hash of entropy of all received packets.
-    QuicPacketEntropyHash packets_entropy_hash_;
-
-    // packet number of the first packet that we do not know the entropy of.
-    // If there are no gaps in the received packet sequence,
-    // packets_entropy_ will be empty and first_gap_ will be equal to
-    // 'largest_observed_ + 1' since that's the first packet for which
-    // entropy is unknown.  If there are gaps, packets_entropy_ will
-    // contain entries for all received packets with packet_number >
-    // first_gap_.
-    QuicPacketNumber first_gap_;
-
-    // packet number of the largest observed packet.
-    QuicPacketNumber largest_observed_;
-
-    DISALLOW_COPY_AND_ASSIGN(EntropyTracker);
-  };
-
   explicit QuicReceivedPacketManager(QuicConnectionStats* stats);
-  ~QuicReceivedPacketManager() override;
+  virtual ~QuicReceivedPacketManager();
 
   // Updates the internal state concerning which packets have been received.
-  // bytes: the packet size in bytes including Quic Headers.
   // header: the packet header.
   // timestamp: the arrival time of the packet.
-  virtual void RecordPacketReceived(QuicByteCount bytes,
-                                    const QuicPacketHeader& header,
+  virtual void RecordPacketReceived(const QuicPacketHeader& header,
                                     QuicTime receipt_time);
 
   // Checks whether |packet_number| is missing and less than largest observed.
@@ -120,12 +47,6 @@ class NET_EXPORT_PRIVATE QuicReceivedPacketManager
   // another packet is received, or it will change.
   const QuicFrame GetUpdatedAckFrame(QuicTime approximate_now);
 
-  // QuicReceivedEntropyHashCalculatorInterface
-  // Called by QuicFramer, when the outgoing ack gets truncated, to recalculate
-  // the received entropy hash for the truncated ack frame.
-  QuicPacketEntropyHash EntropyHash(
-      QuicPacketNumber packet_number) const override;
-
   // Updates internal state based on |stop_waiting|.
   virtual void UpdatePacketInformationSentByPeer(
       const QuicStopWaitingFrame& stop_waiting);
@@ -137,12 +58,6 @@ class NET_EXPORT_PRIVATE QuicReceivedPacketManager
   // packets of the largest observed.
   virtual bool HasNewMissingPackets() const;
 
-  // Returns the number of packets being tracked in the EntropyTracker.
-  size_t NumTrackedPackets() const;
-
-  // Sets the mode of packets set of ack_frame_ based on |version|.
-  void SetVersion(QuicVersion version);
-
   QuicPacketNumber peer_least_packet_awaiting_ack() {
     return peer_least_packet_awaiting_ack_;
   }
@@ -164,9 +79,6 @@ class NET_EXPORT_PRIVATE QuicReceivedPacketManager
   // |least_unacked| unacked, false otherwise.
   bool DontWaitForPacketsBefore(QuicPacketNumber least_unacked);
 
-  // Tracks entropy hashes of received packets.
-  EntropyTracker entropy_tracker_;
-
   // Least packet number of the the packet sent by the peer for which it
   // hasn't received an ack.
   QuicPacketNumber peer_least_packet_awaiting_ack_;
diff --git a/src/net/quic/core/quic_sent_entropy_manager.cc b/src/net/quic/core/quic_sent_entropy_manager.cc
deleted file mode 100644
index f10e5bc..0000000
--- a/src/net/quic/core/quic_sent_entropy_manager.cc
+++ /dev/null
@@ -1,113 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "net/quic/core/quic_sent_entropy_manager.h"
-
-#include "base/logging.h"
-#include "net/base/linked_hash_map.h"
-#include "net/quic/core/quic_flags.h"
-
-using std::make_pair;
-using std::max;
-using std::min;
-
-namespace net {
-
-QuicSentEntropyManager::QuicSentEntropyManager() : map_offset_(1) {}
-
-QuicSentEntropyManager::~QuicSentEntropyManager() {}
-
-QuicPacketEntropyHash QuicSentEntropyManager::GetPacketEntropy(
-    QuicPacketNumber packet_number) const {
-  return packets_entropy_[packet_number - map_offset_];
-}
-
-QuicPacketNumber QuicSentEntropyManager::GetLargestPacketWithEntropy() const {
-  return map_offset_ + packets_entropy_.size() - 1;
-}
-
-QuicPacketNumber QuicSentEntropyManager::GetSmallestPacketWithEntropy() const {
-  return map_offset_;
-}
-
-void QuicSentEntropyManager::UpdateCumulativeEntropy(
-    QuicPacketNumber packet_number,
-    CumulativeEntropy* cumulative) const {
-  while (cumulative->packet_number < packet_number) {
-    ++cumulative->packet_number;
-    cumulative->entropy ^= GetPacketEntropy(cumulative->packet_number);
-  }
-}
-
-void QuicSentEntropyManager::RecordPacketEntropyHash(
-    QuicPacketNumber packet_number,
-    QuicPacketEntropyHash entropy_hash) {
-  if (!packets_entropy_.empty()) {
-    // Ensure packets always are recorded in order.
-    // Every packet's entropy is recorded, even if it's not sent, so there
-    // are not packet number gaps.
-    DCHECK_EQ(GetLargestPacketWithEntropy() + 1, packet_number);
-  }
-  packets_entropy_.push_back(entropy_hash);
-  DVLOG(2) << "Recorded packet number " << packet_number
-           << " with entropy hash: " << static_cast<int>(entropy_hash);
-}
-
-QuicPacketEntropyHash QuicSentEntropyManager::GetCumulativeEntropy(
-    QuicPacketNumber packet_number) {
-  DCHECK_LE(last_cumulative_entropy_.packet_number, packet_number);
-  DCHECK_GE(GetLargestPacketWithEntropy(), packet_number);
-  // First the entropy for largest_observed packet number should be updated.
-  UpdateCumulativeEntropy(packet_number, &last_cumulative_entropy_);
-  return last_cumulative_entropy_.entropy;
-}
-
-bool QuicSentEntropyManager::IsValidEntropy(
-    QuicPacketNumber largest_observed,
-    const PacketNumberQueue& missing_packets,
-    QuicPacketEntropyHash entropy_hash) {
-  DCHECK_GE(largest_observed, last_valid_entropy_.packet_number);
-  // Ensure the largest and smallest packet numbers are in range.
-  if (largest_observed > GetLargestPacketWithEntropy()) {
-    return false;
-  }
-  if (!missing_packets.Empty() &&
-      missing_packets.Min() < GetSmallestPacketWithEntropy()) {
-    return false;
-  }
-  // First the entropy for largest_observed packet number should be updated.
-  UpdateCumulativeEntropy(largest_observed, &last_valid_entropy_);
-
-  // Now XOR out all the missing entropies.
-  QuicPacketEntropyHash expected_entropy_hash = last_valid_entropy_.entropy;
-  for (const Interval<QuicPacketNumber>& interval : missing_packets) {
-    for (QuicPacketNumber packet_number = interval.min();
-         packet_number < interval.max(); ++packet_number) {
-      expected_entropy_hash ^= GetPacketEntropy(packet_number);
-    }
-  }
-  DLOG_IF(WARNING, entropy_hash != expected_entropy_hash)
-      << "Invalid entropy hash: " << static_cast<int>(entropy_hash)
-      << " expected entropy hash: " << static_cast<int>(expected_entropy_hash);
-  return entropy_hash == expected_entropy_hash;
-}
-
-void QuicSentEntropyManager::ClearEntropyBefore(
-    QuicPacketNumber packet_number) {
-  // Don't discard entropy before updating the cumulative entropy used to
-  // calculate EntropyHash and IsValidEntropy.
-  if (last_cumulative_entropy_.packet_number < packet_number) {
-    UpdateCumulativeEntropy(packet_number, &last_cumulative_entropy_);
-  }
-  if (last_valid_entropy_.packet_number < packet_number) {
-    UpdateCumulativeEntropy(packet_number, &last_valid_entropy_);
-  }
-  while (map_offset_ < packet_number) {
-    packets_entropy_.pop_front();
-    ++map_offset_;
-  }
-  DVLOG(2) << "Cleared entropy before: " << packet_number;
-}
-
-}  // namespace net
diff --git a/src/net/quic/core/quic_sent_entropy_manager.h b/src/net/quic/core/quic_sent_entropy_manager.h
deleted file mode 100644
index 45f9b43..0000000
--- a/src/net/quic/core/quic_sent_entropy_manager.h
+++ /dev/null
@@ -1,88 +0,0 @@
-// Copyright 2013 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-//
-// Manages the packet entropy calculation for both sent and received packets
-// for a connection.
-
-#ifndef NET_QUIC_QUIC_SENT_ENTROPY_MANAGER_H_
-#define NET_QUIC_QUIC_SENT_ENTROPY_MANAGER_H_
-
-#include <deque>
-
-#include "base/macros.h"
-#include "net/base/linked_hash_map.h"
-#include "net/quic/core/quic_framer.h"
-#include "net/quic/core/quic_protocol.h"
-
-namespace net {
-
-namespace test {
-class QuicConnectionPeer;
-}  // namespace test
-
-// Records all sent packets by a connection to track the cumulative entropy of
-// sent packets.  It is used by the connection to validate an ack
-// frame sent by the peer as a preventive measure against the optimistic ack
-// attack.
-class NET_EXPORT_PRIVATE QuicSentEntropyManager {
- public:
-  QuicSentEntropyManager();
-  virtual ~QuicSentEntropyManager();
-
-  // Record |entropy_hash| for sent packet corresponding to |packet_number|.
-  void RecordPacketEntropyHash(QuicPacketNumber packet_number,
-                               QuicPacketEntropyHash entropy_hash);
-
-  // Retrieves the cumulative entropy up to |packet_number|.
-  // Must always be called with a monotonically increasing |packet_number|.
-  QuicPacketEntropyHash GetCumulativeEntropy(QuicPacketNumber packet_number);
-
-  // Returns true if |entropy_hash| matches the expected sent entropy hash
-  // up to |largest_observed| removing packet numbers from |missing_packets|.
-  // Must always be called with a monotonically increasing |largest_observed|.
-  bool IsValidEntropy(QuicPacketNumber largest_observed,
-                      const PacketNumberQueue& missing_packets,
-                      QuicPacketEntropyHash entropy_hash);
-
-  // Removes unnecessary entries before |packet_number|.
-  void ClearEntropyBefore(QuicPacketNumber packet_number);
-
- private:
-  friend class test::QuicConnectionPeer;
-
-  typedef std::deque<QuicPacketEntropyHash> SentEntropyMap;
-
-  struct CumulativeEntropy {
-    CumulativeEntropy() : packet_number(0), entropy(0) {}
-
-    QuicPacketNumber packet_number;
-    QuicPacketEntropyHash entropy;
-  };
-
-  // Convenience methods to get the largest and smallest packets with entropies.
-  QuicPacketNumber GetLargestPacketWithEntropy() const;
-  QuicPacketNumber GetSmallestPacketWithEntropy() const;
-  // Convenience method to get the entropy hash for |packet_number|.
-  QuicPacketEntropyHash GetPacketEntropy(QuicPacketNumber packet_number) const;
-
-  // Update the cumulative entropy to |packet_number|.
-  void UpdateCumulativeEntropy(QuicPacketNumber packet_number,
-                               CumulativeEntropy* cumulative) const;
-
-  // Maps packet numbers to the sent entropy hash for the packet number.
-  SentEntropyMap packets_entropy_;
-  QuicPacketNumber map_offset_;
-
-  // Cache the cumulative entropy for IsValidEntropy.
-  CumulativeEntropy last_valid_entropy_;
-
-  // Cache the cumulative entropy for the packet number used by EntropyHash.
-  CumulativeEntropy last_cumulative_entropy_;
-
-  DISALLOW_COPY_AND_ASSIGN(QuicSentEntropyManager);
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_QUIC_SENT_ENTROPY_MANAGER_H_
diff --git a/src/net/quic/core/quic_sent_packet_manager.cc b/src/net/quic/core/quic_sent_packet_manager.cc
index 5a97b1e..022ce3e 100644
--- a/src/net/quic/core/quic_sent_packet_manager.cc
+++ b/src/net/quic/core/quic_sent_packet_manager.cc
@@ -18,9 +18,6 @@
 #include "net/quic/core/quic_connection_stats.h"
 #include "net/quic/core/quic_flags.h"
 
-using std::max;
-using std::min;
-using std::pair;
 
 namespace net {
 
@@ -38,11 +35,14 @@ const size_t kMinTimeoutsBeforePathDegrading = 2;
 // This limits the tenth retransmitted packet to 10s after the initial CHLO.
 static const int64_t kMinHandshakeTimeoutMs = 10;
 
+// Ensure the handshake timer isnt't faster than 25ms.
+static const int64_t kConservativeMinHandshakeTimeoutMs = kMaxDelayedAckTimeMs;
+
 // Sends up to two tail loss probes before firing an RTO,
 // per draft RFC draft-dukkipati-tcpm-tcp-loss-probe.
 static const size_t kDefaultMaxTailLossProbes = 2;
 
-bool HasCryptoHandshake(const TransmissionInfo& transmission_info) {
+bool HasCryptoHandshake(const QuicTransmissionInfo& transmission_info) {
   DCHECK(!transmission_info.has_crypto_handshake ||
          !transmission_info.retransmittable_frames.empty());
   return transmission_info.has_crypto_handshake;
@@ -73,7 +73,6 @@ QuicSentPacketManager::QuicSentPacketManager(
       loss_algorithm_(&general_loss_algorithm_),
       general_loss_algorithm_(loss_type),
       n_connection_simulation_(false),
-      receive_buffer_bytes_(kDefaultSocketReceiveBuffer),
       least_packet_awaited_by_peer_(1),
       first_rto_transmission_(0),
       consecutive_rto_count_(0),
@@ -85,6 +84,7 @@ QuicSentPacketManager::QuicSentPacketManager(
       using_pacing_(false),
       use_new_rto_(false),
       undo_pending_retransmits_(false),
+      conservative_handshake_retransmits_(false),
       largest_newly_acked_(0),
       largest_mtu_acked_(0),
       handshake_confirmed_(false) {
@@ -97,31 +97,50 @@ void QuicSentPacketManager::SetFromConfig(const QuicConfig& config) {
   if (config.HasReceivedInitialRoundTripTimeUs() &&
       config.ReceivedInitialRoundTripTimeUs() > 0) {
     rtt_stats_.set_initial_rtt_us(
-        max(kMinInitialRoundTripTimeUs,
-            min(kMaxInitialRoundTripTimeUs,
-                config.ReceivedInitialRoundTripTimeUs())));
+        std::max(kMinInitialRoundTripTimeUs,
+                 std::min(kMaxInitialRoundTripTimeUs,
+                          config.ReceivedInitialRoundTripTimeUs())));
   } else if (config.HasInitialRoundTripTimeUsToSend() &&
              config.GetInitialRoundTripTimeUsToSend() > 0) {
     rtt_stats_.set_initial_rtt_us(
-        max(kMinInitialRoundTripTimeUs,
-            min(kMaxInitialRoundTripTimeUs,
-                config.GetInitialRoundTripTimeUsToSend())));
-  }
-  // TODO(ianswett): BBR is currently a server only feature.
-  if (FLAGS_quic_allow_bbr && config.HasReceivedConnectionOptions() &&
-      ContainsQuicTag(config.ReceivedConnectionOptions(), kTBBR)) {
-    SetSendAlgorithm(kBBR);
-  }
-  if (config.HasReceivedConnectionOptions() &&
-      ContainsQuicTag(config.ReceivedConnectionOptions(), kRENO)) {
-    if (ContainsQuicTag(config.ReceivedConnectionOptions(), kBYTE)) {
-      SetSendAlgorithm(kRenoBytes);
-    } else {
-      SetSendAlgorithm(kReno);
+        std::max(kMinInitialRoundTripTimeUs,
+                 std::min(kMaxInitialRoundTripTimeUs,
+                          config.GetInitialRoundTripTimeUsToSend())));
+  }
+  // Configure congestion control.
+  const bool enable_client_connection_options =
+      FLAGS_quic_client_connection_options;
+  if (enable_client_connection_options) {
+    if (FLAGS_quic_allow_new_bbr &&
+        config.HasClientRequestedIndependentOption(kTBBR, perspective_)) {
+      SetSendAlgorithm(kBBR);
+    }
+    if (config.HasClientRequestedIndependentOption(kRENO, perspective_)) {
+      if (config.HasClientRequestedIndependentOption(kBYTE, perspective_)) {
+        SetSendAlgorithm(kRenoBytes);
+      } else {
+        SetSendAlgorithm(kReno);
+      }
+    } else if (config.HasClientRequestedIndependentOption(kBYTE,
+                                                          perspective_)) {
+      SetSendAlgorithm(kCubic);
+    }
+  } else {
+    if (FLAGS_quic_allow_new_bbr && config.HasReceivedConnectionOptions() &&
+        ContainsQuicTag(config.ReceivedConnectionOptions(), kTBBR)) {
+      SetSendAlgorithm(kBBR);
+    }
+    if (config.HasReceivedConnectionOptions() &&
+        ContainsQuicTag(config.ReceivedConnectionOptions(), kRENO)) {
+      if (ContainsQuicTag(config.ReceivedConnectionOptions(), kBYTE)) {
+        SetSendAlgorithm(kRenoBytes);
+      } else {
+        SetSendAlgorithm(kReno);
+      }
+    } else if (config.HasReceivedConnectionOptions() &&
+               ContainsQuicTag(config.ReceivedConnectionOptions(), kBYTE)) {
+      SetSendAlgorithm(kCubic);
     }
-  } else if (config.HasReceivedConnectionOptions() &&
-             ContainsQuicTag(config.ReceivedConnectionOptions(), kBYTE)) {
-    SetSendAlgorithm(kCubicBytes);
   }
   using_pacing_ = !FLAGS_quic_disable_pacing_for_perf_tests;
 
@@ -140,17 +159,39 @@ void QuicSentPacketManager::SetFromConfig(const QuicConfig& config) {
   if (config.HasClientSentConnectionOption(kNRTO, perspective_)) {
     use_new_rto_ = true;
   }
-  if (config.HasReceivedConnectionOptions() &&
-      ContainsQuicTag(config.ReceivedConnectionOptions(), kTIME)) {
-    general_loss_algorithm_.SetLossDetectionType(kTime);
-  }
-  if (config.HasReceivedConnectionOptions() &&
-      ContainsQuicTag(config.ReceivedConnectionOptions(), kATIM)) {
-    general_loss_algorithm_.SetLossDetectionType(kAdaptiveTime);
+  // Configure loss detection.
+  if (enable_client_connection_options) {
+    if (config.HasClientRequestedIndependentOption(kTIME, perspective_)) {
+      general_loss_algorithm_.SetLossDetectionType(kTime);
+    }
+    if (config.HasClientRequestedIndependentOption(kATIM, perspective_)) {
+      general_loss_algorithm_.SetLossDetectionType(kAdaptiveTime);
+    }
+    if (FLAGS_quic_enable_lazy_fack &&
+        config.HasClientRequestedIndependentOption(kLFAK, perspective_)) {
+      general_loss_algorithm_.SetLossDetectionType(kLazyFack);
+    }
+  } else {
+    if (config.HasReceivedConnectionOptions() &&
+        ContainsQuicTag(config.ReceivedConnectionOptions(), kTIME)) {
+      general_loss_algorithm_.SetLossDetectionType(kTime);
+    }
+    if (config.HasReceivedConnectionOptions() &&
+        ContainsQuicTag(config.ReceivedConnectionOptions(), kATIM)) {
+      general_loss_algorithm_.SetLossDetectionType(kAdaptiveTime);
+    }
+    if (FLAGS_quic_enable_lazy_fack && config.HasReceivedConnectionOptions() &&
+        ContainsQuicTag(config.ReceivedConnectionOptions(), kLFAK)) {
+      general_loss_algorithm_.SetLossDetectionType(kLazyFack);
+    }
   }
   if (config.HasClientSentConnectionOption(kUNDO, perspective_)) {
     undo_pending_retransmits_ = true;
   }
+  if (FLAGS_quic_conservative_handshake_retransmits &&
+      config.HasClientSentConnectionOption(kCONH, perspective_)) {
+    conservative_handshake_retransmits_ = true;
+  }
   send_algorithm_->SetFromConfig(config, perspective_);
 
   if (network_change_visitor_ != nullptr) {
@@ -165,8 +206,8 @@ void QuicSentPacketManager::ResumeConnectionState(
     uint32_t initial_rtt_us =
         kNumMicrosPerMilli * cached_network_params.min_rtt_ms();
     rtt_stats_.set_initial_rtt_us(
-        max(kMinInitialRoundTripTimeUs,
-            min(kMaxInitialRoundTripTimeUs, initial_rtt_us)));
+        std::max(kMinInitialRoundTripTimeUs,
+                 std::min(kMaxInitialRoundTripTimeUs, initial_rtt_us)));
   }
   send_algorithm_->ResumeConnectionState(cached_network_params,
                                          max_bandwidth_resumption);
@@ -176,7 +217,7 @@ void QuicSentPacketManager::SetNumOpenStreams(size_t num_streams) {
   if (n_connection_simulation_) {
     // Ensure the number of connections is between 1 and 5.
     send_algorithm_->SetNumEmulatedConnections(
-        min<size_t>(5, max<size_t>(1, num_streams)));
+        std::min<size_t>(5, std::max<size_t>(1, num_streams)));
   }
 }
 
@@ -191,7 +232,7 @@ void QuicSentPacketManager::SetHandshakeConfirmed() {
 void QuicSentPacketManager::OnIncomingAck(const QuicAckFrame& ack_frame,
                                           QuicTime ack_receive_time) {
   DCHECK_LE(ack_frame.largest_observed, unacked_packets_.largest_sent_packet());
-  QuicByteCount bytes_in_flight = unacked_packets_.bytes_in_flight();
+  QuicByteCount prior_in_flight = unacked_packets_.bytes_in_flight();
   UpdatePacketInformationReceivedByPeer(ack_frame);
   bool rtt_updated = MaybeUpdateRTT(ack_frame, ack_receive_time);
   DCHECK_GE(ack_frame.largest_observed, unacked_packets_.largest_observed());
@@ -203,7 +244,7 @@ void QuicSentPacketManager::OnIncomingAck(const QuicAckFrame& ack_frame,
   if (consecutive_rto_count_ > 0 && !use_new_rto_) {
     packets_lost_.clear();
   }
-  MaybeInvokeCongestionEvent(rtt_updated, bytes_in_flight);
+  MaybeInvokeCongestionEvent(rtt_updated, prior_in_flight, ack_receive_time);
   unacked_packets_.RemoveObsoletePackets();
 
   sustained_bandwidth_recorder_.RecordEstimate(
@@ -262,15 +303,16 @@ void QuicSentPacketManager::UpdatePacketInformationReceivedByPeer(
 
 void QuicSentPacketManager::MaybeInvokeCongestionEvent(
     bool rtt_updated,
-    QuicByteCount bytes_in_flight) {
+    QuicByteCount prior_in_flight,
+    QuicTime event_time) {
   if (!rtt_updated && packets_acked_.empty() && packets_lost_.empty()) {
     return;
   }
   if (using_pacing_) {
-    pacing_sender_.OnCongestionEvent(rtt_updated, bytes_in_flight,
+    pacing_sender_.OnCongestionEvent(rtt_updated, prior_in_flight, event_time,
                                      packets_acked_, packets_lost_);
   } else {
-    send_algorithm_->OnCongestionEvent(rtt_updated, bytes_in_flight,
+    send_algorithm_->OnCongestionEvent(rtt_updated, prior_in_flight, event_time,
                                        packets_acked_, packets_lost_);
   }
   packets_acked_.clear();
@@ -293,8 +335,7 @@ void QuicSentPacketManager::HandleAckForSentPackets(
       break;
     }
 
-    if ((ack_frame.missing && ack_frame.packets.Contains(packet_number)) ||
-        (!ack_frame.missing && !ack_frame.packets.Contains(packet_number))) {
+    if (!ack_frame.packets.Contains(packet_number)) {
       // Packet is still missing.
       continue;
     }
@@ -351,7 +392,7 @@ void QuicSentPacketManager::NeuterUnencryptedPackets() {
 void QuicSentPacketManager::MarkForRetransmission(
     QuicPacketNumber packet_number,
     TransmissionType transmission_type) {
-  const TransmissionInfo& transmission_info =
+  const QuicTransmissionInfo& transmission_info =
       unacked_packets_.GetTransmissionInfo(packet_number);
   QUIC_BUG_IF(transmission_info.retransmittable_frames.empty());
   // Both TLP and the new RTO leave the packets in flight and let the loss
@@ -375,7 +416,7 @@ void QuicSentPacketManager::MarkForRetransmission(
 }
 
 void QuicSentPacketManager::RecordOneSpuriousRetransmission(
-    const TransmissionInfo& info) {
+    const QuicTransmissionInfo& info) {
   stats_->bytes_spuriously_retransmitted += info.bytes_sent;
   ++stats_->packets_spuriously_retransmitted;
   if (debug_delegate_ != nullptr) {
@@ -385,11 +426,11 @@ void QuicSentPacketManager::RecordOneSpuriousRetransmission(
 }
 
 void QuicSentPacketManager::RecordSpuriousRetransmissions(
-    const TransmissionInfo& info,
+    const QuicTransmissionInfo& info,
     QuicPacketNumber acked_packet_number) {
   QuicPacketNumber retransmission = info.retransmission;
   while (retransmission != 0) {
-    const TransmissionInfo& retransmit_info =
+    const QuicTransmissionInfo& retransmit_info =
         unacked_packets_.GetTransmissionInfo(retransmission);
     retransmission = retransmit_info.retransmission;
     RecordOneSpuriousRetransmission(retransmit_info);
@@ -406,7 +447,7 @@ bool QuicSentPacketManager::HasPendingRetransmissions() const {
   return !pending_retransmissions_.empty();
 }
 
-PendingRetransmission QuicSentPacketManager::NextPendingRetransmission() {
+QuicPendingRetransmission QuicSentPacketManager::NextPendingRetransmission() {
   QUIC_BUG_IF(pending_retransmissions_.empty())
       << "Unexpected call to PendingRetransmissions() with empty pending "
       << "retransmission list. Corrupted memory usage imminent.";
@@ -424,21 +465,21 @@ PendingRetransmission QuicSentPacketManager::NextPendingRetransmission() {
     }
   }
   DCHECK(unacked_packets_.IsUnacked(packet_number)) << packet_number;
-  const TransmissionInfo& transmission_info =
+  const QuicTransmissionInfo& transmission_info =
       unacked_packets_.GetTransmissionInfo(packet_number);
   DCHECK(!transmission_info.retransmittable_frames.empty());
 
-  return PendingRetransmission(path_id_, packet_number, transmission_type,
-                               transmission_info.retransmittable_frames,
-                               transmission_info.has_crypto_handshake,
-                               transmission_info.num_padding_bytes,
-                               transmission_info.encryption_level,
-                               transmission_info.packet_number_length);
+  return QuicPendingRetransmission(path_id_, packet_number, transmission_type,
+                                   transmission_info.retransmittable_frames,
+                                   transmission_info.has_crypto_handshake,
+                                   transmission_info.num_padding_bytes,
+                                   transmission_info.encryption_level,
+                                   transmission_info.packet_number_length);
 }
 
 QuicPacketNumber QuicSentPacketManager::GetNewestRetransmission(
     QuicPacketNumber packet_number,
-    const TransmissionInfo& transmission_info) const {
+    const QuicTransmissionInfo& transmission_info) const {
   QuicPacketNumber retransmission = transmission_info.retransmission;
   while (retransmission != 0) {
     packet_number = retransmission;
@@ -448,31 +489,8 @@ QuicPacketNumber QuicSentPacketManager::GetNewestRetransmission(
   return packet_number;
 }
 
-void QuicSentPacketManager::MarkPacketNotRetransmittable(
-    QuicPacketNumber packet_number,
-    QuicTime::Delta ack_delay_time) {
-  if (!unacked_packets_.IsUnacked(packet_number)) {
-    return;
-  }
-
-  const TransmissionInfo& transmission_info =
-      unacked_packets_.GetTransmissionInfo(packet_number);
-  QuicPacketNumber newest_transmission =
-      GetNewestRetransmission(packet_number, transmission_info);
-  // We do not need to retransmit this packet anymore.
-  if (delegate_ != nullptr) {
-    delegate_->OnPacketMarkedNotRetransmittable(path_id_, newest_transmission,
-                                                ack_delay_time);
-  } else {
-    pending_retransmissions_.erase(newest_transmission);
-  }
-
-  unacked_packets_.NotifyAndClearListeners(newest_transmission, ack_delay_time);
-  unacked_packets_.RemoveRetransmittability(packet_number);
-}
-
 void QuicSentPacketManager::MarkPacketHandled(QuicPacketNumber packet_number,
-                                              TransmissionInfo* info,
+                                              QuicTransmissionInfo* info,
                                               QuicTime::Delta ack_delay_time) {
   QuicPacketNumber newest_transmission =
       GetNewestRetransmission(packet_number, *info);
@@ -499,7 +517,7 @@ void QuicSentPacketManager::MarkPacketHandled(QuicPacketNumber packet_number,
     // transmission of a crypto packet is in flight at once.
     // TODO(ianswett): Instead of handling all crypto packets special,
     // only handle nullptr encrypted packets in a special way.
-    const TransmissionInfo& newest_transmission_info =
+    const QuicTransmissionInfo& newest_transmission_info =
         unacked_packets_.GetTransmissionInfo(newest_transmission);
     if (HasCryptoHandshake(newest_transmission_info)) {
       unacked_packets_.RemoveFromInFlight(newest_transmission);
@@ -577,9 +595,10 @@ void QuicSentPacketManager::OnRetransmissionTimeout() {
       return;
     case LOSS_MODE: {
       ++stats_->loss_timeout_count;
-      QuicByteCount bytes_in_flight = unacked_packets_.bytes_in_flight();
-      InvokeLossDetection(clock_->Now());
-      MaybeInvokeCongestionEvent(false, bytes_in_flight);
+      QuicByteCount prior_in_flight = unacked_packets_.bytes_in_flight();
+      const QuicTime now = clock_->Now();
+      InvokeLossDetection(now);
+      MaybeInvokeCongestionEvent(false, prior_in_flight, now);
       return;
     }
     case TLP_MODE:
@@ -632,9 +651,6 @@ bool QuicSentPacketManager::MaybeRetransmitTailLossProbe() {
     if (!it->in_flight || it->retransmittable_frames.empty()) {
       continue;
     }
-    if (!handshake_confirmed_) {
-      DCHECK(!it->has_crypto_handshake);
-    }
     MarkForRetransmission(packet_number, TLP_RETRANSMISSION);
     return true;
   }
@@ -732,7 +748,7 @@ bool QuicSentPacketManager::MaybeUpdateRTT(const QuicAckFrame& ack_frame,
   }
   // We calculate the RTT based on the highest ACKed packet number, the lower
   // packet numbers will include the ACK aggregation delay.
-  const TransmissionInfo& transmission_info =
+  const QuicTransmissionInfo& transmission_info =
       unacked_packets_.GetTransmissionInfo(ack_frame.largest_observed);
   // Ensure the packet has a valid sent time.
   if (transmission_info.sent_time == QuicTime::Zero()) {
@@ -743,7 +759,8 @@ bool QuicSentPacketManager::MaybeUpdateRTT(const QuicAckFrame& ack_frame,
 
   QuicTime::Delta send_delta = ack_receive_time - transmission_info.sent_time;
   const int kMaxSendDeltaSeconds = 30;
-  if (send_delta.ToSeconds() > kMaxSendDeltaSeconds) {
+  if (!FLAGS_quic_allow_large_send_deltas &&
+      send_delta.ToSeconds() > kMaxSendDeltaSeconds) {
     // send_delta can be very high if local clock is changed mid-connection.
     LOG(WARNING) << "Excessive send delta: " << send_delta.ToSeconds()
                  << ", setting to: " << kMaxSendDeltaSeconds
@@ -779,12 +796,16 @@ QuicTime::Delta QuicSentPacketManager::TimeUntilSend(QuicTime now,
 }
 
 const QuicTime QuicSentPacketManager::GetRetransmissionTime() const {
-  // Don't set the timer if there are no packets in flight or we've already
+  // Don't set the timer if there is nothing to retransmit or we've already
   // queued a tlp transmission and it hasn't been sent yet.
   if (!unacked_packets_.HasInFlightPackets() ||
       pending_timer_transmission_count_ > 0) {
     return QuicTime::Zero();
   }
+  if (FLAGS_quic_more_conservative_retransmission_alarm &&
+      !unacked_packets_.HasUnackedRetransmittableFrames()) {
+    return QuicTime::Zero();
+  }
   switch (GetRetransmissionMode()) {
     case HANDSHAKE_MODE:
       return clock_->ApproximateNow() + GetCryptoRetransmissionDelay();
@@ -818,11 +839,17 @@ const QuicTime::Delta QuicSentPacketManager::GetCryptoRetransmissionDelay()
   // This is equivalent to the TailLossProbeDelay, but slightly more aggressive
   // because crypto handshake messages don't incur a delayed ack time.
   QuicTime::Delta srtt = rtt_stats_.smoothed_rtt();
+  int64_t delay_ms;
   if (srtt.IsZero()) {
     srtt = QuicTime::Delta::FromMicroseconds(rtt_stats_.initial_rtt_us());
   }
-  int64_t delay_ms = max(kMinHandshakeTimeoutMs,
-                         static_cast<int64_t>(1.5 * srtt.ToMilliseconds()));
+  if (conservative_handshake_retransmits_) {
+    delay_ms = std::max(kConservativeMinHandshakeTimeoutMs,
+                        static_cast<int64_t>(2 * srtt.ToMilliseconds()));
+  } else {
+    delay_ms = std::max(kMinHandshakeTimeoutMs,
+                        static_cast<int64_t>(1.5 * srtt.ToMilliseconds()));
+  }
   return QuicTime::Delta::FromMilliseconds(
       delay_ms << consecutive_crypto_retransmission_count_);
 }
@@ -834,33 +861,37 @@ const QuicTime::Delta QuicSentPacketManager::GetTailLossProbeDelay() const {
   }
   if (enable_half_rtt_tail_loss_probe_ && consecutive_tlp_count_ == 0u) {
     return QuicTime::Delta::FromMilliseconds(
-        max(kMinTailLossProbeTimeoutMs,
-            static_cast<int64_t>(0.5 * srtt.ToMilliseconds())));
+        std::max(kMinTailLossProbeTimeoutMs,
+                 static_cast<int64_t>(0.5 * srtt.ToMilliseconds())));
   }
   if (!unacked_packets_.HasMultipleInFlightPackets()) {
     return std::max(2 * srtt, 1.5 * srtt + QuicTime::Delta::FromMilliseconds(
                                                kMinRetransmissionTimeMs / 2));
   }
   return QuicTime::Delta::FromMilliseconds(
-      max(kMinTailLossProbeTimeoutMs,
-          static_cast<int64_t>(2 * srtt.ToMilliseconds())));
+      std::max(kMinTailLossProbeTimeoutMs,
+               static_cast<int64_t>(2 * srtt.ToMilliseconds())));
 }
 
 const QuicTime::Delta QuicSentPacketManager::GetRetransmissionDelay() const {
-  QuicTime::Delta retransmission_delay = send_algorithm_->RetransmissionDelay();
-  if (retransmission_delay.IsZero()) {
+  QuicTime::Delta retransmission_delay = QuicTime::Delta::Zero();
+  if (rtt_stats_.smoothed_rtt().IsZero()) {
     // We are in the initial state, use default timeout values.
     retransmission_delay =
         QuicTime::Delta::FromMilliseconds(kDefaultRetransmissionTimeMs);
-  } else if (retransmission_delay.ToMilliseconds() < kMinRetransmissionTimeMs) {
+  } else {
     retransmission_delay =
-        QuicTime::Delta::FromMilliseconds(kMinRetransmissionTimeMs);
+        rtt_stats_.smoothed_rtt() + 4 * rtt_stats_.mean_deviation();
+    if (retransmission_delay.ToMilliseconds() < kMinRetransmissionTimeMs) {
+      retransmission_delay =
+          QuicTime::Delta::FromMilliseconds(kMinRetransmissionTimeMs);
+    }
   }
 
   // Calculate exponential back off.
   retransmission_delay =
       retransmission_delay *
-      (1 << min<size_t>(consecutive_rto_count_, kMaxRetransmissions));
+      (1 << std::min<size_t>(consecutive_rto_count_, kMaxRetransmissions));
 
   if (retransmission_delay.ToMilliseconds() > kMaxRetransmissionTimeMs) {
     return QuicTime::Delta::FromMilliseconds(kMaxRetransmissionTimeMs);
@@ -923,8 +954,8 @@ void QuicSentPacketManager::CancelRetransmissionsForStream(
 void QuicSentPacketManager::SetSendAlgorithm(
     CongestionControlType congestion_control_type) {
   SetSendAlgorithm(SendAlgorithmInterface::Create(
-      clock_, &rtt_stats_, congestion_control_type, stats_,
-      initial_congestion_window_));
+      clock_, &rtt_stats_, &unacked_packets_, congestion_control_type,
+      QuicRandom::GetInstance(), stats_, initial_congestion_window_));
 }
 
 void QuicSentPacketManager::SetSendAlgorithm(
@@ -946,10 +977,6 @@ void QuicSentPacketManager::OnConnectionMigration(QuicPathId,
   send_algorithm_->OnConnectionMigration();
 }
 
-bool QuicSentPacketManager::IsHandshakeConfirmed() const {
-  return handshake_confirmed_;
-}
-
 void QuicSentPacketManager::SetDebugDelegate(DebugDelegate* debug_delegate) {
   debug_delegate_ = debug_delegate;
 }
@@ -987,17 +1014,12 @@ size_t QuicSentPacketManager::GetConsecutiveTlpCount() const {
   return consecutive_tlp_count_;
 }
 
-TransmissionInfo* QuicSentPacketManager::GetMutableTransmissionInfo(
-    QuicPacketNumber packet_number) {
-  return unacked_packets_.GetMutableTransmissionInfo(packet_number);
-}
-
-void QuicSentPacketManager::RemoveObsoletePackets() {
-  unacked_packets_.RemoveObsoletePackets();
-}
-
 void QuicSentPacketManager::OnApplicationLimited() {
   send_algorithm_->OnApplicationLimited(unacked_packets_.bytes_in_flight());
 }
 
+const SendAlgorithmInterface* QuicSentPacketManager::GetSendAlgorithm() const {
+  return send_algorithm_.get();
+}
+
 }  // namespace net
diff --git a/src/net/quic/core/quic_sent_packet_manager.h b/src/net/quic/core/quic_sent_packet_manager.h
index 17e2203..cb1f607 100644
--- a/src/net/quic/core/quic_sent_packet_manager.h
+++ b/src/net/quic/core/quic_sent_packet_manager.h
@@ -15,12 +15,13 @@
 
 #include "base/macros.h"
 #include "net/base/linked_hash_map.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/congestion_control/general_loss_algorithm.h"
 #include "net/quic/core/congestion_control/loss_detection_interface.h"
 #include "net/quic/core/congestion_control/pacing_sender.h"
 #include "net/quic/core/congestion_control/rtt_stats.h"
 #include "net/quic/core/congestion_control/send_algorithm_interface.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_sent_packet_manager_interface.h"
 #include "net/quic/core/quic_unacked_packet_map.h"
 
@@ -56,11 +57,6 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
     virtual void OnRetransmissionMarked(QuicPathId path_id,
                                         QuicPacketNumber packet_number,
                                         TransmissionType transmission_type) = 0;
-    // Called when |packet_number| is marked as not retransmittable.
-    virtual void OnPacketMarkedNotRetransmittable(
-        QuicPathId path_id,
-        QuicPacketNumber packet_number,
-        QuicTime::Delta delta_largest_observed) = 0;
     // Called when any transmission of |packet_number| is handled.
     virtual void OnPacketMarkedHandled(
         QuicPathId path_id,
@@ -119,7 +115,7 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
 
   // Retrieves the next pending retransmission.  You must ensure that
   // there are pending retransmissions prior to calling this function.
-  PendingRetransmission NextPendingRetransmission() override;
+  QuicPendingRetransmission NextPendingRetransmission() override;
 
   bool HasUnackedPackets() const override;
 
@@ -189,8 +185,6 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
   // Called when peer address changes and the connection migrates.
   void OnConnectionMigration(QuicPathId, PeerAddressChangeType type) override;
 
-  bool IsHandshakeConfirmed() const override;
-
   void SetDebugDelegate(DebugDelegate* debug_delegate) override;
 
   QuicPacketNumber GetLargestObserved(QuicPathId) const override;
@@ -209,6 +203,8 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
 
   void OnApplicationLimited() override;
 
+  const SendAlgorithmInterface* GetSendAlgorithm() const override;
+
  private:
   friend class test::QuicConnectionPeer;
   friend class test::QuicSentPacketManagerPeer;
@@ -258,7 +254,7 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
   // Returns the newest transmission associated with a packet.
   QuicPacketNumber GetNewestRetransmission(
       QuicPacketNumber packet_number,
-      const TransmissionInfo& transmission_info) const;
+      const QuicTransmissionInfo& transmission_info) const;
 
   // Update the RTT if the ack is for the largest acked packet number.
   // Returns true if the rtt was updated.
@@ -270,26 +266,18 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
 
   // Invokes OnCongestionEvent if |rtt_updated| is true, there are pending acks,
   // or pending losses.  Clears pending acks and pending losses afterwards.
-  // |bytes_in_flight| is the number of bytes in flight before the losses or
-  // acks.
+  // |prior_in_flight| is the number of bytes in flight before the losses or
+  // acks, |event_time| is normally the timestamp of the ack packet which caused
+  // the event, although it can be the time at which loss detection was
+  // triggered.
   void MaybeInvokeCongestionEvent(bool rtt_updated,
-                                  QuicByteCount bytes_in_flight);
-
-  // Called when frames of |packet_number| has been received but the packet
-  // itself has not been received by the peer. Currently, this method is not
-  // used.
-  // TODO(fayang): Update the comment when multipath sent packet manager is
-  // landed.
-  // The packet needs no longer to be retransmitted, but the packet remains
-  // pending if it is and the congestion control does not consider the packet
-  // acked.
-  void MarkPacketNotRetransmittable(QuicPacketNumber packet_number,
-                                    QuicTime::Delta ack_delay_time);
+                                  QuicByteCount prior_in_flight,
+                                  QuicTime event_time);
 
   // Removes the retransmittability and in flight properties from the packet at
   // |info| due to receipt by the peer.
   void MarkPacketHandled(QuicPacketNumber packet_number,
-                         TransmissionInfo* info,
+                         QuicTransmissionInfo* info,
                          QuicTime::Delta ack_delay_time);
 
   // Request that |packet_number| be retransmitted after the other pending
@@ -298,25 +286,17 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
   void MarkForRetransmission(QuicPacketNumber packet_number,
                              TransmissionType transmission_type);
 
-  // Notify observers that packet with TransmissionInfo |info| is a spurious
+  // Notify observers that packet with QuicTransmissionInfo |info| is a spurious
   // retransmission. It is caller's responsibility to guarantee the packet with
-  // TransmissionInfo |info| is a spurious retransmission before calling this
-  // function.
-  void RecordOneSpuriousRetransmission(const TransmissionInfo& info);
+  // QuicTransmissionInfo |info| is a spurious retransmission before calling
+  // this function.
+  void RecordOneSpuriousRetransmission(const QuicTransmissionInfo& info);
 
-  // Notify observers about spurious retransmits of packet with TransmissionInfo
-  // |info|.
-  void RecordSpuriousRetransmissions(const TransmissionInfo& info,
+  // Notify observers about spurious retransmits of packet with
+  // QuicTransmissionInfo |info|.
+  void RecordSpuriousRetransmissions(const QuicTransmissionInfo& info,
                                      QuicPacketNumber acked_packet_number);
 
-  // Returns mutable TransmissionInfo associated with |packet_number|, which
-  // must be unacked.
-  TransmissionInfo* GetMutableTransmissionInfo(QuicPacketNumber packet_number);
-
-  // Remove any packets no longer needed for retransmission, congestion, or
-  // RTT measurement purposes.
-  void RemoveObsoletePackets();
-
   // Sets the send algorithm to the given congestion control type and points the
   // pacing sender at |send_algorithm_|. Can be called any number of times.
   void SetSendAlgorithm(CongestionControlType congestion_control_type);
@@ -360,9 +340,6 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
   GeneralLossAlgorithm general_loss_algorithm_;
   bool n_connection_simulation_;
 
-  // Receiver side buffer in bytes.
-  QuicByteCount receive_buffer_bytes_;
-
   // Least packet number which the peer is still waiting for.
   QuicPacketNumber least_packet_awaited_by_peer_;
 
@@ -388,6 +365,8 @@ class NET_EXPORT_PRIVATE QuicSentPacketManager
   // If true, cancel pending retransmissions if they're larger than
   // largest_newly_acked.
   bool undo_pending_retransmits_;
+  // If true, use a more conservative handshake retransmission policy.
+  bool conservative_handshake_retransmits_;
 
   // Vectors packets acked and lost as a result of the last congestion event.
   SendAlgorithmInterface::CongestionVector packets_acked_;
diff --git a/src/net/quic/core/quic_sent_packet_manager_interface.h b/src/net/quic/core/quic_sent_packet_manager_interface.h
index c366ed6..b1860e4 100644
--- a/src/net/quic/core/quic_sent_packet_manager_interface.h
+++ b/src/net/quic/core/quic_sent_packet_manager_interface.h
@@ -6,7 +6,10 @@
 #define NET_QUIC_QUIC_SENT_PACKET_MANAGER_INTERFACE_H_
 
 #include "base/macros.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/congestion_control/send_algorithm_interface.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_pending_retransmission.h"
 #include "net/quic/core/quic_sustained_bandwidth_recorder.h"
 
 namespace net {
@@ -97,7 +100,7 @@ class NET_EXPORT_PRIVATE QuicSentPacketManagerInterface {
 
   virtual bool HasPendingRetransmissions() const = 0;
 
-  virtual PendingRetransmission NextPendingRetransmission() = 0;
+  virtual QuicPendingRetransmission NextPendingRetransmission() = 0;
 
   // Returns true if the default path has unacked packets.
   virtual bool HasUnackedPackets() const = 0;
@@ -165,8 +168,6 @@ class NET_EXPORT_PRIVATE QuicSentPacketManagerInterface {
   virtual void OnConnectionMigration(QuicPathId path_id,
                                      PeerAddressChangeType type) = 0;
 
-  virtual bool IsHandshakeConfirmed() const = 0;
-
   virtual void SetDebugDelegate(DebugDelegate* debug_delegate) = 0;
 
   virtual QuicPacketNumber GetLargestObserved(QuicPathId path_id) const = 0;
@@ -189,6 +190,10 @@ class NET_EXPORT_PRIVATE QuicSentPacketManagerInterface {
   // Signals to the congestion controller that the connection has no outstanding
   // data to send.
   virtual void OnApplicationLimited() = 0;
+
+  // Returns the currently used congestion control algorithm.  The manager
+  // retains the ownership of the algorithm.
+  virtual const SendAlgorithmInterface* GetSendAlgorithm() const = 0;
 };
 
 }  // namespace net
diff --git a/src/net/quic/core/quic_server_id.cc b/src/net/quic/core/quic_server_id.cc
index 9bcf84c..ecc8d0e 100644
--- a/src/net/quic/core/quic_server_id.cc
+++ b/src/net/quic/core/quic_server_id.cc
@@ -46,7 +46,7 @@ QuicServerId QuicServerId::FromString(const std::string& str) {
   GURL url(str);
   if (!url.is_valid())
     return QuicServerId();
-  return QuicServerId(HostPortPair::FromURL(url), url.path() == "/private"
+  return QuicServerId(HostPortPair::FromURL(url), url.path_piece() == "/private"
                                                       ? PRIVACY_MODE_ENABLED
                                                       : PRIVACY_MODE_DISABLED);
 }
diff --git a/src/net/quic/core/quic_server_session_base.cc b/src/net/quic/core/quic_server_session_base.cc
index 7cdc014..0b4f3b5 100644
--- a/src/net/quic/core/quic_server_session_base.cc
+++ b/src/net/quic/core/quic_server_session_base.cc
@@ -10,7 +10,7 @@
 #include "net/quic/core/quic_connection.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_spdy_session.h"
-#include "net/quic/core/reliable_quic_stream.h"
+#include "net/quic/core/quic_stream.h"
 
 using std::string;
 
@@ -23,16 +23,14 @@ QuicServerSessionBase::QuicServerSessionBase(
     QuicCryptoServerStream::Helper* helper,
     const QuicCryptoServerConfig* crypto_config,
     QuicCompressedCertsCache* compressed_certs_cache)
-    : QuicSpdySession(connection, config),
+    : QuicSpdySession(connection, visitor, config),
       crypto_config_(crypto_config),
       compressed_certs_cache_(compressed_certs_cache),
-      visitor_(visitor),
       helper_(helper),
       bandwidth_resumption_enabled_(false),
       bandwidth_estimate_sent_to_client_(QuicBandwidth::Zero()),
       last_scup_time_(QuicTime::Zero()),
-      last_scup_packet_number_(0),
-      server_push_enabled_(false) {}
+      last_scup_packet_number_(0) {}
 
 QuicServerSessionBase::~QuicServerSessionBase() {}
 
@@ -56,8 +54,12 @@ void QuicServerSessionBase::OnConfigNegotiated() {
       ContainsQuicTag(config()->ReceivedConnectionOptions(), kBWMX);
   bandwidth_resumption_enabled_ =
       last_bandwidth_resumption || max_bandwidth_resumption;
-  server_push_enabled_ =
-      ContainsQuicTag(config()->ReceivedConnectionOptions(), kSPSH);
+
+  if (!FLAGS_quic_enable_server_push_by_default ||
+      connection()->version() < QUIC_VERSION_35) {
+    set_server_push_enabled(
+        ContainsQuicTag(config()->ReceivedConnectionOptions(), kSPSH));
+  }
 
   // If the client has provided a bandwidth estimate from the same serving
   // region as this server, then decide whether to use the data for bandwidth
@@ -72,7 +74,7 @@ void QuicServerSessionBase::OnConfigNegotiated() {
 
     if (bandwidth_resumption_enabled_) {
       // Only do bandwidth resumption if estimate is recent enough.
-      const int64_t seconds_since_estimate =
+      const uint64_t seconds_since_estimate =
           connection()->clock()->WallNow().ToUNIXSeconds() -
           cached_network_params->timestamp();
       if (seconds_since_estimate <= kNumSecondsPerHour) {
@@ -92,13 +94,6 @@ void QuicServerSessionBase::OnConnectionClosed(QuicErrorCode error,
   if (crypto_stream_.get() != nullptr) {
     crypto_stream_->CancelOutstandingCallbacks();
   }
-  visitor_->OnConnectionClosed(connection()->connection_id(), error,
-                               error_details);
-}
-
-void QuicServerSessionBase::OnWriteBlocked() {
-  QuicSession::OnWriteBlocked();
-  visitor_->OnWriteBlocked(connection());
 }
 
 void QuicServerSessionBase::OnCongestionWindowChange(QuicTime now) {
diff --git a/src/net/quic/core/quic_server_session_base.h b/src/net/quic/core/quic_server_session_base.h
index 8a09fde..fcf8cc2 100644
--- a/src/net/quic/core/quic_server_session_base.h
+++ b/src/net/quic/core/quic_server_session_base.h
@@ -16,18 +16,17 @@
 #include <vector>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/crypto/quic_compressed_certs_cache.h"
 #include "net/quic/core/quic_crypto_server_stream.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_spdy_session.h"
 
 namespace net {
 
-class QuicBlockedWriterInterface;
 class QuicConfig;
 class QuicConnection;
 class QuicCryptoServerConfig;
-class ReliableQuicStream;
 
 namespace test {
 class QuicServerSessionBasePeer;
@@ -36,44 +35,19 @@ class QuicSimpleServerSessionPeer;
 
 class NET_EXPORT_PRIVATE QuicServerSessionBase : public QuicSpdySession {
  public:
-  // An interface from the session to the entity owning the session.
-  // This lets the session notify its owner (the Dispatcher) when the connection
-  // is closed, blocked, or added/removed from the time-wait std::list.
-  class Visitor {
-   public:
-    virtual ~Visitor() {}
-
-    // Called when the connection is closed.
-    virtual void OnConnectionClosed(QuicConnectionId connection_id,
-                                    QuicErrorCode error,
-                                    const std::string& error_details) = 0;
-
-    // Called when the session has become write blocked.
-    virtual void OnWriteBlocked(QuicBlockedWriterInterface* blocked_writer) = 0;
-
-    // Called after the given connection is added to the time-wait std::list.
-    virtual void OnConnectionAddedToTimeWaitList(
-        QuicConnectionId connection_id) = 0;
-
-    // Called before a packet is going to be processed by |session|.
-    virtual void OnPacketBeingDispatchedToSession(
-        QuicServerSessionBase* session) = 0;
-  };
-
   // Does not take ownership of |connection|. |crypto_config| must outlive the
   // session. |helper| must outlive any created crypto streams.
   QuicServerSessionBase(const QuicConfig& config,
                         QuicConnection* connection,
-                        Visitor* visitor,
+                        QuicSession::Visitor* visitor,
                         QuicCryptoServerStream::Helper* helper,
                         const QuicCryptoServerConfig* crypto_config,
                         QuicCompressedCertsCache* compressed_certs_cache);
 
-  // Override the base class to notify the owner of the connection close.
+  // Override the base class to cancel any ongoing asychronous crypto.
   void OnConnectionClosed(QuicErrorCode error,
                           const std::string& error_details,
                           ConnectionCloseSource source) override;
-  void OnWriteBlocked() override;
 
   // Sends a server config update to the client, containing new bandwidth
   // estimate.
@@ -95,8 +69,6 @@ class NET_EXPORT_PRIVATE QuicServerSessionBase : public QuicSpdySession {
     serving_region_ = serving_region;
   }
 
-  bool server_push_enabled() const { return server_push_enabled_; }
-
  protected:
   // QuicSession methods(override them with return type of QuicSpdyStream*):
   QuicCryptoServerStreamBase* GetCryptoStream() override;
@@ -118,10 +90,6 @@ class NET_EXPORT_PRIVATE QuicServerSessionBase : public QuicSpdySession {
 
   const QuicCryptoServerConfig* crypto_config() { return crypto_config_; }
 
-  void set_server_push_enabled(bool enable) { server_push_enabled_ = enable; }
-
-  Visitor* visitor() { return visitor_; }
-
   QuicCryptoServerStream::Helper* stream_helper() { return helper_; }
 
  private:
@@ -135,7 +103,6 @@ class NET_EXPORT_PRIVATE QuicServerSessionBase : public QuicSpdySession {
   QuicCompressedCertsCache* compressed_certs_cache_;
 
   std::unique_ptr<QuicCryptoServerStreamBase> crypto_stream_;
-  Visitor* visitor_;
 
   // Pointer to the helper used to create crypto server streams. Must outlive
   // streams created via CreateQuicCryptoServerStream.
@@ -163,10 +130,6 @@ class NET_EXPORT_PRIVATE QuicServerSessionBase : public QuicSpdySession {
   int32_t BandwidthToCachedParameterBytesPerSecond(
       const QuicBandwidth& bandwidth);
 
-  // Set during handshake. If true, resources in x-associated-content and link
-  // headers will be pushed. see: go/gfe_server_push.
-  bool server_push_enabled_;
-
   DISALLOW_COPY_AND_ASSIGN(QuicServerSessionBase);
 };
 
diff --git a/src/net/quic/core/quic_session.cc b/src/net/quic/core/quic_session.cc
index 424a6ec..ced354a 100644
--- a/src/net/quic/core/quic_session.cc
+++ b/src/net/quic/core/quic_session.cc
@@ -4,25 +4,18 @@
 
 #include "net/quic/core/quic_session.h"
 
+#include "base/memory/ptr_util.h"
 #include "base/stl_util.h"
 #include "base/strings/string_number_conversions.h"
-#include "base/strings/stringprintf.h"
 #include "net/quic/core/crypto/proof_verifier.h"
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_connection.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_flow_controller.h"
-#if 0
-#include "net/ssl/ssl_info.h"
-#endif
 
 using base::IntToString;
 using base::StringPiece;
-using std::make_pair;
-using std::map;
-using std::max;
 using std::string;
-using std::vector;
 using net::SpdyPriority;
 
 namespace net {
@@ -30,8 +23,11 @@ namespace net {
 #define ENDPOINT \
   (perspective() == Perspective::IS_SERVER ? "Server: " : " Client: ")
 
-QuicSession::QuicSession(QuicConnection* connection, const QuicConfig& config)
+QuicSession::QuicSession(QuicConnection* connection,
+                         Visitor* owner,
+                         const QuicConfig& config)
     : connection_(connection),
+      visitor_(owner),
       config_(config),
       max_open_outgoing_streams_(kDefaultMaxStreamsPerConnection),
       max_open_incoming_streams_(config_.GetMaxIncomingDynamicStreamsToSend()),
@@ -59,9 +55,6 @@ void QuicSession::Initialize() {
 }
 
 QuicSession::~QuicSession() {
-  base::STLDeleteElements(&closed_streams_);
-  base::STLDeleteValues(&dynamic_stream_map_);
-
   DLOG_IF(WARNING, num_locally_closed_incoming_streams_highest_offset() >
                        max_open_incoming_streams_)
       << "Surprisingly high number of locally closed peer initiated streams"
@@ -77,7 +70,7 @@ QuicSession::~QuicSession() {
 void QuicSession::OnStreamFrame(const QuicStreamFrame& frame) {
   // TODO(rch) deal with the error case of stream id 0.
   QuicStreamId stream_id = frame.stream_id;
-  ReliableQuicStream* stream = GetOrCreateStream(stream_id);
+  QuicStream* stream = GetOrCreateStream(stream_id);
   if (!stream) {
     // The stream no longer exists, but we may still be interested in the
     // final stream byte offset sent by the peer. A frame with a FIN can give
@@ -99,7 +92,7 @@ void QuicSession::OnRstStream(const QuicRstStreamFrame& frame) {
     return;
   }
 
-  ReliableQuicStream* stream = GetOrCreateDynamicStream(frame.stream_id);
+  QuicStream* stream = GetOrCreateDynamicStream(frame.stream_id);
   if (!stream) {
     HandleRstOnValidNonexistentStream(frame);
     return;  // Errors are handled by GetOrCreateStream.
@@ -113,7 +106,7 @@ void QuicSession::OnGoAway(const QuicGoAwayFrame& frame) {
 }
 
 void QuicSession::OnConnectionClosed(QuicErrorCode error,
-                                     const string& /*error_details*/,
+                                     const string& error_details,
                                      ConnectionCloseSource source) {
   DCHECK(!connection_->connected());
   if (error_ == QUIC_NO_ERROR) {
@@ -130,6 +123,17 @@ void QuicSession::OnConnectionClosed(QuicErrorCode error,
       CloseStream(id);
     }
   }
+
+  if (visitor_) {
+    visitor_->OnConnectionClosed(connection_->connection_id(), error,
+                                 error_details);
+  }
+}
+
+void QuicSession::OnWriteBlocked() {
+  if (visitor_) {
+    visitor_->OnWriteBlocked(connection_);
+  }
 }
 
 void QuicSession::OnSuccessfulVersionNegotiation(
@@ -150,8 +154,8 @@ void QuicSession::OnWindowUpdateFrame(const QuicWindowUpdateFrame& frame) {
     flow_controller_.UpdateSendWindowOffset(frame.byte_offset);
     return;
   }
-  ReliableQuicStream* stream = GetOrCreateStream(stream_id);
-  if (stream) {
+  QuicStream* stream = GetOrCreateStream(stream_id);
+  if (stream != nullptr) {
     stream->OnWindowUpdateFrame(frame);
   }
 }
@@ -164,6 +168,36 @@ void QuicSession::OnBlockedFrame(const QuicBlockedFrame& frame) {
            << "Received BLOCKED frame with stream id: " << frame.stream_id;
 }
 
+bool QuicSession::CheckStreamNotBusyLooping(QuicStream* stream,
+                                            uint64_t previous_bytes_written,
+                                            bool previous_fin_sent) {
+  if (  // Stream should not be closed.
+      !stream->write_side_closed() &&
+      // Not connection flow control blocked.
+      !flow_controller_.IsBlocked() &&
+      // Detect lack of forward progress.
+      previous_bytes_written == stream->stream_bytes_written() &&
+      previous_fin_sent == stream->fin_sent()) {
+    stream->set_busy_counter(stream->busy_counter() + 1);
+    DVLOG(1) << "Suspected busy loop on stream id " << stream->id()
+             << " stream_bytes_written " << stream->stream_bytes_written()
+             << " fin " << stream->fin_sent() << " count "
+             << stream->busy_counter();
+    // Wait a few iterations before firing, the exact count is
+    // arbitrary, more than a few to cover a few test-only false
+    // positives.
+    if (stream->busy_counter() > 20) {
+      LOG(ERROR) << "Detected busy loop on stream id " << stream->id()
+                 << " stream_bytes_written " << stream->stream_bytes_written()
+                 << " fin " << stream->fin_sent();
+      return false;
+    }
+  } else {
+    stream->set_busy_counter(0);
+  }
+  return true;
+}
+
 void QuicSession::OnCanWrite() {
   // We limit the number of writes to the number of pending streams. If more
   // streams become pending, WillingAndAbleToWrite will be true, which will
@@ -202,12 +236,17 @@ void QuicSession::OnCanWrite() {
       return;
     }
     currently_writing_stream_id_ = write_blocked_streams_.PopFront();
-    ReliableQuicStream* stream =
-        GetOrCreateStream(currently_writing_stream_id_);
+    QuicStream* stream = GetOrCreateStream(currently_writing_stream_id_);
     if (stream != nullptr && !stream->flow_controller()->IsBlocked()) {
       // If the stream can't write all bytes it'll re-add itself to the blocked
       // list.
+      uint64_t previous_bytes_written = stream->stream_bytes_written();
+      bool previous_fin_sent = stream->fin_sent();
+      DVLOG(1) << "stream " << stream->id() << " bytes_written "
+               << previous_bytes_written << " fin " << previous_fin_sent;
       stream->OnCanWrite();
+      DCHECK(CheckStreamNotBusyLooping(stream, previous_bytes_written,
+                                       previous_fin_sent));
     }
     currently_writing_stream_id_ = 0;
   }
@@ -232,14 +271,14 @@ bool QuicSession::HasOpenDynamicStreams() const {
           locally_closed_streams_highest_offset_.size()) > 0;
 }
 
-void QuicSession::ProcessUdpPacket(const IPEndPoint& self_address,
-                                   const IPEndPoint& peer_address,
+void QuicSession::ProcessUdpPacket(const QuicSocketAddress& self_address,
+                                   const QuicSocketAddress& peer_address,
                                    const QuicReceivedPacket& packet) {
   connection_->ProcessUdpPacket(self_address, peer_address, packet);
 }
 
 QuicConsumedData QuicSession::WritevData(
-    ReliableQuicStream* stream,
+    QuicStream* stream,
     QuicStreamId id,
     QuicIOVector iov,
     QuicStreamOffset offset,
@@ -311,19 +350,19 @@ void QuicSession::CloseStreamInner(QuicStreamId stream_id, bool locally_reset) {
   DynamicStreamMap::iterator it = dynamic_stream_map_.find(stream_id);
   if (it == dynamic_stream_map_.end()) {
     // When CloseStreamInner has been called recursively (via
-    // ReliableQuicStream::OnClose), the stream will already have been deleted
+    // QuicStream::OnClose), the stream will already have been deleted
     // from stream_map_, so return immediately.
     DVLOG(1) << ENDPOINT << "Stream is already closed: " << stream_id;
     return;
   }
-  ReliableQuicStream* stream = it->second;
+  QuicStream* stream = it->second.get();
 
   // Tell the stream that a RST has been sent.
   if (locally_reset) {
     stream->set_rst_sent(true);
   }
 
-  closed_streams_.push_back(it->second);
+  closed_streams_.push_back(std::move(it->second));
 
   // If we haven't received a FIN or RST for this stream, we need to keep track
   // of the how many bytes the stream's flow controller believes it has
@@ -352,7 +391,7 @@ void QuicSession::CloseStreamInner(QuicStreamId stream_id, bool locally_reset) {
 void QuicSession::UpdateFlowControlOnFinalReceivedByteOffset(
     QuicStreamId stream_id,
     QuicStreamOffset final_byte_offset) {
-  map<QuicStreamId, QuicStreamOffset>::iterator it =
+  std::map<QuicStreamId, QuicStreamOffset>::iterator it =
       locally_closed_streams_highest_offset_.find(stream_id);
   if (it == locally_closed_streams_highest_offset_.end()) {
     return;
@@ -408,16 +447,16 @@ void QuicSession::OnConfigNegotiated() {
     // Use a minimum number of additional streams, or a percentage increase,
     // whichever is larger.
     uint32_t max_incoming_streams =
-        max(max_streams + kMaxStreamsMinimumIncrement,
-            static_cast<uint32_t>(max_streams * kMaxStreamsMultiplier));
+        std::max(max_streams + kMaxStreamsMinimumIncrement,
+                 static_cast<uint32_t>(max_streams * kMaxStreamsMultiplier));
     set_max_open_incoming_streams(max_incoming_streams);
   } else {
     uint32_t max_incoming_streams_to_send =
         config_.GetMaxIncomingDynamicStreamsToSend();
     uint32_t max_incoming_streams =
-        max(max_incoming_streams_to_send + kMaxStreamsMinimumIncrement,
-            static_cast<uint32_t>(max_incoming_streams_to_send *
-                                  kMaxStreamsMultiplier));
+        std::max(max_incoming_streams_to_send + kMaxStreamsMinimumIncrement,
+                 static_cast<uint32_t>(max_incoming_streams_to_send *
+                                       kMaxStreamsMultiplier));
     set_max_open_incoming_streams(max_incoming_streams);
   }
 
@@ -534,13 +573,14 @@ QuicConfig* QuicSession::config() {
   return &config_;
 }
 
-void QuicSession::ActivateStream(ReliableQuicStream* stream) {
+void QuicSession::ActivateStream(std::unique_ptr<QuicStream> stream) {
+  QuicStreamId stream_id = stream->id();
   DVLOG(1) << ENDPOINT << "num_streams: " << dynamic_stream_map_.size()
-           << ". activating " << stream->id();
-  DCHECK(!base::ContainsKey(dynamic_stream_map_, stream->id()));
-  DCHECK(!base::ContainsKey(static_stream_map_, stream->id()));
-  dynamic_stream_map_[stream->id()] = stream;
-  if (IsIncomingStream(stream->id())) {
+           << ". activating " << stream_id;
+  DCHECK(!base::ContainsKey(dynamic_stream_map_, stream_id));
+  DCHECK(!base::ContainsKey(static_stream_map_, stream_id));
+  dynamic_stream_map_[stream_id] = std::move(stream);
+  if (IsIncomingStream(stream_id)) {
     ++num_dynamic_incoming_streams_;
   }
   // Increase the number of streams being emulated when a new one is opened.
@@ -553,8 +593,7 @@ QuicStreamId QuicSession::GetNextOutgoingStreamId() {
   return id;
 }
 
-ReliableQuicStream* QuicSession::GetOrCreateStream(
-    const QuicStreamId stream_id) {
+QuicStream* QuicSession::GetOrCreateStream(const QuicStreamId stream_id) {
   StaticStreamMap::iterator it = static_stream_map_.find(stream_id);
   if (it != static_stream_map_.end()) {
     return it->second;
@@ -586,7 +625,8 @@ bool QuicSession::MaybeIncreaseLargestPeerStreamId(
   size_t new_num_available_streams =
       GetNumAvailableStreams() + additional_available_streams;
   if (new_num_available_streams > MaxAvailableStreams()) {
-    DVLOG(1) << "Failed to create a new incoming stream with id:" << stream_id
+    DVLOG(1) << ENDPOINT
+             << "Failed to create a new incoming stream with id:" << stream_id
              << ".  There are already " << GetNumAvailableStreams()
              << " streams available, which would become "
              << new_num_available_streams << ", which exceeds the limit "
@@ -614,14 +654,14 @@ bool QuicSession::ShouldYield(QuicStreamId stream_id) {
   return write_blocked_streams()->ShouldYield(stream_id);
 }
 
-ReliableQuicStream* QuicSession::GetOrCreateDynamicStream(
+QuicStream* QuicSession::GetOrCreateDynamicStream(
     const QuicStreamId stream_id) {
   DCHECK(!base::ContainsKey(static_stream_map_, stream_id))
       << "Attempt to call GetOrCreateDynamicStream for a static stream";
 
   DynamicStreamMap::iterator it = dynamic_stream_map_.find(stream_id);
   if (it != dynamic_stream_map_.end()) {
-    return it->second;
+    return it->second.get();
   }
 
   if (IsClosedStream(stream_id)) {
@@ -704,8 +744,12 @@ size_t QuicSession::GetNumOpenIncomingStreams() const {
 }
 
 size_t QuicSession::GetNumOpenOutgoingStreams() const {
-  return GetNumDynamicOutgoingStreams() - GetNumDrainingOutgoingStreams() +
-         GetNumLocallyClosedOutgoingStreamsHighestOffset();
+  CHECK_GE(GetNumDynamicOutgoingStreams() +
+               GetNumLocallyClosedOutgoingStreamsHighestOffset(),
+           GetNumDrainingOutgoingStreams());
+  return GetNumDynamicOutgoingStreams() +
+         GetNumLocallyClosedOutgoingStreamsHighestOffset() -
+         GetNumDrainingOutgoingStreams();
 }
 
 size_t QuicSession::GetNumActiveStreams() const {
@@ -730,19 +774,22 @@ bool QuicSession::HasDataToWrite() const {
 }
 
 void QuicSession::PostProcessAfterData() {
-  base::STLDeleteElements(&closed_streams_);
   closed_streams_.clear();
 }
 
 size_t QuicSession::GetNumDynamicOutgoingStreams() const {
+  DCHECK_GE(dynamic_stream_map_.size(), num_dynamic_incoming_streams_);
   return dynamic_stream_map_.size() - num_dynamic_incoming_streams_;
 }
 
 size_t QuicSession::GetNumDrainingOutgoingStreams() const {
+  DCHECK_GE(draining_streams_.size(), num_draining_incoming_streams_);
   return draining_streams_.size() - num_draining_incoming_streams_;
 }
 
 size_t QuicSession::GetNumLocallyClosedOutgoingStreamsHighestOffset() const {
+  DCHECK_GE(locally_closed_streams_highest_offset_.size(),
+            num_locally_closed_incoming_streams_highest_offset_);
   return locally_closed_streams_highest_offset_.size() -
          num_locally_closed_incoming_streams_highest_offset_;
 }
diff --git a/src/net/quic/core/quic_session.h b/src/net/quic/core/quic_session.h
index 2c93486..50518ca 100644
--- a/src/net/quic/core/quic_session.h
+++ b/src/net/quic/core/quic_session.h
@@ -20,19 +20,19 @@
 #include "base/containers/small_map.h"
 #include "base/macros.h"
 #include "base/strings/string_piece.h"
-#include "net/base/ip_endpoint.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_connection.h"
 #include "net/quic/core/quic_crypto_stream.h"
 #include "net/quic/core/quic_packet_creator.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_stream.h"
 #include "net/quic/core/quic_write_blocked_list.h"
-#include "net/quic/core/reliable_quic_stream.h"
 
 namespace net {
 
 class QuicCryptoStream;
 class QuicFlowController;
-class ReliableQuicStream;
+class QuicStream;
 
 namespace test {
 class QuicSessionPeer;
@@ -40,6 +40,22 @@ class QuicSessionPeer;
 
 class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
  public:
+  // An interface from the session to the entity owning the session.
+  // This lets the session notify its owner (the Dispatcher) when the connection
+  // is closed, blocked, or added/removed from the time-wait std::list.
+  class Visitor {
+   public:
+    virtual ~Visitor() {}
+
+    // Called when the connection is closed after the streams have been closed.
+    virtual void OnConnectionClosed(QuicConnectionId connection_id,
+                                    QuicErrorCode error,
+                                    const std::string& error_details) = 0;
+
+    // Called when the session has become write blocked.
+    virtual void OnWriteBlocked(QuicBlockedWriterInterface* blocked_writer) = 0;
+  };
+
   // CryptoHandshakeEvent enumerates the events generated by a QuicCryptoStream.
   enum CryptoHandshakeEvent {
     // ENCRYPTION_FIRST_ESTABLISHED indicates that a full client hello has been
@@ -57,8 +73,10 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
     HANDSHAKE_CONFIRMED,
   };
 
-  // Does not take ownership of |connection|.
-  QuicSession(QuicConnection* connection, const QuicConfig& config);
+  // Does not take ownership of |connection| or |visitor|.
+  QuicSession(QuicConnection* connection,
+              Visitor* owner,
+              const QuicConfig& config);
 
   ~QuicSession() override;
 
@@ -73,7 +91,7 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
   void OnConnectionClosed(QuicErrorCode error,
                           const std::string& error_details,
                           ConnectionCloseSource source) override;
-  void OnWriteBlocked() override {}
+  void OnWriteBlocked() override;
   void OnSuccessfulVersionNegotiation(const QuicVersion& version) override;
   void OnCanWrite() override;
   void OnCongestionWindowChange(QuicTime /*now*/) override {}
@@ -87,8 +105,8 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
   void OnPathDegrading() override;
 
   // Called on every incoming packet. Passes |packet| through to |connection_|.
-  virtual void ProcessUdpPacket(const IPEndPoint& self_address,
-                                const IPEndPoint& peer_address,
+  virtual void ProcessUdpPacket(const QuicSocketAddress& self_address,
+                                const QuicSocketAddress& peer_address,
                                 const QuicReceivedPacket& packet);
 
   // Called by streams when they want to write data to the peer.
@@ -99,7 +117,7 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
   // If provided, |ack_notifier_delegate| will be registered to be notified when
   // we have seen ACKs for all packets resulting from this call.
   virtual QuicConsumedData WritevData(
-      ReliableQuicStream* stream,
+      QuicStream* stream,
       QuicStreamId id,
       QuicIOVector iov,
       QuicStreamOffset offset,
@@ -158,26 +176,28 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
   QuicConnection* connection() { return connection_; }
   const QuicConnection* connection() const { return connection_; }
   size_t num_active_requests() const { return dynamic_stream_map_.size(); }
-  const IPEndPoint& peer_address() const { return connection_->peer_address(); }
+  const QuicSocketAddress& peer_address() const {
+    return connection_->peer_address();
+  }
   QuicConnectionId connection_id() const {
     return connection_->connection_id();
   }
 
   // Returns the number of currently open streams, excluding the reserved
   // headers and crypto streams, and never counting unfinished streams.
-  virtual size_t GetNumActiveStreams() const;
+  size_t GetNumActiveStreams() const;
 
   // Returns the number of currently open peer initiated streams, excluding the
   // reserved headers and crypto streams.
-  virtual size_t GetNumOpenIncomingStreams() const;
+  size_t GetNumOpenIncomingStreams() const;
 
   // Returns the number of currently open self initiated streams, excluding the
   // reserved headers and crypto streams.
-  virtual size_t GetNumOpenOutgoingStreams() const;
+  size_t GetNumOpenOutgoingStreams() const;
 
   // Returns the number of "available" streams, the stream ids less than
   // largest_peer_created_stream_id_ that have not yet been opened.
-  virtual size_t GetNumAvailableStreams() const;
+  size_t GetNumAvailableStreams() const;
 
   // Add the stream to the session's write-blocked list because it is blocked by
   // connection-level flow control but not by its own stream-level flow control.
@@ -219,7 +239,7 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
   // such stream exists, and |stream_id| is a peer-created dynamic stream id,
   // then a new stream is created and returned. In all other cases, nullptr is
   // returned.
-  ReliableQuicStream* GetOrCreateStream(const QuicStreamId stream_id);
+  QuicStream* GetOrCreateStream(const QuicStreamId stream_id);
 
   // Mark a stream as draining.
   virtual void StreamDraining(QuicStreamId id);
@@ -229,28 +249,29 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
 
  protected:
   using StaticStreamMap =
-      base::SmallMap<std::unordered_map<QuicStreamId, ReliableQuicStream*>, 2>;
+      base::SmallMap<std::unordered_map<QuicStreamId, QuicStream*>, 2>;
+
+  using DynamicStreamMap = base::SmallMap<
+      std::unordered_map<QuicStreamId, std::unique_ptr<QuicStream>>,
+      10>;
 
-  using DynamicStreamMap =
-      base::SmallMap<std::unordered_map<QuicStreamId, ReliableQuicStream*>, 10>;
+  using ClosedStreams = std::vector<std::unique_ptr<QuicStream>>;
 
   // Creates a new stream to handle a peer-initiated stream.
   // Caller does not own the returned stream.
   // Returns nullptr and does error handling if the stream can not be created.
-  virtual ReliableQuicStream* CreateIncomingDynamicStream(QuicStreamId id) = 0;
+  virtual QuicStream* CreateIncomingDynamicStream(QuicStreamId id) = 0;
 
   // Create a new stream to handle a locally-initiated stream.
   // Caller does not own the returned stream.
   // Returns nullptr if max streams have already been opened.
-  virtual ReliableQuicStream* CreateOutgoingDynamicStream(
-      SpdyPriority priority) = 0;
+  virtual QuicStream* CreateOutgoingDynamicStream(SpdyPriority priority) = 0;
 
   // Return the reserved crypto stream.
   virtual QuicCryptoStream* GetCryptoStream() = 0;
 
   // Adds |stream| to the dynamic stream map.
-  // Takes ownership of |stream|.
-  virtual void ActivateStream(ReliableQuicStream* stream);
+  virtual void ActivateStream(std::unique_ptr<QuicStream> stream);
 
   // Returns the stream ID for a new outgoing stream, and increments the
   // underlying counter.
@@ -261,7 +282,7 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
   // returned. However if |stream_id| is a locally-created id and no such stream
   // exists, the connection is closed.
   // Caller does not own the returned stream.
-  ReliableQuicStream* GetOrCreateDynamicStream(QuicStreamId stream_id);
+  QuicStream* GetOrCreateDynamicStream(QuicStreamId stream_id);
 
   // Performs the work required to close |stream_id|.  If |locally_reset|
   // then the stream has been reset by this endpoint, not by the peer.
@@ -286,9 +307,7 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
     return dynamic_stream_map_;
   }
 
-  std::vector<ReliableQuicStream*>* closed_streams() {
-    return &closed_streams_;
-  }
+  ClosedStreams* closed_streams() { return &closed_streams_; }
 
   void set_max_open_incoming_streams(size_t max_open_incoming_streams);
   void set_max_open_outgoing_streams(size_t max_open_outgoing_streams);
@@ -347,6 +366,12 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
   // control window in a negotiated config. Closes the connection if invalid.
   void OnNewSessionFlowControlWindow(QuicStreamOffset new_window);
 
+  // Debug helper for |OnCanWrite()|, check that OnStreamWrite() makes
+  // forward progress.  Returns false if busy loop detected.
+  bool CheckStreamNotBusyLooping(QuicStream* stream,
+                                 uint64_t previous_bytes_written,
+                                 bool previous_fin_sent);
+
   // Keep track of highest received byte offset of locally closed streams, while
   // waiting for a definitive final highest offset from the peer.
   std::map<QuicStreamId, QuicStreamOffset>
@@ -354,7 +379,10 @@ class NET_EXPORT_PRIVATE QuicSession : public QuicConnectionVisitorInterface {
 
   QuicConnection* connection_;
 
-  std::vector<ReliableQuicStream*> closed_streams_;
+  // May be null.
+  Visitor* visitor_;
+
+  ClosedStreams closed_streams_;
 
   QuicConfig config_;
 
diff --git a/src/net/quic/core/quic_simple_buffer_allocator.h b/src/net/quic/core/quic_simple_buffer_allocator.h
index 1cac123..1a7ff35 100644
--- a/src/net/quic/core/quic_simple_buffer_allocator.h
+++ b/src/net/quic/core/quic_simple_buffer_allocator.h
@@ -5,7 +5,8 @@
 #ifndef NET_QUIC_SIMPLE_BUFFER_ALLOCATOR_H_
 #define NET_QUIC_SIMPLE_BUFFER_ALLOCATOR_H_
 
-#include "net/quic/core/quic_protocol.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/quic_buffer_allocator.h"
 
 namespace net {
 
diff --git a/src/net/quic/core/quic_socket_address_coder.cc b/src/net/quic/core/quic_socket_address_coder.cc
index 9d9a043..ae1dd6d 100644
--- a/src/net/quic/core/quic_socket_address_coder.cc
+++ b/src/net/quic/core/quic_socket_address_coder.cc
@@ -4,7 +4,6 @@
 
 #include "net/quic/core/quic_socket_address_coder.h"
 
-#include "net/base/ip_address.h"
 #include "net/base/sys_addrinfo.h"
 
 using std::string;
@@ -22,7 +21,7 @@ const uint16_t kIPv6 = 10;
 
 QuicSocketAddressCoder::QuicSocketAddressCoder() {}
 
-QuicSocketAddressCoder::QuicSocketAddressCoder(const IPEndPoint& address)
+QuicSocketAddressCoder::QuicSocketAddressCoder(const QuicSocketAddress& address)
     : address_(address) {}
 
 QuicSocketAddressCoder::~QuicSocketAddressCoder() {}
@@ -30,11 +29,11 @@ QuicSocketAddressCoder::~QuicSocketAddressCoder() {}
 string QuicSocketAddressCoder::Encode() const {
   string serialized;
   uint16_t address_family;
-  switch (address_.GetSockAddrFamily()) {
-    case AF_INET:
+  switch (address_.host().address_family()) {
+    case IpAddressFamily::IP_V4:
       address_family = kIPv4;
       break;
-    case AF_INET6:
+    case IpAddressFamily::IP_V6:
       address_family = kIPv6;
       break;
     default:
@@ -42,7 +41,7 @@ string QuicSocketAddressCoder::Encode() const {
   }
   serialized.append(reinterpret_cast<const char*>(&address_family),
                     sizeof(address_family));
-  serialized.append(IPAddressToPackedString(address_.address()));
+  serialized.append(address_.host().ToPackedString());
   uint16_t port = address_.port();
   serialized.append(reinterpret_cast<const char*>(&port), sizeof(port));
   return serialized;
@@ -82,7 +81,9 @@ bool QuicSocketAddressCoder::Decode(const char* data, size_t length) {
   }
   memcpy(&port, data, length);
 
-  address_ = IPEndPoint(IPAddress(ip), port);
+  QuicIpAddress ip_address;
+  ip_address.FromPackedString(reinterpret_cast<const char*>(&ip[0]), ip_length);
+  address_ = QuicSocketAddress(ip_address, port);
   return true;
 }
 
diff --git a/src/net/quic/core/quic_socket_address_coder.h b/src/net/quic/core/quic_socket_address_coder.h
index e6f8bf6..5c2bad8 100644
--- a/src/net/quic/core/quic_socket_address_coder.h
+++ b/src/net/quic/core/quic_socket_address_coder.h
@@ -11,32 +11,30 @@
 #include <string>
 
 #include "base/macros.h"
-#include "net/base/ip_endpoint.h"
 #include "net/base/net_export.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 
 namespace net {
 
-class IPAddress;
-
 // Serializes and parses a socket address (IP address and port), to be used in
 // the kCADR tag in the ServerHello handshake message and the Public Reset
 // packet.
 class NET_EXPORT_PRIVATE QuicSocketAddressCoder {
  public:
   QuicSocketAddressCoder();
-  explicit QuicSocketAddressCoder(const IPEndPoint& address);
+  explicit QuicSocketAddressCoder(const QuicSocketAddress& address);
   ~QuicSocketAddressCoder();
 
   std::string Encode() const;
 
   bool Decode(const char* data, size_t length);
 
-  const IPAddress& ip() const { return address_.address(); }
+  QuicIpAddress ip() const { return address_.host(); }
 
   uint16_t port() const { return address_.port(); }
 
  private:
-  IPEndPoint address_;
+  QuicSocketAddress address_;
 
   DISALLOW_COPY_AND_ASSIGN(QuicSocketAddressCoder);
 };
diff --git a/src/net/quic/core/quic_spdy_session.cc b/src/net/quic/core/quic_spdy_session.cc
index 65bfade..d081b65 100644
--- a/src/net/quic/core/quic_spdy_session.cc
+++ b/src/net/quic/core/quic_spdy_session.cc
@@ -15,17 +15,20 @@ using std::string;
 namespace net {
 
 QuicSpdySession::QuicSpdySession(QuicConnection* connection,
+                                 QuicSession::Visitor* visitor,
                                  const QuicConfig& config)
-    : QuicSession(connection, config), force_hol_blocking_(false) {}
+    : QuicSession(connection, visitor, config),
+      force_hol_blocking_(false),
+      server_push_enabled_(false) {}
 
 QuicSpdySession::~QuicSpdySession() {
   // Set the streams' session pointers in closed and dynamic stream lists
   // to null to avoid subsequent use of this session.
-  for (auto* stream : *closed_streams()) {
-    static_cast<QuicSpdyStream*>(stream)->ClearSession();
+  for (auto& stream : *closed_streams()) {
+    static_cast<QuicSpdyStream*>(stream.get())->ClearSession();
   }
   for (auto const& kv : dynamic_streams()) {
-    static_cast<QuicSpdyStream*>(kv.second)->ClearSession();
+    static_cast<QuicSpdyStream*>(kv.second.get())->ClearSession();
   }
 }
 
@@ -44,16 +47,6 @@ void QuicSpdySession::Initialize() {
   static_streams()[kHeadersStreamId] = headers_stream_.get();
 }
 
-void QuicSpdySession::OnStreamHeaders(QuicStreamId stream_id,
-                                      StringPiece headers_data) {
-  QuicSpdyStream* stream = GetSpdyDataStream(stream_id);
-  if (!stream) {
-    // It's quite possible to receive headers after a stream has been reset.
-    return;
-  }
-  stream->OnStreamHeaders(headers_data);
-}
-
 void QuicSpdySession::OnStreamHeadersPriority(QuicStreamId stream_id,
                                               SpdyPriority priority) {
   QuicSpdyStream* stream = GetSpdyDataStream(stream_id);
@@ -64,17 +57,6 @@ void QuicSpdySession::OnStreamHeadersPriority(QuicStreamId stream_id,
   stream->OnStreamHeadersPriority(priority);
 }
 
-void QuicSpdySession::OnStreamHeadersComplete(QuicStreamId stream_id,
-                                              bool fin,
-                                              size_t frame_len) {
-  QuicSpdyStream* stream = GetSpdyDataStream(stream_id);
-  if (!stream) {
-    // It's quite possible to receive headers after a stream has been reset.
-    return;
-  }
-  stream->OnStreamHeadersComplete(fin, frame_len);
-}
-
 void QuicSpdySession::OnStreamHeaderList(QuicStreamId stream_id,
                                          bool fin,
                                          size_t frame_len,
@@ -120,21 +102,12 @@ QuicSpdyStream* QuicSpdySession::GetSpdyDataStream(
   return static_cast<QuicSpdyStream*>(GetOrCreateDynamicStream(stream_id));
 }
 
-void QuicSpdySession::OnPromiseHeaders(QuicStreamId stream_id,
-                                       StringPiece headers_data) {
-  string error = "OnPromiseHeaders should be overriden in client code.";
-  QUIC_BUG << error;
-  connection()->CloseConnection(QUIC_INTERNAL_ERROR, error,
-                                ConnectionCloseBehavior::SILENT_CLOSE);
-}
-
-void QuicSpdySession::OnPromiseHeadersComplete(QuicStreamId stream_id,
-                                               QuicStreamId promised_stream_id,
-                                               size_t frame_len) {
-  string error = "OnPromiseHeadersComplete should be overriden in client code.";
-  QUIC_BUG << error;
-  connection()->CloseConnection(QUIC_INTERNAL_ERROR, error,
-                                ConnectionCloseBehavior::SILENT_CLOSE);
+void QuicSpdySession::OnCryptoHandshakeEvent(CryptoHandshakeEvent event) {
+  QuicSession::OnCryptoHandshakeEvent(event);
+  if (FLAGS_quic_send_max_header_list_size && event == HANDSHAKE_CONFIRMED &&
+      config()->SupportMaxHeaderListSize()) {
+    headers_stream()->SendMaxHeaderListSize(kDefaultMaxUncompressedHeaderSize);
+  }
 }
 
 void QuicSpdySession::OnPromiseHeaderList(QuicStreamId stream_id,
@@ -153,14 +126,22 @@ void QuicSpdySession::OnConfigNegotiated() {
     headers_stream_->DisableHpackDynamicTable();
   }
   const QuicVersion version = connection()->version();
-  if (version > QUIC_VERSION_35 && config()->ForceHolBlocking(perspective())) {
+  if (FLAGS_quic_enable_force_hol_blocking && version > QUIC_VERSION_35 &&
+      config()->ForceHolBlocking(perspective())) {
     force_hol_blocking_ = true;
-    // Autotuning makes sure that the headers stream flow control does
-    // not get in the way, and normal stream and connection level flow
-    // control are active anyway. This is really only for the client
-    // side (and mainly there just in tests and toys), where
-    // autotuning and/or large buffers are not enabled by default.
-    headers_stream_->flow_controller()->set_auto_tune_receive_window(true);
+    // Since all streams are tunneled through the headers stream, it
+    // is important that headers stream never flow control blocks.
+    // Otherwise, busy-loop behaviour can ensue where data streams
+    // data try repeatedly to write data not realizing that the
+    // tunnel through the headers stream is blocked.
+    headers_stream_->flow_controller()->UpdateReceiveWindowSize(
+        kStreamReceiveWindowLimit);
+    headers_stream_->flow_controller()->UpdateSendWindowOffset(
+        kStreamReceiveWindowLimit);
+  }
+
+  if (version > QUIC_VERSION_34) {
+    server_push_enabled_ = FLAGS_quic_enable_server_push_by_default;
   }
 }
 
@@ -180,4 +161,8 @@ void QuicSpdySession::OnStreamFrameData(QuicStreamId stream_id,
   OnStreamFrame(frame);
 }
 
+bool QuicSpdySession::ShouldReleaseHeadersStreamSequencerBuffer() {
+  return false;
+}
+
 }  // namespace net
diff --git a/src/net/quic/core/quic_spdy_session.h b/src/net/quic/core/quic_spdy_session.h
index 0f92a20..eb58af6 100644
--- a/src/net/quic/core/quic_spdy_session.h
+++ b/src/net/quic/core/quic_spdy_session.h
@@ -10,6 +10,7 @@
 #include <memory>
 
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_header_list.h"
 #include "net/quic/core/quic_headers_stream.h"
 #include "net/quic/core/quic_session.h"
@@ -24,27 +25,20 @@ class QuicSpdySessionPeer;
 // A QUIC session with a headers stream.
 class NET_EXPORT_PRIVATE QuicSpdySession : public QuicSession {
  public:
-  // Does not take ownership of |connection|.
-  QuicSpdySession(QuicConnection* connection, const QuicConfig& config);
+  // Does not take ownership of |connection| or |visitor|.
+  QuicSpdySession(QuicConnection* connection,
+                  QuicSession::Visitor* visitor,
+                  const QuicConfig& config);
 
   ~QuicSpdySession() override;
 
   void Initialize() override;
 
-  // Called by |headers_stream_| when headers have been received for a stream.
-  virtual void OnStreamHeaders(QuicStreamId stream_id,
-                               base::StringPiece headers_data);
   // Called by |headers_stream_| when headers with a priority have been
   // received for this stream.  This method will only be called for server
   // streams.
   virtual void OnStreamHeadersPriority(QuicStreamId stream_id,
                                        SpdyPriority priority);
-  // Called by |headers_stream_| when headers have been completely received
-  // for a stream.  |fin| will be true if the fin flag was set in the headers
-  // frame.
-  virtual void OnStreamHeadersComplete(QuicStreamId stream_id,
-                                       bool fin,
-                                       size_t frame_len);
 
   // Called by |headers_stream_| when headers have been completely received
   // for a stream.  |fin| will be true if the fin flag was set in the headers
@@ -55,18 +49,6 @@ class NET_EXPORT_PRIVATE QuicSpdySession : public QuicSession {
                                   const QuicHeaderList& header_list);
 
   // Called by |headers_stream_| when push promise headers have been
-  // received for a stream.
-  virtual void OnPromiseHeaders(QuicStreamId stream_id,
-                                base::StringPiece headers_data);
-
-  // Called by |headers_stream_| when push promise headers have been
-  // completely received.  |fin| will be true if the fin flag was set
-  // in the headers.
-  virtual void OnPromiseHeadersComplete(QuicStreamId stream_id,
-                                        QuicStreamId promised_stream_id,
-                                        size_t frame_len);
-
-  // Called by |headers_stream_| when push promise headers have been
   // completely received.  |fin| will be true if the fin flag was set
   // in the headers.
   virtual void OnPromiseHeaderList(QuicStreamId stream_id,
@@ -109,6 +91,16 @@ class NET_EXPORT_PRIVATE QuicSpdySession : public QuicSession {
 
   bool force_hol_blocking() const { return force_hol_blocking_; }
 
+  bool server_push_enabled() const { return server_push_enabled_; }
+
+  // Called by |QuicHeadersStream::UpdateEnableServerPush()| with
+  // value from SETTINGS_ENABLE_PUSH.
+  void set_server_push_enabled(bool enable) { server_push_enabled_ = enable; }
+
+  // Return true if this session wants to release headers stream's buffer
+  // aggressively.
+  virtual bool ShouldReleaseHeadersStreamSequencerBuffer();
+
  protected:
   // Override CreateIncomingDynamicStream() and CreateOutgoingDynamicStream()
   // with QuicSpdyStream return type to make sure that all data streams are
@@ -125,6 +117,8 @@ class NET_EXPORT_PRIVATE QuicSpdySession : public QuicSession {
   // If an outgoing stream can be created, return true.
   virtual bool ShouldCreateOutgoingDynamicStream() = 0;
 
+  void OnCryptoHandshakeEvent(CryptoHandshakeEvent event) override;
+
  private:
   friend class test::QuicSpdySessionPeer;
 
@@ -135,6 +129,10 @@ class NET_EXPORT_PRIVATE QuicSpdySession : public QuicSession {
   // HTTP/2 over TCP.
   bool force_hol_blocking_;
 
+  // Set during handshake. If true, resources in x-associated-content and link
+  // headers will be pushed.
+  bool server_push_enabled_;
+
   DISALLOW_COPY_AND_ASSIGN(QuicSpdySession);
 };
 
diff --git a/src/net/quic/core/quic_spdy_stream.cc b/src/net/quic/core/quic_spdy_stream.cc
index 0747b8e..6c9335b 100644
--- a/src/net/quic/core/quic_spdy_stream.cc
+++ b/src/net/quic/core/quic_spdy_stream.cc
@@ -8,6 +8,7 @@
 
 #include "base/logging.h"
 #include "base/strings/string_number_conversions.h"
+#include "net/base/parse_number.h"
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_spdy_session.h"
 #include "net/quic/core/quic_utils.h"
@@ -16,7 +17,6 @@
 
 using base::IntToString;
 using base::StringPiece;
-using std::min;
 using std::string;
 
 namespace net {
@@ -26,13 +26,14 @@ namespace net {
                                                                      " ")
 
 QuicSpdyStream::QuicSpdyStream(QuicStreamId id, QuicSpdySession* spdy_session)
-    : ReliableQuicStream(id, spdy_session),
+    : QuicStream(id, spdy_session),
       spdy_session_(spdy_session),
       visitor_(nullptr),
+      allow_bidirectional_data_(false),
       headers_decompressed_(false),
       priority_(kDefaultPriority),
       trailers_decompressed_(false),
-      trailers_delivered_(false) {
+      trailers_consumed_(false) {
   DCHECK_NE(kCryptoStreamId, id);
   // Don't receive any callbacks from the sequencer until headers
   // are complete.
@@ -46,18 +47,6 @@ QuicSpdyStream::~QuicSpdyStream() {
   }
 }
 
-void QuicSpdyStream::CloseWriteSide() {
-  if (!fin_received() && !rst_received() && sequencer()->ignore_read_data() &&
-      !rst_sent()) {
-    DCHECK(fin_sent());
-    // Tell the peer to stop sending further data.
-    DVLOG(1) << ENDPOINT << "Send QUIC_STREAM_NO_ERROR on stream " << id();
-    Reset(QUIC_STREAM_NO_ERROR);
-  }
-
-  ReliableQuicStream::CloseWriteSide();
-}
-
 void QuicSpdyStream::StopReading() {
   if (!fin_received() && !rst_received() && write_side_closed() &&
       !rst_sent()) {
@@ -66,7 +55,7 @@ void QuicSpdyStream::StopReading() {
     DVLOG(1) << ENDPOINT << "Send QUIC_STREAM_NO_ERROR on stream " << id();
     Reset(QUIC_STREAM_NO_ERROR);
   }
-  ReliableQuicStream::StopReading();
+  QuicStream::StopReading();
 }
 
 size_t QuicSpdyStream::WriteHeaders(
@@ -145,25 +134,11 @@ bool QuicSpdyStream::IsDoneReading() const {
 }
 
 bool QuicSpdyStream::HasBytesToRead() const {
-  bool headers_to_read = !decompressed_headers_.empty();
-  bool body_to_read = sequencer()->HasBytesToRead();
-  bool trailers_to_read = !decompressed_trailers_.empty();
-  return headers_to_read || body_to_read || trailers_to_read;
-}
-
-void QuicSpdyStream::MarkHeadersConsumed(size_t bytes_consumed) {
-  decompressed_headers_.erase(0, bytes_consumed);
-  if (FinishedReadingHeaders()) {
-    sequencer()->SetUnblocked();
-  }
-}
-
-void QuicSpdyStream::MarkTrailersConsumed(size_t bytes_consumed) {
-  decompressed_trailers_.erase(0, bytes_consumed);
+  return sequencer()->HasBytesToRead();
 }
 
-void QuicSpdyStream::MarkTrailersDelivered() {
-  trailers_delivered_ = true;
+void QuicSpdyStream::MarkTrailersConsumed() {
+  trailers_consumed_ = true;
 }
 
 void QuicSpdyStream::ConsumeHeaderList() {
@@ -179,31 +154,26 @@ void QuicSpdyStream::SetPriority(SpdyPriority priority) {
   priority_ = priority;
 }
 
-void QuicSpdyStream::OnStreamHeaders(StringPiece headers_data) {
-  if (!headers_decompressed_) {
-    headers_data.AppendToString(&decompressed_headers_);
-  } else {
-    DCHECK(!trailers_decompressed_);
-    headers_data.AppendToString(&decompressed_trailers_);
-  }
-}
-
 void QuicSpdyStream::OnStreamHeadersPriority(SpdyPriority priority) {
   DCHECK_EQ(Perspective::IS_SERVER, session()->connection()->perspective());
   SetPriority(priority);
 }
 
-void QuicSpdyStream::OnStreamHeadersComplete(bool fin, size_t frame_len) {
-  if (!headers_decompressed_) {
-    OnInitialHeadersComplete(fin, frame_len);
-  } else {
-    OnTrailingHeadersComplete(fin, frame_len);
-  }
-}
-
 void QuicSpdyStream::OnStreamHeaderList(bool fin,
                                         size_t frame_len,
                                         const QuicHeaderList& header_list) {
+  // The headers list avoid infinite buffering by clearing the headers list
+  // if the current headers are too large. So if the list is empty here
+  // then the headers list must have been too large, and the stream should
+  // be reset.
+  // TODO(rch): Use an explicit "headers too large" signal. An empty header list
+  // might be acceptable if it corresponds to a trailing header frame.
+  if (FLAGS_quic_limit_uncompressed_headers && header_list.empty()) {
+    OnHeadersTooLarge();
+    if (IsDoneReading()) {
+      return;
+    }
+  }
   if (!headers_decompressed_) {
     OnInitialHeadersComplete(fin, frame_len, header_list);
   } else {
@@ -211,14 +181,8 @@ void QuicSpdyStream::OnStreamHeaderList(bool fin,
   }
 }
 
-void QuicSpdyStream::OnInitialHeadersComplete(bool fin, size_t /*frame_len*/) {
-  headers_decompressed_ = true;
-  if (fin) {
-    OnStreamFrame(QuicStreamFrame(id(), fin, 0, StringPiece()));
-  }
-  if (FinishedReadingHeaders()) {
-    sequencer()->SetUnblocked();
-  }
+void QuicSpdyStream::OnHeadersTooLarge() {
+  Reset(QUIC_HEADERS_TOO_LARGE);
 }
 
 void QuicSpdyStream::OnInitialHeadersComplete(
@@ -235,21 +199,6 @@ void QuicSpdyStream::OnInitialHeadersComplete(
   }
 }
 
-void QuicSpdyStream::OnPromiseHeaders(StringPiece headers_data) {
-  headers_data.AppendToString(&decompressed_headers_);
-}
-
-void QuicSpdyStream::OnPromiseHeadersComplete(
-    QuicStreamId /* promised_stream_id */,
-    size_t /* frame_len */) {
-  // To be overridden in QuicSpdyClientStream.  Not supported on
-  // server side.
-  session()->connection()->CloseConnection(
-      QUIC_INVALID_HEADERS_STREAM_DATA, "Promise headers received by server",
-      ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-  return;
-}
-
 void QuicSpdyStream::OnPromiseHeaderList(
     QuicStreamId /* promised_id */,
     size_t /* frame_len */,
@@ -262,42 +211,6 @@ void QuicSpdyStream::OnPromiseHeaderList(
   return;
 }
 
-void QuicSpdyStream::OnTrailingHeadersComplete(bool fin, size_t /*frame_len*/) {
-  DCHECK(!trailers_decompressed_);
-  if (fin_received()) {
-    DLOG(ERROR) << "Received Trailers after FIN, on stream: " << id();
-    session()->connection()->CloseConnection(
-        QUIC_INVALID_HEADERS_STREAM_DATA, "Trailers after fin",
-        ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-    return;
-  }
-  if (!fin) {
-    DLOG(ERROR) << "Trailers must have FIN set, on stream: " << id();
-    session()->connection()->CloseConnection(
-        QUIC_INVALID_HEADERS_STREAM_DATA, "Fin missing from trailers",
-        ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-    return;
-  }
-
-  size_t final_byte_offset = 0;
-  if (!SpdyUtils::ParseTrailers(decompressed_trailers().data(),
-                                decompressed_trailers().length(),
-                                &final_byte_offset, &received_trailers_)) {
-    DLOG(ERROR) << "Trailers are malformed: " << id();
-    session()->connection()->CloseConnection(
-        QUIC_INVALID_HEADERS_STREAM_DATA, "Trailers are malformed",
-        ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-    return;
-  }
-
-  // The data on this stream ends at |final_byte_offset|.
-  DVLOG(1) << "Stream ends at byte offset: " << final_byte_offset
-           << "  currently read: " << stream_bytes_read();
-
-  OnStreamFrame(QuicStreamFrame(id(), fin, final_byte_offset, StringPiece()));
-  trailers_decompressed_ = true;
-}
-
 void QuicSpdyStream::OnTrailingHeadersComplete(
     bool fin,
     size_t /*frame_len*/,
@@ -327,13 +240,13 @@ void QuicSpdyStream::OnTrailingHeadersComplete(
         ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
     return;
   }
-  OnStreamFrame(QuicStreamFrame(id(), fin, final_byte_offset, StringPiece()));
   trailers_decompressed_ = true;
+  OnStreamFrame(QuicStreamFrame(id(), fin, final_byte_offset, StringPiece()));
 }
 
 void QuicSpdyStream::OnStreamReset(const QuicRstStreamFrame& frame) {
   if (frame.error_code != QUIC_STREAM_NO_ERROR) {
-    ReliableQuicStream::OnStreamReset(frame);
+    QuicStream::OnStreamReset(frame);
     return;
   }
   DVLOG(1) << "Received QUIC_STREAM_NO_ERROR, not discarding response";
@@ -344,7 +257,7 @@ void QuicSpdyStream::OnStreamReset(const QuicRstStreamFrame& frame) {
 }
 
 void QuicSpdyStream::OnClose() {
-  ReliableQuicStream::OnClose();
+  QuicStream::OnClose();
 
   if (visitor_) {
     Visitor* visitor = visitor_;
@@ -356,7 +269,7 @@ void QuicSpdyStream::OnClose() {
 }
 
 void QuicSpdyStream::OnCanWrite() {
-  ReliableQuicStream::OnCanWrite();
+  QuicStream::OnCanWrite();
 
   // Trailers (and hence a FIN) may have been sent ahead of queued body bytes.
   if (!HasBufferedData() && fin_sent()) {
@@ -365,8 +278,7 @@ void QuicSpdyStream::OnCanWrite() {
 }
 
 bool QuicSpdyStream::FinishedReadingHeaders() const {
-  return headers_decompressed_ && decompressed_headers_.empty() &&
-         header_list_.empty();
+  return headers_decompressed_ && header_list_.empty();
 }
 
 bool QuicSpdyStream::ParseHeaderStatusCode(const SpdyHeaderBlock& header,
@@ -379,15 +291,19 @@ bool QuicSpdyStream::ParseHeaderStatusCode(const SpdyHeaderBlock& header,
   if (status.size() != 3) {
     return false;
   }
-  // First character must be an integer in range [1,5].
-  if (status[0] < '1' || status[0] > '5') {
+
+  unsigned int result;
+  if (!ParseUint32(status, &result, nullptr)) {
     return false;
   }
-  // The remaining two characters must be integers.
-  if (!isdigit(status[1]) || !isdigit(status[2])) {
+
+  // Valid status codes are only in the range [100, 599].
+  if (result < 100 || result >= 600) {
     return false;
   }
-  return StringToInt(status, status_code);
+
+  *status_code = static_cast<int>(result);
+  return true;
 }
 
 bool QuicSpdyStream::FinishedReadingTrailers() const {
@@ -398,7 +314,7 @@ bool QuicSpdyStream::FinishedReadingTrailers() const {
   } else if (!trailers_decompressed_) {
     return true;
   } else {
-    return trailers_delivered_ && decompressed_trailers_.empty();
+    return trailers_consumed_;
   }
 }
 
@@ -420,8 +336,7 @@ QuicConsumedData QuicSpdyStream::WritevDataInner(
     return spdy_session_->headers_stream()->WritevStreamData(
         id(), iov, offset, fin, ack_notifier_delegate);
   }
-  return ReliableQuicStream::WritevDataInner(iov, offset, fin,
-                                             ack_notifier_delegate);
+  return QuicStream::WritevDataInner(iov, offset, fin, ack_notifier_delegate);
 }
 
 }  // namespace net
diff --git a/src/net/quic/core/quic_spdy_stream.h b/src/net/quic/core/quic_spdy_stream.h
index 078a3ed..97374e5 100644
--- a/src/net/quic/core/quic_spdy_stream.h
+++ b/src/net/quic/core/quic_spdy_stream.h
@@ -18,20 +18,20 @@
 #include "base/macros.h"
 #include "base/strings/string_piece.h"
 #include "net/base/iovec.h"
-#include "net/base/ip_endpoint.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_header_list.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_stream.h"
 #include "net/quic/core/quic_stream_sequencer.h"
-#include "net/quic/core/reliable_quic_stream.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 #include "net/spdy/spdy_framer.h"
 
 namespace net {
 
 namespace test {
 class QuicSpdyStreamPeer;
-class ReliableQuicStreamPeer;
+class QuicStreamPeer;
 }  // namespace test
 
 class QuicSpdySession;
@@ -43,7 +43,7 @@ class QuicSpdySession;
 const SpdyPriority kDefaultPriority = 3;
 
 // A QUIC stream that can send and receive HTTP2 (SPDY) headers.
-class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
+class NET_EXPORT_PRIVATE QuicSpdyStream : public QuicStream {
  public:
   // Visitor receives callbacks from the stream.
   class NET_EXPORT_PRIVATE Visitor {
@@ -67,23 +67,14 @@ class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
   QuicSpdyStream(QuicStreamId id, QuicSpdySession* spdy_session);
   ~QuicSpdyStream() override;
 
-  // Override the base class to send QUIC_STREAM_NO_ERROR to the peer
-  // when the stream has not received all the data.
-  void CloseWriteSide() override;
   void StopReading() override;
 
-  // ReliableQuicStream implementation
+  // QuicStream implementation
   void OnClose() override;
 
   // Override to maybe close the write side after writing.
   void OnCanWrite() override;
 
-  // Called by the session when decompressed headers data is received
-  // for this stream.
-  // May be called multiple times, with each call providing additional headers
-  // data until OnStreamHeadersComplete is called.
-  virtual void OnStreamHeaders(base::StringPiece headers_data);
-
   // Called by the session when headers with a priority have been received
   // for this stream.  This method will only be called for server streams.
   virtual void OnStreamHeadersPriority(SpdyPriority priority);
@@ -91,25 +82,13 @@ class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
   // Called by the session when decompressed headers have been completely
   // delivered to this stream.  If |fin| is true, then this stream
   // should be closed; no more data will be sent by the peer.
-  virtual void OnStreamHeadersComplete(bool fin, size_t frame_len);
-
-  // Called by the session when decompressed headers have been completely
-  // delivered to this stream.  If |fin| is true, then this stream
-  // should be closed; no more data will be sent by the peer.
   virtual void OnStreamHeaderList(bool fin,
                                   size_t frame_len,
                                   const QuicHeaderList& header_list);
 
-  // Called by the session when decompressed PUSH_PROMISE headers data
-  // is received for this stream.
-  // May be called multiple times, with each call providing additional headers
-  // data until OnPromiseHeadersComplete is called.
-  virtual void OnPromiseHeaders(base::StringPiece headers_data);
-
-  // Called by the session when decompressed push promise headers have
-  // been completely delivered to this stream.
-  virtual void OnPromiseHeadersComplete(QuicStreamId promised_id,
-                                        size_t frame_len);
+  // Called when the received headers are too large. By default this will
+  // reset the stream.
+  virtual void OnHeadersTooLarge();
 
   // Called by the session when decompressed push promise headers have
   // been completely delivered to this stream.
@@ -137,14 +116,10 @@ class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
   virtual size_t WriteTrailers(SpdyHeaderBlock trailer_block,
                                QuicAckListenerInterface* ack_notifier_delegate);
 
-  // Marks |bytes_consumed| of the headers data as consumed.
-  void MarkHeadersConsumed(size_t bytes_consumed);
-
-  // Marks |bytes_consumed| of the trailers data as consumed.
-  void MarkTrailersConsumed(size_t bytes_consumed);
-
-  // Marks the trailers as consumed.
-  void MarkTrailersDelivered();
+  // Marks the trailers as consumed. This applies to the case where this object
+  // receives headers and trailers as QuicHeaderLists via calls to
+  // OnStreamHeaderList().
+  void MarkTrailersConsumed();
 
   // Clears |header_list_|.
   void ConsumeHeaderList();
@@ -169,18 +144,10 @@ class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
 
   bool headers_decompressed() const { return headers_decompressed_; }
 
-  const std::string& decompressed_headers() const {
-    return decompressed_headers_;
-  }
-
   const QuicHeaderList& header_list() const { return header_list_; }
 
   bool trailers_decompressed() const { return trailers_decompressed_; }
 
-  const std::string& decompressed_trailers() const {
-    return decompressed_trailers_;
-  }
-
   // Returns whatever trailers have been received for this stream.
   const SpdyHeaderBlock& received_trailers() const {
     return received_trailers_;
@@ -189,6 +156,10 @@ class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
   // Returns true if headers have been fully read and consumed.
   bool FinishedReadingHeaders() const;
 
+  // Returns true if trailers have been fully read and consumed, or FIN has
+  // been received and there are no trailers.
+  bool FinishedReadingTrailers() const;
+
   virtual SpdyPriority priority() const;
 
   // Sets priority_ to priority.  This should only be called before bytes are
@@ -203,11 +174,15 @@ class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
   // will be available.
   bool IsClosed() { return sequencer()->IsClosed(); }
 
+  void set_allow_bidirectional_data(bool value) {
+    allow_bidirectional_data_ = value;
+  }
+
+  bool allow_bidirectional_data() const { return allow_bidirectional_data_; }
+
+  using QuicStream::CloseWriteSide;
+
  protected:
-  // Called by OnStreamHeadersComplete depending on which type (initial or
-  // trailing) headers are expected next.
-  virtual void OnInitialHeadersComplete(bool fin, size_t frame_len);
-  virtual void OnTrailingHeadersComplete(bool fin, size_t frame_len);
   virtual void OnInitialHeadersComplete(bool fin,
                                         size_t frame_len,
                                         const QuicHeaderList& header_list);
@@ -227,33 +202,28 @@ class NET_EXPORT_PRIVATE QuicSpdyStream : public ReliableQuicStream {
 
  private:
   friend class test::QuicSpdyStreamPeer;
-  friend class test::ReliableQuicStreamPeer;
+  friend class test::QuicStreamPeer;
   friend class QuicStreamUtils;
 
-  // Returns true if trailers have been fully read and consumed.
-  bool FinishedReadingTrailers() const;
-
   QuicSpdySession* spdy_session_;
 
   Visitor* visitor_;
+  // If true, allow sending of a request to continue while the response is
+  // arriving.
+  bool allow_bidirectional_data_;
   // True if the headers have been completely decompressed.
   bool headers_decompressed_;
   // The priority of the stream, once parsed.
   SpdyPriority priority_;
-  // Contains a copy of the decompressed headers until they are consumed
-  // via ProcessData or Readv.
-  std::string decompressed_headers_;
-  // Contains a copy of the decompressed header (name, value) pairs until they
+  // Contains a copy of the decompressed header (name, value) std::pairs until
+  // they
   // are consumed via Readv.
   QuicHeaderList header_list_;
 
   // True if the trailers have been completely decompressed.
   bool trailers_decompressed_;
   // True if the trailers have been consumed.
-  bool trailers_delivered_;
-  // Contains a copy of the decompressed trailers until they are consumed
-  // via ProcessData or Readv.
-  std::string decompressed_trailers_;
+  bool trailers_consumed_;
   // The parsed trailers received from the peer.
   SpdyHeaderBlock received_trailers_;
 
diff --git a/src/net/quic/core/quic_stream_sequencer.cc b/src/net/quic/core/quic_stream_sequencer.cc
index 4a6ea83..64c6b4c 100644
--- a/src/net/quic/core/quic_stream_sequencer.cc
+++ b/src/net/quic/core/quic_stream_sequencer.cc
@@ -9,29 +9,30 @@
 #include <string>
 #include <utility>
 
+#include "base/format_macros.h"
 #include "base/logging.h"
 #include "base/strings/string_number_conversions.h"
+#include "base/strings/stringprintf.h"
 #include "net/quic/core/quic_bug_tracker.h"
-#include "net/quic/core/quic_clock.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_stream.h"
 #include "net/quic/core/quic_stream_sequencer_buffer.h"
 #include "net/quic/core/quic_utils.h"
-#include "net/quic/core/reliable_quic_stream.h"
+#include "net/quic/platform/api/quic_clock.h"
 
 using base::IntToString;
 using base::StringPiece;
-using std::min;
-using std::numeric_limits;
+using base::StringPrintf;
 using std::string;
 
 namespace net {
 
-QuicStreamSequencer::QuicStreamSequencer(ReliableQuicStream* quic_stream,
+QuicStreamSequencer::QuicStreamSequencer(QuicStream* quic_stream,
                                          const QuicClock* clock)
     : stream_(quic_stream),
       buffered_frames_(kStreamReceiveWindowLimit),
-      close_offset_(numeric_limits<QuicStreamOffset>::max()),
+      close_offset_(std::numeric_limits<QuicStreamOffset>::max()),
       blocked_(false),
       num_frames_received_(0),
       num_duplicate_frames_received_(0),
@@ -58,10 +59,10 @@ void QuicStreamSequencer::OnStreamFrame(const QuicStreamFrame& frame) {
       clock_->ApproximateNow(), &bytes_written, &error_details);
   if (result != QUIC_NO_ERROR) {
     string details = "Stream" + base::Uint64ToString(stream_->id()) + ": " +
-                     QuicUtils::ErrorToString(result) + ": " + error_details +
+                     QuicErrorCodeToString(result) + ": " + error_details +
                      "\nPeer Address: " +
                      stream_->PeerAddressOfLatestPacket().ToString();
-    DLOG(WARNING) << QuicUtils::ErrorToString(result);
+    DLOG(WARNING) << QuicErrorCodeToString(result);
     DLOG(WARNING) << details;
     stream_->CloseConnectionWithDetails(result, details);
     return;
@@ -87,7 +88,8 @@ void QuicStreamSequencer::OnStreamFrame(const QuicStreamFrame& frame) {
 }
 
 void QuicStreamSequencer::CloseStreamAtOffset(QuicStreamOffset offset) {
-  const QuicStreamOffset kMaxOffset = numeric_limits<QuicStreamOffset>::max();
+  const QuicStreamOffset kMaxOffset =
+      std::numeric_limits<QuicStreamOffset>::max();
 
   // If there is a scheduled close, the new offset should match it.
   if (close_offset_ != kMaxOffset && offset != close_offset_) {
@@ -135,7 +137,17 @@ bool QuicStreamSequencer::GetReadableRegion(iovec* iov,
 
 int QuicStreamSequencer::Readv(const struct iovec* iov, size_t iov_len) {
   DCHECK(!blocked_);
-  size_t bytes_read = buffered_frames_.Readv(iov, iov_len);
+  string error_details;
+  size_t bytes_read;
+  QuicErrorCode read_error =
+      buffered_frames_.Readv(iov, iov_len, &bytes_read, &error_details);
+  if (read_error != QUIC_NO_ERROR) {
+    string details = StringPrintf("Stream %" PRIu32 ": %s", stream_->id(),
+                                  error_details.c_str());
+    stream_->CloseConnectionWithDetails(read_error, details);
+    return static_cast<int>(bytes_read);
+  }
+
   stream_->AddBytesConsumed(bytes_read);
   return static_cast<int>(bytes_read);
 }
@@ -184,6 +196,12 @@ void QuicStreamSequencer::ReleaseBuffer() {
   buffered_frames_.ReleaseWholeBuffer();
 }
 
+void QuicStreamSequencer::ReleaseBufferIfEmpty() {
+  if (buffered_frames_.Empty()) {
+    buffered_frames_.ReleaseWholeBuffer();
+  }
+}
+
 void QuicStreamSequencer::FlushBufferedFrames() {
   DCHECK(ignore_read_data_);
   size_t bytes_flushed = buffered_frames_.FlushBufferedFrames();
diff --git a/src/net/quic/core/quic_stream_sequencer.h b/src/net/quic/core/quic_stream_sequencer.h
index 9b37366..bb8a144 100644
--- a/src/net/quic/core/quic_stream_sequencer.h
+++ b/src/net/quic/core/quic_stream_sequencer.h
@@ -10,7 +10,8 @@
 #include <map>
 
 #include "base/macros.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/quic/core/quic_stream_sequencer_buffer.h"
 
 namespace net {
@@ -20,14 +21,13 @@ class QuicStreamSequencerPeer;
 }  // namespace test
 
 class QuicClock;
-class QuicSession;
-class ReliableQuicStream;
+class QuicStream;
 
 // Buffers frames until we have something which can be passed
 // up to the next layer.
 class NET_EXPORT_PRIVATE QuicStreamSequencer {
  public:
-  QuicStreamSequencer(ReliableQuicStream* quic_stream, const QuicClock* clock);
+  QuicStreamSequencer(QuicStream* quic_stream, const QuicClock* clock);
   virtual ~QuicStreamSequencer();
 
   // If the frame is the next one we need in order to process in-order data,
@@ -82,6 +82,9 @@ class NET_EXPORT_PRIVATE QuicStreamSequencer {
   // Free the memory of underlying buffer.
   void ReleaseBuffer();
 
+  // Free the memory of underlying buffer when no bytes remain in it.
+  void ReleaseBufferIfEmpty();
+
   // Number of bytes in the buffer right now.
   size_t NumBytesBuffered() const;
 
@@ -114,7 +117,7 @@ class NET_EXPORT_PRIVATE QuicStreamSequencer {
   bool MaybeCloseStream();
 
   // The stream which owns this sequencer.
-  ReliableQuicStream* stream_;
+  QuicStream* stream_;
 
   // Stores received data in offset order.
   QuicStreamSequencerBuffer buffered_frames_;
diff --git a/src/net/quic/core/quic_stream_sequencer_buffer.cc b/src/net/quic/core/quic_stream_sequencer_buffer.cc
index 0c55fe7..6b3ee9d 100644
--- a/src/net/quic/core/quic_stream_sequencer_buffer.cc
+++ b/src/net/quic/core/quic_stream_sequencer_buffer.cc
@@ -4,12 +4,14 @@
 
 #include "net/quic/core/quic_stream_sequencer_buffer.h"
 
+#include "base/format_macros.h"
 #include "base/logging.h"
 #include "base/strings/string_number_conversions.h"
+#include "base/strings/stringprintf.h"
 #include "net/quic/core/quic_bug_tracker.h"
 #include "net/quic/core/quic_flags.h"
 
-using std::min;
+using base::StringPrintf;
 using std::string;
 
 namespace net {
@@ -47,20 +49,21 @@ QuicStreamSequencerBuffer::QuicStreamSequencerBuffer(size_t max_capacity_bytes)
       blocks_count_(
           ceil(static_cast<double>(max_capacity_bytes) / kBlockSizeBytes)),
       total_bytes_read_(0),
-      reduce_sequencer_buffer_memory_life_time_(
-          FLAGS_quic_reduce_sequencer_buffer_memory_life_time),  // NOLINT
-      blocks_(reduce_sequencer_buffer_memory_life_time_
-                  ? nullptr
-                  : new BufferBlock*[blocks_count_]()) {
+      blocks_(nullptr),
+      destruction_indicator_(123456) {
+  CHECK_GT(blocks_count_, 1u)
+      << "blocks_count_ = " << blocks_count_
+      << ", max_buffer_capacity_bytes_ = " << max_buffer_capacity_bytes_;
   Clear();
 }
 
 QuicStreamSequencerBuffer::~QuicStreamSequencerBuffer() {
   Clear();
+  destruction_indicator_ = 654321;
 }
 
 void QuicStreamSequencerBuffer::Clear() {
-  if (!reduce_sequencer_buffer_memory_life_time_ || blocks_ != nullptr) {
+  if (blocks_ != nullptr) {
     for (size_t i = 0; i < blocks_count_; ++i) {
       if (blocks_[i] != nullptr) {
         RetireBlock(i);
@@ -72,15 +75,19 @@ void QuicStreamSequencerBuffer::Clear() {
   // total_bytes_read_ has been consumed, and those after total_bytes_read_
   // has never arrived.
   gaps_ = std::list<Gap>(
-      1, Gap(total_bytes_read_, std::numeric_limits<QuicStreamOffset>::max())),
+      1, Gap(total_bytes_read_, std::numeric_limits<QuicStreamOffset>::max()));
   frame_arrival_time_map_.clear();
 }
 
-void QuicStreamSequencerBuffer::RetireBlock(size_t idx) {
-  DCHECK(blocks_[idx] != nullptr);
+bool QuicStreamSequencerBuffer::RetireBlock(size_t idx) {
+  if (blocks_[idx] == nullptr) {
+    QUIC_BUG << "Try to retire block twice";
+    return false;
+  }
   delete blocks_[idx];
   blocks_[idx] = nullptr;
   DVLOG(1) << "Retired block with index: " << idx;
+  return true;
 }
 
 QuicErrorCode QuicStreamSequencerBuffer::OnStreamData(
@@ -89,6 +96,7 @@ QuicErrorCode QuicStreamSequencerBuffer::OnStreamData(
     QuicTime timestamp,
     size_t* const bytes_buffered,
     std::string* error_details) {
+  CHECK_EQ(destruction_indicator_, 123456) << "This object has been destructed";
   *bytes_buffered = 0;
   QuicStreamOffset offset = starting_offset;
   size_t size = data.size();
@@ -174,22 +182,52 @@ QuicErrorCode QuicStreamSequencerBuffer::OnStreamData(
       bytes_avail = total_bytes_read_ + max_buffer_capacity_bytes_ - offset;
     }
 
-    if (reduce_sequencer_buffer_memory_life_time_ && blocks_ == nullptr) {
+    if (blocks_ == nullptr) {
       blocks_.reset(new BufferBlock*[blocks_count_]());
       for (size_t i = 0; i < blocks_count_; ++i) {
         blocks_[i] = nullptr;
       }
     }
 
+    if (write_block_num >= blocks_count_) {
+      *error_details = StringPrintf(
+          "QuicStreamSequencerBuffer error: OnStreamData() exceed array bounds."
+          "write offset = %" PRIu64 " write_block_num = %" PRIuS
+          " blocks_count_ = %" PRIuS,
+          offset, write_block_num, blocks_count_);
+      return QUIC_STREAM_SEQUENCER_INVALID_STATE;
+    }
+    if (blocks_ == nullptr) {
+      *error_details =
+          "QuicStreamSequencerBuffer error: OnStreamData() blocks_ is null";
+      return QUIC_STREAM_SEQUENCER_INVALID_STATE;
+    }
     if (blocks_[write_block_num] == nullptr) {
       // TODO(danzh): Investigate if using a freelist would improve performance.
       // Same as RetireBlock().
       blocks_[write_block_num] = new BufferBlock();
     }
 
-    const size_t bytes_to_copy = min<size_t>(bytes_avail, source_remaining);
+    const size_t bytes_to_copy =
+        std::min<size_t>(bytes_avail, source_remaining);
     char* dest = blocks_[write_block_num]->buffer + write_block_offset;
     DVLOG(1) << "Write at offset: " << offset << " length: " << bytes_to_copy;
+
+    if (dest == nullptr || source == nullptr) {
+      *error_details = StringPrintf(
+          "QuicStreamSequencerBuffer error: OnStreamData()"
+          " dest == nullptr: %s"
+          " source == nullptr: %s"
+          " Writing at offset %" PRIu64
+          " Gaps: %s"
+          " Remaining frames: %s"
+          " total_bytes_read_ = %" PRIu64,
+          (dest == nullptr ? "true" : "false"),
+          (source == nullptr ? "true" : "false"), offset,
+          GapsDebugString().c_str(), ReceivedFramesDebugString().c_str(),
+          total_bytes_read_);
+      return QUIC_STREAM_SEQUENCER_INVALID_STATE;
+    }
     memcpy(dest, source, bytes_to_copy);
     source += bytes_to_copy;
     source_remaining -= bytes_to_copy;
@@ -237,46 +275,71 @@ inline void QuicStreamSequencerBuffer::UpdateGapList(
   }
 }
 
-size_t QuicStreamSequencerBuffer::Readv(const iovec* dest_iov,
-                                        size_t dest_count) {
-  size_t bytes_read = 0;
+QuicErrorCode QuicStreamSequencerBuffer::Readv(const iovec* dest_iov,
+                                               size_t dest_count,
+                                               size_t* bytes_read,
+                                               string* error_details) {
+  CHECK_EQ(destruction_indicator_, 123456) << "This object has been destructed";
+
+  *bytes_read = 0;
   for (size_t i = 0; i < dest_count && ReadableBytes() > 0; ++i) {
     char* dest = reinterpret_cast<char*>(dest_iov[i].iov_base);
+    CHECK_NE(dest, nullptr);
     size_t dest_remaining = dest_iov[i].iov_len;
     while (dest_remaining > 0 && ReadableBytes() > 0) {
       size_t block_idx = NextBlockToRead();
       size_t start_offset_in_block = ReadOffset();
       size_t block_capacity = GetBlockCapacity(block_idx);
-      size_t bytes_available_in_block =
-          min<size_t>(ReadableBytes(), block_capacity - start_offset_in_block);
+      size_t bytes_available_in_block = std::min<size_t>(
+          ReadableBytes(), block_capacity - start_offset_in_block);
       size_t bytes_to_copy =
-          min<size_t>(bytes_available_in_block, dest_remaining);
-      DCHECK_GT(bytes_to_copy, 0u);
-      DCHECK_NE(static_cast<BufferBlock*>(nullptr), blocks_[block_idx]);
+          std::min<size_t>(bytes_available_in_block, dest_remaining);
+      DCHECK_GT(bytes_to_copy, 0UL);
+      if (blocks_[block_idx] == nullptr || dest == nullptr) {
+        *error_details = StringPrintf(
+            "QuicStreamSequencerBuffer error:"
+            " Readv() dest == nullptr: %s"
+            " blocks_[%" PRIuS "] == nullptr: %s",
+            (dest == nullptr ? "true" : "false"), block_idx,
+            (blocks_[block_idx] == nullptr ? "true" : "false"));
+        return QUIC_STREAM_SEQUENCER_INVALID_STATE;
+      }
       memcpy(dest, blocks_[block_idx]->buffer + start_offset_in_block,
              bytes_to_copy);
       dest += bytes_to_copy;
       dest_remaining -= bytes_to_copy;
       num_bytes_buffered_ -= bytes_to_copy;
       total_bytes_read_ += bytes_to_copy;
-      bytes_read += bytes_to_copy;
+      *bytes_read += bytes_to_copy;
 
-      // Retire the block if all the data is read out
-      // and no other data is stored in this block.
+      // Retire the block if all the data is read out and no other data is
+      // stored in this block.
+      // In case of failing to retire a block which is ready to retire, return
+      // immediately.
       if (bytes_to_copy == bytes_available_in_block) {
-        RetireBlockIfEmpty(block_idx);
+        bool retire_successfully = RetireBlockIfEmpty(block_idx);
+        if (!retire_successfully) {
+          *error_details = StringPrintf(
+              "QuicStreamSequencerBuffer error: fail to retire block %" PRIuS
+              " as the block is already released + total_bytes_read_ = %" PRIu64
+              " Gaps: %s",
+              block_idx, total_bytes_read_, GapsDebugString().c_str());
+          return QUIC_STREAM_SEQUENCER_INVALID_STATE;
+        }
       }
     }
   }
 
-  if (bytes_read > 0) {
+  if (*bytes_read > 0) {
     UpdateFrameArrivalMap(total_bytes_read_);
   }
-  return bytes_read;
+  return QUIC_NO_ERROR;
 }
 
 int QuicStreamSequencerBuffer::GetReadableRegions(struct iovec* iov,
                                                   int iov_count) const {
+  CHECK_EQ(destruction_indicator_, 123456) << "This object has been destructed";
+
   DCHECK(iov != nullptr);
   DCHECK_GT(iov_count, 0);
 
@@ -335,6 +398,8 @@ int QuicStreamSequencerBuffer::GetReadableRegions(struct iovec* iov,
 
 bool QuicStreamSequencerBuffer::GetReadableRegion(iovec* iov,
                                                   QuicTime* timestamp) const {
+  CHECK_EQ(destruction_indicator_, 123456) << "This object has been destructed";
+
   if (ReadableBytes() == 0) {
     iov[0].iov_base = nullptr;
     iov[0].iov_len = 0;
@@ -343,7 +408,7 @@ bool QuicStreamSequencerBuffer::GetReadableRegion(iovec* iov,
 
   size_t start_block_idx = NextBlockToRead();
   iov->iov_base = blocks_[start_block_idx]->buffer + ReadOffset();
-  size_t readable_bytes_in_block = min<size_t>(
+  size_t readable_bytes_in_block = std::min<size_t>(
       GetBlockCapacity(start_block_idx) - ReadOffset(), ReadableBytes());
   size_t region_len = 0;
   auto iter = frame_arrival_time_map_.begin();
@@ -373,6 +438,8 @@ bool QuicStreamSequencerBuffer::GetReadableRegion(iovec* iov,
 }
 
 bool QuicStreamSequencerBuffer::MarkConsumed(size_t bytes_used) {
+  CHECK_EQ(destruction_indicator_, 123456) << "This object has been destructed";
+
   if (bytes_used > ReadableBytes()) {
     return false;
   }
@@ -380,9 +447,9 @@ bool QuicStreamSequencerBuffer::MarkConsumed(size_t bytes_used) {
   while (bytes_to_consume > 0) {
     size_t block_idx = NextBlockToRead();
     size_t offset_in_block = ReadOffset();
-    size_t bytes_available = min<size_t>(
+    size_t bytes_available = std::min<size_t>(
         ReadableBytes(), GetBlockCapacity(block_idx) - offset_in_block);
-    size_t bytes_read = min<size_t>(bytes_to_consume, bytes_available);
+    size_t bytes_read = std::min<size_t>(bytes_to_consume, bytes_available);
     total_bytes_read_ += bytes_read;
     num_bytes_buffered_ -= bytes_read;
     bytes_to_consume -= bytes_read;
@@ -406,10 +473,6 @@ size_t QuicStreamSequencerBuffer::FlushBufferedFrames() {
 }
 
 void QuicStreamSequencerBuffer::ReleaseWholeBuffer() {
-  if (!reduce_sequencer_buffer_memory_life_time_) {
-    // Don't release buffer if flag is off.
-    return;
-  }
   Clear();
   blocks_.reset(nullptr);
 }
@@ -447,21 +510,20 @@ size_t QuicStreamSequencerBuffer::NextBlockToRead() const {
   return GetBlockIndex(total_bytes_read_);
 }
 
-void QuicStreamSequencerBuffer::RetireBlockIfEmpty(size_t block_index) {
+bool QuicStreamSequencerBuffer::RetireBlockIfEmpty(size_t block_index) {
   DCHECK(ReadableBytes() == 0 || GetInBlockOffset(total_bytes_read_) == 0)
       << "RetireBlockIfEmpty() should only be called when advancing to next "
          "block"
          " or a gap has been reached.";
   // If the whole buffer becomes empty, the last piece of data has been read.
   if (Empty()) {
-    RetireBlock(block_index);
-    return;
+    return RetireBlock(block_index);
   }
 
   // Check where the logical end of this buffer is.
   // Not empty if the end of circular buffer has been wrapped to this block.
   if (GetBlockIndex(gaps_.back().begin_offset - 1) == block_index) {
-    return;
+    return true;
   }
 
   // Read index remains in this block, which means a gap has been reached.
@@ -473,10 +535,10 @@ void QuicStreamSequencerBuffer::RetireBlockIfEmpty(size_t block_index) {
     bool gap_ends_in_this_block =
         (GetBlockIndex(first_gap.end_offset) == block_index);
     if (gap_ends_in_this_block) {
-      return;
+      return true;
     }
   }
-  RetireBlock(block_index);
+  return RetireBlock(block_index);
 }
 
 bool QuicStreamSequencerBuffer::Empty() const {
@@ -534,8 +596,9 @@ string QuicStreamSequencerBuffer::ReceivedFramesDebugString() {
     QuicStreamOffset current_frame_begin_offset = it.first;
     QuicStreamOffset current_frame_end_offset =
         it.second.length + current_frame_begin_offset;
-    current_frames_string +=
-        RangeDebugString(current_frame_begin_offset, current_frame_end_offset);
+    current_frames_string = string(StringPrintf(
+        "%s[%" PRIu64 ", %" PRIu64 ") ", current_frames_string.c_str(),
+        current_frame_begin_offset, current_frame_end_offset));
   }
   return current_frames_string;
 }
diff --git a/src/net/quic/core/quic_stream_sequencer_buffer.h b/src/net/quic/core/quic_stream_sequencer_buffer.h
index 135e7d1..930dbd5 100644
--- a/src/net/quic/core/quic_stream_sequencer_buffer.h
+++ b/src/net/quic/core/quic_stream_sequencer_buffer.h
@@ -67,7 +67,8 @@
 #include <memory>
 
 #include "base/macros.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/quic_packets.h"
 
 namespace net {
 
@@ -125,7 +126,10 @@ class NET_EXPORT_PRIVATE QuicStreamSequencerBuffer {
 
   // Reads from this buffer into given iovec array, up to number of iov_len
   // iovec objects and returns the number of bytes read.
-  size_t Readv(const struct iovec* dest_iov, size_t dest_count);
+  QuicErrorCode Readv(const struct iovec* dest_iov,
+                      size_t dest_count,
+                      size_t* bytes_read,
+                      std::string* error_details);
 
   // Returns the readable region of valid data in iovec format. The readable
   // region is the buffer region where there is valid data not yet read by
@@ -164,23 +168,21 @@ class NET_EXPORT_PRIVATE QuicStreamSequencerBuffer {
   // Count how many bytes are in buffer at this moment.
   size_t BytesBuffered() const;
 
-  bool reduce_sequencer_buffer_memory_life_time() const {
-    return reduce_sequencer_buffer_memory_life_time_;
-  }
-
  private:
   friend class test::QuicStreamSequencerBufferPeer;
 
   // Dispose the given buffer block.
   // After calling this method, blocks_[index] is set to nullptr
   // in order to indicate that no memory set is allocated for that block.
-  void RetireBlock(size_t index);
+  // Returns true on success, false otherwise.
+  bool RetireBlock(size_t index);
 
   // Should only be called after the indexed block is read till the end of the
   // block or a gap has been reached.
-  // If the block at |block_index| contains no buffered data, then the block is
-  // retired.
-  void RetireBlockIfEmpty(size_t block_index);
+  // If the block at |block_index| contains no buffered data, the block
+  // should be retired.
+  // Return false on success, or false otherwise.
+  bool RetireBlockIfEmpty(size_t block_index);
 
   // Called within OnStreamData() to update the gap OnStreamData() writes into
   // (remove, split or change begin/end offset).
@@ -235,10 +237,6 @@ class NET_EXPORT_PRIVATE QuicStreamSequencerBuffer {
   // Contains Gaps which represents currently missing data.
   std::list<Gap> gaps_;
 
-  // If true, allocate buffer memory upon the first frame arrival and release
-  // the memory when stream is read closed.
-  bool reduce_sequencer_buffer_memory_life_time_;
-
   // An ordered, variable-length list of blocks, with the length limited
   // such that the number of blocks never exceeds blocks_count_.
   // Each list entry can hold up to kBlockSizeBytes bytes.
@@ -250,6 +248,11 @@ class NET_EXPORT_PRIVATE QuicStreamSequencerBuffer {
   // Stores all the buffered frames' start offset, length and arrival time.
   std::map<QuicStreamOffset, FrameInfo> frame_arrival_time_map_;
 
+  // For debugging use after free, assigned to 123456 in constructor and 654321
+  // in destructor. As long as it's not 123456, this means either use after free
+  // or memory corruption.
+  int32_t destruction_indicator_;
+
   DISALLOW_COPY_AND_ASSIGN(QuicStreamSequencerBuffer);
 };
 }  // namespace net
diff --git a/src/net/quic/core/quic_sustained_bandwidth_recorder.h b/src/net/quic/core/quic_sustained_bandwidth_recorder.h
index 12c8c3f..be5afef 100644
--- a/src/net/quic/core/quic_sustained_bandwidth_recorder.h
+++ b/src/net/quic/core/quic_sustained_bandwidth_recorder.h
@@ -9,6 +9,7 @@
 
 #include "base/logging.h"
 #include "base/macros.h"
+#include "net/base/net_export.h"
 #include "net/quic/core/quic_bandwidth.h"
 #include "net/quic/core/quic_time.h"
 
diff --git a/src/net/quic/core/quic_time.h b/src/net/quic/core/quic_time.h
index 92e31bc..08b7d21 100644
--- a/src/net/quic/core/quic_time.h
+++ b/src/net/quic/core/quic_time.h
@@ -24,12 +24,6 @@
 
 namespace net {
 
-static const int kNumSecondsPerMinute = 60;
-static const int kNumSecondsPerHour = kNumSecondsPerMinute * 60;
-static const uint64_t kNumMicrosPerSecond = base::Time::kMicrosecondsPerSecond;
-static const uint64_t kNumMicrosPerMilli =
-    base::Time::kMicrosecondsPerMillisecond;
-
 // A QuicTime is a purely relative time. QuicTime values from different clocks
 // cannot be compared to each other. If you need an absolute time, see
 // QuicWallTime, below.
diff --git a/src/net/quic/core/quic_types.cc b/src/net/quic/core/quic_types.cc
index 49260ba..4167c94 100644
--- a/src/net/quic/core/quic_types.cc
+++ b/src/net/quic/core/quic_types.cc
@@ -4,19 +4,26 @@
 
 #include "net/quic/core/quic_types.h"
 
-using std::ostream;
-
 namespace net {
 
 QuicConsumedData::QuicConsumedData(size_t bytes_consumed, bool fin_consumed)
     : bytes_consumed(bytes_consumed), fin_consumed(fin_consumed) {}
 
-ostream& operator<<(ostream& os, const QuicConsumedData& s) {
+std::ostream& operator<<(std::ostream& os, const QuicConsumedData& s) {
   os << "bytes_consumed: " << s.bytes_consumed
      << " fin_consumed: " << s.fin_consumed;
   return os;
 }
 
+std::ostream& operator<<(std::ostream& os, const Perspective& s) {
+  if (s == Perspective::IS_SERVER) {
+    os << "IS_SERVER";
+  } else {
+    os << "IS_CLIENT";
+  }
+  return os;
+}
+
 WriteResult::WriteResult() : status(WRITE_STATUS_ERROR), bytes_written(0) {}
 
 WriteResult::WriteResult(WriteStatus status, int bytes_written_or_error_code)
diff --git a/src/net/quic/core/quic_types.h b/src/net/quic/core/quic_types.h
index 4f24e95..31e0425 100644
--- a/src/net/quic/core/quic_types.h
+++ b/src/net/quic/core/quic_types.h
@@ -5,18 +5,30 @@
 #ifndef NET_QUIC_QUIC_TYPES_H_
 #define NET_QUIC_QUIC_TYPES_H_
 
-// This header defines some basic types that don't depend on quic_protocol.h,
-// so that classes not directly related to the protocol wire format can avoid
-// including quic_protocol.h.
-
 #include <stddef.h>
-
+#include <array>
+#include <map>
 #include <ostream>
+#include <vector>
 
 #include "net/base/net_export.h"
+#include "net/quic/core/quic_time.h"
 
 namespace net {
 
+typedef uint8_t QuicPathId;
+typedef uint16_t QuicPacketLength;
+typedef uint32_t QuicHeaderId;
+typedef uint32_t QuicStreamId;
+typedef uint64_t QuicByteCount;
+typedef uint64_t QuicConnectionId;
+typedef uint64_t QuicPacketCount;
+typedef uint64_t QuicPacketNumber;
+typedef uint64_t QuicPublicResetNonceProof;
+typedef uint64_t QuicStreamOffset;
+typedef std::array<char, 32> DiversificationNonce;
+typedef std::vector<std::pair<QuicPacketNumber, QuicTime>> PacketTimeVector;
+
 // A struct for functions which consume data payloads and fins.
 struct NET_EXPORT_PRIVATE QuicConsumedData {
   QuicConsumedData(size_t bytes_consumed, bool fin_consumed);
@@ -65,6 +77,183 @@ struct NET_EXPORT_PRIVATE WriteResult {
   };
 };
 
+enum TransmissionType : int8_t {
+  NOT_RETRANSMISSION,
+  FIRST_TRANSMISSION_TYPE = NOT_RETRANSMISSION,
+  HANDSHAKE_RETRANSMISSION,    // Retransmits due to handshake timeouts.
+  ALL_UNACKED_RETRANSMISSION,  // Retransmits all unacked packets.
+  ALL_INITIAL_RETRANSMISSION,  // Retransmits all initially encrypted packets.
+  LOSS_RETRANSMISSION,         // Retransmits due to loss detection.
+  RTO_RETRANSMISSION,          // Retransmits due to retransmit time out.
+  TLP_RETRANSMISSION,          // Tail loss probes.
+  LAST_TRANSMISSION_TYPE = TLP_RETRANSMISSION,
+};
+
+enum HasRetransmittableData : int8_t {
+  NO_RETRANSMITTABLE_DATA,
+  HAS_RETRANSMITTABLE_DATA,
+};
+
+enum IsHandshake : int8_t { NOT_HANDSHAKE, IS_HANDSHAKE };
+
+enum class Perspective { IS_SERVER, IS_CLIENT };
+NET_EXPORT_PRIVATE std::ostream& operator<<(std::ostream& os,
+                                            const Perspective& s);
+
+// Describes whether a ConnectionClose was originated by the peer.
+enum class ConnectionCloseSource { FROM_PEER, FROM_SELF };
+
+// Should a connection be closed silently or not.
+enum class ConnectionCloseBehavior {
+  SILENT_CLOSE,
+  SEND_CONNECTION_CLOSE_PACKET,
+  SEND_CONNECTION_CLOSE_PACKET_WITH_NO_ACK
+};
+
+enum QuicFrameType {
+  // Regular frame types. The values set here cannot change without the
+  // introduction of a new QUIC version.
+  PADDING_FRAME = 0,
+  RST_STREAM_FRAME = 1,
+  CONNECTION_CLOSE_FRAME = 2,
+  GOAWAY_FRAME = 3,
+  WINDOW_UPDATE_FRAME = 4,
+  BLOCKED_FRAME = 5,
+  STOP_WAITING_FRAME = 6,
+  PING_FRAME = 7,
+  PATH_CLOSE_FRAME = 8,
+
+  // STREAM and ACK frames are special frames. They are encoded differently on
+  // the wire and their values do not need to be stable.
+  STREAM_FRAME,
+  ACK_FRAME,
+  // The path MTU discovery frame is encoded as a PING frame on the wire.
+  MTU_DISCOVERY_FRAME,
+  NUM_FRAME_TYPES
+};
+
+enum QuicConnectionIdLength {
+  PACKET_0BYTE_CONNECTION_ID = 0,
+  PACKET_8BYTE_CONNECTION_ID = 8
+};
+
+enum QuicPacketNumberLength : int8_t {
+  PACKET_1BYTE_PACKET_NUMBER = 1,
+  PACKET_2BYTE_PACKET_NUMBER = 2,
+  PACKET_4BYTE_PACKET_NUMBER = 4,
+  PACKET_6BYTE_PACKET_NUMBER = 6
+};
+
+// Used to indicate a QuicSequenceNumberLength using two flag bits.
+enum QuicPacketNumberLengthFlags {
+  PACKET_FLAGS_1BYTE_PACKET = 0,           // 00
+  PACKET_FLAGS_2BYTE_PACKET = 1,           // 01
+  PACKET_FLAGS_4BYTE_PACKET = 1 << 1,      // 10
+  PACKET_FLAGS_6BYTE_PACKET = 1 << 1 | 1,  // 11
+};
+
+// The public flags are specified in one byte.
+enum QuicPacketPublicFlags {
+  PACKET_PUBLIC_FLAGS_NONE = 0,
+
+  // Bit 0: Does the packet header contains version info?
+  PACKET_PUBLIC_FLAGS_VERSION = 1 << 0,
+
+  // Bit 1: Is this packet a public reset packet?
+  PACKET_PUBLIC_FLAGS_RST = 1 << 1,
+
+  // Bit 2: indicates the that public header includes a nonce.
+  PACKET_PUBLIC_FLAGS_NONCE = 1 << 2,
+
+  // Bit 3: indicates whether a ConnectionID is included.
+  PACKET_PUBLIC_FLAGS_0BYTE_CONNECTION_ID = 0,
+  PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID = 1 << 3,
+
+  // QUIC_VERSION_32 and earlier use two bits for an 8 byte
+  // connection id.
+  PACKET_PUBLIC_FLAGS_8BYTE_CONNECTION_ID_OLD = 1 << 3 | 1 << 2,
+
+  // Bits 4 and 5 describe the packet number length as follows:
+  // --00----: 1 byte
+  // --01----: 2 bytes
+  // --10----: 4 bytes
+  // --11----: 6 bytes
+  PACKET_PUBLIC_FLAGS_1BYTE_PACKET = PACKET_FLAGS_1BYTE_PACKET << 4,
+  PACKET_PUBLIC_FLAGS_2BYTE_PACKET = PACKET_FLAGS_2BYTE_PACKET << 4,
+  PACKET_PUBLIC_FLAGS_4BYTE_PACKET = PACKET_FLAGS_4BYTE_PACKET << 4,
+  PACKET_PUBLIC_FLAGS_6BYTE_PACKET = PACKET_FLAGS_6BYTE_PACKET << 4,
+
+  // Bit 6: Does the packet header contain a path id?
+  PACKET_PUBLIC_FLAGS_MULTIPATH = 1 << 6,
+
+  // Reserved, unimplemented flags:
+
+  // Bit 7: indicates the presence of a second flags byte.
+  PACKET_PUBLIC_FLAGS_TWO_OR_MORE_BYTES = 1 << 7,
+
+  // All bits set (bit 7 is not currently used): 01111111
+  PACKET_PUBLIC_FLAGS_MAX = (1 << 7) - 1,
+};
+
+// The private flags are specified in one byte.
+enum QuicPacketPrivateFlags {
+  PACKET_PRIVATE_FLAGS_NONE = 0,
+
+  // Bit 0: Does this packet contain an entropy bit?
+  PACKET_PRIVATE_FLAGS_ENTROPY = 1 << 0,
+
+  // (bits 1-7 are not used): 00000001
+  PACKET_PRIVATE_FLAGS_MAX = (1 << 1) - 1
+};
+
+// Defines for all types of congestion control algorithms that can be used in
+// QUIC. Note that this is separate from the congestion feedback type -
+// some congestion control algorithms may use the same feedback type
+// (Reno and Cubic are the classic example for that).
+enum CongestionControlType {
+  kCubic,
+  kCubicBytes,
+  kReno,
+  kRenoBytes,
+  kBBR,
+};
+
+enum LossDetectionType {
+  kNack,          // Used to mimic TCP's loss detection.
+  kTime,          // Time based loss detection.
+  kAdaptiveTime,  // Adaptive time based loss detection.
+  kLazyFack,      // Nack based but with FACK disabled for the first ack.
+};
+
+// EncryptionLevel enumerates the stages of encryption that a QUIC connection
+// progresses through. When retransmitting a packet, the encryption level needs
+// to be specified so that it is retransmitted at a level which the peer can
+// understand.
+enum EncryptionLevel : int8_t {
+  ENCRYPTION_NONE = 0,
+  ENCRYPTION_INITIAL = 1,
+  ENCRYPTION_FORWARD_SECURE = 2,
+
+  NUM_ENCRYPTION_LEVELS,
+};
+
+enum PeerAddressChangeType {
+  // IP address and port remain unchanged.
+  NO_CHANGE,
+  // Port changed, but IP address remains unchanged.
+  PORT_CHANGE,
+  // IPv4 address changed, but within the /24 subnet (port may have changed.)
+  IPV4_SUBNET_CHANGE,
+  // IPv4 address changed, excluding /24 subnet change (port may have changed.)
+  IPV4_TO_IPV4_CHANGE,
+  // IP address change from an IPv4 to an IPv6 address (port may have changed.)
+  IPV4_TO_IPV6_CHANGE,
+  // IP address change from an IPv6 to an IPv4 address (port may have changed.)
+  IPV6_TO_IPV4_CHANGE,
+  // IP address change from an IPv6 to an IPv6 address (port may have changed.)
+  IPV6_TO_IPV6_CHANGE,
+};
+
 }  // namespace net
 
 #endif  // NET_QUIC_QUIC_TYPES_H_
diff --git a/src/net/quic/core/quic_unacked_packet_map.cc b/src/net/quic/core/quic_unacked_packet_map.cc
index 0c70d14..ce0829e 100644
--- a/src/net/quic/core/quic_unacked_packet_map.cc
+++ b/src/net/quic/core/quic_unacked_packet_map.cc
@@ -12,22 +12,20 @@
 #include "net/quic/core/quic_flags.h"
 #include "net/quic/core/quic_utils.h"
 
-using std::max;
 
 namespace net {
 
 QuicUnackedPacketMap::QuicUnackedPacketMap()
     : largest_sent_packet_(0),
+      largest_sent_retransmittable_packet_(0),
       largest_observed_(0),
       least_unacked_(1),
       bytes_in_flight_(0),
       pending_crypto_packet_count_(0) {}
 
 QuicUnackedPacketMap::~QuicUnackedPacketMap() {
-  QuicPacketNumber index = least_unacked_;
-  for (UnackedPacketMap::iterator it = unacked_packets_.begin();
-       it != unacked_packets_.end(); ++it, ++index) {
-    QuicUtils::DeleteFrames(&it->retransmittable_frames);
+  for (QuicTransmissionInfo& transmission_info : unacked_packets_) {
+    DeleteFrames(&(transmission_info.retransmittable_frames));
   }
 }
 
@@ -41,15 +39,15 @@ void QuicUnackedPacketMap::AddSentPacket(SerializedPacket* packet,
   QUIC_BUG_IF(largest_sent_packet_ >= packet_number) << packet_number;
   DCHECK_GE(packet_number, least_unacked_ + unacked_packets_.size());
   while (least_unacked_ + unacked_packets_.size() < packet_number) {
-    unacked_packets_.push_back(TransmissionInfo());
+    unacked_packets_.push_back(QuicTransmissionInfo());
     unacked_packets_.back().is_unackable = true;
   }
 
   const bool has_crypto_handshake =
       packet->has_crypto_handshake == IS_HANDSHAKE;
-  TransmissionInfo info(packet->encryption_level, packet->packet_number_length,
-                        transmission_type, sent_time, bytes_sent,
-                        has_crypto_handshake, packet->num_padding_bytes);
+  QuicTransmissionInfo info(
+      packet->encryption_level, packet->packet_number_length, transmission_type,
+      sent_time, bytes_sent, has_crypto_handshake, packet->num_padding_bytes);
   if (old_packet_number > 0) {
     TransferRetransmissionInfo(old_packet_number, packet_number,
                                transmission_type, &info);
@@ -59,6 +57,7 @@ void QuicUnackedPacketMap::AddSentPacket(SerializedPacket* packet,
   if (set_in_flight) {
     bytes_in_flight_ += bytes_sent;
     info.in_flight = true;
+    largest_sent_retransmittable_packet_ = packet_number;
   }
   unacked_packets_.push_back(info);
   // Swap the ack listeners and retransmittable frames to avoid allocations.
@@ -89,7 +88,7 @@ void QuicUnackedPacketMap::TransferRetransmissionInfo(
     QuicPacketNumber old_packet_number,
     QuicPacketNumber new_packet_number,
     TransmissionType transmission_type,
-    TransmissionInfo* info) {
+    QuicTransmissionInfo* info) {
   if (old_packet_number < least_unacked_) {
     // This can happen when a retransmission packet is queued because of write
     // blocked socket, and the original packet gets acked before the
@@ -97,14 +96,14 @@ void QuicUnackedPacketMap::TransferRetransmissionInfo(
     return;
   }
   if (old_packet_number > largest_sent_packet_) {
-    QUIC_BUG << "Old TransmissionInfo never existed for :" << old_packet_number
-             << " largest_sent:" << largest_sent_packet_;
+    QUIC_BUG << "Old QuicTransmissionInfo never existed for :"
+             << old_packet_number << " largest_sent:" << largest_sent_packet_;
     return;
   }
   DCHECK_GE(new_packet_number, least_unacked_ + unacked_packets_.size());
   DCHECK_NE(NOT_RETRANSMISSION, transmission_type);
 
-  TransmissionInfo* transmission_info =
+  QuicTransmissionInfo* transmission_info =
       &unacked_packets_.at(old_packet_number - least_unacked_);
   QuicFrames* frames = &transmission_info->retransmittable_frames;
   for (AckListenerWrapper& wrapper : transmission_info->ack_listeners) {
@@ -143,34 +142,32 @@ bool QuicUnackedPacketMap::HasRetransmittableFrames(
               .retransmittable_frames.empty();
 }
 
-void QuicUnackedPacketMap::RemoveRetransmittability(TransmissionInfo* info) {
+void QuicUnackedPacketMap::RemoveRetransmittability(
+    QuicTransmissionInfo* info) {
   while (info->retransmission != 0) {
     const QuicPacketNumber retransmission = info->retransmission;
     info->retransmission = 0;
     info = &unacked_packets_[retransmission - least_unacked_];
   }
-  MaybeRemoveRetransmittableFrames(info);
+
+  if (info->has_crypto_handshake) {
+    DCHECK(!info->retransmittable_frames.empty());
+    DCHECK_LT(0u, pending_crypto_packet_count_);
+    --pending_crypto_packet_count_;
+    info->has_crypto_handshake = false;
+  }
+  DeleteFrames(&info->retransmittable_frames);
 }
 
 void QuicUnackedPacketMap::RemoveRetransmittability(
     QuicPacketNumber packet_number) {
   DCHECK_GE(packet_number, least_unacked_);
   DCHECK_LT(packet_number, least_unacked_ + unacked_packets_.size());
-  TransmissionInfo* info = &unacked_packets_[packet_number - least_unacked_];
+  QuicTransmissionInfo* info =
+      &unacked_packets_[packet_number - least_unacked_];
   RemoveRetransmittability(info);
 }
 
-void QuicUnackedPacketMap::MaybeRemoveRetransmittableFrames(
-    TransmissionInfo* transmission_info) {
-  if (transmission_info->has_crypto_handshake) {
-    DCHECK(!transmission_info->retransmittable_frames.empty());
-    DCHECK_LT(0u, pending_crypto_packet_count_);
-    --pending_crypto_packet_count_;
-    transmission_info->has_crypto_handshake = false;
-  }
-  QuicUtils::DeleteFrames(&transmission_info->retransmittable_frames);
-}
-
 void QuicUnackedPacketMap::IncreaseLargestObserved(
     QuicPacketNumber largest_observed) {
   DCHECK_LE(largest_observed_, largest_observed);
@@ -179,20 +176,20 @@ void QuicUnackedPacketMap::IncreaseLargestObserved(
 
 bool QuicUnackedPacketMap::IsPacketUsefulForMeasuringRtt(
     QuicPacketNumber packet_number,
-    const TransmissionInfo& info) const {
+    const QuicTransmissionInfo& info) const {
   // Packet can be used for RTT measurement if it may yet be acked as the
   // largest observed packet by the receiver.
   return !info.is_unackable && packet_number > largest_observed_;
 }
 
 bool QuicUnackedPacketMap::IsPacketUsefulForCongestionControl(
-    const TransmissionInfo& info) const {
+    const QuicTransmissionInfo& info) const {
   // Packet contributes to congestion control if it is considered inflight.
   return info.in_flight;
 }
 
 bool QuicUnackedPacketMap::IsPacketUsefulForRetransmittableData(
-    const TransmissionInfo& info) const {
+    const QuicTransmissionInfo& info) const {
   // Packet may have retransmittable frames, or the data may have been
   // retransmitted with a new packet number.
   return !info.retransmittable_frames.empty() ||
@@ -200,8 +197,9 @@ bool QuicUnackedPacketMap::IsPacketUsefulForRetransmittableData(
          info.retransmission > largest_observed_;
 }
 
-bool QuicUnackedPacketMap::IsPacketUseless(QuicPacketNumber packet_number,
-                                           const TransmissionInfo& info) const {
+bool QuicUnackedPacketMap::IsPacketUseless(
+    QuicPacketNumber packet_number,
+    const QuicTransmissionInfo& info) const {
   return !IsPacketUsefulForMeasuringRtt(packet_number, info) &&
          !IsPacketUsefulForCongestionControl(info) &&
          !IsPacketUsefulForRetransmittableData(info);
@@ -230,11 +228,12 @@ void QuicUnackedPacketMap::NotifyAndClearListeners(
     QuicTime::Delta ack_delay_time) {
   DCHECK_GE(packet_number, least_unacked_);
   DCHECK_LT(packet_number, least_unacked_ + unacked_packets_.size());
-  TransmissionInfo* info = &unacked_packets_[packet_number - least_unacked_];
+  QuicTransmissionInfo* info =
+      &unacked_packets_[packet_number - least_unacked_];
   NotifyAndClearListeners(&info->ack_listeners, ack_delay_time);
 }
 
-void QuicUnackedPacketMap::RemoveFromInFlight(TransmissionInfo* info) {
+void QuicUnackedPacketMap::RemoveFromInFlight(QuicTransmissionInfo* info) {
   if (info->in_flight) {
     QUIC_BUG_IF(bytes_in_flight_ < info->bytes_sent);
     bytes_in_flight_ -= info->bytes_sent;
@@ -245,14 +244,16 @@ void QuicUnackedPacketMap::RemoveFromInFlight(TransmissionInfo* info) {
 void QuicUnackedPacketMap::RemoveFromInFlight(QuicPacketNumber packet_number) {
   DCHECK_GE(packet_number, least_unacked_);
   DCHECK_LT(packet_number, least_unacked_ + unacked_packets_.size());
-  TransmissionInfo* info = &unacked_packets_[packet_number - least_unacked_];
+  QuicTransmissionInfo* info =
+      &unacked_packets_[packet_number - least_unacked_];
   RemoveFromInFlight(info);
 }
 
 void QuicUnackedPacketMap::RestoreToInFlight(QuicPacketNumber packet_number) {
   DCHECK_GE(packet_number, least_unacked_);
   DCHECK_LT(packet_number, least_unacked_ + unacked_packets_.size());
-  TransmissionInfo* info = &unacked_packets_[packet_number - least_unacked_];
+  QuicTransmissionInfo* info =
+      &unacked_packets_[packet_number - least_unacked_];
   DCHECK(!info->is_unackable);
   bytes_in_flight_ += info->bytes_sent;
   info->in_flight = true;
@@ -267,7 +268,7 @@ void QuicUnackedPacketMap::CancelRetransmissionsForStream(
     if (frames->empty()) {
       continue;
     }
-    QuicUtils::RemoveFramesForStream(frames, stream_id);
+    RemoveFramesForStream(frames, stream_id);
     if (frames->empty()) {
       RemoveRetransmittability(packet_number);
     }
@@ -282,12 +283,12 @@ bool QuicUnackedPacketMap::HasInFlightPackets() const {
   return bytes_in_flight_ > 0;
 }
 
-const TransmissionInfo& QuicUnackedPacketMap::GetTransmissionInfo(
+const QuicTransmissionInfo& QuicUnackedPacketMap::GetTransmissionInfo(
     QuicPacketNumber packet_number) const {
   return unacked_packets_[packet_number - least_unacked_];
 }
 
-TransmissionInfo* QuicUnackedPacketMap::GetMutableTransmissionInfo(
+QuicTransmissionInfo* QuicUnackedPacketMap::GetMutableTransmissionInfo(
     QuicPacketNumber packet_number) {
   return &unacked_packets_[packet_number - least_unacked_];
 }
diff --git a/src/net/quic/core/quic_unacked_packet_map.h b/src/net/quic/core/quic_unacked_packet_map.h
index 73969fd..9871b5c 100644
--- a/src/net/quic/core/quic_unacked_packet_map.h
+++ b/src/net/quic/core/quic_unacked_packet_map.h
@@ -10,12 +10,12 @@
 #include <deque>
 
 #include "base/macros.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/base/net_export.h"
+#include "net/quic/core/quic_packets.h"
+#include "net/quic/core/quic_transmission_info.h"
 
 namespace net {
 
-class AckNotifierManager;
-
 // Class which tracks unacked packets for three purposes:
 // 1) Track retransmittable data, including multiple transmissions of frames.
 // 2) Track packets and bytes in flight for congestion control.
@@ -32,7 +32,7 @@ class NET_EXPORT_PRIVATE QuicUnackedPacketMap {
   // |old_packet_number| is the packet number of the previous transmission,
   // or 0 if there was none.
   // Any AckNotifierWrappers in |serialized_packet| are swapped from the
-  // serialized packet into the TransmissionInfo.
+  // serialized packet into the QuicTransmissionInfo.
   void AddSentPacket(SerializedPacket* serialized_packet,
                      QuicPacketNumber old_packet_number,
                      TransmissionType transmission_type,
@@ -52,7 +52,7 @@ class NET_EXPORT_PRIVATE QuicUnackedPacketMap {
                                QuicTime::Delta delta_largest_observed);
 
   // Marks |info| as no longer in flight.
-  void RemoveFromInFlight(TransmissionInfo* info);
+  void RemoveFromInFlight(QuicTransmissionInfo* info);
 
   // Marks |packet_number| as no longer in flight.
   void RemoveFromInFlight(QuicPacketNumber packet_number);
@@ -80,6 +80,11 @@ class NET_EXPORT_PRIVATE QuicUnackedPacketMap {
   // Returns the largest packet number that has been sent.
   QuicPacketNumber largest_sent_packet() const { return largest_sent_packet_; }
 
+  // Returns the largest retransmittable packet number that has been sent.
+  QuicPacketNumber largest_sent_retransmittable_packet() const {
+    return largest_sent_retransmittable_packet_;
+  }
+
   // Returns the largest packet number that has been acked.
   QuicPacketNumber largest_observed() const { return largest_observed_; }
 
@@ -90,7 +95,7 @@ class NET_EXPORT_PRIVATE QuicUnackedPacketMap {
   // been acked by the peer.  If there are no unacked packets, returns 0.
   QuicPacketNumber GetLeastUnacked() const;
 
-  typedef std::deque<TransmissionInfo> UnackedPacketMap;
+  typedef std::deque<QuicTransmissionInfo> UnackedPacketMap;
 
   typedef UnackedPacketMap::const_iterator const_iterator;
   typedef UnackedPacketMap::iterator iterator;
@@ -103,14 +108,15 @@ class NET_EXPORT_PRIVATE QuicUnackedPacketMap {
   // Returns true if there are unacked packets that are in flight.
   bool HasInFlightPackets() const;
 
-  // Returns the TransmissionInfo associated with |packet_number|, which
+  // Returns the QuicTransmissionInfo associated with |packet_number|, which
   // must be unacked.
-  const TransmissionInfo& GetTransmissionInfo(
+  const QuicTransmissionInfo& GetTransmissionInfo(
       QuicPacketNumber packet_number) const;
 
-  // Returns mutable TransmissionInfo associated with |packet_number|, which
+  // Returns mutable QuicTransmissionInfo associated with |packet_number|, which
   // must be unacked.
-  TransmissionInfo* GetMutableTransmissionInfo(QuicPacketNumber packet_number);
+  QuicTransmissionInfo* GetMutableTransmissionInfo(
+      QuicPacketNumber packet_number);
 
   // Returns the time that the last unacked packet was sent.
   QuicTime GetLastPacketSentTime() const;
@@ -127,9 +133,9 @@ class NET_EXPORT_PRIVATE QuicUnackedPacketMap {
   // Removes any retransmittable frames from this transmission or an associated
   // transmission.  It removes now useless transmissions, and disconnects any
   // other packets from other transmissions.
-  void RemoveRetransmittability(TransmissionInfo* info);
+  void RemoveRetransmittability(QuicTransmissionInfo* info);
 
-  // Looks up the TransmissionInfo by |packet_number| and calls
+  // Looks up the QuicTransmissionInfo by |packet_number| and calls
   // RemoveRetransmittability.
   void RemoveRetransmittability(QuicPacketNumber packet_number);
 
@@ -149,26 +155,28 @@ class NET_EXPORT_PRIVATE QuicUnackedPacketMap {
   void TransferRetransmissionInfo(QuicPacketNumber old_packet_number,
                                   QuicPacketNumber new_packet_number,
                                   TransmissionType transmission_type,
-                                  TransmissionInfo* info);
-
-  void MaybeRemoveRetransmittableFrames(TransmissionInfo* transmission_info);
+                                  QuicTransmissionInfo* info);
 
   // Returns true if packet may be useful for an RTT measurement.
   bool IsPacketUsefulForMeasuringRtt(QuicPacketNumber packet_number,
-                                     const TransmissionInfo& info) const;
+                                     const QuicTransmissionInfo& info) const;
 
   // Returns true if packet may be useful for congestion control purposes.
-  bool IsPacketUsefulForCongestionControl(const TransmissionInfo& info) const;
+  bool IsPacketUsefulForCongestionControl(
+      const QuicTransmissionInfo& info) const;
 
   // Returns true if packet may be associated with retransmittable data
   // directly or through retransmissions.
-  bool IsPacketUsefulForRetransmittableData(const TransmissionInfo& info) const;
+  bool IsPacketUsefulForRetransmittableData(
+      const QuicTransmissionInfo& info) const;
 
   // Returns true if the packet no longer has a purpose in the map.
   bool IsPacketUseless(QuicPacketNumber packet_number,
-                       const TransmissionInfo& info) const;
+                       const QuicTransmissionInfo& info) const;
 
   QuicPacketNumber largest_sent_packet_;
+  // The largest sent packet we expect to receive an ack for.
+  QuicPacketNumber largest_sent_retransmittable_packet_;
   QuicPacketNumber largest_observed_;
 
   // Newly serialized retransmittable packets are added to this map, which
diff --git a/src/net/quic/core/quic_utils.cc b/src/net/quic/core/quic_utils.cc
index 52c0def..e4dcd9b 100644
--- a/src/net/quic/core/quic_utils.cc
+++ b/src/net/quic/core/quic_utils.cc
@@ -15,9 +15,8 @@
 #include "base/strings/string_number_conversions.h"
 #include "base/strings/string_split.h"
 #include "base/strings/stringprintf.h"
-#include "net/base/ip_address.h"
+#include "net/quic/core/quic_constants.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_write_blocked_list.h"
 
 using base::StringPiece;
 using std::string;
@@ -78,10 +77,6 @@ uint128 IncrementalHash(uint128 hash, const char* data, size_t len) {
 #endif
 }
 
-bool IsInitializedIPEndPoint(const IPEndPoint& address) {
-  return address.address().IsValid();
-}
-
 }  // namespace
 
 // static
@@ -125,53 +120,6 @@ uint128 QuicUtils::FNV1a_128_Hash_Two(const char* data1,
 }
 
 // static
-bool QuicUtils::FindMutualTag(const QuicTagVector& our_tags_vector,
-                              const QuicTag* their_tags,
-                              size_t num_their_tags,
-                              Priority priority,
-                              QuicTag* out_result,
-                              size_t* out_index) {
-  if (our_tags_vector.empty()) {
-    return false;
-  }
-  const size_t num_our_tags = our_tags_vector.size();
-  const QuicTag* our_tags = &our_tags_vector[0];
-
-  size_t num_priority_tags, num_inferior_tags;
-  const QuicTag* priority_tags;
-  const QuicTag* inferior_tags;
-  if (priority == LOCAL_PRIORITY) {
-    num_priority_tags = num_our_tags;
-    priority_tags = our_tags;
-    num_inferior_tags = num_their_tags;
-    inferior_tags = their_tags;
-  } else {
-    num_priority_tags = num_their_tags;
-    priority_tags = their_tags;
-    num_inferior_tags = num_our_tags;
-    inferior_tags = our_tags;
-  }
-
-  for (size_t i = 0; i < num_priority_tags; i++) {
-    for (size_t j = 0; j < num_inferior_tags; j++) {
-      if (priority_tags[i] == inferior_tags[j]) {
-        *out_result = priority_tags[i];
-        if (out_index) {
-          if (priority == LOCAL_PRIORITY) {
-            *out_index = j;
-          } else {
-            *out_index = i;
-          }
-        }
-        return true;
-      }
-    }
-  }
-
-  return false;
-}
-
-// static
 void QuicUtils::SerializeUint128Short(uint128 v, uint8_t* out) {
   const uint64_t lo = Uint128Low64(v);
   const uint64_t hi = Uint128High64(v);
@@ -185,135 +133,6 @@ void QuicUtils::SerializeUint128Short(uint128 v, uint8_t* out) {
     return #x;
 
 // static
-const char* QuicUtils::StreamErrorToString(QuicRstStreamErrorCode error) {
-  switch (error) {
-    RETURN_STRING_LITERAL(QUIC_STREAM_NO_ERROR);
-    RETURN_STRING_LITERAL(QUIC_STREAM_CONNECTION_ERROR);
-    RETURN_STRING_LITERAL(QUIC_ERROR_PROCESSING_STREAM);
-    RETURN_STRING_LITERAL(QUIC_MULTIPLE_TERMINATION_OFFSETS);
-    RETURN_STRING_LITERAL(QUIC_BAD_APPLICATION_PAYLOAD);
-    RETURN_STRING_LITERAL(QUIC_STREAM_PEER_GOING_AWAY);
-    RETURN_STRING_LITERAL(QUIC_STREAM_CANCELLED);
-    RETURN_STRING_LITERAL(QUIC_RST_ACKNOWLEDGEMENT);
-    RETURN_STRING_LITERAL(QUIC_REFUSED_STREAM);
-    RETURN_STRING_LITERAL(QUIC_STREAM_LAST_ERROR);
-    RETURN_STRING_LITERAL(QUIC_INVALID_PROMISE_URL);
-    RETURN_STRING_LITERAL(QUIC_UNAUTHORIZED_PROMISE_URL);
-    RETURN_STRING_LITERAL(QUIC_DUPLICATE_PROMISE_URL);
-    RETURN_STRING_LITERAL(QUIC_PROMISE_VARY_MISMATCH);
-    RETURN_STRING_LITERAL(QUIC_INVALID_PROMISE_METHOD);
-  }
-  // Return a default value so that we return this when |error| doesn't match
-  // any of the QuicRstStreamErrorCodes. This can happen when the RstStream
-  // frame sent by the peer (attacker) has invalid error code.
-  return "INVALID_RST_STREAM_ERROR_CODE";
-}
-
-// static
-const char* QuicUtils::ErrorToString(QuicErrorCode error) {
-  switch (error) {
-    RETURN_STRING_LITERAL(QUIC_NO_ERROR);
-    RETURN_STRING_LITERAL(QUIC_INTERNAL_ERROR);
-    RETURN_STRING_LITERAL(QUIC_STREAM_DATA_AFTER_TERMINATION);
-    RETURN_STRING_LITERAL(QUIC_INVALID_PACKET_HEADER);
-    RETURN_STRING_LITERAL(QUIC_INVALID_FRAME_DATA);
-    RETURN_STRING_LITERAL(QUIC_MISSING_PAYLOAD);
-    RETURN_STRING_LITERAL(QUIC_INVALID_FEC_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_STREAM_DATA);
-    RETURN_STRING_LITERAL(QUIC_OVERLAPPING_STREAM_DATA);
-    RETURN_STRING_LITERAL(QUIC_UNENCRYPTED_STREAM_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_RST_STREAM_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_CONNECTION_CLOSE_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_GOAWAY_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_WINDOW_UPDATE_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_BLOCKED_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_STOP_WAITING_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_PATH_CLOSE_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_ACK_DATA);
-    RETURN_STRING_LITERAL(QUIC_INVALID_VERSION_NEGOTIATION_PACKET);
-    RETURN_STRING_LITERAL(QUIC_INVALID_PUBLIC_RST_PACKET);
-    RETURN_STRING_LITERAL(QUIC_DECRYPTION_FAILURE);
-    RETURN_STRING_LITERAL(QUIC_ENCRYPTION_FAILURE);
-    RETURN_STRING_LITERAL(QUIC_PACKET_TOO_LARGE);
-    RETURN_STRING_LITERAL(QUIC_PEER_GOING_AWAY);
-    RETURN_STRING_LITERAL(QUIC_HANDSHAKE_FAILED);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_TAGS_OUT_OF_ORDER);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_TOO_MANY_ENTRIES);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_TOO_MANY_REJECTS);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_INVALID_VALUE_LENGTH)
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_MESSAGE_AFTER_HANDSHAKE_COMPLETE);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_INTERNAL_ERROR);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_VERSION_NOT_SUPPORTED);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_HANDSHAKE_STATELESS_REJECT);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_NO_SUPPORT);
-    RETURN_STRING_LITERAL(QUIC_INVALID_CRYPTO_MESSAGE_TYPE);
-    RETURN_STRING_LITERAL(QUIC_INVALID_CRYPTO_MESSAGE_PARAMETER);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_MESSAGE_PARAMETER_NOT_FOUND);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_MESSAGE_PARAMETER_NO_OVERLAP);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_MESSAGE_INDEX_NOT_FOUND);
-    RETURN_STRING_LITERAL(QUIC_UNSUPPORTED_PROOF_DEMAND);
-    RETURN_STRING_LITERAL(QUIC_INVALID_STREAM_ID);
-    RETURN_STRING_LITERAL(QUIC_INVALID_PRIORITY);
-    RETURN_STRING_LITERAL(QUIC_TOO_MANY_OPEN_STREAMS);
-    RETURN_STRING_LITERAL(QUIC_PUBLIC_RESET);
-    RETURN_STRING_LITERAL(QUIC_INVALID_VERSION);
-    RETURN_STRING_LITERAL(QUIC_INVALID_HEADER_ID);
-    RETURN_STRING_LITERAL(QUIC_INVALID_NEGOTIATED_VALUE);
-    RETURN_STRING_LITERAL(QUIC_DECOMPRESSION_FAILURE);
-    RETURN_STRING_LITERAL(QUIC_NETWORK_IDLE_TIMEOUT);
-    RETURN_STRING_LITERAL(QUIC_HANDSHAKE_TIMEOUT);
-    RETURN_STRING_LITERAL(QUIC_ERROR_MIGRATING_ADDRESS);
-    RETURN_STRING_LITERAL(QUIC_ERROR_MIGRATING_PORT);
-    RETURN_STRING_LITERAL(QUIC_PACKET_WRITE_ERROR);
-    RETURN_STRING_LITERAL(QUIC_PACKET_READ_ERROR);
-    RETURN_STRING_LITERAL(QUIC_EMPTY_STREAM_FRAME_NO_FIN);
-    RETURN_STRING_LITERAL(QUIC_INVALID_HEADERS_STREAM_DATA);
-    RETURN_STRING_LITERAL(QUIC_FLOW_CONTROL_RECEIVED_TOO_MUCH_DATA);
-    RETURN_STRING_LITERAL(QUIC_FLOW_CONTROL_SENT_TOO_MUCH_DATA);
-    RETURN_STRING_LITERAL(QUIC_FLOW_CONTROL_INVALID_WINDOW);
-    RETURN_STRING_LITERAL(QUIC_CONNECTION_IP_POOLED);
-    RETURN_STRING_LITERAL(QUIC_PROOF_INVALID);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_DUPLICATE_TAG);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_ENCRYPTION_LEVEL_INCORRECT);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_SERVER_CONFIG_EXPIRED);
-    RETURN_STRING_LITERAL(QUIC_INVALID_CHANNEL_ID_SIGNATURE);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_SYMMETRIC_KEY_SETUP_FAILED);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_MESSAGE_WHILE_VALIDATING_CLIENT_HELLO);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_UPDATE_BEFORE_HANDSHAKE_COMPLETE);
-    RETURN_STRING_LITERAL(QUIC_VERSION_NEGOTIATION_MISMATCH);
-    RETURN_STRING_LITERAL(QUIC_TOO_MANY_OUTSTANDING_SENT_PACKETS);
-    RETURN_STRING_LITERAL(QUIC_TOO_MANY_OUTSTANDING_RECEIVED_PACKETS);
-    RETURN_STRING_LITERAL(QUIC_CONNECTION_CANCELLED);
-    RETURN_STRING_LITERAL(QUIC_BAD_PACKET_LOSS_RATE);
-    RETURN_STRING_LITERAL(QUIC_PUBLIC_RESETS_POST_HANDSHAKE);
-    RETURN_STRING_LITERAL(QUIC_TIMEOUTS_WITH_OPEN_STREAMS);
-    RETURN_STRING_LITERAL(QUIC_FAILED_TO_SERIALIZE_PACKET);
-    RETURN_STRING_LITERAL(QUIC_TOO_MANY_AVAILABLE_STREAMS);
-    RETURN_STRING_LITERAL(QUIC_UNENCRYPTED_FEC_DATA);
-    RETURN_STRING_LITERAL(QUIC_BAD_MULTIPATH_FLAG);
-    RETURN_STRING_LITERAL(QUIC_IP_ADDRESS_CHANGED);
-    RETURN_STRING_LITERAL(QUIC_CONNECTION_MIGRATION_NO_MIGRATABLE_STREAMS);
-    RETURN_STRING_LITERAL(QUIC_CONNECTION_MIGRATION_TOO_MANY_CHANGES);
-    RETURN_STRING_LITERAL(QUIC_CONNECTION_MIGRATION_NO_NEW_NETWORK);
-    RETURN_STRING_LITERAL(QUIC_CONNECTION_MIGRATION_NON_MIGRATABLE_STREAM);
-    RETURN_STRING_LITERAL(QUIC_TOO_MANY_RTOS);
-    RETURN_STRING_LITERAL(QUIC_ATTEMPT_TO_SEND_UNENCRYPTED_STREAM_DATA);
-    RETURN_STRING_LITERAL(QUIC_MAYBE_CORRUPTED_MEMORY);
-    RETURN_STRING_LITERAL(QUIC_CRYPTO_CHLO_TOO_LARGE);
-    RETURN_STRING_LITERAL(QUIC_MULTIPATH_PATH_DOES_NOT_EXIST);
-    RETURN_STRING_LITERAL(QUIC_MULTIPATH_PATH_NOT_ACTIVE);
-    RETURN_STRING_LITERAL(QUIC_TOO_MANY_FRAME_GAPS);
-    RETURN_STRING_LITERAL(QUIC_LAST_ERROR);
-    // Intentionally have no default case, so we'll break the build
-    // if we add errors and don't put them here.
-  }
-  // Return a default value so that we return this when |error| doesn't match
-  // any of the QuicErrorCodes. This can happen when the ConnectionClose
-  // frame sent by the peer (attacker) has invalid error code.
-  return "INVALID_ERROR_CODE";
-}
-
-// static
 const char* QuicUtils::EncryptionLevelToString(EncryptionLevel level) {
   switch (level) {
     RETURN_STRING_LITERAL(ENCRYPTION_NONE);
@@ -339,31 +158,6 @@ const char* QuicUtils::TransmissionTypeToString(TransmissionType type) {
 }
 
 // static
-string QuicUtils::TagToString(QuicTag tag) {
-  char chars[sizeof tag];
-  bool ascii = true;
-  const QuicTag orig_tag = tag;
-
-  for (size_t i = 0; i < arraysize(chars); i++) {
-    chars[i] = static_cast<char>(tag);
-    if ((chars[i] == 0 || chars[i] == '\xff') && i == arraysize(chars) - 1) {
-      chars[i] = ' ';
-    }
-    if (!isprint(static_cast<unsigned char>(chars[i]))) {
-      ascii = false;
-      break;
-    }
-    tag >>= 8;
-  }
-
-  if (ascii) {
-    return string(chars, sizeof(chars));
-  }
-
-  return base::UintToString(orig_tag);
-}
-
-// static
 QuicTagVector QuicUtils::ParseQuicConnectionOptions(
     const std::string& connection_options) {
   QuicTagVector options;
@@ -396,72 +190,6 @@ string QuicUtils::PeerAddressChangeTypeToString(PeerAddressChangeType type) {
 }
 
 // static
-void QuicUtils::DeleteFrames(QuicFrames* frames) {
-  for (QuicFrame& frame : *frames) {
-    switch (frame.type) {
-      // Frames smaller than a pointer are inlined, so don't need to be deleted.
-      case PADDING_FRAME:
-      case MTU_DISCOVERY_FRAME:
-      case PING_FRAME:
-        break;
-      case STREAM_FRAME:
-        delete frame.stream_frame;
-        break;
-      case ACK_FRAME:
-        delete frame.ack_frame;
-        break;
-      case STOP_WAITING_FRAME:
-        delete frame.stop_waiting_frame;
-        break;
-      case RST_STREAM_FRAME:
-        delete frame.rst_stream_frame;
-        break;
-      case CONNECTION_CLOSE_FRAME:
-        delete frame.connection_close_frame;
-        break;
-      case GOAWAY_FRAME:
-        delete frame.goaway_frame;
-        break;
-      case BLOCKED_FRAME:
-        delete frame.blocked_frame;
-        break;
-      case WINDOW_UPDATE_FRAME:
-        delete frame.window_update_frame;
-        break;
-      case PATH_CLOSE_FRAME:
-        delete frame.path_close_frame;
-        break;
-      case NUM_FRAME_TYPES:
-        DCHECK(false) << "Cannot delete type: " << frame.type;
-    }
-  }
-  frames->clear();
-}
-
-// static
-void QuicUtils::RemoveFramesForStream(QuicFrames* frames,
-                                      QuicStreamId stream_id) {
-  QuicFrames::iterator it = frames->begin();
-  while (it != frames->end()) {
-    if (it->type != STREAM_FRAME || it->stream_frame->stream_id != stream_id) {
-      ++it;
-      continue;
-    }
-    delete it->stream_frame;
-    it = frames->erase(it);
-  }
-}
-
-// static
-void QuicUtils::ClearSerializedPacket(SerializedPacket* serialized_packet) {
-  if (!serialized_packet->retransmittable_frames.empty()) {
-    DeleteFrames(&serialized_packet->retransmittable_frames);
-  }
-  serialized_packet->encrypted_buffer = nullptr;
-  serialized_packet->encrypted_length = 0;
-}
-
-// static
 uint64_t QuicUtils::PackPathIdAndPacketNumber(QuicPathId path_id,
                                               QuicPacketNumber packet_number) {
   // Setting the nonce below relies on QuicPathId and QuicPacketNumber being
@@ -477,27 +205,20 @@ uint64_t QuicUtils::PackPathIdAndPacketNumber(QuicPathId path_id,
 }
 
 // static
-char* QuicUtils::CopyBuffer(const SerializedPacket& packet) {
-  char* dst_buffer = new char[packet.encrypted_length];
-  memcpy(dst_buffer, packet.encrypted_buffer, packet.encrypted_length);
-  return dst_buffer;
-}
-
-// static
 PeerAddressChangeType QuicUtils::DetermineAddressChangeType(
-    const IPEndPoint& old_address,
-    const IPEndPoint& new_address) {
-  if (!IsInitializedIPEndPoint(old_address) ||
-      !IsInitializedIPEndPoint(new_address) || old_address == new_address) {
+    const QuicSocketAddress& old_address,
+    const QuicSocketAddress& new_address) {
+  if (!old_address.IsInitialized() || !new_address.IsInitialized() ||
+      old_address == new_address) {
     return NO_CHANGE;
   }
 
-  if (old_address.address() == new_address.address()) {
+  if (old_address.host() == new_address.host()) {
     return PORT_CHANGE;
   }
 
-  bool old_ip_is_ipv4 = old_address.address().IsIPv4();
-  bool migrating_ip_is_ipv4 = new_address.address().IsIPv4();
+  bool old_ip_is_ipv4 = old_address.host().IsIPv4() ? true : false;
+  bool migrating_ip_is_ipv4 = new_address.host().IsIPv4() ? true : false;
   if (old_ip_is_ipv4 && !migrating_ip_is_ipv4) {
     return IPV4_TO_IPV6_CHANGE;
   }
@@ -506,8 +227,8 @@ PeerAddressChangeType QuicUtils::DetermineAddressChangeType(
     return migrating_ip_is_ipv4 ? IPV6_TO_IPV4_CHANGE : IPV6_TO_IPV6_CHANGE;
   }
 
-  if (IPAddressMatchesPrefix(old_address.address(), new_address.address(),
-                             24)) {
+  const int kSubnetMaskLength = 24;
+  if (old_address.host().InSameSubnet(new_address.host(), kSubnetMaskLength)) {
     // Subnet part does not change (here, we use /24), which is considered to be
     // caused by NATs.
     return IPV4_SUBNET_CHANGE;
@@ -524,10 +245,6 @@ string QuicUtils::HexEncode(StringPiece data) {
   return ::base::HexEncode(data.data(), data.size());
 }
 
-string QuicUtils::HexDecode(const char* data, size_t length) {
-  return HexDecode(StringPiece(data, length));
-}
-
 string QuicUtils::HexDecode(StringPiece data) {
   if (data.empty())
     return "";
diff --git a/src/net/quic/core/quic_utils.h b/src/net/quic/core/quic_utils.h
index 66b338a..e90ca4d 100644
--- a/src/net/quic/core/quic_utils.h
+++ b/src/net/quic/core/quic_utils.h
@@ -1,8 +1,6 @@
 // Copyright (c) 2012 The Chromium Authors. All rights reserved.
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
-//
-// Some helpers for quic.
 
 #ifndef NET_QUIC_CORE_QUIC_UTILS_H_
 #define NET_QUIC_CORE_QUIC_UTILS_H_
@@ -16,7 +14,10 @@
 #include "base/strings/string_piece.h"
 #include "net/base/int128.h"
 #include "net/base/net_export.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_error_codes.h"
+#include "net/quic/core/quic_tag.h"
+#include "net/quic/core/quic_types.h"
+#include "net/quic/platform/api/quic_socket_address.h"
 
 #ifdef _MSC_VER
 // MSVC 2013 and prior don't have alignof or aligned(); they have __alignof and
@@ -32,11 +33,6 @@ namespace net {
 
 class NET_EXPORT_PRIVATE QuicUtils {
  public:
-  enum Priority {
-    LOCAL_PRIORITY,
-    PEER_PRIORITY,
-  };
-
   // Returns the 64 bit FNV1a hash of the data.  See
   // http://www.isthe.com/chongo/tech/comp/fnv/index.html#FNV-param
   static uint64_t FNV1a_64_Hash(const char* data, int len);
@@ -52,43 +48,16 @@ class NET_EXPORT_PRIVATE QuicUtils {
                                     const char* data2,
                                     int len2);
 
-  // FindMutualTag sets |out_result| to the first tag in the priority list that
-  // is also in the other list and returns true. If there is no intersection it
-  // returns false.
-  //
-  // Which list has priority is determined by |priority|.
-  //
-  // If |out_index| is non-nullptr and a match is found then the index of that
-  // match in |their_tags| is written to |out_index|.
-  static bool FindMutualTag(const QuicTagVector& our_tags,
-                            const QuicTag* their_tags,
-                            size_t num_their_tags,
-                            Priority priority,
-                            QuicTag* out_result,
-                            size_t* out_index);
-
   // SerializeUint128 writes the first 96 bits of |v| in little-endian form
   // to |out|.
   static void SerializeUint128Short(uint128 v, uint8_t* out);
 
-  // Returns the name of the QuicRstStreamErrorCode as a char*
-  static const char* StreamErrorToString(QuicRstStreamErrorCode error);
-
-  // Returns the name of the QuicErrorCode as a char*
-  static const char* ErrorToString(QuicErrorCode error);
-
   // Returns the level of encryption as a char*
   static const char* EncryptionLevelToString(EncryptionLevel level);
 
   // Returns TransmissionType as a char*
   static const char* TransmissionTypeToString(TransmissionType type);
 
-  // TagToString is a utility function for pretty-printing handshake messages
-  // that converts a tag to a string. It will try to maintain the human friendly
-  // name if possible (i.e. kABCD -> "ABCD"), or will just treat it as a number
-  // if not.
-  static std::string TagToString(QuicTag tag);
-
   // Returns the list of QUIC tags represented by the comma separated
   // string in |connection_options|.
   static QuicTagVector ParseQuicConnectionOptions(
@@ -97,43 +66,25 @@ class NET_EXPORT_PRIVATE QuicUtils {
   // Returns PeerAddressChangeType as a std::string.
   static std::string PeerAddressChangeTypeToString(PeerAddressChangeType type);
 
-  static char* AsChars(unsigned char* data) {
-    return reinterpret_cast<char*>(data);
-  }
-
-  // Deletes all the sub-frames contained in |frames|.
-  static void DeleteFrames(QuicFrames* frames);
-
-  // Deletes all the QuicStreamFrames for the specified |stream_id|.
-  static void RemoveFramesForStream(QuicFrames* frames, QuicStreamId stream_id);
-
-  // Deletes and clears all the frames and the packet from serialized packet.
-  static void ClearSerializedPacket(SerializedPacket* serialized_packet);
-
   // Returns a packed representation of |path_id| and |packet_number| in which
   // the highest byte is set to |path_id| and the lower 7 bytes are the lower
   // 7 bytes of |packet_number|.
   static uint64_t PackPathIdAndPacketNumber(QuicPathId path_id,
                                             QuicPacketNumber packet_number);
 
-  // Allocates a new char[] of size |packet.encrypted_length| and copies in
-  // |packet.encrypted_buffer|.
-  static char* CopyBuffer(const SerializedPacket& packet);
-
   // Determines and returns change type of address change from |old_address| to
   // |new_address|.
   static PeerAddressChangeType DetermineAddressChangeType(
-      const IPEndPoint& old_address,
-      const IPEndPoint& new_address);
+      const QuicSocketAddress& old_address,
+      const QuicSocketAddress& new_address);
 
-  // This converts 'num' bytes of binary to a 2*'num'-character hexadecimal
-  // representation. Return value: 2*'num' characters of ascii std::string.
+  // This converts |length| bytes of binary to a 2*|length|-character
+  // hexadecimal representation.
+  // Return value: 2*|length| characters of ASCII std::string.
   static std::string HexEncode(const char* data, size_t length);
   static std::string HexEncode(base::StringPiece data);
 
-  // This converts 2*'num' hexadecimal characters to 'num' binary data.
-  // Return value: 'num' bytes of binary data (via the 'to' argument).
-  static std::string HexDecode(const char* data, size_t length);
+  // Converts |data| from a hexadecimal ASCII std::string to binary.
   static std::string HexDecode(base::StringPiece data);
 
   // Returns a std::string containing hex and ASCII representations of |binary|,
@@ -146,15 +97,6 @@ class NET_EXPORT_PRIVATE QuicUtils {
   DISALLOW_COPY_AND_ASSIGN(QuicUtils);
 };
 
-// Utility function that returns an QuicIOVector object wrapped around |str|.
-// |str|'s data is stored in |iov|.
-inline QuicIOVector MakeIOVector(base::StringPiece str, struct iovec* iov) {
-  iov->iov_base = const_cast<char*>(str.data());
-  iov->iov_len = static_cast<size_t>(str.size());
-  QuicIOVector quic_iov(iov, 1, str.size());
-  return quic_iov;
-}
-
 }  // namespace net
 
 #endif  // NET_QUIC_CORE_QUIC_UTILS_H_
diff --git a/src/net/quic/core/quic_write_blocked_list.h b/src/net/quic/core/quic_write_blocked_list.h
index c7b6d44..7f3dd2d 100644
--- a/src/net/quic/core/quic_write_blocked_list.h
+++ b/src/net/quic/core/quic_write_blocked_list.h
@@ -13,7 +13,7 @@
 #include "base/macros.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/spdy/priority_write_scheduler.h"
 
 namespace net {
diff --git a/src/net/quic/core/reliable_quic_stream.cc b/src/net/quic/core/reliable_quic_stream.cc
deleted file mode 100644
index 740f161..0000000
--- a/src/net/quic/core/reliable_quic_stream.cc
+++ /dev/null
@@ -1,473 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-#include "net/quic/core/reliable_quic_stream.h"
-
-#include "base/logging.h"
-#include "net/quic/core/iovector.h"
-#include "net/quic/core/quic_bug_tracker.h"
-#include "net/quic/core/quic_flags.h"
-#include "net/quic/core/quic_flow_controller.h"
-#include "net/quic/core/quic_session.h"
-#include "net/quic/core/quic_write_blocked_list.h"
-
-using base::StringPiece;
-using std::min;
-using std::string;
-
-namespace net {
-
-#define ENDPOINT \
-  (perspective_ == Perspective::IS_SERVER ? "Server: " : "Client: ")
-
-namespace {
-
-struct iovec MakeIovec(StringPiece data) {
-  struct iovec iov = {const_cast<char*>(data.data()),
-                      static_cast<size_t>(data.size())};
-  return iov;
-}
-
-size_t GetInitialStreamFlowControlWindowToSend(QuicSession* session) {
-  return session->config()->GetInitialStreamFlowControlWindowToSend();
-}
-
-size_t GetReceivedFlowControlWindow(QuicSession* session) {
-  if (session->config()->HasReceivedInitialStreamFlowControlWindowBytes()) {
-    return session->config()->ReceivedInitialStreamFlowControlWindowBytes();
-  }
-
-  return kMinimumFlowControlSendWindow;
-}
-
-}  // namespace
-
-ReliableQuicStream::PendingData::PendingData(
-    string data_in,
-    QuicAckListenerInterface* ack_listener_in)
-    : data(std::move(data_in)), offset(0), ack_listener(ack_listener_in) {}
-
-ReliableQuicStream::PendingData::~PendingData() {}
-
-ReliableQuicStream::ReliableQuicStream(QuicStreamId id, QuicSession* session)
-    : queued_data_bytes_(0),
-      sequencer_(this, session->connection()->clock()),
-      id_(id),
-      session_(session),
-      stream_bytes_read_(0),
-      stream_bytes_written_(0),
-      stream_error_(QUIC_STREAM_NO_ERROR),
-      connection_error_(QUIC_NO_ERROR),
-      read_side_closed_(false),
-      write_side_closed_(false),
-      fin_buffered_(false),
-      fin_sent_(false),
-      fin_received_(false),
-      rst_sent_(false),
-      rst_received_(false),
-      perspective_(session_->perspective()),
-      flow_controller_(session_->connection(),
-                       id_,
-                       perspective_,
-                       GetReceivedFlowControlWindow(session),
-                       GetInitialStreamFlowControlWindowToSend(session),
-                       session_->flow_controller()->auto_tune_receive_window()),
-      connection_flow_controller_(session_->flow_controller()),
-      stream_contributes_to_connection_flow_control_(true) {
-  SetFromConfig();
-}
-
-ReliableQuicStream::~ReliableQuicStream() {}
-
-void ReliableQuicStream::SetFromConfig() {}
-
-void ReliableQuicStream::OnStreamFrame(const QuicStreamFrame& frame) {
-  DCHECK_EQ(frame.stream_id, id_);
-
-  DCHECK(!(read_side_closed_ && write_side_closed_));
-
-  if (frame.fin) {
-    fin_received_ = true;
-    if (fin_sent_) {
-      session_->StreamDraining(id_);
-    }
-  }
-
-  if (read_side_closed_) {
-    DVLOG(1) << ENDPOINT << "Ignoring data in frame " << frame.stream_id;
-    // The subclass does not want to read data:  blackhole the data.
-    return;
-  }
-
-  // This count includes duplicate data received.
-  size_t frame_payload_size = frame.data_length;
-  stream_bytes_read_ += frame_payload_size;
-
-  // Flow control is interested in tracking highest received offset.
-  // Only interested in received frames that carry data.
-  if (frame_payload_size > 0 &&
-      MaybeIncreaseHighestReceivedOffset(frame.offset + frame_payload_size)) {
-    // As the highest received offset has changed, check to see if this is a
-    // violation of flow control.
-    if (flow_controller_.FlowControlViolation() ||
-        connection_flow_controller_->FlowControlViolation()) {
-      CloseConnectionWithDetails(
-          QUIC_FLOW_CONTROL_RECEIVED_TOO_MUCH_DATA,
-          "Flow control violation after increasing offset");
-      return;
-    }
-  }
-
-  sequencer_.OnStreamFrame(frame);
-}
-
-int ReliableQuicStream::num_frames_received() const {
-  return sequencer_.num_frames_received();
-}
-
-int ReliableQuicStream::num_duplicate_frames_received() const {
-  return sequencer_.num_duplicate_frames_received();
-}
-
-void ReliableQuicStream::OnStreamReset(const QuicRstStreamFrame& frame) {
-  rst_received_ = true;
-  MaybeIncreaseHighestReceivedOffset(frame.byte_offset);
-
-  stream_error_ = frame.error_code;
-  CloseWriteSide();
-  CloseReadSide();
-}
-
-void ReliableQuicStream::OnConnectionClosed(QuicErrorCode error,
-                                            ConnectionCloseSource /*source*/) {
-  if (read_side_closed_ && write_side_closed_) {
-    return;
-  }
-  if (error != QUIC_NO_ERROR) {
-    stream_error_ = QUIC_STREAM_CONNECTION_ERROR;
-    connection_error_ = error;
-  }
-
-  CloseWriteSide();
-  CloseReadSide();
-}
-
-void ReliableQuicStream::OnFinRead() {
-  DCHECK(sequencer_.IsClosed());
-  // OnFinRead can be called due to a FIN flag in a headers block, so there may
-  // have been no OnStreamFrame call with a FIN in the frame.
-  fin_received_ = true;
-  // If fin_sent_ is true, then CloseWriteSide has already been called, and the
-  // stream will be destroyed by CloseReadSide, so don't need to call
-  // StreamDraining.
-  CloseReadSide();
-}
-
-void ReliableQuicStream::Reset(QuicRstStreamErrorCode error) {
-  stream_error_ = error;
-  // Sending a RstStream results in calling CloseStream.
-  session()->SendRstStream(id(), error, stream_bytes_written_);
-  rst_sent_ = true;
-}
-
-void ReliableQuicStream::CloseConnectionWithDetails(QuicErrorCode error,
-                                                    const string& details) {
-  session()->connection()->CloseConnection(
-      error, details, ConnectionCloseBehavior::SEND_CONNECTION_CLOSE_PACKET);
-}
-
-void ReliableQuicStream::WriteOrBufferData(
-    StringPiece data,
-    bool fin,
-    QuicAckListenerInterface* ack_listener) {
-  if (data.empty() && !fin) {
-    QUIC_BUG << "data.empty() && !fin";
-    return;
-  }
-
-  if (fin_buffered_) {
-    QUIC_BUG << "Fin already buffered";
-    return;
-  }
-  if (write_side_closed_) {
-    DLOG(ERROR) << ENDPOINT << "Attempt to write when the write side is closed";
-    return;
-  }
-
-  QuicConsumedData consumed_data(0, false);
-  fin_buffered_ = fin;
-
-  if (queued_data_.empty()) {
-    struct iovec iov(MakeIovec(data));
-    consumed_data = WritevData(&iov, 1, fin, ack_listener);
-    DCHECK_LE(consumed_data.bytes_consumed, data.length());
-  }
-
-  // If there's unconsumed data or an unconsumed fin, queue it.
-  if (consumed_data.bytes_consumed < data.length() ||
-      (fin && !consumed_data.fin_consumed)) {
-    StringPiece remainder(data.substr(consumed_data.bytes_consumed));
-    queued_data_bytes_ += remainder.size();
-    queued_data_.emplace_back(remainder.as_string(), ack_listener);
-  }
-}
-
-void ReliableQuicStream::OnCanWrite() {
-  bool fin = false;
-  while (!queued_data_.empty()) {
-    PendingData* pending_data = &queued_data_.front();
-    QuicAckListenerInterface* ack_listener = pending_data->ack_listener.get();
-    if (queued_data_.size() == 1 && fin_buffered_) {
-      fin = true;
-    }
-    if (pending_data->offset > 0 &&
-        pending_data->offset >= pending_data->data.size()) {
-      // This should be impossible because offset tracks the amount of
-      // pending_data written thus far.
-      QUIC_BUG << "Pending offset is beyond available data. offset: "
-               << pending_data->offset << " vs: " << pending_data->data.size();
-      return;
-    }
-    size_t remaining_len = pending_data->data.size() - pending_data->offset;
-    struct iovec iov = {
-        const_cast<char*>(pending_data->data.data()) + pending_data->offset,
-        remaining_len};
-    QuicConsumedData consumed_data = WritevData(&iov, 1, fin, ack_listener);
-    queued_data_bytes_ -= consumed_data.bytes_consumed;
-    if (consumed_data.bytes_consumed == remaining_len &&
-        fin == consumed_data.fin_consumed) {
-      queued_data_.pop_front();
-    } else {
-      if (consumed_data.bytes_consumed > 0) {
-        pending_data->offset += consumed_data.bytes_consumed;
-      }
-      break;
-    }
-  }
-}
-
-void ReliableQuicStream::MaybeSendBlocked() {
-  flow_controller_.MaybeSendBlocked();
-  if (!stream_contributes_to_connection_flow_control_) {
-    return;
-  }
-  connection_flow_controller_->MaybeSendBlocked();
-  // If the stream is blocked by connection-level flow control but not by
-  // stream-level flow control, add the stream to the write blocked list so that
-  // the stream will be given a chance to write when a connection-level
-  // WINDOW_UPDATE arrives.
-  if (connection_flow_controller_->IsBlocked() &&
-      !flow_controller_.IsBlocked()) {
-    session_->MarkConnectionLevelWriteBlocked(id());
-  }
-}
-
-QuicConsumedData ReliableQuicStream::WritevData(
-    const struct iovec* iov,
-    int iov_count,
-    bool fin,
-    QuicAckListenerInterface* ack_listener) {
-  if (write_side_closed_) {
-    DLOG(ERROR) << ENDPOINT << "Attempt to write when the write side is closed";
-    return QuicConsumedData(0, false);
-  }
-
-  // How much data was provided.
-  size_t write_length = TotalIovecLength(iov, iov_count);
-
-  // A FIN with zero data payload should not be flow control blocked.
-  bool fin_with_zero_data = (fin && write_length == 0);
-
-  // How much data flow control permits to be written.
-  QuicByteCount send_window = flow_controller_.SendWindowSize();
-  if (stream_contributes_to_connection_flow_control_) {
-    send_window =
-        min(send_window, connection_flow_controller_->SendWindowSize());
-  }
-
-  if (session_->ShouldYield(id())) {
-    session_->MarkConnectionLevelWriteBlocked(id());
-    return QuicConsumedData(0, false);
-  }
-
-  if (send_window == 0 && !fin_with_zero_data) {
-    // Quick return if nothing can be sent.
-    MaybeSendBlocked();
-    return QuicConsumedData(0, false);
-  }
-
-  if (write_length > send_window) {
-    // Don't send the FIN unless all the data will be sent.
-    fin = false;
-
-    // Writing more data would be a violation of flow control.
-    write_length = static_cast<size_t>(send_window);
-  }
-
-  QuicConsumedData consumed_data =
-      WritevDataInner(QuicIOVector(iov, iov_count, write_length),
-                      stream_bytes_written_, fin, ack_listener);
-  stream_bytes_written_ += consumed_data.bytes_consumed;
-
-  AddBytesSent(consumed_data.bytes_consumed);
-
-  // The write may have generated a write error causing this stream to be
-  // closed. If so, simply return without marking the stream write blocked.
-  if (write_side_closed_) {
-    return consumed_data;
-  }
-
-  if (consumed_data.bytes_consumed == write_length) {
-    if (!fin_with_zero_data) {
-      MaybeSendBlocked();
-    }
-    if (fin && consumed_data.fin_consumed) {
-      fin_sent_ = true;
-      if (fin_received_) {
-        session_->StreamDraining(id_);
-      }
-      CloseWriteSide();
-    } else if (fin && !consumed_data.fin_consumed) {
-      session_->MarkConnectionLevelWriteBlocked(id());
-    }
-  } else {
-    session_->MarkConnectionLevelWriteBlocked(id());
-  }
-  return consumed_data;
-}
-
-QuicConsumedData ReliableQuicStream::WritevDataInner(
-    QuicIOVector iov,
-    QuicStreamOffset offset,
-    bool fin,
-    QuicAckListenerInterface* ack_notifier_delegate) {
-  return session()->WritevData(this, id(), iov, offset, fin,
-                               ack_notifier_delegate);
-}
-
-void ReliableQuicStream::CloseReadSide() {
-  if (read_side_closed_) {
-    return;
-  }
-  DVLOG(1) << ENDPOINT << "Done reading from stream " << id();
-
-  read_side_closed_ = true;
-  sequencer_.ReleaseBuffer();
-
-  if (write_side_closed_) {
-    DVLOG(1) << ENDPOINT << "Closing stream: " << id();
-    session_->CloseStream(id());
-  }
-}
-
-void ReliableQuicStream::CloseWriteSide() {
-  if (write_side_closed_) {
-    return;
-  }
-  DVLOG(1) << ENDPOINT << "Done writing to stream " << id();
-
-  write_side_closed_ = true;
-  if (read_side_closed_) {
-    DVLOG(1) << ENDPOINT << "Closing stream: " << id();
-    session_->CloseStream(id());
-  }
-}
-
-bool ReliableQuicStream::HasBufferedData() const {
-  return !queued_data_.empty();
-}
-
-QuicVersion ReliableQuicStream::version() const {
-  return session_->connection()->version();
-}
-
-void ReliableQuicStream::StopReading() {
-  DVLOG(1) << ENDPOINT << "Stop reading from stream " << id();
-  sequencer_.StopReading();
-}
-
-const IPEndPoint& ReliableQuicStream::PeerAddressOfLatestPacket() const {
-  return session_->connection()->last_packet_source_address();
-}
-
-void ReliableQuicStream::OnClose() {
-  CloseReadSide();
-  CloseWriteSide();
-
-  if (!fin_sent_ && !rst_sent_) {
-    // For flow control accounting, tell the peer how many bytes have been
-    // written on this stream before termination. Done here if needed, using a
-    // RST_STREAM frame.
-    DVLOG(1) << ENDPOINT << "Sending RST_STREAM in OnClose: " << id();
-    session_->SendRstStream(id(), QUIC_RST_ACKNOWLEDGEMENT,
-                            stream_bytes_written_);
-    rst_sent_ = true;
-  }
-
-  // The stream is being closed and will not process any further incoming bytes.
-  // As there may be more bytes in flight, to ensure that both endpoints have
-  // the same connection level flow control state, mark all unreceived or
-  // buffered bytes as consumed.
-  QuicByteCount bytes_to_consume =
-      flow_controller_.highest_received_byte_offset() -
-      flow_controller_.bytes_consumed();
-  AddBytesConsumed(bytes_to_consume);
-}
-
-void ReliableQuicStream::OnWindowUpdateFrame(
-    const QuicWindowUpdateFrame& frame) {
-  if (flow_controller_.UpdateSendWindowOffset(frame.byte_offset)) {
-    // Writing can be done again!
-    // TODO(rjshade): This does not respect priorities (e.g. multiple
-    //                outstanding POSTs are unblocked on arrival of
-    //                SHLO with initial window).
-    // As long as the connection is not flow control blocked, write on!
-    OnCanWrite();
-  }
-}
-
-bool ReliableQuicStream::MaybeIncreaseHighestReceivedOffset(
-    QuicStreamOffset new_offset) {
-  uint64_t increment =
-      new_offset - flow_controller_.highest_received_byte_offset();
-  if (!flow_controller_.UpdateHighestReceivedOffset(new_offset)) {
-    return false;
-  }
-
-  // If |new_offset| increased the stream flow controller's highest received
-  // offset, increase the connection flow controller's value by the incremental
-  // difference.
-  if (stream_contributes_to_connection_flow_control_) {
-    connection_flow_controller_->UpdateHighestReceivedOffset(
-        connection_flow_controller_->highest_received_byte_offset() +
-        increment);
-  }
-  return true;
-}
-
-void ReliableQuicStream::AddBytesSent(QuicByteCount bytes) {
-  flow_controller_.AddBytesSent(bytes);
-  if (stream_contributes_to_connection_flow_control_) {
-    connection_flow_controller_->AddBytesSent(bytes);
-  }
-}
-
-void ReliableQuicStream::AddBytesConsumed(QuicByteCount bytes) {
-  // Only adjust stream level flow controller if still reading.
-  if (!read_side_closed_) {
-    flow_controller_.AddBytesConsumed(bytes);
-  }
-
-  if (stream_contributes_to_connection_flow_control_) {
-    connection_flow_controller_->AddBytesConsumed(bytes);
-  }
-}
-
-void ReliableQuicStream::UpdateSendWindowOffset(QuicStreamOffset new_window) {
-  if (flow_controller_.UpdateSendWindowOffset(new_window)) {
-    OnCanWrite();
-  }
-}
-
-}  // namespace net
diff --git a/src/net/quic/core/reliable_quic_stream.h b/src/net/quic/core/reliable_quic_stream.h
deleted file mode 100644
index 2122e86..0000000
--- a/src/net/quic/core/reliable_quic_stream.h
+++ /dev/null
@@ -1,311 +0,0 @@
-// Copyright (c) 2012 The Chromium Authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-//
-// The base class for client/server reliable streams.
-
-// It does not contain the entire interface needed by an application to interact
-// with a QUIC stream.  Some parts of the interface must be obtained by
-// accessing the owning session object.  A subclass of ReliableQuicStream
-// connects the object and the application that generates and consumes the data
-// of the stream.
-
-// The ReliableQuicStream object has a dependent QuicStreamSequencer object,
-// which is given the stream frames as they arrive, and provides stream data in
-// order by invoking ProcessRawData().
-
-#ifndef NET_QUIC_RELIABLE_QUIC_STREAM_H_
-#define NET_QUIC_RELIABLE_QUIC_STREAM_H_
-
-#include <stddef.h>
-#include <stdint.h>
-#include <sys/types.h>
-
-#include <list>
-#include <string>
-
-#include "base/macros.h"
-#include "base/memory/ref_counted.h"
-#include "base/strings/string_piece.h"
-#include "net/base/iovec.h"
-#include "net/base/net_export.h"
-#include "net/quic/core/quic_flow_controller.h"
-#include "net/quic/core/quic_protocol.h"
-#include "net/quic/core/quic_stream_sequencer.h"
-#include "net/quic/core/quic_types.h"
-
-namespace net {
-
-namespace test {
-class ReliableQuicStreamPeer;
-}  // namespace test
-
-class QuicSession;
-
-class NET_EXPORT_PRIVATE ReliableQuicStream {
- public:
-  ReliableQuicStream(QuicStreamId id, QuicSession* session);
-
-  virtual ~ReliableQuicStream();
-
-  // Not in use currently.
-  void SetFromConfig();
-
-  // Called by the session when a (potentially duplicate) stream frame has been
-  // received for this stream.
-  virtual void OnStreamFrame(const QuicStreamFrame& frame);
-
-  // Called by the session when the connection becomes writeable to allow the
-  // stream to write any pending data.
-  virtual void OnCanWrite();
-
-  // Called by the session just before the object is destroyed.
-  // The object should not be accessed after OnClose is called.
-  // Sends a RST_STREAM with code QUIC_RST_ACKNOWLEDGEMENT if neither a FIN nor
-  // a RST_STREAM has been sent.
-  virtual void OnClose();
-
-  // Called by the session when the endpoint receives a RST_STREAM from the
-  // peer.
-  virtual void OnStreamReset(const QuicRstStreamFrame& frame);
-
-  // Called by the session when the endpoint receives or sends a connection
-  // close, and should immediately close the stream.
-  virtual void OnConnectionClosed(QuicErrorCode error,
-                                  ConnectionCloseSource source);
-
-  // Called by the stream subclass after it has consumed the final incoming
-  // data.
-  void OnFinRead();
-
-  // Called when new data is available from the sequencer.  Subclasses must
-  // actively retrieve the data using the sequencer's Readv() or
-  // GetReadableRegions() method.
-  virtual void OnDataAvailable() = 0;
-
-  // Called by the subclass or the sequencer to reset the stream from this
-  // end.
-  virtual void Reset(QuicRstStreamErrorCode error);
-
-  // Called by the subclass or the sequencer to close the entire connection from
-  // this end.
-  virtual void CloseConnectionWithDetails(QuicErrorCode error,
-                                          const std::string& details);
-
-  QuicStreamId id() const { return id_; }
-
-  QuicRstStreamErrorCode stream_error() const { return stream_error_; }
-  QuicErrorCode connection_error() const { return connection_error_; }
-
-  bool reading_stopped() const {
-    return sequencer_.ignore_read_data() || read_side_closed_;
-  }
-  bool write_side_closed() const { return write_side_closed_; }
-
-  bool rst_received() { return rst_received_; }
-  bool rst_sent() { return rst_sent_; }
-  bool fin_received() { return fin_received_; }
-  bool fin_sent() { return fin_sent_; }
-
-  uint64_t queued_data_bytes() const { return queued_data_bytes_; }
-
-  uint64_t stream_bytes_read() const { return stream_bytes_read_; }
-  uint64_t stream_bytes_written() const { return stream_bytes_written_; }
-
-  void set_fin_sent(bool fin_sent) { fin_sent_ = fin_sent; }
-  void set_fin_received(bool fin_received) { fin_received_ = fin_received; }
-  void set_rst_sent(bool rst_sent) { rst_sent_ = rst_sent; }
-
-  void set_rst_received(bool rst_received) { rst_received_ = rst_received; }
-  void set_stream_error(QuicRstStreamErrorCode error) { stream_error_ = error; }
-
-  // Adjust the flow control window according to new offset in |frame|.
-  virtual void OnWindowUpdateFrame(const QuicWindowUpdateFrame& frame);
-
-  // Used in Chrome.
-  int num_frames_received() const;
-  int num_duplicate_frames_received() const;
-
-  QuicFlowController* flow_controller() { return &flow_controller_; }
-
-  // Called when endpoint receives a frame which could increase the highest
-  // offset.
-  // Returns true if the highest offset did increase.
-  bool MaybeIncreaseHighestReceivedOffset(QuicStreamOffset new_offset);
-  // Called when bytes are sent to the peer.
-  void AddBytesSent(QuicByteCount bytes);
-  // Called by the stream sequencer as bytes are consumed from the buffer.
-  // If the receive window has dropped below the threshold, then send a
-  // WINDOW_UPDATE frame.
-  void AddBytesConsumed(QuicByteCount bytes);
-
-  // Updates the flow controller's send window offset and calls OnCanWrite if
-  // it was blocked before.
-  void UpdateSendWindowOffset(QuicStreamOffset new_offset);
-
-  // Returns true if the stream has received either a RST_STREAM or a FIN -
-  // either of which gives a definitive number of bytes which the peer has
-  // sent. If this is not true on deletion of the stream object, the session
-  // must keep track of the stream's byte offset until a definitive final value
-  // arrives.
-  bool HasFinalReceivedByteOffset() const {
-    return fin_received_ || rst_received_;
-  }
-
-  // Returns true if the stream has queued data waiting to write.
-  bool HasBufferedData() const;
-
-  // Returns the version of QUIC being used for this stream.
-  QuicVersion version() const;
-
-  bool fin_received() const { return fin_received_; }
-
-  // Sets the sequencer to consume all incoming data itself and not call
-  // OnDataAvailable().
-  // When the FIN is received, the stream will be notified automatically (via
-  // OnFinRead()) (which may happen during the call of StopReading()).
-  // TODO(dworley): There should be machinery to send a RST_STREAM/NO_ERROR and
-  // stop sending stream-level flow-control updates when this end sends FIN.
-  virtual void StopReading();
-
-  // Get peer IP of the lastest packet which connection is dealing/delt with.
-  virtual const IPEndPoint& PeerAddressOfLatestPacket() const;
-
- protected:
-  // Sends as much of 'data' to the connection as the connection will consume,
-  // and then buffers any remaining data in queued_data_.
-  // If fin is true: if it is immediately passed on to the session,
-  // write_side_closed() becomes true, otherwise fin_buffered_ becomes true.
-  void WriteOrBufferData(base::StringPiece data,
-                         bool fin,
-                         QuicAckListenerInterface* ack_listener);
-
-  // Sends as many bytes in the first |count| buffers of |iov| to the connection
-  // as the connection will consume.
-  // If |ack_listener| is provided, then it will be notified once all
-  // the ACKs for this write have been received.
-  // Returns the number of bytes consumed by the connection.
-  QuicConsumedData WritevData(const struct iovec* iov,
-                              int iov_count,
-                              bool fin,
-                              QuicAckListenerInterface* ack_listener);
-
-  // Allows override of the session level writev, for the force HOL
-  // blocking experiment.
-  virtual QuicConsumedData WritevDataInner(
-      QuicIOVector iov,
-      QuicStreamOffset offset,
-      bool fin,
-      QuicAckListenerInterface* ack_notifier_delegate);
-
-  // Close the write side of the socket.  Further writes will fail.
-  // Can be called by the subclass or internally.
-  // Does not send a FIN.  May cause the stream to be closed.
-  virtual void CloseWriteSide();
-
-  bool fin_buffered() const { return fin_buffered_; }
-
-  const QuicSession* session() const { return session_; }
-  QuicSession* session() { return session_; }
-
-  const QuicStreamSequencer* sequencer() const { return &sequencer_; }
-  QuicStreamSequencer* sequencer() { return &sequencer_; }
-
-  void DisableConnectionFlowControlForThisStream() {
-    stream_contributes_to_connection_flow_control_ = false;
-  }
-
- private:
-  friend class test::ReliableQuicStreamPeer;
-  friend class QuicStreamUtils;
-
-  // Close the read side of the socket.  May cause the stream to be closed.
-  // Subclasses and consumers should use StopReading to terminate reading early.
-  void CloseReadSide();
-
-  // Subclasses and consumers should use reading_stopped.
-  bool read_side_closed() const { return read_side_closed_; }
-
-  struct PendingData {
-    PendingData(std::string data_in, QuicAckListenerInterface* ack_listener_in);
-    ~PendingData();
-
-    // Pending data to be written.
-    std::string data;
-    // Index of the first byte in data still to be written.
-    size_t offset;
-    // AckListener that should be notified when the pending data is acked.
-    // Can be nullptr.
-    scoped_refptr<QuicAckListenerInterface> ack_listener;
-  };
-
-  // Calls MaybeSendBlocked on the stream's flow controller and the connection
-  // level flow controller.  If the stream is flow control blocked by the
-  // connection-level flow controller but not by the stream-level flow
-  // controller, marks this stream as connection-level write blocked.
-  void MaybeSendBlocked();
-
-  std::list<PendingData> queued_data_;
-  // How many bytes are queued?
-  uint64_t queued_data_bytes_;
-
-  QuicStreamSequencer sequencer_;
-  QuicStreamId id_;
-  // Pointer to the owning QuicSession object.
-  QuicSession* session_;
-  // Bytes read and written refer to payload bytes only: they do not include
-  // framing, encryption overhead etc.
-  uint64_t stream_bytes_read_;
-  uint64_t stream_bytes_written_;
-
-  // Stream error code received from a RstStreamFrame or error code sent by the
-  // visitor or sequencer in the RstStreamFrame.
-  QuicRstStreamErrorCode stream_error_;
-  // Connection error code due to which the stream was closed. |stream_error_|
-  // is set to |QUIC_STREAM_CONNECTION_ERROR| when this happens and consumers
-  // should check |connection_error_|.
-  QuicErrorCode connection_error_;
-
-  // True if the read side is closed and further frames should be rejected.
-  bool read_side_closed_;
-  // True if the write side is closed, and further writes should fail.
-  bool write_side_closed_;
-
-  // True if the subclass has written a FIN with WriteOrBufferData, but it was
-  // buffered in queued_data_ rather than being sent to the session.
-  bool fin_buffered_;
-  // True if a FIN has been sent to the session.
-  bool fin_sent_;
-
-  // True if this stream has received (and the sequencer has accepted) a
-  // StreamFrame with the FIN set.
-  bool fin_received_;
-
-  // True if an RST_STREAM has been sent to the session.
-  // In combination with fin_sent_, used to ensure that a FIN and/or a
-  // RST_STREAM is always sent to terminate the stream.
-  bool rst_sent_;
-
-  // True if this stream has received a RST_STREAM frame.
-  bool rst_received_;
-
-  // Tracks if the session this stream is running under was created by a
-  // server or a client.
-  Perspective perspective_;
-
-  QuicFlowController flow_controller_;
-
-  // The connection level flow controller. Not owned.
-  QuicFlowController* connection_flow_controller_;
-
-  // Special streams, such as the crypto and headers streams, do not respect
-  // connection level flow control limits (but are stream level flow control
-  // limited).
-  bool stream_contributes_to_connection_flow_control_;
-
-  DISALLOW_COPY_AND_ASSIGN(ReliableQuicStream);
-};
-
-}  // namespace net
-
-#endif  // NET_QUIC_RELIABLE_QUIC_STREAM_H_
diff --git a/src/net/quic/core/spdy_utils.cc b/src/net/quic/core/spdy_utils.cc
index 9ed8642..366bb88 100644
--- a/src/net/quic/core/spdy_utils.cc
+++ b/src/net/quic/core/spdy_utils.cc
@@ -19,18 +19,16 @@
 #include "url/gurl.h"
 
 using base::StringPiece;
+using base::ContainsKey;
 using std::string;
-using std::vector;
 
 namespace net {
 
 // static
 string SpdyUtils::SerializeUncompressedHeaders(const SpdyHeaderBlock& headers) {
-  SpdyMajorVersion spdy_version = HTTP2;
-
-  size_t length = SpdyFramer::GetSerializedLength(spdy_version, &headers);
-  SpdyFrameBuilder builder(length, spdy_version);
-  SpdyFramer framer(spdy_version);
+  size_t length = SpdyFramer::GetSerializedLength(&headers);
+  SpdyFrameBuilder builder(length);
+  SpdyFramer framer;
   framer.SerializeHeaderBlockWithoutCompression(&builder, headers);
   SpdySerializedFrame block(builder.take());
   return string(block.data(), length);
@@ -41,21 +39,35 @@ bool SpdyUtils::ParseHeaders(const char* data,
                              uint32_t data_len,
                              int64_t* content_length,
                              SpdyHeaderBlock* headers) {
-  SpdyFramer framer(HTTP2);
+  SpdyFramer framer;
   if (!framer.ParseHeaderBlockInBuffer(data, data_len, headers) ||
       headers->empty()) {
     return false;  // Headers were invalid.
   }
 
-  if (base::ContainsKey(*headers, "content-length")) {
+  if (!ContainsKey(*headers, "content-length")) {
+    return true;
+  }
+
+  return ExtractContentLengthFromHeaders(content_length, headers);
+}
+
+// static
+bool SpdyUtils::ExtractContentLengthFromHeaders(int64_t* content_length,
+                                                SpdyHeaderBlock* headers) {
+  auto it = headers->find("content-length");
+  if (it == headers->end()) {
+    return false;
+  } else {
     // Check whether multiple values are consistent.
-    base::StringPiece content_length_header = (*headers)["content-length"];
-    vector<string> values =
+    StringPiece content_length_header = it->second;
+    std::vector<string> values =
         base::SplitString(content_length_header, base::StringPiece("\0", 1),
                           base::TRIM_WHITESPACE, base::SPLIT_WANT_ALL);
     for (const string& value : values) {
       int64_t new_value;
       if (!base::StringToInt64(value, &new_value) || new_value < 0) {
+        DLOG(ERROR) << "Content length was either unparseable or negative.";
         return false;
       }
       if (*content_length < 0) {
@@ -63,12 +75,14 @@ bool SpdyUtils::ParseHeaders(const char* data,
         continue;
       }
       if (new_value != *content_length) {
+        DLOG(ERROR) << "Parsed content length " << new_value << " is "
+                    << "inconsistent with previously detected content length "
+                    << *content_length;
         return false;
       }
     }
+    return true;
   }
-
-  return true;
 }
 
 // static
@@ -76,7 +90,7 @@ bool SpdyUtils::ParseTrailers(const char* data,
                               uint32_t data_len,
                               size_t* final_byte_offset,
                               SpdyHeaderBlock* trailers) {
-  SpdyFramer framer(HTTP2);
+  SpdyFramer framer;
   if (!framer.ParseHeaderBlockInBuffer(data, data_len, trailers) ||
       trailers->empty()) {
     DVLOG(1) << "Request Trailers are invalid.";
@@ -98,7 +112,7 @@ bool SpdyUtils::ParseTrailers(const char* data,
   for (const auto& trailer : *trailers) {
     base::StringPiece key = trailer.first;
     base::StringPiece value = trailer.second;
-    if (key.starts_with(":")) {
+    if (base::StartsWith(key, ":", base::CompareCase::INSENSITIVE_ASCII)) {
       DVLOG(1) << "Trailers must not contain pseudo-header: '" << key << "','"
                << value << "'.";
       return false;
@@ -127,51 +141,12 @@ bool SpdyUtils::CopyAndValidateHeaders(const QuicHeaderList& header_list,
       return false;
     }
 
-    if (FLAGS_chromium_http2_flag_use_new_spdy_header_block_header_joining) {
-      headers->AppendValueOrAddHeader(name, p.second);
-    } else {
-      auto iter = headers->find(name);
-      if (iter == headers->end()) {
-        (*headers)[name] = p.second;
-      } else {
-        // This header had multiple values, so it must be reconstructed.
-        StringPiece v = iter->second;
-        string s(v.data(), v.length());
-        if (name == "cookie") {
-          // Obeys section 8.1.2.5 in RFC 7540 for cookie reconstruction.
-          s.append("; ");
-        } else {
-          StringPiece("\0", 1).AppendToString(&s);
-        }
-        s.append(p.second);
-        headers->ReplaceOrAppendHeader(name, s);
-      }
-    }
+    headers->AppendValueOrAddHeader(name, p.second);
   }
 
-  if (base::ContainsKey(*headers, "content-length")) {
-    // Check whether multiple values are consistent.
-    StringPiece content_length_header = (*headers)["content-length"];
-    vector<string> values =
-        base::SplitString(content_length_header, base::StringPiece("\0", 1),
-                          base::TRIM_WHITESPACE, base::SPLIT_WANT_ALL);
-    for (const string& value : values) {
-      int64_t new_value;
-      if (!base::StringToInt64(value, &new_value) || new_value < 0) {
-        DLOG(ERROR) << "Content length was either unparseable or negative.";
-        return false;
-      }
-      if (*content_length < 0) {
-        *content_length = new_value;
-        continue;
-      }
-      if (new_value != *content_length) {
-        DLOG(ERROR) << "Parsed content length " << new_value << " is "
-                    << "inconsistent with previously detected content length "
-                    << *content_length;
-        return false;
-      }
-    }
+  if (ContainsKey(*headers, "content-length") &&
+      !ExtractContentLengthFromHeaders(content_length, headers)) {
+    return false;
   }
 
   DVLOG(1) << "Successfully parsed headers: " << headers->DebugString();
@@ -261,4 +236,25 @@ bool SpdyUtils::UrlIsValid(const SpdyHeaderBlock& headers) {
   return url != "" && GURL(url).is_valid();
 }
 
+// static
+bool SpdyUtils::PopulateHeaderBlockFromUrl(const string url,
+                                           SpdyHeaderBlock* headers) {
+  (*headers)[":method"] = "GET";
+  size_t pos = url.find("://");
+  if (pos == string::npos) {
+    return false;
+  }
+  (*headers)[":scheme"] = url.substr(0, pos);
+  size_t start = pos + 3;
+  pos = url.find("/", start);
+  if (pos == string::npos) {
+    (*headers)[":authority"] = url.substr(start);
+    (*headers)[":path"] = "/";
+    return true;
+  }
+  (*headers)[":authority"] = url.substr(start, pos - start);
+  (*headers)[":path"] = url.substr(pos);
+  return true;
+}
+
 }  // namespace net
diff --git a/src/net/quic/core/spdy_utils.h b/src/net/quic/core/spdy_utils.h
index 36ca93f..0383332 100644
--- a/src/net/quic/core/spdy_utils.h
+++ b/src/net/quic/core/spdy_utils.h
@@ -14,7 +14,7 @@
 #include "base/macros.h"
 #include "net/base/net_export.h"
 #include "net/quic/core/quic_header_list.h"
-#include "net/quic/core/quic_protocol.h"
+#include "net/quic/core/quic_packets.h"
 #include "net/spdy/spdy_framer.h"
 
 namespace net {
@@ -34,6 +34,12 @@ class NET_EXPORT_PRIVATE SpdyUtils {
                            int64_t* content_length,
                            SpdyHeaderBlock* headers);
 
+  // Populate |content length| with the value of the content-length header.
+  // Returns true on success, false if parsing fails or content-length header is
+  // missing.
+  static bool ExtractContentLengthFromHeaders(int64_t* content_length,
+                                              SpdyHeaderBlock* headers);
+
   // Parses |data| as a std::string containing serialized HTTP/2 HEADERS frame,
   // populating |trailers| with the key->value std:pairs found.
   // The final offset header will be excluded from |trailers|, and instead the
@@ -67,6 +73,11 @@ class NET_EXPORT_PRIVATE SpdyUtils {
   // and is a well-formed URL.
   static bool UrlIsValid(const net::SpdyHeaderBlock& headers);
 
+  // Populates the fields of |headers| to make a GET request of |url|,
+  // which must be fully-qualified.
+  static bool PopulateHeaderBlockFromUrl(const std::string url,
+                                         SpdyHeaderBlock* headers);
+
  private:
   DISALLOW_COPY_AND_ASSIGN(SpdyUtils);
 };
diff --git a/src/net/spdy/hpack/hpack_constants.cc b/src/net/spdy/hpack/hpack_constants.cc
index b9db0ef..1a2a267 100644
--- a/src/net/spdy/hpack/hpack_constants.cc
+++ b/src/net/spdy/hpack/hpack_constants.cc
@@ -25,7 +25,7 @@ struct SharedHpackHuffmanTable {
     std::unique_ptr<HpackHuffmanTable> mutable_table(new HpackHuffmanTable());
     CHECK(mutable_table->Initialize(&code[0], code.size()));
     CHECK(mutable_table->IsInitialized());
-    table.reset(mutable_table.release());
+    table = std::move(mutable_table);
   }
 
   static SharedHpackHuffmanTable* GetInstance() {
@@ -44,7 +44,7 @@ struct SharedHpackStaticTable {
     std::unique_ptr<HpackStaticTable> mutable_table(new HpackStaticTable());
     mutable_table->Initialize(&static_table[0], static_table.size());
     CHECK(mutable_table->IsInitialized());
-    table.reset(mutable_table.release());
+    table = std::move(mutable_table);
   }
 
   static SharedHpackStaticTable* GetInstance() {
diff --git a/src/net/spdy/hpack/hpack_decoder.cc b/src/net/spdy/hpack/hpack_decoder.cc
index 075176a..575a5c1 100644
--- a/src/net/spdy/hpack/hpack_decoder.cc
+++ b/src/net/spdy/hpack/hpack_decoder.cc
@@ -83,11 +83,17 @@ bool HpackDecoder::HandleControlFrameHeadersComplete(size_t* compressed_len) {
   // Data in headers_block_buffer_ should have been parsed by
   // HandleControlFrameHeadersData and removed.
   if (headers_block_buffer_.size() > 0) {
+    DVLOG(1) << "headers_block_buffer_.size() should be zero, but is "
+             << headers_block_buffer_.size();
     return false;
   }
 
   if (handler_ != nullptr) {
-    handler_->OnHeaderBlockEnd(total_header_bytes_);
+    if (FLAGS_chromium_http2_flag_log_compressed_size) {
+      handler_->OnHeaderBlockEnd(total_header_bytes_, total_parsed_bytes_);
+    } else {
+      handler_->OnHeaderBlockEnd(total_header_bytes_);
+    }
   }
   headers_block_buffer_.clear();
   total_parsed_bytes_ = 0;
@@ -116,21 +122,7 @@ bool HpackDecoder::HandleHeaderRepresentation(StringPiece name,
   total_header_bytes_ += name.size() + value.size();
 
   if (handler_ == nullptr) {
-    if (FLAGS_chromium_http2_flag_use_new_spdy_header_block_header_joining) {
-      decoded_block_.AppendValueOrAddHeader(name, value);
-    } else {
-      auto it = decoded_block_.find(name);
-      if (it == decoded_block_.end()) {
-        // This is a new key.
-        decoded_block_[name] = value;
-      } else {
-        // The key already exists, append |value| with appropriate delimiter.
-        string new_value = it->second.as_string();
-        new_value.append((name == "cookie") ? "; " : string(1, '\0'));
-        value.AppendToString(&new_value);
-        decoded_block_.ReplaceOrAppendHeader(name, new_value);
-      }
-    }
+    decoded_block_.AppendValueOrAddHeader(name, value);
   } else {
     DCHECK(decoded_block_.empty());
     handler_->OnHeader(name, value);
@@ -241,6 +233,7 @@ bool HpackDecoder::DecodeNextName(HpackInputStream* input_stream,
                                   StringPiece* next_name) {
   uint32_t index_or_zero = 0;
   if (!input_stream->DecodeNextUint32(&index_or_zero)) {
+    DVLOG(1) << "Failed to decode the next uint.";
     return false;
   }
 
@@ -271,11 +264,13 @@ bool HpackDecoder::DecodeNextStringLiteral(HpackInputStream* input_stream,
     bool result = input_stream->DecodeNextHuffmanString(buffer);
     *output = StringPiece(*buffer);
     return result;
-  }
-  if (input_stream->MatchPrefixAndConsume(kStringLiteralIdentityEncoded)) {
+  } else if (input_stream->MatchPrefixAndConsume(
+                 kStringLiteralIdentityEncoded)) {
     return input_stream->DecodeNextIdentityString(output);
+  } else {
+    DVLOG(1) << "String literal is neither Huffman nor identity encoded!";
+    return false;
   }
-  return false;
 }
 
 }  // namespace net
diff --git a/src/net/spdy/hpack/hpack_decoder_interface.h b/src/net/spdy/hpack/hpack_decoder_interface.h
index e866853..8adb62f 100644
--- a/src/net/spdy/hpack/hpack_decoder_interface.h
+++ b/src/net/spdy/hpack/hpack_decoder_interface.h
@@ -44,7 +44,7 @@ class NET_EXPORT_PRIVATE HpackDecoderInterface {
   // Discards the handler supplied at the start of decoding the block.
   // TODO(jamessynge): Determine if compressed_len is needed; it is used to
   // produce UUMA stat Net.SpdyHpackDecompressionPercentage, but only for
-  // SPDY3, not HTTP2.
+  // deprecated SPDY3.
   virtual bool HandleControlFrameHeadersComplete(size_t* compressed_len) = 0;
 
   // Accessor for the most recently decoded headers block. Valid until the next
@@ -56,7 +56,7 @@ class NET_EXPORT_PRIVATE HpackDecoderInterface {
   virtual void SetHeaderTableDebugVisitor(
       std::unique_ptr<HpackHeaderTable::DebugVisitorInterface> visitor) = 0;
 
-  // How much encoded data this decoder is willing to buffer.
+  // Set how much encoded data this decoder is willing to buffer.
   virtual void set_max_decode_buffer_size_bytes(
       size_t max_decode_buffer_size_bytes) = 0;
 };
diff --git a/src/net/spdy/hpack/hpack_encoder.cc b/src/net/spdy/hpack/hpack_encoder.cc
index a9e52a9..7362bb1 100644
--- a/src/net/spdy/hpack/hpack_encoder.cc
+++ b/src/net/spdy/hpack/hpack_encoder.cc
@@ -8,6 +8,7 @@
 #include <limits>
 
 #include "base/logging.h"
+#include "base/memory/ptr_util.h"
 #include "net/spdy/hpack/hpack_constants.h"
 #include "net/spdy/hpack/hpack_header_table.h"
 #include "net/spdy/hpack/hpack_huffman_table.h"
@@ -56,6 +57,9 @@ class HpackEncoder::RepresentationIterator {
 
 namespace {
 
+// The default header listener.
+void NoOpListener(StringPiece /*name*/, StringPiece /*value*/) {}
+
 // The default HPACK indexing policy.
 bool DefaultPolicy(StringPiece name, StringPiece /* value */) {
   if (name.empty()) {
@@ -76,6 +80,7 @@ HpackEncoder::HpackEncoder(const HpackHuffmanTable& table)
     : output_stream_(),
       huffman_table_(table),
       min_table_size_setting_received_(std::numeric_limits<size_t>::max()),
+      listener_(NoOpListener),
       should_index_(DefaultPolicy),
       allow_huffman_compression_(true),
       should_emit_table_size_(false) {}
@@ -121,6 +126,7 @@ bool HpackEncoder::EncodeHeaderSetWithoutCompression(
   allow_huffman_compression_ = false;
   MaybeEmitTableSize();
   for (const auto& header : header_set) {
+    listener_(header.first, header.second);
     // Note that cookies are not crumbled in this case.
     EmitNonIndexedLiteral(header);
   }
@@ -146,6 +152,7 @@ void HpackEncoder::EncodeRepresentations(RepresentationIterator* iter,
   MaybeEmitTableSize();
   while (iter->HasNext()) {
     const auto header = iter->Next();
+    listener_(header.first, header.second);
     const HpackEntry* entry =
         header_table_.GetByNameAndValue(header.first, header.second);
     if (entry != nullptr) {
@@ -270,4 +277,101 @@ void HpackEncoder::DecomposeRepresentation(const Representation& header_field,
   }
 }
 
+// static
+void HpackEncoder::GatherRepresentation(const Representation& header_field,
+                                        Representations* out) {
+  out->push_back(std::make_pair(header_field.first, header_field.second));
+}
+
+// Iteratively encodes a SpdyHeaderBlock.
+class HpackEncoder::Encoderator : public ProgressiveEncoder {
+ public:
+  Encoderator(const SpdyHeaderBlock& header_set,
+              HpackEncoder* encoder,
+              bool use_compression);
+
+  // Encoderator is neither copyable nor movable.
+  Encoderator(const Encoderator&) = delete;
+  Encoderator& operator=(const Encoderator&) = delete;
+
+  // Returns true iff more remains to encode.
+  bool HasNext() const override { return has_next_; }
+
+  // Encodes up to max_encoded_bytes of the current header block into the
+  // given output string.
+  void Next(size_t max_encoded_bytes, string* output) override;
+
+ private:
+  HpackEncoder* encoder_;
+  std::unique_ptr<RepresentationIterator> header_it_;
+  Representations pseudo_headers_;
+  Representations regular_headers_;
+  bool has_next_;
+  bool use_compression_;
+};
+
+HpackEncoder::Encoderator::Encoderator(const SpdyHeaderBlock& header_set,
+                                       HpackEncoder* encoder,
+                                       bool use_compression)
+    : encoder_(encoder), has_next_(true), use_compression_(use_compression) {
+  // Separate header set into pseudo-headers and regular headers.
+  bool found_cookie = false;
+  for (const auto& header : header_set) {
+    if (!found_cookie && header.first == "cookie") {
+      // Note that there can only be one "cookie" header, because header_set
+      // is a map.
+      found_cookie = true;
+      use_compression_ ? CookieToCrumbs(header, &regular_headers_)
+                       : GatherRepresentation(header, &regular_headers_);
+    } else if (!header.first.empty() &&
+               header.first[0] == kPseudoHeaderPrefix) {
+      use_compression_ ? DecomposeRepresentation(header, &pseudo_headers_)
+                       : GatherRepresentation(header, &pseudo_headers_);
+    } else {
+      use_compression_ ? DecomposeRepresentation(header, &regular_headers_)
+                       : GatherRepresentation(header, &regular_headers_);
+    }
+  }
+  header_it_ = base::MakeUnique<RepresentationIterator>(pseudo_headers_,
+                                                        regular_headers_);
+
+  encoder_->MaybeEmitTableSize();
+}
+
+void HpackEncoder::Encoderator::Next(size_t max_encoded_bytes, string* output) {
+  SPDY_BUG_IF(!has_next_)
+      << "Encoderator::Next called with nothing left to encode.";
+
+  // Encode up to max_encoded_bytes of headers.
+  while (header_it_->HasNext() &&
+         encoder_->output_stream_.size() <= max_encoded_bytes) {
+    const Representation header = header_it_->Next();
+    encoder_->listener_(header.first, header.second);
+    if (use_compression_) {
+      const HpackEntry* entry = encoder_->header_table_.GetByNameAndValue(
+          header.first, header.second);
+      if (entry != nullptr) {
+        encoder_->EmitIndex(entry);
+      } else if (encoder_->should_index_(header.first, header.second)) {
+        encoder_->EmitIndexedLiteral(header);
+      } else {
+        encoder_->EmitNonIndexedLiteral(header);
+      }
+    } else {
+      encoder_->allow_huffman_compression_ = false;
+      encoder_->EmitNonIndexedLiteral(header);
+      encoder_->allow_huffman_compression_ = true;
+    }
+  }
+
+  has_next_ = encoder_->output_stream_.size() > max_encoded_bytes;
+  encoder_->output_stream_.BoundedTakeString(max_encoded_bytes, output);
+}
+
+std::unique_ptr<HpackEncoder::ProgressiveEncoder> HpackEncoder::EncodeHeaderSet(
+    const SpdyHeaderBlock& header_set,
+    bool use_compression) {
+  return base::MakeUnique<Encoderator>(header_set, this, use_compression);
+}
+
 }  // namespace net
diff --git a/src/net/spdy/hpack/hpack_encoder.h b/src/net/spdy/hpack/hpack_encoder.h
index 89f2dc1..b2778af 100644
--- a/src/net/spdy/hpack/hpack_encoder.h
+++ b/src/net/spdy/hpack/hpack_encoder.h
@@ -37,6 +37,11 @@ class NET_EXPORT_PRIVATE HpackEncoder {
   using Representation = std::pair<base::StringPiece, base::StringPiece>;
   using Representations = std::vector<Representation>;
 
+  // Callers may provide a HeaderListener to be informed of header name-value
+  // pairs processed by this encoder.
+  typedef std::function<void(base::StringPiece, base::StringPiece)>
+      HeaderListener;
+
   // An indexing policy should return true if the provided header name-value
   // pair should be inserted into the HPACK dynamic table.
   using IndexingPolicy =
@@ -61,6 +66,24 @@ class NET_EXPORT_PRIVATE HpackEncoder {
   bool EncodeHeaderSetWithoutCompression(const SpdyHeaderBlock& header_set,
                                          std::string* output);
 
+  class NET_EXPORT_PRIVATE ProgressiveEncoder {
+   public:
+    virtual ~ProgressiveEncoder() {}
+
+    // Returns true iff more remains to encode.
+    virtual bool HasNext() const = 0;
+
+    // Encodes up to max_encoded_bytes of the current header block into the
+    // given output string.
+    virtual void Next(size_t max_encoded_bytes, std::string* output) = 0;
+  };
+
+  // Returns a ProgressiveEncoder which must be outlived by both the given
+  // SpdyHeaderBlock and this object.
+  std::unique_ptr<ProgressiveEncoder> EncodeHeaderSet(
+      const SpdyHeaderBlock& header_set,
+      bool use_compression);
+
   // Called upon a change to SETTINGS_HEADER_TABLE_SIZE. Specifically, this
   // is to be called after receiving (and sending an acknowledgement for) a
   // SETTINGS_HEADER_TABLE_SIZE update from the remote decoding endpoint.
@@ -74,6 +97,10 @@ class NET_EXPORT_PRIVATE HpackEncoder {
   // name-value pairs into the dynamic table.
   void SetIndexingPolicy(IndexingPolicy policy) { should_index_ = policy; }
 
+  // |listener| will be invoked for each header name-value pair processed by
+  // this encoder.
+  void SetHeaderListener(HeaderListener listener) { listener_ = listener; }
+
   void SetHeaderTableDebugVisitor(
       std::unique_ptr<HpackHeaderTable::DebugVisitorInterface> visitor) {
     header_table_.set_debug_visitor(std::move(visitor));
@@ -83,6 +110,7 @@ class NET_EXPORT_PRIVATE HpackEncoder {
   friend class test::HpackEncoderPeer;
 
   class RepresentationIterator;
+  class Encoderator;
 
   // Encodes a sequence of header name-value pairs as a single header block.
   void EncodeRepresentations(RepresentationIterator* iter, std::string* output);
@@ -110,11 +138,16 @@ class NET_EXPORT_PRIVATE HpackEncoder {
   static void DecomposeRepresentation(const Representation& header_field,
                                       Representations* out);
 
+  // Gathers headers without crumbling. Used when compression is not enabled.
+  static void GatherRepresentation(const Representation& header_field,
+                                   Representations* out);
+
   HpackHeaderTable header_table_;
   HpackOutputStream output_stream_;
 
   const HpackHuffmanTable& huffman_table_;
   size_t min_table_size_setting_received_;
+  HeaderListener listener_;
   IndexingPolicy should_index_;
   bool allow_huffman_compression_;
   bool should_emit_table_size_;
diff --git a/src/net/spdy/hpack/hpack_header_table.cc b/src/net/spdy/hpack/hpack_header_table.cc
index 7043ae8..6599b66 100644
--- a/src/net/spdy/hpack/hpack_header_table.cc
+++ b/src/net/spdy/hpack/hpack_header_table.cc
@@ -9,6 +9,7 @@
 #include "base/logging.h"
 #include "net/spdy/hpack/hpack_constants.h"
 #include "net/spdy/hpack/hpack_static_table.h"
+#include "net/spdy/spdy_flags.h"
 
 namespace net {
 
@@ -125,7 +126,11 @@ void HpackHeaderTable::SetMaxSize(size_t max_size) {
 
 void HpackHeaderTable::SetSettingsHeaderTableSize(size_t settings_size) {
   settings_size_bound_ = settings_size;
-  if (settings_size_bound_ < max_size_) {
+  if (!FLAGS_chromium_reloadable_flag_increase_hpack_table_size) {
+    if (settings_size_bound_ < max_size_) {
+      SetMaxSize(settings_size_bound_);
+    }
+  } else {
     SetMaxSize(settings_size_bound_);
   }
 }
diff --git a/src/net/spdy/hpack/hpack_huffman_decoder.cc b/src/net/spdy/hpack/hpack_huffman_decoder.cc
index f305a66..dcb512c 100644
--- a/src/net/spdy/hpack/hpack_huffman_decoder.cc
+++ b/src/net/spdy/hpack/hpack_huffman_decoder.cc
@@ -158,7 +158,7 @@ const uint8_t kCanonicalToSymbol[] = {
 };
 // clang-format on
 
-#if !defined(NDEBUG) || defined(DCHECK_ALWAYS_ON)
+#if DCHECK_IS_ON()
 
 // Only used in DLOG.
 bool IsEOSPrefix(HuffmanWord bits, HuffmanCodeLength bits_available) {
@@ -171,7 +171,7 @@ bool IsEOSPrefix(HuffmanWord bits, HuffmanCodeLength bits_available) {
   return bits == expected;
 }
 
-#endif  // NDEBUG && !defined(DCHECK_ALWAYS_ON)
+#endif  // DCHECK_IS_ON()
 
 }  // namespace
 
diff --git a/src/net/spdy/hpack/hpack_output_stream.cc b/src/net/spdy/hpack/hpack_output_stream.cc
index 18aa4e6..6337d7d 100644
--- a/src/net/spdy/hpack/hpack_output_stream.cc
+++ b/src/net/spdy/hpack/hpack_output_stream.cc
@@ -4,6 +4,8 @@
 
 #include "net/spdy/hpack/hpack_output_stream.h"
 
+#include <utility>
+
 #include "base/logging.h"
 
 namespace net {
@@ -72,4 +74,22 @@ void HpackOutputStream::TakeString(string* output) {
   bit_offset_ = 0;
 }
 
+void HpackOutputStream::BoundedTakeString(size_t max_size, string* output) {
+  if (buffer_.size() > max_size) {
+    // Save off overflow bytes to temporary string (causes a copy).
+    string overflow(buffer_.data() + max_size, buffer_.size() - max_size);
+
+    // Resize buffer down to the given limit.
+    buffer_.resize(max_size);
+
+    // Give buffer to output string.
+    *output = std::move(buffer_);
+
+    // Reset to contain overflow.
+    buffer_ = std::move(overflow);
+  } else {
+    TakeString(output);
+  }
+}
+
 }  // namespace net
diff --git a/src/net/spdy/hpack/hpack_output_stream.h b/src/net/spdy/hpack/hpack_output_stream.h
index 0c5a013..4451a88 100644
--- a/src/net/spdy/hpack/hpack_output_stream.h
+++ b/src/net/spdy/hpack/hpack_output_stream.h
@@ -49,15 +49,22 @@ class NET_EXPORT_PRIVATE HpackOutputStream {
   // boundary after this function is called.
   void AppendUint32(uint32_t I);
 
-  // Swaps the interal buffer with |output|.
+  // Swaps the internal buffer with |output|, then resets state.
   void TakeString(std::string* output);
 
+  // Gives up to |max_size| bytes of the internal buffer to |output|. Resets
+  // internal state with the overflow.
+  void BoundedTakeString(size_t max_size, std::string* output);
+
+  // Size in bytes of stream's internal buffer.
+  size_t size() const { return buffer_.size(); }
+
  private:
   // The internal bit buffer.
   std::string buffer_;
 
   // If 0, the buffer ends on a byte boundary. If non-zero, the buffer
-  // ends on the most significant nth bit. Guaranteed to be < 8.
+  // ends on the nth most significant bit. Guaranteed to be < 8.
   size_t bit_offset_;
 
   DISALLOW_COPY_AND_ASSIGN(HpackOutputStream);
diff --git a/src/net/spdy/hpack/hpack_static_table.h b/src/net/spdy/hpack/hpack_static_table.h
index 42798bf..ad22097 100644
--- a/src/net/spdy/hpack/hpack_static_table.h
+++ b/src/net/spdy/hpack/hpack_static_table.h
@@ -7,6 +7,7 @@
 
 #include <stddef.h>
 
+#include "net/base/net_export.h"
 #include "net/spdy/hpack/hpack_header_table.h"
 
 namespace net {
diff --git a/src/net/spdy/spdy_alt_svc_wire_format.cc b/src/net/spdy/spdy_alt_svc_wire_format.cc
index 38c8fdd..df4e84d 100644
--- a/src/net/spdy/spdy_alt_svc_wire_format.cc
+++ b/src/net/spdy/spdy_alt_svc_wire_format.cc
@@ -9,6 +9,7 @@
 #include <string>
 
 #include "base/logging.h"
+#include "base/strings/string_util.h"
 #include "base/strings/stringprintf.h"
 
 namespace net {
@@ -22,7 +23,8 @@ bool ParsePositiveIntegerImpl(StringPiece::const_iterator c,
                               StringPiece::const_iterator end,
                               T* value) {
   *value = 0;
-  for (; c != end && isdigit(*c); ++c) {
+  // TODO(mmenke):  This really should be using methods in parse_number.h.
+  for (; c != end && '0' <= *c && *c <= '9'; ++c) {
     if (*value > std::numeric_limits<T>::max() / 10) {
       return false;
     }
@@ -277,22 +279,20 @@ bool SpdyAltSvcWireFormat::PercentDecode(StringPiece::const_iterator c,
     }
     DCHECK_EQ('%', *c);
     ++c;
-    if (c == end || !isxdigit(*c)) {
+    if (c == end || !base::IsHexDigit(*c)) {
       return false;
     }
-    char decoded = tolower(*c);
-    // '0' is 0, 'a' is 10.
-    decoded += isdigit(*c) ? (0 - '0') : (10 - 'a');
     // Network byte order is big-endian.
-    decoded <<= 4;
+    int decoded = base::HexDigitToInt(*c) << 4;
+
     ++c;
-    if (c == end || !isxdigit(*c)) {
+    if (c == end || !base::IsHexDigit(*c)) {
       return false;
     }
-    decoded += tolower(*c);
-    // '0' is 0, 'a' is 10.
-    decoded += isdigit(*c) ? (0 - '0') : (10 - 'a');
-    output->push_back(decoded);
+    // Network byte order is big-endian.
+    decoded += base::HexDigitToInt(*c);
+
+    output->push_back(static_cast<char>(decoded));
   }
   return true;
 }
@@ -303,20 +303,39 @@ bool SpdyAltSvcWireFormat::ParseAltAuthority(StringPiece::const_iterator c,
                                              std::string* host,
                                              uint16_t* port) {
   host->clear();
-  for (; c != end && *c != ':'; ++c) {
-    if (*c == '"') {
-      // Port is mandatory.
+  if (c == end) {
+    return false;
+  }
+  if (*c == '[') {
+    for (; c != end && *c != ']'; ++c) {
+      if (*c == '"') {
+        // Port is mandatory.
+        return false;
+      }
+      host->push_back(*c);
+    }
+    if (c == end) {
       return false;
     }
-    if (*c == '\\') {
-      ++c;
-      if (c == end) {
+    DCHECK_EQ(']', *c);
+    host->push_back(*c);
+    ++c;
+  } else {
+    for (; c != end && *c != ':'; ++c) {
+      if (*c == '"') {
+        // Port is mandatory.
         return false;
       }
+      if (*c == '\\') {
+        ++c;
+        if (c == end) {
+          return false;
+        }
+      }
+      host->push_back(*c);
     }
-    host->push_back(*c);
   }
-  if (c == end) {
+  if (c == end || *c != ':') {
     return false;
   }
   DCHECK_EQ(':', *c);
diff --git a/src/net/spdy/spdy_flags.cc b/src/net/spdy/spdy_flags.cc
index e9415bc..e8c495b 100644
--- a/src/net/spdy/spdy_flags.cc
+++ b/src/net/spdy/spdy_flags.cc
@@ -4,12 +4,19 @@
 
 #include "net/spdy/spdy_flags.h"
 
+namespace net {
+
+// Log compressed size of HTTP/2 requests.
+bool FLAGS_chromium_http2_flag_log_compressed_size = true;
+
+// Use //net/http2/hpack/decoder as HPACK decoder.
+bool FLAGS_chromium_http2_flag_spdy_use_hpack_decoder2 = false;
+
+// If true, increase HPACK table size up to optimal size kOptTableSize if
+// clients allow it.
+bool FLAGS_chromium_reloadable_flag_increase_hpack_table_size = false;
+
 // Use NestedSpdyFramerDecoder.
 bool FLAGS_use_nested_spdy_framer_decoder = false;
 
-// If true, SpdyFramer uses the new visitor methods OnHeaderFrameStart and
-// OnHeaderFrameEnd.  Fourth attempt.
-bool FLAGS_chromium_http2_flag_spdy_framer_use_new_methods4 = true;
-
-// Use SpdyHeaderBlock::AppendValueOrAddHeader when adding to headers.
-bool FLAGS_chromium_http2_flag_use_new_spdy_header_block_header_joining = true;
+}  // namespace net
diff --git a/src/net/spdy/spdy_flags.h b/src/net/spdy/spdy_flags.h
index f9b87f7..efd1f24 100644
--- a/src/net/spdy/spdy_flags.h
+++ b/src/net/spdy/spdy_flags.h
@@ -7,10 +7,15 @@
 
 #include "net/base/net_export.h"
 
-NET_EXPORT_PRIVATE extern bool FLAGS_use_nested_spdy_framer_decoder;
+namespace net {
+
+NET_EXPORT_PRIVATE extern bool FLAGS_chromium_http2_flag_log_compressed_size;
 NET_EXPORT_PRIVATE extern bool
-    FLAGS_chromium_http2_flag_spdy_framer_use_new_methods4;
+    FLAGS_chromium_http2_flag_spdy_use_hpack_decoder2;
 NET_EXPORT_PRIVATE extern bool
-    FLAGS_chromium_http2_flag_use_new_spdy_header_block_header_joining;
+    FLAGS_chromium_reloadable_flag_increase_hpack_table_size;
+NET_EXPORT_PRIVATE extern bool FLAGS_use_nested_spdy_framer_decoder;
+
+}  // namespace net
 
 #endif  // NET_SPDY_SPDY_FLAGS_H_
diff --git a/src/net/spdy/spdy_frame_builder.cc b/src/net/spdy/spdy_frame_builder.cc
index d6918b7..9996257 100644
--- a/src/net/spdy/spdy_frame_builder.cc
+++ b/src/net/spdy/spdy_frame_builder.cc
@@ -13,33 +13,8 @@
 
 namespace net {
 
-namespace {
-
-// A special structure for the 8 bit flags and 24 bit length fields.
-union FlagsAndLength {
-  uint8_t flags[4];  // 8 bits
-  uint32_t length;   // 24 bits
-};
-
-// Creates a FlagsAndLength.
-FlagsAndLength CreateFlagsAndLength(uint8_t flags, size_t length) {
-  DCHECK_EQ(0u, length & ~static_cast<size_t>(kLengthMask));
-  FlagsAndLength flags_length;
-  flags_length.length = base::HostToNet32(static_cast<uint32_t>(length));
-  DCHECK_EQ(0, flags & ~kControlFlagsMask);
-  flags_length.flags[0] = flags;
-  return flags_length;
-}
-
-}  // namespace
-
-SpdyFrameBuilder::SpdyFrameBuilder(size_t size, SpdyMajorVersion version)
-    : buffer_(new char[size]),
-      capacity_(size),
-      length_(0),
-      offset_(0),
-      version_(version) {
-}
+SpdyFrameBuilder::SpdyFrameBuilder(size_t size)
+    : buffer_(new char[size]), capacity_(size), length_(0), offset_(0) {}
 
 SpdyFrameBuilder::~SpdyFrameBuilder() {
 }
@@ -60,54 +35,15 @@ bool SpdyFrameBuilder::Seek(size_t length) {
   return true;
 }
 
-bool SpdyFrameBuilder::WriteControlFrameHeader(const SpdyFramer& framer,
-                                               SpdyFrameType type,
-                                               uint8_t flags) {
-  DCHECK_EQ(SPDY3, version_);
-  DCHECK(SpdyConstants::IsValidFrameType(
-      version_, SpdyConstants::SerializeFrameType(version_, type)));
-  bool success = true;
-  FlagsAndLength flags_length =
-      CreateFlagsAndLength(flags, capacity_ - framer.GetFrameHeaderSize());
-  success &= WriteUInt16(kControlFlagMask | kSpdy3Version);
-  success &= WriteUInt16(
-      SpdyConstants::SerializeFrameType(framer.protocol_version(), type));
-  success &= WriteBytes(&flags_length, sizeof(flags_length));
-  DCHECK_EQ(framer.GetFrameHeaderSize(), length());
-  return success;
-}
-
-bool SpdyFrameBuilder::WriteDataFrameHeader(const SpdyFramer& framer,
-                                            SpdyStreamId stream_id,
-                                            uint8_t flags) {
-  if (version_ == HTTP2) {
-    return BeginNewFrame(framer, DATA, flags, stream_id);
-  }
-  DCHECK_EQ(0u, stream_id & ~kStreamIdMask);
-  bool success = true;
-  success &= WriteUInt32(stream_id);
-  size_t length_field = capacity_ - framer.GetDataFrameMinimumSize();
-  DCHECK_EQ(0u, length_field & ~static_cast<size_t>(kLengthMask));
-  FlagsAndLength flags_length;
-  flags_length.length = base::HostToNet32(static_cast<uint32_t>(length_field));
-  DCHECK_EQ(0, flags & ~kDataFlagsMask);
-  flags_length.flags[0] = flags;
-  success &= WriteBytes(&flags_length, sizeof(flags_length));
-  DCHECK_EQ(framer.GetDataFrameMinimumSize(), length());
-  return success;
-}
-
 bool SpdyFrameBuilder::BeginNewFrame(const SpdyFramer& framer,
                                      SpdyFrameType type,
                                      uint8_t flags,
                                      SpdyStreamId stream_id) {
-  DCHECK(SpdyConstants::IsValidFrameType(
-      version_, SpdyConstants::SerializeFrameType(version_, type)));
+  DCHECK(
+      SpdyConstants::IsValidFrameType(SpdyConstants::SerializeFrameType(type)));
   DCHECK_EQ(0u, stream_id & ~kStreamIdMask);
-  DCHECK_EQ(HTTP2, framer.protocol_version());
   bool success = true;
-  size_t frame_header_length =
-      SpdyConstants::GetFrameHeaderSize(framer.protocol_version());
+  size_t frame_header_length = SpdyConstants::kFrameHeaderSize;
   if (length_ > 0) {
     // Update length field for previous frame.
     OverwriteLength(framer, length_ - frame_header_length);
@@ -124,7 +60,7 @@ bool SpdyFrameBuilder::BeginNewFrame(const SpdyFramer& framer,
   // Don't check for length limits here because this may be larger than the
   // actual frame length.
   success &= WriteUInt24(capacity_ - offset_ - frame_header_length);
-  success &= WriteUInt8(SpdyConstants::SerializeFrameType(version_, type));
+  success &= WriteUInt8(SpdyConstants::SerializeFrameType(type));
   success &= WriteUInt8(flags);
   success &= WriteUInt32(stream_id);
   DCHECK_EQ(framer.GetDataFrameMinimumSize(), length_);
@@ -169,35 +105,18 @@ bool SpdyFrameBuilder::RewriteLength(const SpdyFramer& framer) {
 
 bool SpdyFrameBuilder::OverwriteLength(const SpdyFramer& framer,
                                        size_t length) {
-  if (version_ == SPDY3) {
-    DCHECK_GE(framer.GetFrameMaximumSize() - framer.GetFrameMinimumSize(),
-              length);
-  } else {
-    DCHECK_GE(framer.GetFrameMaximumSize(), length);
-  }
+  DCHECK_GE(framer.GetFrameMaximumSize(), length);
   bool success = false;
   const size_t old_length = length_;
 
-  if (version_ == SPDY3) {
-    FlagsAndLength flags_length = CreateFlagsAndLength(
-        0,  // We're not writing over the flags value anyway.
-        length);
-
-    // Write into the correct location by temporarily faking the offset.
-    length_ = 5;  // Offset at which the length field occurs.
-    success = WriteBytes(reinterpret_cast<char*>(&flags_length) + 1,
-                         sizeof(flags_length) - 1);
-  } else {
-    length_ = 0;
-    success = WriteUInt24(length);
-  }
+  length_ = 0;
+  success = WriteUInt24(length);
 
   length_ = old_length;
   return success;
 }
 
 bool SpdyFrameBuilder::OverwriteFlags(const SpdyFramer& framer, uint8_t flags) {
-  DCHECK_EQ(HTTP2, framer.protocol_version());
   bool success = false;
   const size_t old_length = length_;
   // Flags are the fifth octet in the frame prefix.
diff --git a/src/net/spdy/spdy_frame_builder.h b/src/net/spdy/spdy_frame_builder.h
index 47ec816..c445a9a 100644
--- a/src/net/spdy/spdy_frame_builder.h
+++ b/src/net/spdy/spdy_frame_builder.h
@@ -31,7 +31,7 @@ class SpdyFramer;
 class NET_EXPORT_PRIVATE SpdyFrameBuilder {
  public:
   // Initializes a SpdyFrameBuilder with a buffer of given size
-  SpdyFrameBuilder(size_t size, SpdyMajorVersion version);
+  explicit SpdyFrameBuilder(size_t size);
 
   ~SpdyFrameBuilder();
 
@@ -51,24 +51,8 @@ class NET_EXPORT_PRIVATE SpdyFrameBuilder {
   // GetWriteableBuffer() above.
   bool Seek(size_t length);
 
-  // Populates this frame with a SPDY control frame header using
-  // version-specific information from the |framer| and length information from
-  // capacity_. The given type must be a control frame type.
-  // Used only for SPDY versions <4.
-  bool WriteControlFrameHeader(const SpdyFramer& framer,
-                               SpdyFrameType type,
-                               uint8_t flags);
-
-  // Populates this frame with a SPDY data frame header using version-specific
-  // information from the |framer| and length information from capacity_.
-  bool WriteDataFrameHeader(const SpdyFramer& framer,
-                            SpdyStreamId stream_id,
-                            uint8_t flags);
-
-  // Populates this frame with a SPDY4/HTTP2 frame prefix using
-  // version-specific information from the |framer| and length information from
-  // capacity_. The given type must be a control frame type.
-  // Used only for SPDY versions >=4.
+  // Populates this frame with a HTTP2 frame prefix using length information
+  // from |capacity_|. The given type must be a control frame type.
   bool BeginNewFrame(const SpdyFramer& framer,
                      SpdyFrameType type,
                      uint8_t flags,
@@ -76,11 +60,9 @@ class NET_EXPORT_PRIVATE SpdyFrameBuilder {
 
   // Takes the buffer from the SpdyFrameBuilder.
   SpdySerializedFrame take() {
-    if (version_ == HTTP2) {
-      SPDY_BUG_IF(SpdyConstants::GetMaxFrameSizeLimit(version_) < length_)
-          << "Frame length " << length_
-          << " is longer than the maximum possible allowed length.";
-    }
+    SPDY_BUG_IF(SpdyConstants::kMaxFrameSizeLimit < length_)
+        << "Frame length " << length_
+        << " is longer than the maximum possible allowed length.";
     SpdySerializedFrame rv(buffer_.release(), length(), true);
     capacity_ = 0;
     length_ = 0;
@@ -131,7 +113,6 @@ class NET_EXPORT_PRIVATE SpdyFrameBuilder {
 
   // Update (in-place) the flags field in the frame being built to reflect the
   // given flags value.
-  // Used only for SPDY versions >=4.
   bool OverwriteFlags(const SpdyFramer& framer, uint8_t flags);
 
  private:
@@ -143,8 +124,6 @@ class NET_EXPORT_PRIVATE SpdyFrameBuilder {
   size_t capacity_;  // Allocation size of payload, set by constructor.
   size_t length_;    // Length of the latest frame in the buffer.
   size_t offset_;    // Position at which the latest frame begins.
-
-  const SpdyMajorVersion version_;
 };
 
 }  // namespace net
diff --git a/src/net/spdy/spdy_framer.cc b/src/net/spdy/spdy_framer.cc
index 8289b43..0ec0236 100644
--- a/src/net/spdy/spdy_framer.cc
+++ b/src/net/spdy/spdy_framer.cc
@@ -7,6 +7,7 @@
 #include <string.h>
 
 #include <algorithm>
+#include <cctype>
 #include <ios>
 #include <iterator>
 #include <list>
@@ -17,9 +18,13 @@
 
 #include "base/lazy_instance.h"
 #include "base/logging.h"
+#include "base/memory/ptr_util.h"
 #include "base/metrics/histogram_macros.h"
+#include "base/strings/string_util.h"
 #include "net/quic/core/quic_flags.h"
 #include "net/spdy/hpack/hpack_constants.h"
+#include "net/spdy/hpack/hpack_decoder.h"
+#include "net/spdy/hpack/hpack_decoder2.h"
 #include "net/spdy/spdy_bitmasks.h"
 #include "net/spdy/spdy_bug_tracker.h"
 #include "net/spdy/spdy_flags.h"
@@ -27,7 +32,6 @@
 #include "net/spdy/spdy_frame_reader.h"
 #include "net/spdy/spdy_framer_decoder_adapter.h"
 #include "net/spdy/spdy_headers_block_parser.h"
-#include "third_party/zlib/zlib.h"
 
 using base::StringPiece;
 using std::hex;
@@ -38,37 +42,6 @@ namespace net {
 
 namespace {
 
-// Compute the id of our dictionary so that we know we're using the
-// right one when asked for it.
-uLong CalculateDictionaryId(const char* dictionary,
-                            const size_t dictionary_size) {
-  uLong initial_value = adler32(0L, Z_NULL, 0);
-  return adler32(initial_value,
-                 reinterpret_cast<const Bytef*>(dictionary),
-                 dictionary_size);
-}
-
-#if !defined(USE_SYSTEM_ZLIB)
-// Check to see if the name and value of a cookie are both empty.
-bool IsCookieEmpty(const base::StringPiece& cookie) {
-  if (cookie.size() == 0) {
-     return true;
-  }
-  size_t pos = cookie.find('=');
-  if (pos  == base::StringPiece::npos) {
-     return false;
-  }
-  // Ignore leading whitespaces of cookie value.
-  size_t value_start = pos + 1;
-  for (; value_start < cookie.size(); value_start++) {
-     if (!(cookie[value_start] == ' ' || cookie[value_start] == '\t')) {
-        break;
-     }
-  }
-  return (pos == 0) && ((cookie.size() - value_start) == 0);
-}
-#endif  // !defined(USE_SYSTEM_ZLIB)
-
 // Pack parent stream ID and exclusive flag into the format used by HTTP/2
 // headers and priority frames.
 uint32_t PackStreamDependencyValues(bool exclusive,
@@ -101,18 +74,7 @@ std::unique_ptr<SpdyFramerDecoderAdapter> DecoderAdapterFactory(
   return nullptr;
 }
 
-struct DictionaryIds {
-  DictionaryIds()
-      : v3_dictionary_id(
-            CalculateDictionaryId(kV3Dictionary, kV3DictionarySize)) {}
-  const uLong v3_dictionary_id;
-};
-
-// Adler ID for the SPDY header compressor dictionaries. Note that they are
-// initialized lazily to avoid static initializers.
-base::LazyInstance<DictionaryIds>::Leaky g_dictionary_ids;
-
-// Used to indicate no flags in a SPDY flags field.
+// Used to indicate no flags in a HTTP2 flags field.
 const uint8_t kNoFlags = 0;
 
 // Wire sizes of priority payloads.
@@ -132,8 +94,7 @@ const size_t SpdyFramer::kHeaderDataChunkMaxSize = 1024;
 const size_t SpdyFramer::kMaxControlFrameSize = (1 << 14) - 1;
 const size_t SpdyFramer::kMaxDataPayloadSendSize = 1 << 14;
 // The size of the control frame buffer. Must be >= the minimum size of the
-// largest control frame, which is SYN_STREAM. See GetSynStreamMinimumSize() for
-// calculation details.
+// largest control frame.
 const size_t SpdyFramer::kControlFrameBufferSize = 19;
 
 #ifdef DEBUG_SPDY_STATE_CHANGES
@@ -157,18 +118,17 @@ const size_t SpdyFramer::kControlFrameBufferSize = 19;
   } while (false)
 #endif
 
-SettingsFlagsAndId SettingsFlagsAndId::FromWireFormat(SpdyMajorVersion version,
-                                                      uint32_t wire) {
+SettingsFlagsAndId SettingsFlagsAndId::FromWireFormat(uint32_t wire) {
   return SettingsFlagsAndId(base::NetToHost32(wire) >> 24,
                             base::NetToHost32(wire) & 0x00ffffff);
 }
 
 SettingsFlagsAndId::SettingsFlagsAndId(uint8_t flags, uint32_t id)
     : flags_(flags), id_(id & 0x00ffffff) {
-  SPDY_BUG_IF(id > (1u << 24)) << "SPDY setting ID too large: " << id;
+  SPDY_BUG_IF(id > (1u << 24)) << "HTTP2 setting ID too large: " << id;
 }
 
-uint32_t SettingsFlagsAndId::GetWireFormat(SpdyMajorVersion version) const {
+uint32_t SettingsFlagsAndId::GetWireFormat() const {
   return base::HostToNet32(id_ & 0x00ffffff) | base::HostToNet32(flags_ << 24);
 }
 
@@ -183,20 +143,15 @@ bool SpdyFramerVisitorInterface::OnRstStreamFrameData(
   return true;
 }
 
-SpdyFramer::SpdyFramer(SpdyMajorVersion version,
-                       SpdyFramer::DecoderAdapterFactoryFn adapter_factory)
+SpdyFramer::SpdyFramer(SpdyFramer::DecoderAdapterFactoryFn adapter_factory)
     : current_frame_buffer_(kControlFrameBufferSize),
       expect_continuation_(0),
       visitor_(NULL),
       debug_visitor_(NULL),
       header_handler_(nullptr),
-      display_protocol_("SPDY"),
-      protocol_version_(version),
       enable_compression_(true),
-      syn_frame_processed_(false),
       probable_http_response_(false),
       end_stream_when_done_(false) {
-  DCHECK(protocol_version_ == SPDY3 || protocol_version_ == HTTP2);
   // TODO(bnc): The way kMaxControlFrameSize is currently interpreted, it
   // includes the frame header, whereas kSpdyInitialFrameSizeLimit does not.
   // Therefore this assertion is unnecessarily strict.
@@ -204,21 +159,14 @@ SpdyFramer::SpdyFramer(SpdyMajorVersion version,
                 "Our send limit should be at most our receive limit");
   Reset();
 
-  if (version == HTTP2 && adapter_factory != nullptr) {
+  if (adapter_factory != nullptr) {
     decoder_adapter_ = adapter_factory(this);
   }
 }
 
-SpdyFramer::SpdyFramer(SpdyMajorVersion version)
-    : SpdyFramer(version, &DecoderAdapterFactory) {}
+SpdyFramer::SpdyFramer() : SpdyFramer(&DecoderAdapterFactory) {}
 
 SpdyFramer::~SpdyFramer() {
-  if (header_compressor_.get()) {
-    deflateEnd(header_compressor_.get());
-  }
-  if (header_decompressor_.get()) {
-    inflateEnd(header_decompressor_.get());
-  }
 }
 
 void SpdyFramer::Reset() {
@@ -284,77 +232,33 @@ SpdyFramer::SpdyState SpdyFramer::state() const {
 }
 
 size_t SpdyFramer::GetDataFrameMinimumSize() const {
-  return SpdyConstants::GetDataFrameMinimumSize(protocol_version_);
+  return SpdyConstants::kDataFrameMinimumSize;
 }
 
 // Size, in bytes, of the control frame header.
 size_t SpdyFramer::GetFrameHeaderSize() const {
-  return SpdyConstants::GetFrameHeaderSize(protocol_version_);
-}
-
-size_t SpdyFramer::GetSynStreamMinimumSize() const {
-  // Size, in bytes, of a SYN_STREAM frame not including the variable-length
-  // header block.
-  if (protocol_version_ == SPDY3) {
-    // Calculated as:
-    // control frame header + 2 * 4 (stream IDs) + 1 (priority)
-    // + 1 (unused)
-    return GetFrameHeaderSize() + 10;
-  } else {
-    return GetFrameHeaderSize() + kPriorityDependencyPayloadSize +
-           kPriorityWeightPayloadSize;
-  }
-}
-
-size_t SpdyFramer::GetSynReplyMinimumSize() const {
-  // Size, in bytes, of a SYN_REPLY frame not including the variable-length
-  // header block.
-  size_t size = GetFrameHeaderSize();
-  if (protocol_version_ == SPDY3) {
-    // Calculated as:
-    // control frame header + 4 (stream IDs)
-    size += 4;
-  }
-
-  return size;
+  return SpdyConstants::kFrameHeaderSize;
 }
 
 // TODO(jamessynge): Rename this to GetRstStreamSize as the frame is fixed size.
 size_t SpdyFramer::GetRstStreamMinimumSize() const {
   // Size, in bytes, of a RST_STREAM frame.
-  if (protocol_version_ == SPDY3) {
-    // Calculated as:
-    // control frame header + 4 (stream id) + 4 (status code)
-    return GetFrameHeaderSize() + 8;
-  } else {
-    // Calculated as:
-    // frame prefix + 4 (status code)
-    return GetFrameHeaderSize() + 4;
-  }
+  // Calculated as:
+  // frame prefix + 4 (status code)
+  return GetFrameHeaderSize() + 4;
 }
 
 size_t SpdyFramer::GetSettingsMinimumSize() const {
   // Size, in bytes, of a SETTINGS frame not including the IDs and values
-  // from the variable-length value block. Calculated as:
-  // control frame header + 4 (number of ID/value pairs)
-  if (protocol_version_ == SPDY3) {
-    return GetFrameHeaderSize() + 4;
-  } else {
-    return GetFrameHeaderSize();
-  }
+  // from the variable-length value block.
+  return GetFrameHeaderSize();
 }
 
 size_t SpdyFramer::GetPingSize() const {
   // Size, in bytes, of this PING frame.
-  if (protocol_version_ == SPDY3) {
-    // Calculated as:
-    // control frame header + 4 (id)
-    return GetFrameHeaderSize() + 4;
-  } else {
-    // Calculated as:
-    // control frame header + 8 (id)
-    return GetFrameHeaderSize() + 8;
-  }
+  // Calculated as:
+  // control frame header + 8 (id)
+  return GetFrameHeaderSize() + 8;
 }
 
 size_t SpdyFramer::GetGoAwayMinimumSize() const {
@@ -366,38 +270,23 @@ size_t SpdyFramer::GetGoAwayMinimumSize() const {
 size_t SpdyFramer::GetHeadersMinimumSize() const  {
   // Size, in bytes, of a HEADERS frame not including the variable-length
   // header block.
-  size_t size = GetFrameHeaderSize();
-  if (protocol_version_ == SPDY3) {
-    // Calculated as:
-    // control frame header + 4 (stream IDs)
-    size += 4;
-  }
-
-  return size;
+  return GetFrameHeaderSize();
 }
 
 size_t SpdyFramer::GetWindowUpdateSize() const {
   // Size, in bytes, of a WINDOW_UPDATE frame.
-  if (protocol_version_ == SPDY3) {
-    // Calculated as:
-    // control frame header + 4 (stream id) + 4 (delta)
-    return GetFrameHeaderSize() + 8;
-  } else {
-    // Calculated as:
-    // frame prefix + 4 (delta)
-    return GetFrameHeaderSize() + 4;
-  }
+  // Calculated as:
+  // frame prefix + 4 (delta)
+  return GetFrameHeaderSize() + 4;
 }
 
 size_t SpdyFramer::GetBlockedSize() const {
-  DCHECK_EQ(HTTP2, protocol_version_);
   // Size, in bytes, of a BLOCKED frame.
   // The BLOCKED frame has no payload beyond the control frame header.
   return GetFrameHeaderSize();
 }
 
 size_t SpdyFramer::GetPushPromiseMinimumSize() const {
-  DCHECK_EQ(HTTP2, protocol_version_);
   // Size, in bytes, of a PUSH_PROMISE frame, sans the embedded header block.
   // Calculated as frame prefix + 4 (promised stream id)
   return GetFrameHeaderSize() + 4;
@@ -429,21 +318,12 @@ size_t SpdyFramer::GetFrameMinimumSize() const {
 }
 
 size_t SpdyFramer::GetFrameMaximumSize() const {
-  if (protocol_version_ == HTTP2) {
-    return send_frame_size_limit_ +
-           SpdyConstants::GetFrameHeaderSize(protocol_version_);
-  } else {
-    return SpdyConstants::GetMaxFrameSizeLimit(protocol_version_);
-  }
+  return send_frame_size_limit_ + SpdyConstants::kFrameHeaderSize;
 }
 
 size_t SpdyFramer::GetDataFrameMaximumPayload() const {
-  if (protocol_version_ == HTTP2) {
-    return std::min(kMaxDataPayloadSendSize,
-                    GetFrameMaximumSize() - GetDataFrameMinimumSize());
-  } else {
-    return GetFrameMaximumSize() - GetDataFrameMinimumSize();
-  }
+  return std::min(kMaxDataPayloadSendSize,
+                  GetFrameMaximumSize() - GetDataFrameMinimumSize());
 }
 
 const char* SpdyFramer::StateToString(int state) {
@@ -535,8 +415,8 @@ const char* SpdyFramer::ErrorCodeToString(int error_code) {
 
 const char* SpdyFramer::StatusCodeToString(int status_code) {
   switch (status_code) {
-    case RST_STREAM_INVALID:
-      return "INVALID";
+    case RST_STREAM_NO_ERROR:
+      return "NO_ERROR";
     case RST_STREAM_PROTOCOL_ERROR:
       return "PROTOCOL_ERROR";
     case RST_STREAM_INVALID_STREAM:
@@ -573,10 +453,6 @@ const char* SpdyFramer::FrameTypeToString(SpdyFrameType type) {
   switch (type) {
     case DATA:
       return "DATA";
-    case SYN_STREAM:
-      return "SYN_STREAM";
-    case SYN_REPLY:
-      return "SYN_REPLY";
     case RST_STREAM:
       return "RST_STREAM";
     case SETTINGS:
@@ -641,7 +517,7 @@ size_t SpdyFramer::ProcessInput(const char* data, size_t len) {
 
       case SPDY_CONTROL_FRAME_BEFORE_HEADER_BLOCK: {
         // Control frames that contain header blocks
-        // (SYN_STREAM, SYN_REPLY, HEADERS, PUSH_PROMISE, CONTINUATION)
+        // (HEADERS, PUSH_PROMISE, CONTINUATION)
         // take a special path through the state machine - they
         // will go:
         //   1. SPDY_CONTROL_FRAME_BEFORE_HEADER_BLOCK
@@ -667,8 +543,7 @@ size_t SpdyFramer::ProcessInput(const char* data, size_t len) {
       }
 
       case SPDY_CONTROL_FRAME_HEADER_BLOCK: {
-        int bytes_read = ProcessControlFrameHeaderBlock(
-            data, len, protocol_version_ == HTTP2);
+        int bytes_read = ProcessControlFrameHeaderBlock(data, len);
         len -= bytes_read;
         data += bytes_read;
         break;
@@ -731,8 +606,7 @@ size_t SpdyFramer::ProcessInput(const char* data, size_t len) {
       }
 
       default:
-        SPDY_BUG << "Invalid value for " << display_protocol_
-                 << " framer state: " << state_;
+        SPDY_BUG << "Invalid value for framer state: " << state_;
         // This ensures that we don't infinite-loop if state_ gets an
         // invalid value somehow, such as due to a SpdyFramer getting deleted
         // from a callback it calls.
@@ -777,72 +651,58 @@ void SpdyFramer::SpdySettingsScratch::Reset() {
 SpdyFrameType SpdyFramer::ValidateFrameHeader(bool is_control_frame,
                                               int frame_type_field,
                                               size_t payload_length_field) {
-  if (!SpdyConstants::IsValidFrameType(protocol_version_, frame_type_field)) {
-    if (protocol_version_ == SPDY3) {
-      if (is_control_frame) {
-        DLOG(WARNING) << "Invalid control frame type " << frame_type_field
-                      << " (protocol version: " << protocol_version_ << ")";
-        set_error(SPDY_INVALID_CONTROL_FRAME);
-      } else {
-        // Else it's a SPDY3 data frame which we don't validate further here
-      }
+  if (!SpdyConstants::IsValidFrameType(frame_type_field)) {
+    // We ignore unknown frame types for extensibility, as long as
+    // the rest of the control frame header is valid.
+    // We rely on the visitor to check validity of current_frame_stream_id_.
+    bool valid_stream =
+        visitor_->OnUnknownFrame(current_frame_stream_id_, frame_type_field);
+    if (expect_continuation_) {
+      // Report an unexpected frame error and close the connection
+      // if we expect a continuation and receive an unknown frame.
+      DLOG(ERROR) << "The framer was expecting to receive a CONTINUATION "
+                  << "frame, but instead received an unknown frame of type "
+                  << frame_type_field;
+      set_error(SPDY_UNEXPECTED_FRAME);
+    } else if (!valid_stream) {
+      // Report an invalid frame error and close the stream if the
+      // stream_id is not valid.
+      DLOG(WARNING) << "Unknown control frame type " << frame_type_field
+                    << " received on invalid stream "
+                    << current_frame_stream_id_;
+      set_error(SPDY_INVALID_CONTROL_FRAME);
     } else {
-      // In HTTP2 we ignore unknown frame types for extensibility, as long as
-      // the rest of the control frame header is valid.
-      // We rely on the visitor to check validity of current_frame_stream_id_.
-      bool valid_stream =
-          visitor_->OnUnknownFrame(current_frame_stream_id_, frame_type_field);
-      if (expect_continuation_) {
-        // Report an unexpected frame error and close the connection
-        // if we expect a continuation and receive an unknown frame.
-        DLOG(ERROR) << "The framer was expecting to receive a CONTINUATION "
-                    << "frame, but instead received an unknown frame of type "
-                    << frame_type_field;
-        set_error(SPDY_UNEXPECTED_FRAME);
-      } else if (!valid_stream) {
-        // Report an invalid frame error and close the stream if the
-        // stream_id is not valid.
-        DLOG(WARNING) << "Unknown control frame type " << frame_type_field
-                      << " received on invalid stream "
-                      << current_frame_stream_id_;
-        set_error(SPDY_INVALID_CONTROL_FRAME);
-      } else {
-        DVLOG(1) << "Ignoring unknown frame type.";
-        CHANGE_STATE(SPDY_IGNORE_REMAINING_PAYLOAD);
-      }
+      DVLOG(1) << "Ignoring unknown frame type.";
+      CHANGE_STATE(SPDY_IGNORE_REMAINING_PAYLOAD);
     }
     return DATA;
   }
 
-  SpdyFrameType frame_type =
-      SpdyConstants::ParseFrameType(protocol_version_, frame_type_field);
+  SpdyFrameType frame_type = SpdyConstants::ParseFrameType(frame_type_field);
 
-  if (protocol_version_ == HTTP2) {
-    if (!SpdyConstants::IsValidHTTP2FrameStreamId(current_frame_stream_id_,
-                                                  frame_type)) {
-      DLOG(ERROR) << "The framer received an invalid streamID of "
-                  << current_frame_stream_id_ << " for a frame of type "
-                  << FrameTypeToString(frame_type);
-      set_error(SPDY_INVALID_STREAM_ID);
-      return frame_type;
-    }
+  if (!SpdyConstants::IsValidHTTP2FrameStreamId(current_frame_stream_id_,
+                                                frame_type)) {
+    DLOG(ERROR) << "The framer received an invalid streamID of "
+                << current_frame_stream_id_ << " for a frame of type "
+                << FrameTypeToString(frame_type);
+    set_error(SPDY_INVALID_STREAM_ID);
+    return frame_type;
+  }
 
-    // Ensure that we see a CONTINUATION frame iff we expect to.
-    if ((frame_type == CONTINUATION) != (expect_continuation_ != 0)) {
-      if (expect_continuation_ != 0) {
-        DLOG(ERROR) << "The framer was expecting to receive a CONTINUATION "
-                    << "frame, but instead received a frame of type "
-                    << FrameTypeToString(frame_type);
-      } else {
-        DLOG(ERROR) << "The framer received an unexpected CONTINUATION frame.";
-      }
-      set_error(SPDY_UNEXPECTED_FRAME);
-      return frame_type;
+  // Ensure that we see a CONTINUATION frame iff we expect to.
+  if ((frame_type == CONTINUATION) != (expect_continuation_ != 0)) {
+    if (expect_continuation_ != 0) {
+      DLOG(ERROR) << "The framer was expecting to receive a CONTINUATION "
+                  << "frame, but instead received a frame of type "
+                  << FrameTypeToString(frame_type);
+    } else {
+      DLOG(ERROR) << "The framer received an unexpected CONTINUATION frame.";
     }
+    set_error(SPDY_UNEXPECTED_FRAME);
+    return frame_type;
   }
 
-  if (protocol_version_ == HTTP2 &&
-      payload_length_field > recv_frame_size_limit_) {
+  if (payload_length_field > recv_frame_size_limit_) {
     set_error(SPDY_OVERSIZED_PAYLOAD);
   }
 
@@ -871,85 +731,43 @@ size_t SpdyFramer::ProcessCommonHeader(const char* data, size_t len) {
                          current_frame_buffer_.len());
   bool is_control_frame = false;
 
-  int control_frame_type_field =
-      SpdyConstants::DataFrameType(protocol_version_);
+  int control_frame_type_field = SpdyConstants::kDataFrameType;
   // ProcessControlFrameHeader() will set current_frame_type_ to the
   // correct value if this is a valid control frame.
   current_frame_type_ = DATA;
-  if (protocol_version_ == SPDY3) {
-    uint16_t version = 0;
-    bool successful_read = reader.ReadUInt16(&version);
-    DCHECK(successful_read);
-    is_control_frame = (version & kControlFlagMask) != 0;
-    if (is_control_frame) {
-      version &= ~kControlFlagMask;
-      if (version != kSpdy3Version) {
-        // Version does not match the version the framer was initialized with.
-        DVLOG(1) << "Unsupported SPDY version " << version << " (expected "
-                 << kSpdy3Version << ")";
-        set_error(SPDY_UNSUPPORTED_VERSION);
-        return 0;
-      }
-      uint16_t control_frame_type_field_uint16;
-      successful_read = reader.ReadUInt16(&control_frame_type_field_uint16);
-      control_frame_type_field = control_frame_type_field_uint16;
-    } else {
-      reader.Rewind();
-      successful_read = reader.ReadUInt31(&current_frame_stream_id_);
-    }
-    DCHECK(successful_read);
-
-    successful_read = reader.ReadUInt8(&current_frame_flags_);
-    DCHECK(successful_read);
+  uint32_t length_field = 0;
+  bool successful_read = reader.ReadUInt24(&length_field);
+  DCHECK(successful_read);
 
-    uint32_t length_field = 0;
-    successful_read = reader.ReadUInt24(&length_field);
-    DCHECK(successful_read);
-    remaining_data_length_ = length_field;
-    current_frame_length_ = remaining_data_length_ + reader.GetBytesConsumed();
-  } else {
-    uint32_t length_field = 0;
-    bool successful_read = reader.ReadUInt24(&length_field);
-    DCHECK(successful_read);
-
-    uint8_t control_frame_type_field_uint8;
-    successful_read = reader.ReadUInt8(&control_frame_type_field_uint8);
-    DCHECK(successful_read);
-    // We check control_frame_type_field's validity in
-    // ProcessControlFrameHeader().
-    control_frame_type_field = control_frame_type_field_uint8;
-    is_control_frame =
-        control_frame_type_field !=
-        SpdyConstants::SerializeFrameType(protocol_version_, DATA);
+  uint8_t control_frame_type_field_uint8;
+  successful_read = reader.ReadUInt8(&control_frame_type_field_uint8);
+  DCHECK(successful_read);
+  // We check control_frame_type_field's validity in
+  // ProcessControlFrameHeader().
+  control_frame_type_field = control_frame_type_field_uint8;
+  is_control_frame = control_frame_type_field != SpdyConstants::kDataFrameType;
 
-    current_frame_length_ = length_field + GetFrameHeaderSize();
+  current_frame_length_ = length_field + GetFrameHeaderSize();
 
-    successful_read = reader.ReadUInt8(&current_frame_flags_);
-    DCHECK(successful_read);
+  successful_read = reader.ReadUInt8(&current_frame_flags_);
+  DCHECK(successful_read);
 
-    successful_read = reader.ReadUInt31(&current_frame_stream_id_);
-    DCHECK(successful_read);
+  successful_read = reader.ReadUInt31(&current_frame_stream_id_);
+  DCHECK(successful_read);
 
-    remaining_data_length_ = current_frame_length_ - reader.GetBytesConsumed();
-  }
+  remaining_data_length_ = current_frame_length_ - reader.GetBytesConsumed();
 
   DCHECK_EQ(GetFrameHeaderSize(), reader.GetBytesConsumed());
   DCHECK_EQ(current_frame_length_,
             remaining_data_length_ + reader.GetBytesConsumed());
 
   // This is just a sanity check for help debugging early frame errors.
-  if (remaining_data_length_ > 1000000u) {
-    // The strncmp for 5 is safe because we only hit this point if we
-    // have kMinCommonHeader (8) bytes
-    if (!syn_frame_processed_ &&
-        strncmp(current_frame_buffer_.data(), "HTTP/", 5) == 0) {
-      LOG(WARNING) << "Unexpected HTTP response to " << display_protocol_
-                   << " request";
-      probable_http_response_ = true;
-    } else {
-      LOG(WARNING) << "Unexpectedly large frame.  " << display_protocol_
-                   << " session is likely corrupt.";
-    }
+  // The strncmp for 5 is safe because we only hit this point if we
+  // have kMinCommonHeader (8) bytes
+  if (remaining_data_length_ > 1000000u &&
+      strncmp(current_frame_buffer_.data(), "HTTP/", 5) == 0) {
+    LOG(WARNING) << "Unexpected HTTP response to HTTP2 request";
+    probable_http_response_ = true;
   }
 
   // If we're here, then we have the common header all received.
@@ -964,12 +782,7 @@ size_t SpdyFramer::ProcessCommonHeader(const char* data, size_t len) {
   }
 
   if (!is_control_frame) {
-    uint8_t valid_data_flags = 0;
-    if (protocol_version_ == SPDY3) {
-      valid_data_flags = DATA_FLAG_FIN;
-    } else {
-      valid_data_flags = DATA_FLAG_FIN | DATA_FLAG_PADDED;
-    }
+    uint8_t valid_data_flags = DATA_FLAG_FIN | DATA_FLAG_PADDED;
 
     if (current_frame_flags_ & ~valid_data_flags) {
       set_error(SPDY_INVALID_DATA_FRAME_FLAGS);
@@ -1000,21 +813,6 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
 
   // Do some sanity checking on the control frame sizes and flags.
   switch (current_frame_type_) {
-    case SYN_STREAM:
-      if (current_frame_length_ < GetSynStreamMinimumSize()) {
-        set_error(SPDY_INVALID_CONTROL_FRAME);
-      } else if (current_frame_flags_ &
-                 ~(CONTROL_FLAG_FIN | CONTROL_FLAG_UNIDIRECTIONAL)) {
-        set_error(SPDY_INVALID_CONTROL_FRAME_FLAGS);
-      }
-      break;
-    case SYN_REPLY:
-      if (current_frame_length_ < GetSynReplyMinimumSize()) {
-        set_error(SPDY_INVALID_CONTROL_FRAME);
-      } else if (current_frame_flags_ & ~CONTROL_FLAG_FIN) {
-        set_error(SPDY_INVALID_CONTROL_FRAME_FLAGS);
-      }
-      break;
     case RST_STREAM:
       if (current_frame_length_ != GetRstStreamMinimumSize()) {
         set_error(SPDY_INVALID_CONTROL_FRAME_SIZE);
@@ -1027,26 +825,17 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
     case SETTINGS:
     {
       // Make sure that we have an integral number of 8-byte key/value pairs,
-      // plus a 4-byte length field in SPDY3 and below.
-      size_t values_prefix_size = (protocol_version_ == SPDY3 ? 4 : 0);
       // Size of each key/value pair in bytes.
-      size_t setting_size = SpdyConstants::GetSettingSize(protocol_version_);
+      int setting_size = 6;
       if (current_frame_length_ < GetSettingsMinimumSize() ||
-          (current_frame_length_ - GetFrameHeaderSize()) % setting_size !=
-              values_prefix_size) {
+          (current_frame_length_ - GetFrameHeaderSize()) % setting_size != 0) {
         DLOG(WARNING) << "Invalid length for SETTINGS frame: "
                       << current_frame_length_;
         set_error(SPDY_INVALID_CONTROL_FRAME_SIZE);
-      } else if (protocol_version_ == SPDY3 &&
-                 current_frame_flags_ &
-                     ~SETTINGS_FLAG_CLEAR_PREVIOUSLY_PERSISTED_SETTINGS) {
-        set_error(SPDY_INVALID_CONTROL_FRAME_FLAGS);
-      } else if (protocol_version_ == HTTP2 &&
-                 current_frame_flags_ & SETTINGS_FLAG_ACK &&
+      } else if (current_frame_flags_ & SETTINGS_FLAG_ACK &&
                  current_frame_length_ > GetSettingsMinimumSize()) {
         set_error(SPDY_INVALID_CONTROL_FRAME_SIZE);
-      } else if (protocol_version_ == HTTP2 &&
-                 current_frame_flags_ & ~SETTINGS_FLAG_ACK) {
+      } else if (current_frame_flags_ & ~SETTINGS_FLAG_ACK) {
         VLOG(1) << "Undefined frame flags for SETTINGS frame: " << hex
                 << static_cast<int>(current_frame_flags_);
         current_frame_flags_ &= SETTINGS_FLAG_ACK;
@@ -1057,12 +846,7 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
       if (current_frame_length_ != GetPingSize()) {
         set_error(SPDY_INVALID_CONTROL_FRAME_SIZE);
       } else {
-        if (protocol_version_ == SPDY3 && current_frame_flags_ != 0) {
-          VLOG(1) << "Undefined frame flags for PING frame: " << hex
-                  << static_cast<int>(current_frame_flags_);
-          current_frame_flags_ = 0;
-        } else if (protocol_version_ == HTTP2 &&
-                   current_frame_flags_ & ~PING_FLAG_ACK) {
+        if (current_frame_flags_ & ~PING_FLAG_ACK) {
           VLOG(1) << "Undefined frame flags for PING frame: " << hex
                   << static_cast<int>(current_frame_flags_);
           current_frame_flags_ &= PING_FLAG_ACK;
@@ -1071,14 +855,10 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
       break;
     case GOAWAY:
       {
-        // For SPDY/3, there are only mandatory fields and the header has a
-        // fixed length. For HTTP/2, optional opaque data may be appended to the
-        // GOAWAY frame, thus there is only a minimal length restriction.
-        if ((protocol_version_ == SPDY3 &&
-             current_frame_length_ != GetGoAwayMinimumSize()) ||
-            (protocol_version_ == HTTP2 &&
-             current_frame_length_ < GetGoAwayMinimumSize())) {
-          set_error(SPDY_INVALID_CONTROL_FRAME);
+      // For HTTP/2, optional opaque data may be appended to the
+      // GOAWAY frame, thus there is only a minimal length restriction.
+      if (current_frame_length_ < GetGoAwayMinimumSize()) {
+        set_error(SPDY_INVALID_CONTROL_FRAME);
         } else if (current_frame_flags_ != 0) {
           VLOG(1) << "Undefined frame flags for GOAWAY frame: " << hex
                   << static_cast<int>(current_frame_flags_);
@@ -1089,23 +869,16 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
     case HEADERS:
       {
         size_t min_size = GetHeadersMinimumSize();
-        if (protocol_version_ == HTTP2 &&
-            (current_frame_flags_ & HEADERS_FLAG_PRIORITY)) {
+        if (current_frame_flags_ & HEADERS_FLAG_PRIORITY) {
           min_size += 4;
         }
         if (current_frame_length_ < min_size) {
           // TODO(mlavan): check here for HEADERS with no payload?
           // (not allowed in HTTP2)
           set_error(SPDY_INVALID_CONTROL_FRAME);
-        } else if (protocol_version_ == SPDY3 &&
-                   current_frame_flags_ & ~CONTROL_FLAG_FIN) {
-          VLOG(1) << "Undefined frame flags for HEADERS frame: " << hex
-                  << static_cast<int>(current_frame_flags_);
-          current_frame_flags_ &= CONTROL_FLAG_FIN;
-        } else if (protocol_version_ == HTTP2 &&
-                   current_frame_flags_ &
-                       ~(CONTROL_FLAG_FIN | HEADERS_FLAG_PRIORITY |
-                         HEADERS_FLAG_END_HEADERS | HEADERS_FLAG_PADDED)) {
+        } else if (current_frame_flags_ &
+                   ~(CONTROL_FLAG_FIN | HEADERS_FLAG_PRIORITY |
+                     HEADERS_FLAG_END_HEADERS | HEADERS_FLAG_PADDED)) {
           VLOG(1) << "Undefined frame flags for HEADERS frame: " << hex
                   << static_cast<int>(current_frame_flags_);
           current_frame_flags_ &=
@@ -1124,8 +897,7 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
       }
       break;
     case BLOCKED:
-      if (protocol_version_ == SPDY3 ||
-          current_frame_length_ != GetBlockedSize()) {
+      if (current_frame_length_ != GetBlockedSize()) {
         set_error(SPDY_INVALID_CONTROL_FRAME);
       } else if (current_frame_flags_ != 0) {
         VLOG(1) << "Undefined frame flags for BLOCKED frame: " << hex
@@ -1136,14 +908,8 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
     case PUSH_PROMISE:
       if (current_frame_length_ < GetPushPromiseMinimumSize()) {
         set_error(SPDY_INVALID_CONTROL_FRAME);
-      } else if (protocol_version_ == SPDY3 && current_frame_flags_ != 0) {
-        VLOG(1) << "Undefined frame flags for PUSH_PROMISE frame: " << hex
-                << static_cast<int>(current_frame_flags_);
-        current_frame_flags_ = 0;
-      } else if (protocol_version_ == HTTP2 &&
-                 current_frame_flags_ &
-                     ~(PUSH_PROMISE_FLAG_END_PUSH_PROMISE |
-                       HEADERS_FLAG_PADDED)) {
+      } else if (current_frame_flags_ &
+                 ~(PUSH_PROMISE_FLAG_END_PUSH_PROMISE | HEADERS_FLAG_PADDED)) {
         VLOG(1) << "Undefined frame flags for PUSH_PROMISE frame: " << hex
                 << static_cast<int>(current_frame_flags_);
         current_frame_flags_ &=
@@ -1151,8 +917,7 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
       }
       break;
     case CONTINUATION:
-      if (protocol_version_ == SPDY3 ||
-          current_frame_length_ < GetContinuationMinimumSize()) {
+      if (current_frame_length_ < GetContinuationMinimumSize()) {
         set_error(SPDY_INVALID_CONTROL_FRAME);
       } else if (current_frame_flags_ & ~HEADERS_FLAG_END_HEADERS) {
         VLOG(1) << "Undefined frame flags for CONTINUATION frame: " << hex
@@ -1170,8 +935,7 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
       }
       break;
     case PRIORITY:
-      if (protocol_version_ == SPDY3 ||
-          current_frame_length_ != GetPrioritySize()) {
+      if (current_frame_length_ != GetPrioritySize()) {
         set_error(SPDY_INVALID_CONTROL_FRAME_SIZE);
       } else if (current_frame_flags_ != 0) {
         VLOG(1) << "Undefined frame flags for PRIORITY frame: " << hex
@@ -1180,8 +944,7 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
       }
       break;
     default:
-      LOG(WARNING) << "Valid " << display_protocol_
-                   << " control frame with unhandled type: "
+      LOG(WARNING) << "Valid control frame with unhandled type: "
                    << current_frame_type_;
       // This branch should be unreachable because of the frame type bounds
       // check above. However, we DLOG(FATAL) here in an effort to painfully
@@ -1196,17 +959,6 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
     return;
   }
 
-  if (protocol_version_ == SPDY3 &&
-      current_frame_length_ >
-          kSpdyInitialFrameSizeLimit +
-              SpdyConstants::GetFrameHeaderSize(protocol_version_)) {
-    DLOG(WARNING) << "Received control frame of type " << current_frame_type_
-                  << " with way too big of a payload: "
-                  << current_frame_length_;
-    set_error(SPDY_CONTROL_PAYLOAD_TOO_LARGE);
-    return;
-  }
-
   if (current_frame_type_ == GOAWAY) {
     CHANGE_STATE(SPDY_GOAWAY_FRAME_PAYLOAD);
     return;
@@ -1224,34 +976,22 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
   // Determine the frame size without variable-length data.
   int32_t frame_size_without_variable_data;
   switch (current_frame_type_) {
-    case SYN_STREAM:
-      syn_frame_processed_ = true;
-      frame_size_without_variable_data = GetSynStreamMinimumSize();
-      break;
-    case SYN_REPLY:
-      syn_frame_processed_ = true;
-      frame_size_without_variable_data = GetSynReplyMinimumSize();
-      break;
     case SETTINGS:
       frame_size_without_variable_data = GetSettingsMinimumSize();
       break;
     case HEADERS:
       frame_size_without_variable_data = GetHeadersMinimumSize();
-      if (protocol_version_ == HTTP2) {
-        if (current_frame_flags_ & HEADERS_FLAG_PADDED) {
-          frame_size_without_variable_data += kPadLengthFieldSize;
-        }
-        if (current_frame_flags_ & HEADERS_FLAG_PRIORITY) {
+      if (current_frame_flags_ & HEADERS_FLAG_PADDED) {
+        frame_size_without_variable_data += kPadLengthFieldSize;
+      }
+      if (current_frame_flags_ & HEADERS_FLAG_PRIORITY) {
         frame_size_without_variable_data +=
-            kPriorityDependencyPayloadSize +
-            kPriorityWeightPayloadSize;
-        }
+            kPriorityDependencyPayloadSize + kPriorityWeightPayloadSize;
       }
       break;
     case PUSH_PROMISE:
       frame_size_without_variable_data = GetPushPromiseMinimumSize();
-      if (protocol_version_ == HTTP2 &&
-          current_frame_flags_ & PUSH_PROMISE_FLAG_PADDED) {
+      if (current_frame_flags_ & PUSH_PROMISE_FLAG_PADDED) {
         frame_size_without_variable_data += kPadLengthFieldSize;
       }
       break;
@@ -1268,8 +1008,7 @@ void SpdyFramer::ProcessControlFrameHeader(int control_frame_type_field) {
     // We should already be in an error state. Double-check.
     DCHECK_EQ(SPDY_ERROR, state_);
     if (state_ != SPDY_ERROR) {
-      SPDY_BUG << display_protocol_
-               << " control frame buffer too small for fixed-length frame.";
+      SPDY_BUG << "Control frame buffer too small for fixed-length frame.";
       set_error(SPDY_CONTROL_PAYLOAD_TOO_LARGE);
     }
     return;
@@ -1307,7 +1046,6 @@ size_t SpdyFramer::UpdateCurrentFrameBuffer(const char** data, size_t* len,
 }
 
 size_t SpdyFramer::GetSerializedLength(
-    const SpdyMajorVersion spdy_version,
     const SpdyHeaderBlock* headers) {
   const size_t num_name_value_pairs_size = sizeof(uint32_t);
   const size_t length_of_name_size = num_name_value_pairs_size;
@@ -1323,177 +1061,6 @@ size_t SpdyFramer::GetSerializedLength(
   return total_length;
 }
 
-// TODO(phajdan.jr): Clean up after we no longer need
-// to workaround http://crbug.com/139744.
-#if !defined(USE_SYSTEM_ZLIB)
-
-// These constants are used by zlib to differentiate between normal data and
-// cookie data. Cookie data is handled specially by zlib when compressing.
-enum ZDataClass {
-  // kZStandardData is compressed normally, save that it will never match
-  // against any other class of data in the window.
-  kZStandardData = Z_CLASS_STANDARD,
-  // kZCookieData is compressed in its own Huffman blocks and only matches in
-  // its entirety and only against other kZCookieData blocks. Any matches must
-  // be preceeded by a kZStandardData byte, or a semicolon to prevent matching
-  // a suffix. It's assumed that kZCookieData ends in a semicolon to prevent
-  // prefix matches.
-  kZCookieData = Z_CLASS_COOKIE,
-  // kZHuffmanOnlyData is only Huffman compressed - no matches are performed
-  // against the window.
-  kZHuffmanOnlyData = Z_CLASS_HUFFMAN_ONLY,
-};
-
-// WriteZ writes |data| to the deflate context |out|. WriteZ will flush as
-// needed when switching between classes of data.
-static void WriteZ(const base::StringPiece& data,
-                   ZDataClass clas,
-                   z_stream* out) {
-  int rv;
-
-  // If we are switching from standard to non-standard data then we need to end
-  // the current Huffman context to avoid it leaking between them.
-  if (out->clas == kZStandardData &&
-      clas != kZStandardData) {
-    out->avail_in = 0;
-    rv = deflate(out, Z_PARTIAL_FLUSH);
-    DCHECK_EQ(Z_OK, rv);
-    DCHECK_EQ(0u, out->avail_in);
-    DCHECK_LT(0u, out->avail_out);
-  }
-
-  out->next_in = reinterpret_cast<Bytef*>(const_cast<char*>(data.data()));
-  out->avail_in = data.size();
-  out->clas = clas;
-  if (clas == kZStandardData) {
-    rv = deflate(out, Z_NO_FLUSH);
-  } else {
-    rv = deflate(out, Z_PARTIAL_FLUSH);
-  }
-  if (!data.empty()) {
-    // If we didn't provide any data then zlib will return Z_BUF_ERROR.
-    DCHECK_EQ(Z_OK, rv);
-  }
-  DCHECK_EQ(0u, out->avail_in);
-  DCHECK_LT(0u, out->avail_out);
-}
-
-// WriteLengthZ writes |n| as a |length|-byte, big-endian number to |out|.
-static void WriteLengthZ(size_t n,
-                         unsigned length,
-                         ZDataClass clas,
-                         z_stream* out) {
-  char buf[4];
-  DCHECK_LE(length, sizeof(buf));
-  for (unsigned i = 1; i <= length; i++) {
-    buf[length - i] = static_cast<char>(n);
-    n >>= 8;
-  }
-  WriteZ(base::StringPiece(buf, length), clas, out);
-}
-
-// WriteHeaderBlockToZ serialises |headers| to the deflate context |z| in a
-// manner that resists the length of the compressed data from compromising
-// cookie data.
-void SpdyFramer::WriteHeaderBlockToZ(const SpdyHeaderBlock* headers,
-                                     z_stream* z) const {
-  const size_t length_length = 4;
-  WriteLengthZ(headers->size(), length_length, kZStandardData, z);
-
-  SpdyHeaderBlock::const_iterator it;
-  for (it = headers->begin(); it != headers->end(); ++it) {
-    WriteLengthZ(it->first.size(), length_length, kZStandardData, z);
-    WriteZ(it->first, kZStandardData, z);
-
-    if (it->first == "cookie") {
-      // We require the cookie values (save for the last) to end with a
-      // semicolon and (save for the first) to start with a space. This is
-      // typically the format that we are given them in but we reserialize them
-      // to be sure.
-
-      std::vector<base::StringPiece> cookie_values;
-      size_t cookie_length = 0;
-      base::StringPiece cookie_data(it->second);
-
-      for (;;) {
-        while (!cookie_data.empty() &&
-               (cookie_data[0] == ' ' || cookie_data[0] == '\t')) {
-          cookie_data.remove_prefix(1);
-        }
-        if (cookie_data.empty())
-          break;
-
-        size_t i;
-        for (i = 0; i < cookie_data.size(); i++) {
-          if (cookie_data[i] == ';')
-            break;
-        }
-        if (i < cookie_data.size()) {
-          if (!IsCookieEmpty(cookie_data.substr(0, i))) {
-            cookie_values.push_back(cookie_data.substr(0, i));
-            cookie_length += i + 2 /* semicolon and space */;
-          }
-          cookie_data.remove_prefix(i + 1);
-        } else {
-          if (!IsCookieEmpty(cookie_data)) {
-            cookie_values.push_back(cookie_data);
-            cookie_length += cookie_data.size();
-          } else if (cookie_length > 2) {
-            cookie_length -= 2 /* compensate for previously added length */;
-          }
-          cookie_data.remove_prefix(i);
-        }
-      }
-
-      WriteLengthZ(cookie_length, length_length, kZStandardData, z);
-      for (size_t i = 0; i < cookie_values.size(); i++) {
-        std::string cookie;
-        // Since zlib will only back-reference complete cookies, a cookie that
-        // is currently last (and so doesn't have a trailing semicolon) won't
-        // match if it's later in a non-final position. The same is true of
-        // the first cookie.
-        if (i == 0 && cookie_values.size() == 1) {
-          cookie = cookie_values[i].as_string();
-        } else if (i == 0) {
-          cookie = cookie_values[i].as_string() + ";";
-        } else if (i < cookie_values.size() - 1) {
-          cookie = " " + cookie_values[i].as_string() + ";";
-        } else {
-          cookie = " " + cookie_values[i].as_string();
-        }
-        WriteZ(cookie, kZCookieData, z);
-      }
-    } else if (it->first == "accept" ||
-               it->first == "accept-charset" ||
-               it->first == "accept-encoding" ||
-               it->first == "accept-language" ||
-               it->first == "host" ||
-               it->first == "version" ||
-               it->first == "method" ||
-               it->first == "scheme" ||
-               it->first == ":host" ||
-               it->first == ":version" ||
-               it->first == ":method" ||
-               it->first == ":scheme" ||
-               it->first == "user-agent") {
-      WriteLengthZ(it->second.size(), length_length, kZStandardData, z);
-      WriteZ(it->second, kZStandardData, z);
-    } else {
-      // Non-whitelisted headers are Huffman compressed in their own block, but
-      // don't match against the window.
-      WriteLengthZ(it->second.size(), length_length, kZStandardData, z);
-      WriteZ(it->second, kZHuffmanOnlyData, z);
-    }
-  }
-
-  z->avail_in = 0;
-  int rv = deflate(z, Z_SYNC_FLUSH);
-  DCHECK_EQ(Z_OK, rv);
-  z->clas = kZStandardData;
-}
-
-#endif  // !defined(USE_SYSTEM_ZLIB)
-
 size_t SpdyFramer::ProcessControlFrameBeforeHeaderBlock(const char* data,
                                                         size_t len) {
   DCHECK_EQ(SPDY_CONTROL_FRAME_BEFORE_HEADER_BLOCK, state_);
@@ -1512,67 +1079,19 @@ size_t SpdyFramer::ProcessControlFrameBeforeHeaderBlock(const char* data,
     reader.Seek(GetFrameHeaderSize());  // Seek past frame header.
 
     switch (current_frame_type_) {
-      case SYN_STREAM:
-        {
-          DCHECK_EQ(SPDY3, protocol_version_);
-          bool successful_read = true;
-          successful_read = reader.ReadUInt31(&current_frame_stream_id_);
-          DCHECK(successful_read);
-          if (current_frame_stream_id_ == 0) {
-            set_error(SPDY_INVALID_CONTROL_FRAME);
-            return original_len - len;
-          }
-
-          SpdyStreamId associated_to_stream_id = kInvalidStream;
-          successful_read = reader.ReadUInt31(&associated_to_stream_id);
-          DCHECK(successful_read);
-
-          SpdyPriority priority = 0;
-          successful_read = reader.ReadUInt8(&priority);
-          DCHECK(successful_read);
-          priority = priority >> 5;
-
-          // Seek past unused byte.
-          reader.Seek(1);
-
-          DCHECK(reader.IsDoneReading());
-          if (debug_visitor_) {
-            debug_visitor_->OnReceiveCompressedFrame(
-                current_frame_stream_id_,
-                current_frame_type_,
-                current_frame_length_);
-          }
-          visitor_->OnSynStream(
-              current_frame_stream_id_,
-              associated_to_stream_id,
-              priority,
-              (current_frame_flags_ & CONTROL_FLAG_FIN) != 0,
-              (current_frame_flags_ & CONTROL_FLAG_UNIDIRECTIONAL) != 0);
-        }
-        break;
-      case SYN_REPLY:
-        DCHECK_EQ(SPDY3, protocol_version_);
-        /* FALLTHROUGH */
       case HEADERS:
-        // SYN_REPLY and HEADERS are the same, save for the visitor call.
         {
           bool successful_read = true;
-          if (protocol_version_ == SPDY3) {
-            successful_read = reader.ReadUInt31(&current_frame_stream_id_);
-            DCHECK(successful_read);
-          }
           if (current_frame_stream_id_ == 0) {
             set_error(SPDY_INVALID_CONTROL_FRAME);
             return original_len - len;
           }
-          if (protocol_version_ == HTTP2 &&
-              !(current_frame_flags_ & HEADERS_FLAG_END_HEADERS) &&
+          if (!(current_frame_flags_ & HEADERS_FLAG_END_HEADERS) &&
               current_frame_type_ == HEADERS) {
             expect_continuation_ = current_frame_stream_id_;
             end_stream_when_done_ = current_frame_flags_ & CONTROL_FLAG_FIN;
           }
-          if (protocol_version_ == HTTP2 &&
-              current_frame_flags_ & HEADERS_FLAG_PADDED) {
+          if (current_frame_flags_ & HEADERS_FLAG_PADDED) {
             uint8_t pad_payload_len = 0;
             DCHECK_EQ(remaining_padding_payload_length_, 0u);
             successful_read = reader.ReadUInt8(&pad_payload_len);
@@ -1584,7 +1103,7 @@ size_t SpdyFramer::ProcessControlFrameBeforeHeaderBlock(const char* data,
           int weight = 0;
           uint32_t parent_stream_id = 0;
           bool exclusive = false;
-          if (protocol_version_ == HTTP2 && has_priority) {
+          if (has_priority) {
             uint32_t stream_dependency;
             successful_read = reader.ReadUInt32(&stream_dependency);
             DCHECK(successful_read);
@@ -1601,35 +1120,26 @@ size_t SpdyFramer::ProcessControlFrameBeforeHeaderBlock(const char* data,
           }
           DCHECK(reader.IsDoneReading());
           if (debug_visitor_) {
-            debug_visitor_->OnReceiveCompressedFrame(
-                current_frame_stream_id_,
-                current_frame_type_,
-                current_frame_length_);
-          }
-          if (current_frame_type_ == SYN_REPLY) {
-            visitor_->OnSynReply(
-                current_frame_stream_id_,
-                (current_frame_flags_ & CONTROL_FLAG_FIN) != 0);
-          } else {
-            visitor_->OnHeaders(
-                current_frame_stream_id_,
-                (current_frame_flags_ & HEADERS_FLAG_PRIORITY) != 0, weight,
-                parent_stream_id, exclusive,
-                (current_frame_flags_ & CONTROL_FLAG_FIN) != 0,
-                expect_continuation_ == 0);
+            debug_visitor_->OnReceiveCompressedFrame(current_frame_stream_id_,
+                                                     current_frame_type_,
+                                                     current_frame_length_);
           }
+          visitor_->OnHeaders(
+              current_frame_stream_id_,
+              (current_frame_flags_ & HEADERS_FLAG_PRIORITY) != 0, weight,
+              parent_stream_id, exclusive,
+              (current_frame_flags_ & CONTROL_FLAG_FIN) != 0,
+              expect_continuation_ == 0);
         }
         break;
       case PUSH_PROMISE:
         {
-          DCHECK_EQ(HTTP2, protocol_version_);
           if (current_frame_stream_id_ == 0) {
             set_error(SPDY_INVALID_CONTROL_FRAME);
             return original_len - len;
           }
           bool successful_read = true;
-          if (protocol_version_ == HTTP2 &&
-              current_frame_flags_ & PUSH_PROMISE_FLAG_PADDED) {
+          if (current_frame_flags_ & PUSH_PROMISE_FLAG_PADDED) {
             DCHECK_EQ(remaining_padding_payload_length_, 0u);
             uint8_t pad_payload_len = 0;
             successful_read = reader.ReadUInt8(&pad_payload_len);
@@ -1695,19 +1205,14 @@ size_t SpdyFramer::ProcessControlFrameBeforeHeaderBlock(const char* data,
 #endif
     }
 
-    if (use_new_methods_ && current_frame_type_ != CONTINUATION) {
+    if (current_frame_type_ != CONTINUATION) {
       header_handler_ = visitor_->OnHeaderFrameStart(current_frame_stream_id_);
       if (header_handler_ == nullptr) {
         SPDY_BUG << "visitor_->OnHeaderFrameStart returned nullptr";
         set_error(SPDY_INTERNAL_FRAMER_ERROR);
         return original_len - len;
       }
-      if (protocol_version() == SPDY3) {
-        header_parser_.reset(
-            new SpdyHeadersBlockParser(protocol_version(), header_handler_));
-      } else {
-        GetHpackDecoder()->HandleControlFrameHeadersStart(header_handler_);
-      }
+      GetHpackDecoder()->HandleControlFrameHeadersStart(header_handler_);
     }
     CHANGE_STATE(SPDY_CONTROL_FRAME_HEADER_BLOCK);
   }
@@ -1716,18 +1221,13 @@ size_t SpdyFramer::ProcessControlFrameBeforeHeaderBlock(const char* data,
 
 // Does not buffer the control payload. Instead, either passes directly to the
 // visitor or decompresses and then passes directly to the visitor, via
-// IncrementallyDeliverControlFrameHeaderData() or
-// IncrementallyDecompressControlFrameHeaderData() respectively.
+// IncrementallyDeliverControlFrameHeaderData()
 size_t SpdyFramer::ProcessControlFrameHeaderBlock(const char* data,
-                                                  size_t data_len,
-                                                  bool is_hpack_header_block) {
+                                                  size_t data_len) {
   DCHECK_EQ(SPDY_CONTROL_FRAME_HEADER_BLOCK, state_);
 
   bool processed_successfully = true;
-  if (current_frame_type_ != SYN_STREAM &&
-      current_frame_type_ != SYN_REPLY &&
-      current_frame_type_ != HEADERS &&
-      current_frame_type_ != PUSH_PROMISE &&
+  if (current_frame_type_ != HEADERS && current_frame_type_ != PUSH_PROMISE &&
       current_frame_type_ != CONTINUATION) {
     SPDY_BUG << "Unhandled frame type in ProcessControlFrameHeaderBlock.";
   }
@@ -1739,21 +1239,10 @@ size_t SpdyFramer::ProcessControlFrameHeaderBlock(const char* data,
 
   size_t process_bytes = std::min(
       data_len, remaining_data_length_ - remaining_padding_payload_length_);
-  if (is_hpack_header_block) {
-    if (!GetHpackDecoder()->HandleControlFrameHeadersData(data,
-                                                          process_bytes)) {
-      // TODO(jgraettinger): Finer-grained HPACK error codes.
-      set_error(SPDY_DECOMPRESS_FAILURE);
-      processed_successfully = false;
-    }
-  } else if (process_bytes > 0) {
-    if (protocol_version_ == SPDY3 && enable_compression_) {
-      processed_successfully = IncrementallyDecompressControlFrameHeaderData(
-          current_frame_stream_id_, data, process_bytes);
-    } else {
-      processed_successfully = IncrementallyDeliverControlFrameHeaderData(
-          current_frame_stream_id_, data, process_bytes);
-    }
+  if (!GetHpackDecoder()->HandleControlFrameHeadersData(data, process_bytes)) {
+    // TODO(jgraettinger): Finer-grained HPACK error codes.
+    set_error(SPDY_DECOMPRESS_FAILURE);
+    processed_successfully = false;
   }
   remaining_data_length_ -= process_bytes;
 
@@ -1761,39 +1250,16 @@ size_t SpdyFramer::ProcessControlFrameHeaderBlock(const char* data,
   if (remaining_data_length_ == remaining_padding_payload_length_ &&
       processed_successfully) {
     if (expect_continuation_ == 0) {
-      if (is_hpack_header_block) {
-        size_t compressed_len = 0;
-        if (GetHpackDecoder()->HandleControlFrameHeadersComplete(
-                &compressed_len)) {
-          if (use_new_methods_) {
-            visitor_->OnHeaderFrameEnd(current_frame_stream_id_, true);
-            if (state_ == SPDY_ERROR) {
-              return data_len;
-            }
-          } else {
-            // TODO(jgraettinger): To be removed with migration to
-            // SpdyHeadersHandlerInterface. Serializes the HPACK block as a
-            // SPDY3 block, delivered via reentrant call to
-            // ProcessControlFrameHeaderBlock().
-            DeliverHpackBlockAsSpdy3Block(compressed_len);
-            return process_bytes;
-          }
-        } else {
-          set_error(SPDY_DECOMPRESS_FAILURE);
-          processed_successfully = false;
+      size_t compressed_len = 0;
+      if (GetHpackDecoder()->HandleControlFrameHeadersComplete(
+              &compressed_len)) {
+        visitor_->OnHeaderFrameEnd(current_frame_stream_id_, true);
+        if (state_ == SPDY_ERROR) {
+          return data_len;
         }
       } else {
-        if (use_new_methods_) {
-          visitor_->OnHeaderFrameEnd(current_frame_stream_id_, true);
-          if (state_ == SPDY_ERROR) {
-            return data_len;
-          }
-        } else {
-          // The complete header block has been delivered. We send a zero-length
-          // OnControlFrameHeaderData() to indicated this.
-          visitor_->OnControlFrameHeaderData(current_frame_stream_id_, nullptr,
-                                             0);
-        }
+        set_error(SPDY_DECOMPRESS_FAILURE);
+        processed_successfully = false;
       }
     }
     if (processed_successfully) {
@@ -1822,8 +1288,7 @@ size_t SpdyFramer::ProcessSettingsFrameHeader(const char* data, size_t len) {
     remaining_data_length_ -= bytes_read;
   }
   if (remaining_control_header_ == 0) {
-    if (protocol_version_ == HTTP2 &&
-        current_frame_flags_ & SETTINGS_FLAG_ACK) {
+    if (current_frame_flags_ & SETTINGS_FLAG_ACK) {
       visitor_->OnSettingsAck();
       CHANGE_STATE(SPDY_FRAME_COMPLETE);
     } else {
@@ -1842,7 +1307,7 @@ size_t SpdyFramer::ProcessSettingsFramePayload(const char* data,
   size_t unprocessed_bytes = std::min(data_len, remaining_data_length_);
   size_t processed_bytes = 0;
 
-  size_t setting_size = SpdyConstants::GetSettingSize(protocol_version_);
+  size_t setting_size = 6;
 
   // Loop over our incoming data.
   while (unprocessed_bytes > 0) {
@@ -1887,96 +1352,23 @@ size_t SpdyFramer::ProcessSettingsFramePayload(const char* data,
   return processed_bytes;
 }
 
-void SpdyFramer::DeliverHpackBlockAsSpdy3Block(size_t compressed_len) {
-  DCHECK_EQ(HTTP2, protocol_version_);
-  DCHECK_EQ(remaining_padding_payload_length_, remaining_data_length_);
-
-  const SpdyHeaderBlock& block = GetHpackDecoder()->decoded_block();
-  if (block.empty()) {
-    // Special-case this to make tests happy.
-    ProcessControlFrameHeaderBlock(NULL, 0, false);
-    return;
-  }
-  size_t payload_len = GetSerializedLength(protocol_version_, &block);
-  SpdyFrameBuilder builder(payload_len, SPDY3);
-
-  SerializeHeaderBlockWithoutCompression(&builder, block);
-  SpdySerializedFrame frame = builder.take();
-
-  // Preserve padding length, and reset it after the re-entrant call.
-  size_t remaining_padding = remaining_padding_payload_length_;
-
-  remaining_padding_payload_length_ = 0;
-  remaining_data_length_ = frame.size();
-
-  if (payload_len != 0) {
-    int compression_pct = 100 - (100 * compressed_len) / payload_len;
-    DVLOG(1) << "Net.SpdyHpackDecompressionPercentage: " << compression_pct;
-    UMA_HISTOGRAM_PERCENTAGE("Net.SpdyHpackDecompressionPercentage",
-                             compression_pct);
-  }
-
-  ProcessControlFrameHeaderBlock(frame.data(), frame.size(), false);
-
-  remaining_padding_payload_length_ = remaining_padding;
-  remaining_data_length_ = remaining_padding;
-}
-
 bool SpdyFramer::ProcessSetting(const char* data) {
-  int id_field;
-  SpdySettingsIds id;
-  uint8_t flags = 0;
-  uint32_t value;
-
   // Extract fields.
   // Maintain behavior of old SPDY 2 bug with byte ordering of flags/id.
-  if (protocol_version_ == SPDY3) {
-    const uint32_t id_and_flags_wire =
-        *(reinterpret_cast<const uint32_t*>(data));
-    SettingsFlagsAndId id_and_flags = SettingsFlagsAndId::FromWireFormat(
-        protocol_version_, id_and_flags_wire);
-    id_field = id_and_flags.id();
-    flags = id_and_flags.flags();
-    value = base::NetToHost32(*(reinterpret_cast<const uint32_t*>(data + 4)));
-  } else {
-    id_field = base::NetToHost16(*(reinterpret_cast<const uint16_t*>(data)));
-    value = base::NetToHost32(*(reinterpret_cast<const uint32_t*>(data + 2)));
-  }
+  int id_field = base::NetToHost16(*(reinterpret_cast<const uint16_t*>(data)));
+  int32_t value =
+      base::NetToHost32(*(reinterpret_cast<const uint32_t*>(data + 2)));
 
   // Validate id.
-  if (!SpdyConstants::IsValidSettingId(protocol_version_, id_field)) {
+  SpdySettingsIds setting_id;
+  if (!SpdyConstants::ParseSettingsId(id_field, &setting_id)) {
     DLOG(WARNING) << "Unknown SETTINGS ID: " << id_field;
-    if (protocol_version_ == SPDY3) {
-      return false;
-    } else {
-      // In HTTP2 we ignore unknown settings for extensibility.
-      return true;
-    }
-  }
-  id = SpdyConstants::ParseSettingId(protocol_version_, id_field);
-
-  if (protocol_version_ == SPDY3) {
-    // Detect duplicates.
-    if (id <= settings_scratch_.last_setting_id) {
-      DLOG(WARNING) << "Duplicate entry or invalid ordering for id " << id
-                    << " in " << display_protocol_ << " SETTINGS frame "
-                    << "(last setting id was "
-                    << settings_scratch_.last_setting_id << ").";
-      return false;
-    }
-    settings_scratch_.last_setting_id = id;
-
-    // Validate flags.
-    uint8_t kFlagsMask = SETTINGS_FLAG_PLEASE_PERSIST | SETTINGS_FLAG_PERSISTED;
-    if ((flags & ~(kFlagsMask)) != 0) {
-      DLOG(WARNING) << "Unknown SETTINGS flags provided for id " << id << ": "
-                    << flags;
-      return false;
-    }
+    // Ignore unknown settings for extensibility.
+    return true;
   }
 
   // Validation succeeded. Pass on to visitor.
-  visitor_->OnSetting(id, flags, value);
+  visitor_->OnSetting(setting_id, /*flags=*/0, value);
   return true;
 }
 
@@ -1994,16 +1386,9 @@ size_t SpdyFramer::ProcessControlFramePayload(const char* data, size_t len) {
     switch (current_frame_type_) {
       case PING: {
           SpdyPingId id = 0;
-          bool is_ack = protocol_version_ == HTTP2 &&
-                        (current_frame_flags_ & PING_FLAG_ACK);
+          bool is_ack = current_frame_flags_ & PING_FLAG_ACK;
           bool successful_read = true;
-          if (protocol_version_ == SPDY3) {
-            uint32_t id32 = 0;
-            successful_read = reader.ReadUInt32(&id32);
-            id = id32;
-          } else {
-            successful_read = reader.ReadUInt64(&id);
-          }
+          successful_read = reader.ReadUInt64(&id);
           DCHECK(successful_read);
           DCHECK(reader.IsDoneReading());
           visitor_->OnPing(id, is_ack);
@@ -2012,10 +1397,6 @@ size_t SpdyFramer::ProcessControlFramePayload(const char* data, size_t len) {
       case WINDOW_UPDATE: {
         uint32_t delta_window_size = 0;
           bool successful_read = true;
-          if (protocol_version_ == SPDY3) {
-            successful_read = reader.ReadUInt31(&current_frame_stream_id_);
-            DCHECK(successful_read);
-          }
           successful_read = reader.ReadUInt32(&delta_window_size);
           DCHECK(successful_read);
           DCHECK(reader.IsDoneReading());
@@ -2024,13 +1405,11 @@ size_t SpdyFramer::ProcessControlFramePayload(const char* data, size_t len) {
         }
         break;
       case BLOCKED: {
-          DCHECK_EQ(HTTP2, protocol_version_);
           DCHECK(reader.IsDoneReading());
           visitor_->OnBlocked(current_frame_stream_id_);
         }
         break;
       case PRIORITY: {
-          DCHECK_EQ(HTTP2, protocol_version_);
           uint32_t stream_dependency;
           uint32_t parent_stream_id;
           bool exclusive;
@@ -2092,15 +1471,12 @@ size_t SpdyFramer::ProcessGoAwayFramePayload(const char* data, size_t len) {
       uint32_t status_raw = GOAWAY_OK;
       successful_read = reader.ReadUInt32(&status_raw);
       DCHECK(successful_read);
-      if (SpdyConstants::IsValidGoAwayStatus(protocol_version_, status_raw)) {
-        status =
-            SpdyConstants::ParseGoAwayStatus(protocol_version_, status_raw);
+      if (SpdyConstants::IsValidGoAwayStatus(status_raw)) {
+        status = SpdyConstants::ParseGoAwayStatus(status_raw);
       } else {
-        if (protocol_version_ == HTTP2) {
-          // Treat unrecognized status codes as INTERNAL_ERROR as
-          // recommended by the HTTP/2 spec.
-          status = GOAWAY_INTERNAL_ERROR;
-        }
+        // Treat unrecognized status codes as INTERNAL_ERROR as
+        // recommended by the HTTP/2 spec.
+        status = GOAWAY_INTERNAL_ERROR;
       }
       // Finished parsing the GOAWAY header, call frame handler.
       visitor_->OnGoAway(current_frame_stream_id_, status);
@@ -2148,25 +1524,17 @@ size_t SpdyFramer::ProcessRstStreamFramePayload(const char* data, size_t len) {
       SpdyFrameReader reader(current_frame_buffer_.data(),
                              current_frame_buffer_.len());
       reader.Seek(GetFrameHeaderSize());  // Seek past frame header.
-      if (protocol_version_ == SPDY3) {
-        bool successful_read = reader.ReadUInt31(&current_frame_stream_id_);
-        DCHECK(successful_read);
-      }
 
-      SpdyRstStreamStatus status = RST_STREAM_INVALID;
+      SpdyRstStreamStatus status = RST_STREAM_NO_ERROR;
       uint32_t status_raw = status;
       bool successful_read = reader.ReadUInt32(&status_raw);
       DCHECK(successful_read);
-      if (SpdyConstants::IsValidRstStreamStatus(protocol_version_,
-                                                status_raw)) {
-        status =
-            SpdyConstants::ParseRstStreamStatus(protocol_version_, status_raw);
+      if (SpdyConstants::IsValidRstStreamStatus(status_raw)) {
+        status = SpdyConstants::ParseRstStreamStatus(status_raw);
       } else {
-        if (protocol_version_ == HTTP2) {
-          // Treat unrecognized status codes as INTERNAL_ERROR as
-          // recommended by the HTTP/2 spec.
-          status = RST_STREAM_INTERNAL_ERROR;
-        }
+        // Treat unrecognized status codes as INTERNAL_ERROR as
+        // recommended by the HTTP/2 spec.
+        status = RST_STREAM_INTERNAL_ERROR;
       }
       // Finished parsing the RST_STREAM header, call frame handler.
       visitor_->OnRstStream(current_frame_stream_id_, status);
@@ -2275,8 +1643,6 @@ size_t SpdyFramer::ProcessFramePadding(const char* data, size_t len) {
     DCHECK_EQ(remaining_padding_payload_length_, remaining_data_length_);
     size_t amount_to_discard = std::min(remaining_padding_payload_length_, len);
     if (current_frame_type_ == DATA && amount_to_discard > 0) {
-      SPDY_BUG_IF(protocol_version_ == SPDY3)
-          << "Padding invalid for SPDY version " << protocol_version_;
       visitor_->OnStreamPadding(current_frame_stream_id_, amount_to_discard);
     }
     data += amount_to_discard;
@@ -2359,6 +1725,14 @@ bool SpdyFramer::ParseHeaderBlockInBuffer(const char* header_data,
                << num_headers << ").";
       return false;
     }
+    const char* begin = temp.data();
+    const char* end = begin;
+    std::advance(end, temp.size());
+    if (std::any_of(begin, end, isupper)) {
+      DVLOG(1) << "Malformed header: Header name " << temp
+               << " contains upper-case characters.";
+      return false;
+    }
     std::string name = temp.as_string();
 
     // Read header value.
@@ -2389,42 +1763,89 @@ bool SpdyFramer::ParseHeaderBlockInBuffer(const char* header_data,
   return true;
 }
 
+SpdyFramer::SpdyHeaderFrameIterator::SpdyHeaderFrameIterator(
+    SpdyFramer* framer,
+    std::unique_ptr<SpdyHeadersIR> headers_ir)
+    : headers_ir_(std::move(headers_ir)),
+      framer_(framer),
+      debug_total_size_(0),
+      is_first_frame_(true),
+      has_next_frame_(true) {
+  encoder_ = framer_->GetHpackEncoder()->EncodeHeaderSet(
+      headers_ir_->header_block(), framer_->enable_compression_);
+}
+
+SpdyFramer::SpdyHeaderFrameIterator::~SpdyHeaderFrameIterator() {}
+
+SpdySerializedFrame SpdyFramer::SpdyHeaderFrameIterator::NextFrame() {
+  if (!has_next_frame_) {
+    SPDY_BUG << "SpdyFramer::SpdyHeaderFrameIterator::NextFrame called without "
+             << "a next frame.";
+    return SpdySerializedFrame();
+  }
+
+  size_t size_without_block =
+      is_first_frame_ ? framer_->GetHeaderFrameSizeSansBlock(*headers_ir_)
+                      : framer_->GetContinuationMinimumSize();
+  auto encoding = base::MakeUnique<string>();
+  encoder_->Next(kMaxControlFrameSize - size_without_block, encoding.get());
+  has_next_frame_ = encoder_->HasNext();
+
+  if (framer_->debug_visitor_ != nullptr) {
+    debug_total_size_ += size_without_block;
+    debug_total_size_ += encoding->size();
+    if (!has_next_frame_) {
+      // TODO(birenroy) are these (here and below) still necessary?
+      // HTTP2 uses HPACK for header compression. However, continue to
+      // use GetSerializedLength() for an apples-to-apples comparision of
+      // compression performance between HPACK and SPDY w/ deflate.
+      size_t debug_payload_len =
+          framer_->GetSerializedLength(&headers_ir_->header_block());
+      framer_->debug_visitor_->OnSendCompressedFrame(headers_ir_->stream_id(),
+                                                     HEADERS, debug_payload_len,
+                                                     debug_total_size_);
+    }
+  }
+
+  if (is_first_frame_) {
+    is_first_frame_ = false;
+    headers_ir_->set_end_headers(!has_next_frame_);
+    return framer_->SerializeHeadersGivenEncoding(*headers_ir_, *encoding);
+  } else {
+    SpdyContinuationIR continuation_ir(headers_ir_->stream_id());
+    continuation_ir.set_end_headers(!has_next_frame_);
+    continuation_ir.take_encoding(std::move(encoding));
+    return framer_->SerializeContinuation(continuation_ir);
+  }
+}
+
 SpdySerializedFrame SpdyFramer::SerializeData(const SpdyDataIR& data_ir) const {
   uint8_t flags = DATA_FLAG_NONE;
   if (data_ir.fin()) {
     flags = DATA_FLAG_FIN;
   }
 
-  if (protocol_version_ == SPDY3) {
-    const size_t size = GetDataFrameMinimumSize() + data_ir.data().length();
-    SpdyFrameBuilder builder(size, protocol_version_);
-    builder.WriteDataFrameHeader(*this, data_ir.stream_id(), flags);
-    builder.WriteBytes(data_ir.data().data(), data_ir.data().length());
-    DCHECK_EQ(size, builder.length());
-    return builder.take();
-  } else {
-    int num_padding_fields = 0;
-    if (data_ir.padded()) {
-      flags |= DATA_FLAG_PADDED;
-      ++num_padding_fields;
-    }
+  int num_padding_fields = 0;
+  if (data_ir.padded()) {
+    flags |= DATA_FLAG_PADDED;
+    ++num_padding_fields;
+  }
 
-    const size_t size_with_padding = num_padding_fields +
-        data_ir.data().length() + data_ir.padding_payload_len() +
-        GetDataFrameMinimumSize();
-    SpdyFrameBuilder builder(size_with_padding, protocol_version_);
-    builder.WriteDataFrameHeader(*this, data_ir.stream_id(), flags);
-    if (data_ir.padded()) {
-      builder.WriteUInt8(data_ir.padding_payload_len() & 0xff);
-    }
-    builder.WriteBytes(data_ir.data().data(), data_ir.data().length());
-    if (data_ir.padding_payload_len() > 0) {
-      string padding(data_ir.padding_payload_len(), 0);
-      builder.WriteBytes(padding.data(), padding.length());
-    }
-    DCHECK_EQ(size_with_padding, builder.length());
-    return builder.take();
+  const size_t size_with_padding = num_padding_fields + data_ir.data_len() +
+                                   data_ir.padding_payload_len() +
+                                   GetDataFrameMinimumSize();
+  SpdyFrameBuilder builder(size_with_padding);
+  builder.BeginNewFrame(*this, DATA, flags, data_ir.stream_id());
+  if (data_ir.padded()) {
+    builder.WriteUInt8(data_ir.padding_payload_len() & 0xff);
+  }
+  builder.WriteBytes(data_ir.data(), data_ir.data_len());
+  if (data_ir.padding_payload_len() > 0) {
+    string padding(data_ir.padding_payload_len(), 0);
+    builder.WriteBytes(padding.data(), padding.length());
   }
+  DCHECK_EQ(size_with_padding, builder.length());
+  return builder.take();
 }
 
 SpdySerializedFrame SpdyFramer::SerializeDataFrameHeaderWithPaddingLengthField(
@@ -2436,122 +1857,37 @@ SpdySerializedFrame SpdyFramer::SerializeDataFrameHeaderWithPaddingLengthField(
 
   size_t frame_size = GetDataFrameMinimumSize();
   size_t num_padding_fields = 0;
-  if (protocol_version_ == HTTP2) {
-    if (data_ir.padded()) {
-      flags |= DATA_FLAG_PADDED;
-      ++num_padding_fields;
-    }
+  if (data_ir.padded()) {
+    flags |= DATA_FLAG_PADDED;
+    ++num_padding_fields;
     frame_size += num_padding_fields;
   }
 
-  SpdyFrameBuilder builder(frame_size, protocol_version_);
-  builder.WriteDataFrameHeader(*this, data_ir.stream_id(), flags);
-  if (protocol_version_ == HTTP2) {
-    if (data_ir.padded()) {
-      builder.WriteUInt8(data_ir.padding_payload_len() & 0xff);
-    }
-    builder.OverwriteLength(*this,  num_padding_fields +
-        data_ir.data().length() + data_ir.padding_payload_len());
-  } else {
-    builder.OverwriteLength(*this, data_ir.data().length());
+  SpdyFrameBuilder builder(frame_size);
+  builder.BeginNewFrame(*this, DATA, flags, data_ir.stream_id());
+  if (data_ir.padded()) {
+    builder.WriteUInt8(data_ir.padding_payload_len() & 0xff);
   }
+  builder.OverwriteLength(*this, num_padding_fields + data_ir.data_len() +
+                                     data_ir.padding_payload_len());
   DCHECK_EQ(frame_size, builder.length());
   return builder.take();
 }
 
-SpdySerializedFrame SpdyFramer::SerializeSynStream(
-    const SpdySynStreamIR& syn_stream) {
-  DCHECK_EQ(SPDY3, protocol_version_);
-  uint8_t flags = 0;
-  if (syn_stream.fin()) {
-    flags |= CONTROL_FLAG_FIN;
-  }
-  if (syn_stream.unidirectional()) {
-    flags |= CONTROL_FLAG_UNIDIRECTIONAL;
-  }
-
-  // Sanitize priority.
-  uint8_t priority = syn_stream.priority();
-  if (priority > GetLowestPriority()) {
-    SPDY_BUG << "Priority out-of-bounds.";
-    priority = GetLowestPriority();
-  }
-
-  // The size of this frame, including variable-length header block.
-  size_t size = GetSynStreamMinimumSize() +
-                GetSerializedLength(syn_stream.header_block());
-
-  SpdyFrameBuilder builder(size, protocol_version_);
-  builder.WriteControlFrameHeader(*this, SYN_STREAM, flags);
-  builder.WriteUInt32(syn_stream.stream_id());
-  builder.WriteUInt32(syn_stream.associated_to_stream_id());
-  builder.WriteUInt8(priority << 5);
-  builder.WriteUInt8(0);  // Unused byte.
-  DCHECK_EQ(GetSynStreamMinimumSize(), builder.length());
-  SerializeHeaderBlock(&builder, syn_stream);
-
-  if (debug_visitor_) {
-    const size_t payload_len =
-        GetSerializedLength(protocol_version_, &(syn_stream.header_block()));
-    debug_visitor_->OnSendCompressedFrame(syn_stream.stream_id(),
-                                          SYN_STREAM,
-                                          payload_len,
-                                          builder.length());
-  }
-
-  return builder.take();
-}
-
-SpdySerializedFrame SpdyFramer::SerializeSynReply(
-    const SpdySynReplyIR& syn_reply) {
-  DCHECK_EQ(SPDY3, protocol_version_);
-  uint8_t flags = 0;
-  if (syn_reply.fin()) {
-    flags |= CONTROL_FLAG_FIN;
-  }
-
-  // The size of this frame, including variable-length header block.
-  const size_t size =
-      GetSynReplyMinimumSize() + GetSerializedLength(syn_reply.header_block());
-
-  SpdyFrameBuilder builder(size, protocol_version_);
-  builder.WriteControlFrameHeader(*this, SYN_REPLY, flags);
-  builder.WriteUInt32(syn_reply.stream_id());
-  DCHECK_EQ(GetSynReplyMinimumSize(), builder.length());
-  SerializeHeaderBlock(&builder, syn_reply);
-
-  if (debug_visitor_) {
-    const size_t payload_len =
-        GetSerializedLength(protocol_version_, &(syn_reply.header_block()));
-    debug_visitor_->OnSendCompressedFrame(syn_reply.stream_id(),
-                                          SYN_REPLY,
-                                          payload_len,
-                                          builder.length());
-  }
-
-  return builder.take();
-}
-
 SpdySerializedFrame SpdyFramer::SerializeRstStream(
     const SpdyRstStreamIR& rst_stream) const {
   // TODO(jgraettinger): For now, Chromium will support parsing RST_STREAM
-  // payloads, but will not emit them. SPDY4 is used for draft HTTP/2,
+  // payloads, but will not emit them. This is used for draft HTTP/2,
   // which doesn't currently include RST_STREAM payloads. GFE flags have been
   // commented but left in place to simplify future patching.
   // Compute the output buffer size, taking opaque data into account.
   size_t expected_length = GetRstStreamMinimumSize();
-  SpdyFrameBuilder builder(expected_length, protocol_version_);
+  SpdyFrameBuilder builder(expected_length);
 
-  // Serialize the RST_STREAM frame.
-  if (protocol_version_ == SPDY3) {
-    builder.WriteControlFrameHeader(*this, RST_STREAM, 0);
-    builder.WriteUInt32(rst_stream.stream_id());
-  } else {
-    builder.BeginNewFrame(*this, RST_STREAM, 0, rst_stream.stream_id());
-  }
+  builder.BeginNewFrame(*this, RST_STREAM, 0, rst_stream.stream_id());
 
-  builder.WriteUInt32(SpdyConstants::SerializeRstStreamStatus(
-      protocol_version_, rst_stream.status()));
+  builder.WriteUInt32(
+      SpdyConstants::SerializeRstStreamStatus(rst_stream.status()));
 
   DCHECK_EQ(expected_length, builder.length());
   return builder.take();
@@ -2561,58 +1897,29 @@ SpdySerializedFrame SpdyFramer::SerializeSettings(
     const SpdySettingsIR& settings) const {
   uint8_t flags = 0;
 
-  if (protocol_version_ == SPDY3) {
-    if (settings.clear_settings()) {
-      flags |= SETTINGS_FLAG_CLEAR_PREVIOUSLY_PERSISTED_SETTINGS;
-    }
-  } else {
-    if (settings.is_ack()) {
-      flags |= SETTINGS_FLAG_ACK;
-    }
+  if (settings.is_ack()) {
+    flags |= SETTINGS_FLAG_ACK;
   }
   const SpdySettingsIR::ValueMap* values = &(settings.values());
 
-  size_t setting_size = SpdyConstants::GetSettingSize(protocol_version_);
+  int setting_size = 6;
   // Size, in bytes, of this SETTINGS frame.
   const size_t size = GetSettingsMinimumSize() +
                       (values->size() * setting_size);
-  SpdyFrameBuilder builder(size, protocol_version_);
-  if (protocol_version_ == SPDY3) {
-    builder.WriteControlFrameHeader(*this, SETTINGS, flags);
-  } else {
-    builder.BeginNewFrame(*this, SETTINGS, flags, 0);
-  }
+  SpdyFrameBuilder builder(size);
+  builder.BeginNewFrame(*this, SETTINGS, flags, 0);
 
   // If this is an ACK, payload should be empty.
-  if (protocol_version_ == HTTP2 && settings.is_ack()) {
+  if (settings.is_ack()) {
     return builder.take();
   }
 
-  if (protocol_version_ == SPDY3) {
-    builder.WriteUInt32(values->size());
-  }
   DCHECK_EQ(GetSettingsMinimumSize(), builder.length());
   for (SpdySettingsIR::ValueMap::const_iterator it = values->begin();
-       it != values->end();
-       ++it) {
-    int setting_id =
-        SpdyConstants::SerializeSettingId(protocol_version_, it->first);
+       it != values->end(); ++it) {
+    int setting_id = it->first;
     DCHECK_GE(setting_id, 0);
-    if (protocol_version_ == SPDY3) {
-      uint8_t setting_flags = 0;
-      if (it->second.persist_value) {
-        setting_flags |= SETTINGS_FLAG_PLEASE_PERSIST;
-      }
-      if (it->second.persisted) {
-        setting_flags |= SETTINGS_FLAG_PERSISTED;
-      }
-      SettingsFlagsAndId flags_and_id(setting_flags, setting_id);
-      uint32_t id_and_flags_wire =
-          flags_and_id.GetWireFormat(protocol_version_);
-      builder.WriteBytes(&id_and_flags_wire, 4);
-    } else {
-      builder.WriteUInt16(static_cast<uint16_t>(setting_id));
-    }
+    builder.WriteUInt16(static_cast<uint16_t>(setting_id));
     builder.WriteUInt32(it->second.value);
   }
   DCHECK_EQ(size, builder.length());
@@ -2620,18 +1927,13 @@ SpdySerializedFrame SpdyFramer::SerializeSettings(
 }
 
 SpdySerializedFrame SpdyFramer::SerializePing(const SpdyPingIR& ping) const {
-  SpdyFrameBuilder builder(GetPingSize(), protocol_version_);
-  if (protocol_version_ == SPDY3) {
-    builder.WriteControlFrameHeader(*this, PING, kNoFlags);
-    builder.WriteUInt32(static_cast<uint32_t>(ping.id()));
-  } else {
-    uint8_t flags = 0;
-    if (ping.is_ack()) {
-      flags |= PING_FLAG_ACK;
-    }
-    builder.BeginNewFrame(*this, PING, flags, 0);
-    builder.WriteUInt64(ping.id());
+  SpdyFrameBuilder builder(GetPingSize());
+  uint8_t flags = 0;
+  if (ping.is_ack()) {
+    flags |= PING_FLAG_ACK;
   }
+  builder.BeginNewFrame(*this, PING, flags, 0);
+  builder.WriteUInt64(ping.id());
   DCHECK_EQ(GetPingSize(), builder.length());
   return builder.take();
 }
@@ -2640,27 +1942,20 @@ SpdySerializedFrame SpdyFramer::SerializeGoAway(
     const SpdyGoAwayIR& goaway) const {
   // Compute the output buffer size, take opaque data into account.
   size_t expected_length = GetGoAwayMinimumSize();
-  if (protocol_version_ == HTTP2) {
-    expected_length += goaway.description().size();
-  }
-  SpdyFrameBuilder builder(expected_length, protocol_version_);
+  expected_length += goaway.description().size();
+  SpdyFrameBuilder builder(expected_length);
 
   // Serialize the GOAWAY frame.
-  if (protocol_version_ == SPDY3) {
-    builder.WriteControlFrameHeader(*this, GOAWAY, kNoFlags);
-  } else {
-    builder.BeginNewFrame(*this, GOAWAY, 0, 0);
-  }
+  builder.BeginNewFrame(*this, GOAWAY, 0, 0);
 
-  // GOAWAY frames specify the last good stream id for all SPDY versions.
+  // GOAWAY frames specify the last good stream id.
   builder.WriteUInt32(goaway.last_good_stream_id());
 
   // GOAWAY frames also specify the error status code.
-  builder.WriteUInt32(
-      SpdyConstants::SerializeGoAwayStatus(protocol_version_, goaway.status()));
+  builder.WriteUInt32(SpdyConstants::SerializeGoAwayStatus(goaway.status()));
 
-  // In HTTP2, GOAWAY frames may also specify opaque data.
-  if ((protocol_version_ == HTTP2) && (goaway.description().size() > 0)) {
+  // GOAWAY frames may also specify opaque data.
+  if (!goaway.description().empty()) {
     builder.WriteBytes(goaway.description().data(),
                        goaway.description().size());
   }
@@ -2674,22 +1969,20 @@ SpdySerializedFrame SpdyFramer::SerializeHeaders(const SpdyHeadersIR& headers) {
   if (headers.fin()) {
     flags |= CONTROL_FLAG_FIN;
   }
-  if (protocol_version_ == HTTP2) {
-    // This will get overwritten if we overflow into a CONTINUATION frame.
-    flags |= HEADERS_FLAG_END_HEADERS;
-    if (headers.has_priority()) {
-      flags |= HEADERS_FLAG_PRIORITY;
-    }
-    if (headers.padded()) {
-      flags |= HEADERS_FLAG_PADDED;
-    }
+  // This will get overwritten if we overflow into a CONTINUATION frame.
+  flags |= HEADERS_FLAG_END_HEADERS;
+  if (headers.has_priority()) {
+    flags |= HEADERS_FLAG_PRIORITY;
+  }
+  if (headers.padded()) {
+    flags |= HEADERS_FLAG_PADDED;
   }
 
   // The size of this frame, including padding (if there is any) and
   // variable-length header block.
   size_t size = GetHeadersMinimumSize();
 
-  if (protocol_version_ == HTTP2 && headers.padded()) {
+  if (headers.padded()) {
     size += kPadLengthFieldSize;
     size += headers.padding_payload_len();
   }
@@ -2701,63 +1994,42 @@ SpdySerializedFrame SpdyFramer::SerializeHeaders(const SpdyHeadersIR& headers) {
   }
 
   string hpack_encoding;
-  if (protocol_version_ == SPDY3) {
-    size += GetSerializedLength(headers.header_block());
+  if (enable_compression_) {
+    GetHpackEncoder()->EncodeHeaderSet(headers.header_block(), &hpack_encoding);
   } else {
-    if (enable_compression_) {
-      GetHpackEncoder()->EncodeHeaderSet(headers.header_block(),
-                                         &hpack_encoding);
-    } else {
-      GetHpackEncoder()->EncodeHeaderSetWithoutCompression(
-          headers.header_block(), &hpack_encoding);
-    }
-    size += hpack_encoding.size();
-    if (size > kMaxControlFrameSize) {
-      size += GetNumberRequiredContinuationFrames(size) *
-              GetContinuationMinimumSize();
-      flags &= ~HEADERS_FLAG_END_HEADERS;
-    }
+    GetHpackEncoder()->EncodeHeaderSetWithoutCompression(headers.header_block(),
+                                                         &hpack_encoding);
   }
-
-  SpdyFrameBuilder builder(size, protocol_version_);
-  if (protocol_version_ == SPDY3) {
-    builder.WriteControlFrameHeader(*this, HEADERS, flags);
-    builder.WriteUInt32(headers.stream_id());
-  } else {
-    builder.BeginNewFrame(*this,
-                          HEADERS,
-                          flags,
-                          headers.stream_id());
+  size += hpack_encoding.size();
+  if (size > kMaxControlFrameSize) {
+    size += GetNumberRequiredContinuationFrames(size) *
+            GetContinuationMinimumSize();
+    flags &= ~HEADERS_FLAG_END_HEADERS;
   }
+
+  SpdyFrameBuilder builder(size);
+  builder.BeginNewFrame(*this, HEADERS, flags, headers.stream_id());
   DCHECK_EQ(GetHeadersMinimumSize(), builder.length());
 
-  if (protocol_version_ == SPDY3) {
-    SerializeHeaderBlock(&builder, headers);
-  } else {
-    int padding_payload_len = 0;
-    if (headers.padded()) {
-      builder.WriteUInt8(headers.padding_payload_len());
-      padding_payload_len = headers.padding_payload_len();
-    }
-    if (headers.has_priority()) {
-      builder.WriteUInt32(PackStreamDependencyValues(
-          headers.exclusive(), headers.parent_stream_id()));
-      // Per RFC 7540 section 6.3, serialized weight value is actual value - 1.
-      builder.WriteUInt8(weight - 1);
-    }
-    WritePayloadWithContinuation(&builder,
-                                 hpack_encoding,
-                                 headers.stream_id(),
-                                 HEADERS,
-                                 padding_payload_len);
+  int padding_payload_len = 0;
+  if (headers.padded()) {
+    builder.WriteUInt8(headers.padding_payload_len());
+    padding_payload_len = headers.padding_payload_len();
+  }
+  if (headers.has_priority()) {
+    builder.WriteUInt32(PackStreamDependencyValues(headers.exclusive(),
+                                                   headers.parent_stream_id()));
+    // Per RFC 7540 section 6.3, serialized weight value is actual value - 1.
+    builder.WriteUInt8(weight - 1);
   }
+  WritePayloadWithContinuation(&builder, hpack_encoding, headers.stream_id(),
+                               HEADERS, padding_payload_len);
 
   if (debug_visitor_) {
     // HTTP2 uses HPACK for header compression. However, continue to
     // use GetSerializedLength() for an apples-to-apples comparision of
     // compression performance between HPACK and SPDY w/ deflate.
-    const size_t payload_len =
-        GetSerializedLength(protocol_version_, &(headers.header_block()));
+    const size_t payload_len = GetSerializedLength(&(headers.header_block()));
     debug_visitor_->OnSendCompressedFrame(headers.stream_id(),
                                           HEADERS,
                                           payload_len,
@@ -2769,16 +2041,9 @@ SpdySerializedFrame SpdyFramer::SerializeHeaders(const SpdyHeadersIR& headers) {
 
 SpdySerializedFrame SpdyFramer::SerializeWindowUpdate(
     const SpdyWindowUpdateIR& window_update) const {
-  SpdyFrameBuilder builder(GetWindowUpdateSize(), protocol_version_);
-  if (protocol_version_ == SPDY3) {
-    builder.WriteControlFrameHeader(*this, WINDOW_UPDATE, kNoFlags);
-    builder.WriteUInt32(window_update.stream_id());
-  } else {
-    builder.BeginNewFrame(*this,
-                          WINDOW_UPDATE,
-                          kNoFlags,
-                          window_update.stream_id());
-  }
+  SpdyFrameBuilder builder(GetWindowUpdateSize());
+  builder.BeginNewFrame(*this, WINDOW_UPDATE, kNoFlags,
+                        window_update.stream_id());
   builder.WriteUInt32(window_update.delta());
   DCHECK_EQ(GetWindowUpdateSize(), builder.length());
   return builder.take();
@@ -2786,15 +2051,13 @@ SpdySerializedFrame SpdyFramer::SerializeWindowUpdate(
 
 SpdySerializedFrame SpdyFramer::SerializeBlocked(
     const SpdyBlockedIR& blocked) const {
-  DCHECK_EQ(HTTP2, protocol_version_);
-  SpdyFrameBuilder builder(GetBlockedSize(), protocol_version_);
+  SpdyFrameBuilder builder(GetBlockedSize());
   builder.BeginNewFrame(*this, BLOCKED, kNoFlags, blocked.stream_id());
   return builder.take();
 }
 
 SpdySerializedFrame SpdyFramer::SerializePushPromise(
     const SpdyPushPromiseIR& push_promise) {
-  DCHECK_EQ(HTTP2, protocol_version_);
   uint8_t flags = 0;
   // This will get overwritten if we overflow into a CONTINUATION frame.
   flags |= PUSH_PROMISE_FLAG_END_PUSH_PROMISE;
@@ -2822,7 +2085,7 @@ SpdySerializedFrame SpdyFramer::SerializePushPromise(
     flags &= ~PUSH_PROMISE_FLAG_END_PUSH_PROMISE;
   }
 
-  SpdyFrameBuilder builder(size, protocol_version_);
+  SpdyFrameBuilder builder(size);
   builder.BeginNewFrame(*this,
                         PUSH_PROMISE,
                         flags,
@@ -2851,7 +2114,7 @@ SpdySerializedFrame SpdyFramer::SerializePushPromise(
     // use GetSerializedLength() for an apples-to-apples comparision of
     // compression performance between HPACK and SPDY w/ deflate.
     const size_t payload_len =
-        GetSerializedLength(protocol_version_, &(push_promise.header_block()));
+        GetSerializedLength(&(push_promise.header_block()));
     debug_visitor_->OnSendCompressedFrame(push_promise.stream_id(),
                                           PUSH_PROMISE,
                                           payload_len,
@@ -2861,48 +2124,57 @@ SpdySerializedFrame SpdyFramer::SerializePushPromise(
   return builder.take();
 }
 
-// TODO(jgraettinger): This implementation is incorrect. The continuation
-// frame continues a previously-begun HPACK encoding; it doesn't begin a
-// new one. Figure out whether it makes sense to keep SerializeContinuation().
-SpdySerializedFrame SpdyFramer::SerializeContinuation(
-    const SpdyContinuationIR& continuation) {
-  CHECK_EQ(HTTP2, protocol_version_);
-  uint8_t flags = 0;
-  if (continuation.end_headers()) {
-    flags |= HEADERS_FLAG_END_HEADERS;
+SpdySerializedFrame SpdyFramer::SerializeHeadersGivenEncoding(
+    const SpdyHeadersIR& headers,
+    const string& encoding) const {
+  size_t frame_size = GetHeaderFrameSizeSansBlock(headers) + encoding.size();
+  SpdyFrameBuilder builder(frame_size);
+  builder.BeginNewFrame(*this, HEADERS, SerializeHeaderFrameFlags(headers),
+                        headers.stream_id());
+  DCHECK_EQ(GetFrameHeaderSize(), builder.length());
+
+  if (headers.padded()) {
+    builder.WriteUInt8(headers.padding_payload_len());
   }
 
-  // The size of this frame, including variable-length name-value block.
-  size_t size = GetContinuationMinimumSize();
-  string hpack_encoding;
-  if (enable_compression_) {
-    GetHpackEncoder()->EncodeHeaderSet(continuation.header_block(),
-                                       &hpack_encoding);
-  } else {
-    GetHpackEncoder()->EncodeHeaderSetWithoutCompression(
-        continuation.header_block(), &hpack_encoding);
+  if (headers.has_priority()) {
+    int weight = ClampHttp2Weight(headers.weight());
+    builder.WriteUInt32(PackStreamDependencyValues(headers.exclusive(),
+                                                   headers.parent_stream_id()));
+    // Per RFC 7540 section 6.3, serialized weight value is actual value - 1.
+    builder.WriteUInt8(weight - 1);
   }
-  size += hpack_encoding.size();
 
-  SpdyFrameBuilder builder(size, protocol_version_);
-  builder.BeginNewFrame(*this, CONTINUATION, flags,
-      continuation.stream_id());
-  DCHECK_EQ(GetContinuationMinimumSize(), builder.length());
+  builder.WriteBytes(&encoding[0], encoding.size());
 
-  builder.WriteBytes(&hpack_encoding[0], hpack_encoding.size());
+  if (headers.padding_payload_len() > 0) {
+    string padding(headers.padding_payload_len(), 0);
+    builder.WriteBytes(padding.data(), padding.length());
+  }
   return builder.take();
 }
 
-SpdySerializedFrame SpdyFramer::SerializeAltSvc(const SpdyAltSvcIR& altsvc_ir) {
-  DCHECK_EQ(HTTP2, protocol_version_);
+SpdySerializedFrame SpdyFramer::SerializeContinuation(
+    const SpdyContinuationIR& continuation) const {
+  const string& encoding = continuation.encoding();
+  size_t frame_size = GetContinuationMinimumSize() + encoding.size();
+  SpdyFrameBuilder builder(frame_size);
+  uint8_t flags = continuation.end_headers() ? HEADERS_FLAG_END_HEADERS : 0;
+  builder.BeginNewFrame(*this, CONTINUATION, flags, continuation.stream_id());
+  DCHECK_EQ(GetFrameHeaderSize(), builder.length());
+
+  builder.WriteBytes(&encoding[0], encoding.size());
+  return builder.take();
+}
 
+SpdySerializedFrame SpdyFramer::SerializeAltSvc(const SpdyAltSvcIR& altsvc_ir) {
   size_t size = GetAltSvcMinimumSize();
   size += altsvc_ir.origin().length();
   string value = SpdyAltSvcWireFormat::SerializeHeaderFieldValue(
       altsvc_ir.altsvc_vector());
   size += value.length();
 
-  SpdyFrameBuilder builder(size, protocol_version_);
+  SpdyFrameBuilder builder(size);
   builder.BeginNewFrame(*this, ALTSVC, kNoFlags, altsvc_ir.stream_id());
 
   builder.WriteUInt16(altsvc_ir.origin().length());
@@ -2914,10 +2186,9 @@ SpdySerializedFrame SpdyFramer::SerializeAltSvc(const SpdyAltSvcIR& altsvc_ir) {
 
 SpdySerializedFrame SpdyFramer::SerializePriority(
     const SpdyPriorityIR& priority) const {
-  DCHECK_EQ(HTTP2, protocol_version_);
   size_t size = GetPrioritySize();
 
-  SpdyFrameBuilder builder(size, protocol_version_);
+  SpdyFrameBuilder builder(size);
   builder.BeginNewFrame(*this, PRIORITY, kNoFlags, priority.stream_id());
 
   builder.WriteUInt32(PackStreamDependencyValues(priority.exclusive(),
@@ -2941,12 +2212,6 @@ class FrameSerializationVisitor : public SpdyFrameVisitor {
   void VisitData(const SpdyDataIR& data) override {
     frame_ = framer_->SerializeData(data);
   }
-  void VisitSynStream(const SpdySynStreamIR& syn_stream) override {
-    frame_ = framer_->SerializeSynStream(syn_stream);
-  }
-  void VisitSynReply(const SpdySynReplyIR& syn_reply) override {
-    frame_ = framer_->SerializeSynReply(syn_reply);
-  }
   void VisitRstStream(const SpdyRstStreamIR& rst_stream) override {
     frame_ = framer_->SerializeRstStream(rst_stream);
   }
@@ -2994,20 +2259,7 @@ SpdySerializedFrame SpdyFramer::SerializeFrame(const SpdyFrameIR& frame) {
   return visitor.ReleaseSerializedFrame();
 }
 
-size_t SpdyFramer::GetSerializedLength(const SpdyHeaderBlock& headers) {
-  const size_t uncompressed_length =
-      GetSerializedLength(protocol_version_, &headers);
-  if (!enable_compression_) {
-    return uncompressed_length;
-  }
-  z_stream* compressor = GetHeaderCompressor();
-  // Since we'll be performing lots of flushes when compressing the data,
-  // zlib's lower bounds may be insufficient.
-  return 2 * deflateBound(compressor, uncompressed_length);
-}
-
 size_t SpdyFramer::GetNumberRequiredContinuationFrames(size_t size) {
-  DCHECK_EQ(HTTP2, protocol_version_);
   DCHECK_GT(size, kMaxControlFrameSize);
   size_t overflow = size - kMaxControlFrameSize;
   size_t payload_size = kMaxControlFrameSize - GetContinuationMinimumSize();
@@ -3015,6 +2267,40 @@ size_t SpdyFramer::GetNumberRequiredContinuationFrames(size_t size) {
   return (overflow - 1) / payload_size + 1;
 }
 
+size_t SpdyFramer::GetHeaderFrameSizeSansBlock(
+    const SpdyHeadersIR& header_ir) const {
+  size_t min_size = GetFrameHeaderSize();
+
+  if (header_ir.padded()) {
+    min_size += 1;
+    min_size += header_ir.padding_payload_len();
+  }
+
+  if (header_ir.has_priority()) {
+    min_size += 5;
+  }
+
+  return min_size;
+}
+
+uint8_t SpdyFramer::SerializeHeaderFrameFlags(
+    const SpdyHeadersIR& header_ir) const {
+  uint8_t flags = 0;
+  if (header_ir.fin()) {
+    flags |= CONTROL_FLAG_FIN;
+  }
+  if (header_ir.end_headers()) {
+    flags |= HEADERS_FLAG_END_HEADERS;
+  }
+  if (header_ir.padded()) {
+    flags |= HEADERS_FLAG_PADDED;
+  }
+  if (header_ir.has_priority()) {
+    flags |= HEADERS_FLAG_PRIORITY;
+  }
+  return flags;
+}
+
 void SpdyFramer::WritePayloadWithContinuation(SpdyFrameBuilder* builder,
                                               const string& hpack_encoding,
                                               SpdyStreamId stream_id,
@@ -3066,68 +2352,7 @@ void SpdyFramer::WritePayloadWithContinuation(SpdyFrameBuilder* builder,
   }
 }
 
-// The following compression setting are based on Brian Olson's analysis. See
-// https://groups.google.com/group/spdy-dev/browse_thread/thread/dfaf498542fac792
-// for more details.
-#if defined(USE_SYSTEM_ZLIB)
-// System zlib is not expected to have workaround for http://crbug.com/139744,
-// so disable compression in that case.
-// TODO(phajdan.jr): Remove the special case when it's no longer necessary.
-static const int kCompressorLevel = 0;
-#else  // !defined(USE_SYSTEM_ZLIB)
-static const int kCompressorLevel = 9;
-#endif  // !defined(USE_SYSTEM_ZLIB)
-static const int kCompressorWindowSizeInBits = 11;
-static const int kCompressorMemLevel = 1;
-
-z_stream* SpdyFramer::GetHeaderCompressor() {
-  if (header_compressor_.get()) {
-    return header_compressor_.get();  // Already initialized.
-  }
-
-  header_compressor_.reset(new z_stream);
-  memset(header_compressor_.get(), 0, sizeof(z_stream));
-
-  int success = deflateInit2(header_compressor_.get(),
-                             kCompressorLevel,
-                             Z_DEFLATED,
-                             kCompressorWindowSizeInBits,
-                             kCompressorMemLevel,
-                             Z_DEFAULT_STRATEGY);
-  if (success == Z_OK) {
-    const char* dictionary = kV3Dictionary;
-    const int dictionary_size = kV3DictionarySize;
-    success = deflateSetDictionary(header_compressor_.get(),
-                                   reinterpret_cast<const Bytef*>(dictionary),
-                                   dictionary_size);
-  }
-  if (success != Z_OK) {
-    LOG(WARNING) << "deflateSetDictionary failure: " << success;
-    header_compressor_.reset(NULL);
-    return NULL;
-  }
-  return header_compressor_.get();
-}
-
-z_stream* SpdyFramer::GetHeaderDecompressor() {
-  if (header_decompressor_.get()) {
-    return header_decompressor_.get();  // Already initialized.
-  }
-
-  header_decompressor_.reset(new z_stream);
-  memset(header_decompressor_.get(), 0, sizeof(z_stream));
-
-  int success = inflateInit(header_decompressor_.get());
-  if (success != Z_OK) {
-    LOG(WARNING) << "inflateInit failure: " << success;
-    header_decompressor_.reset(NULL);
-    return NULL;
-  }
-  return header_decompressor_.get();
-}
-
 HpackEncoder* SpdyFramer::GetHpackEncoder() {
-  DCHECK_EQ(HTTP2, protocol_version_);
   if (hpack_encoder_.get() == nullptr) {
     hpack_encoder_.reset(new HpackEncoder(ObtainHpackHuffmanTable()));
   }
@@ -3135,92 +2360,14 @@ HpackEncoder* SpdyFramer::GetHpackEncoder() {
 }
 
 HpackDecoderInterface* SpdyFramer::GetHpackDecoder() {
-  DCHECK_EQ(HTTP2, protocol_version_);
   if (hpack_decoder_.get() == nullptr) {
-    hpack_decoder_.reset(new HpackDecoder());
-  }
-  return hpack_decoder_.get();
-}
-
-// Incrementally decompress the control frame's header block, feeding the
-// result to the visitor in chunks. Continue this until the visitor
-// indicates that it cannot process any more data, or (more commonly) we
-// run out of data to deliver.
-bool SpdyFramer::IncrementallyDecompressControlFrameHeaderData(
-    SpdyStreamId stream_id,
-    const char* data,
-    size_t len) {
-  // Get a decompressor or set error.
-  z_stream* decomp = GetHeaderDecompressor();
-  if (decomp == NULL) {
-    SPDY_BUG << "Couldn't get decompressor for handling compressed headers.";
-    set_error(SPDY_DECOMPRESS_FAILURE);
-    return false;
-  }
-
-  bool processed_successfully = true;
-  char buffer[kHeaderDataChunkMaxSize];
-
-  decomp->next_in = reinterpret_cast<Bytef*>(const_cast<char*>(data));
-  decomp->avail_in = len;
-  // If we get a SYN_STREAM/SYN_REPLY/HEADERS frame with stream ID zero, we
-  // signal an error back in ProcessControlFrameBeforeHeaderBlock.  So if we've
-  // reached this method successfully, stream_id should be nonzero.
-  DCHECK_LT(0u, stream_id);
-  while (decomp->avail_in > 0 && processed_successfully) {
-    decomp->next_out = reinterpret_cast<Bytef*>(buffer);
-    decomp->avail_out = arraysize(buffer);
-
-    int rv = inflate(decomp, Z_SYNC_FLUSH);
-    if (rv == Z_NEED_DICT) {
-      const char* dictionary = kV3Dictionary;
-      const int dictionary_size = kV3DictionarySize;
-      const DictionaryIds& ids = g_dictionary_ids.Get();
-      const uLong dictionary_id = ids.v3_dictionary_id;
-      // Need to try again with the right dictionary.
-      if (decomp->adler == dictionary_id) {
-        rv = inflateSetDictionary(decomp,
-                                  reinterpret_cast<const Bytef*>(dictionary),
-                                  dictionary_size);
-        if (rv == Z_OK) {
-          rv = inflate(decomp, Z_SYNC_FLUSH);
-        }
-      }
-    }
-
-    // Inflate will generate a Z_BUF_ERROR if it runs out of input
-    // without producing any output.  The input is consumed and
-    // buffered internally by zlib so we can detect this condition by
-    // checking if avail_in is 0 after the call to inflate.
-    bool input_exhausted = ((rv == Z_BUF_ERROR) && (decomp->avail_in == 0));
-    if ((rv == Z_OK) || input_exhausted) {
-      size_t decompressed_len = arraysize(buffer) - decomp->avail_out;
-      if (decompressed_len > 0) {
-        if (use_new_methods_) {
-          processed_successfully =
-              header_parser_->HandleControlFrameHeadersData(stream_id, buffer,
-                                                            decompressed_len);
-          if (header_parser_->get_error() ==
-              SpdyHeadersBlockParser::NEED_MORE_DATA) {
-            processed_successfully = true;
-          }
-        } else {
-          processed_successfully = visitor_->OnControlFrameHeaderData(
-              stream_id, buffer, decompressed_len);
-        }
-      }
-      if (!processed_successfully) {
-        // Assume that the problem was the header block was too large for the
-        // visitor.
-        set_error(SPDY_CONTROL_PAYLOAD_TOO_LARGE);
-      }
+    if (FLAGS_chromium_http2_flag_spdy_use_hpack_decoder2) {
+      hpack_decoder_.reset(new HpackDecoder2());
     } else {
-      DLOG(WARNING) << "inflate failure: " << rv << " " << len;
-      set_error(SPDY_DECOMPRESS_FAILURE);
-      processed_successfully = false;
+      hpack_decoder_.reset(new HpackDecoder());
     }
   }
-  return processed_successfully;
+  return hpack_decoder_.get();
 }
 
 bool SpdyFramer::IncrementallyDeliverControlFrameHeaderData(
@@ -3228,16 +2375,10 @@ bool SpdyFramer::IncrementallyDeliverControlFrameHeaderData(
   bool read_successfully = true;
   while (read_successfully && len > 0) {
     size_t bytes_to_deliver = std::min(len, kHeaderDataChunkMaxSize);
-    if (use_new_methods_) {
-      read_successfully = header_parser_->HandleControlFrameHeadersData(
-          stream_id, data, bytes_to_deliver);
-      if (header_parser_->get_error() ==
-          SpdyHeadersBlockParser::NEED_MORE_DATA) {
-        read_successfully = true;
-      }
-    } else {
-      read_successfully =
-          visitor_->OnControlFrameHeaderData(stream_id, data, bytes_to_deliver);
+    read_successfully = header_parser_->HandleControlFrameHeadersData(
+        stream_id, data, bytes_to_deliver);
+    if (header_parser_->get_error() == SpdyHeadersBlockParser::NEED_MORE_DATA) {
+      read_successfully = true;
     }
     data += bytes_to_deliver;
     len -= bytes_to_deliver;
@@ -3288,67 +2429,9 @@ void SpdyFramer::SerializeHeaderBlockWithoutCompression(
 
   // Serialize each header.
   for (const auto& header : header_block) {
-    builder->WriteStringPiece32(header.first);
+    builder->WriteStringPiece32(base::ToLowerASCII(header.first));
     builder->WriteStringPiece32(header.second);
   }
 }
 
-void SpdyFramer::SerializeHeaderBlock(SpdyFrameBuilder* builder,
-                                      const SpdyFrameWithHeaderBlockIR& frame) {
-  if (!enable_compression_) {
-    return SerializeHeaderBlockWithoutCompression(builder,
-                                                  frame.header_block());
-  }
-
-  // First build an uncompressed version to be fed into the compressor.
-  const size_t uncompressed_len =
-      GetSerializedLength(protocol_version_, &(frame.header_block()));
-  SpdyFrameBuilder uncompressed_builder(uncompressed_len, protocol_version_);
-  SerializeHeaderBlockWithoutCompression(&uncompressed_builder,
-                                         frame.header_block());
-  SpdySerializedFrame uncompressed_payload(uncompressed_builder.take());
-
-  z_stream* compressor = GetHeaderCompressor();
-  if (!compressor) {
-    SPDY_BUG << "Could not obtain compressor.";
-    return;
-  }
-  // Create an output frame.
-  // Since we'll be performing lots of flushes when compressing the data,
-  // zlib's lower bounds may be insufficient.
-  //
-  // TODO(akalin): Avoid the duplicate calculation with
-  // GetSerializedLength(const SpdyHeaderBlock&).
-  const int compressed_max_size =
-      2 * deflateBound(compressor, uncompressed_len);
-
-  // TODO(phajdan.jr): Clean up after we no longer need
-  // to workaround http://crbug.com/139744.
-#if defined(USE_SYSTEM_ZLIB)
-  compressor->next_in = reinterpret_cast<Bytef*>(uncompressed_payload.data());
-  compressor->avail_in = uncompressed_len;
-#endif  // defined(USE_SYSTEM_ZLIB)
-  compressor->next_out = reinterpret_cast<Bytef*>(
-      builder->GetWritableBuffer(compressed_max_size));
-  compressor->avail_out = compressed_max_size;
-
-  // TODO(phajdan.jr): Clean up after we no longer need
-  // to workaround http://crbug.com/139744.
-#if defined(USE_SYSTEM_ZLIB)
-  int rv = deflate(compressor, Z_SYNC_FLUSH);
-  if (rv != Z_OK) {  // How can we know that it compressed everything?
-    // This shouldn't happen, right?
-    LOG(WARNING) << "deflate failure: " << rv;
-    // TODO(akalin): Upstream this return.
-    return;
-  }
-#else
-  WriteHeaderBlockToZ(&frame.header_block(), compressor);
-#endif  // defined(USE_SYSTEM_ZLIB)
-
-  int compressed_size = compressed_max_size - compressor->avail_out;
-  builder->Seek(compressed_size);
-  builder->RewriteLength(*this);
-}
-
 }  // namespace net
diff --git a/src/net/spdy/spdy_framer.h b/src/net/spdy/spdy_framer.h
index acde58d..223fdf8 100644
--- a/src/net/spdy/spdy_framer.h
+++ b/src/net/spdy/spdy_framer.h
@@ -16,7 +16,6 @@
 #include "base/strings/string_piece.h"
 #include "base/sys_byteorder.h"
 #include "net/base/net_export.h"
-#include "net/spdy/hpack/hpack_decoder.h"
 #include "net/spdy/hpack/hpack_decoder_interface.h"
 #include "net/spdy/hpack/hpack_encoder.h"
 #include "net/spdy/spdy_alt_svc_wire_format.h"
@@ -26,8 +25,6 @@
 #include "net/spdy/spdy_headers_handler_interface.h"
 #include "net/spdy/spdy_protocol.h"
 
-typedef struct z_stream_s z_stream;  // Forward declaration for zlib.
-
 namespace net {
 
 class HttpProxyClientSocketPoolTest;
@@ -54,15 +51,14 @@ class SpdyFramerPeer;
 // Conveniently handles converstion to/from wire format.
 class NET_EXPORT_PRIVATE SettingsFlagsAndId {
  public:
-  static SettingsFlagsAndId FromWireFormat(SpdyMajorVersion version,
-                                           uint32_t wire);
+  static SettingsFlagsAndId FromWireFormat(uint32_t wire);
 
   SettingsFlagsAndId() : flags_(0), id_(0) {}
 
   // TODO(hkhalil): restrict to enums instead of free-form ints.
   SettingsFlagsAndId(uint8_t flags, uint32_t id);
 
-  uint32_t GetWireFormat(SpdyMajorVersion version) const;
+  uint32_t GetWireFormat() const;
 
   uint32_t id() const { return id_; }
   uint8_t flags() const { return flags_; }
@@ -80,24 +76,18 @@ typedef std::map<SpdySettingsIds, SettingsFlagsAndValue> SettingsMap;
 // Implement this interface to receive event callbacks as frames are
 // decoded from the framer.
 //
-// Control frames that contain SPDY header blocks (SYN_STREAM, SYN_REPLY,
-// HEADER, and PUSH_PROMISE) are processed in fashion that allows the
-// decompressed header block to be delivered in chunks to the visitor.
+// Control frames that contain HTTP2 header blocks (HEADER, and PUSH_PROMISE)
+// are processed in fashion that allows the decompressed header block to be
+// delivered in chunks to the visitor.
 // The following steps are followed:
-//   1. OnSynStream, OnSynReply, OnHeaders, or OnPushPromise is called.
-//   2. Repeated: OnControlFrameHeaderData is called with chunks of the
-//      decompressed header block. In each call the len parameter is greater
-//      than zero.
-//   3. OnControlFrameHeaderData is called with len set to zero, indicating
-//      that the full header block has been delivered for the control frame.
-// During step 2 the visitor may return false, indicating that the chunk of
-// header data could not be handled by the visitor (typically this indicates
-// resource exhaustion). If this occurs the framer will discontinue
-// delivering chunks to the visitor, set a SPDY_CONTROL_PAYLOAD_TOO_LARGE
-// error, and clean up appropriately. Note that this will cause the header
-// decompressor to lose synchronization with the sender's header compressor,
-// making the SPDY session unusable for future work. The visitor's OnError
-// function should deal with this condition by closing the SPDY connection.
+//   1. OnHeaders, or OnPushPromise is called.
+//   2. OnHeaderFrameStart is called; visitor is expected to return an instance
+//      of SpdyHeadersHandlerInterface that will receive the header key-value
+//      pairs.
+//   3. OnHeaderFrameEnd is called, indicating that the full header block has
+//      been delivered for the control frame.
+// During step 2, if the visitor is not interested in accepting the header data,
+// it should return a no-op implementation of SpdyHeadersHandlerInterface.
 class NET_EXPORT_PRIVATE SpdyFramerVisitorInterface {
  public:
   virtual ~SpdyFramerVisitorInterface() {}
@@ -150,33 +140,6 @@ class NET_EXPORT_PRIVATE SpdyFramerVisitorInterface {
   // frames.
   virtual void OnHeaderFrameEnd(SpdyStreamId stream_id, bool end_headers) = 0;
 
-  // Called when a chunk of header data is available. This is called
-  // after OnSynStream, OnSynReply, OnHeaders(), or OnPushPromise.
-  // |stream_id| The stream receiving the header data.
-  // |header_data| A buffer containing the header data chunk received.
-  // |len| The length of the header data buffer. A length of zero indicates
-  //       that the header data block has been completely sent.
-  // When this function returns true the visitor indicates that it accepted
-  // all of the data. Returning false indicates that that an unrecoverable
-  // error has occurred, such as bad header data or resource exhaustion.
-  virtual bool OnControlFrameHeaderData(SpdyStreamId stream_id,
-                                        const char* header_data,
-                                        size_t len) = 0;
-
-  // Called when a SYN_STREAM frame is received.
-  // Note that header block data is not included. See
-  // OnControlFrameHeaderData().
-  virtual void OnSynStream(SpdyStreamId stream_id,
-                           SpdyStreamId associated_stream_id,
-                           SpdyPriority priority,
-                           bool fin,
-                           bool unidirectional) = 0;
-
-  // Called when a SYN_REPLY frame is received.
-  // Note that header block data is not included. See
-  // OnControlFrameHeaderData().
-  virtual void OnSynReply(SpdyStreamId stream_id, bool fin) = 0;
-
   // Called when a RST_STREAM frame has been parsed.
   virtual void OnRstStream(SpdyStreamId stream_id,
                            SpdyRstStreamStatus status) = 0;
@@ -203,18 +166,16 @@ class NET_EXPORT_PRIVATE SpdyFramerVisitorInterface {
                         SpdyGoAwayStatus status) = 0;
 
   // Called when a HEADERS frame is received.
-  // Note that header block data is not included. See
-  // OnControlFrameHeaderData().
+  // Note that header block data is not included. See OnHeaderFrameStart().
   // |stream_id| The stream receiving the header.
   // |has_priority| Whether or not the headers frame included a priority value,
-  //     and, if protocol version == HTTP2, stream dependency info.
+  //     and stream dependency info.
   // |weight| If |has_priority| is true, then weight (in the range [1, 256])
   //     for the receiving stream, otherwise 0.
-  // |parent_stream_id| If |has_priority| is true and protocol
-  //     version == HTTP2, the parent stream of the receiving stream, else 0.
-  // |exclusive| If |has_priority| is true and protocol
-  //     version == HTTP2, the exclusivity of dependence on the parent stream,
-  //     else false.
+  // |parent_stream_id| If |has_priority| is true the parent stream of the
+  //     receiving stream, else 0.
+  // |exclusive| If |has_priority| is true the exclusivity of dependence on the
+  //     parent stream, else false.
   // |fin| Whether FIN flag is set in frame headers.
   // |end| False if HEADERs frame is to be followed by a CONTINUATION frame,
   //     or true if not.
@@ -253,15 +214,13 @@ class NET_EXPORT_PRIVATE SpdyFramerVisitorInterface {
   virtual void OnBlocked(SpdyStreamId stream_id) {}
 
   // Called when a PUSH_PROMISE frame is received.
-  // Note that header block data is not included. See
-  // OnControlFrameHeaderData().
+  // Note that header block data is not included. See OnHeaderFrameStart().
   virtual void OnPushPromise(SpdyStreamId stream_id,
                              SpdyStreamId promised_stream_id,
                              bool end) = 0;
 
   // Called when a CONTINUATION frame is received.
-  // Note that header block data is not included. See
-  // OnControlFrameHeaderData().
+  // Note that header block data is not included. See OnHeaderFrameStart().
   virtual void OnContinuation(SpdyStreamId stream_id, bool end) = 0;
 
   // Called when an ALTSVC frame has been parsed.
@@ -293,7 +252,7 @@ class NET_EXPORT_PRIVATE SpdyFramerVisitorInterface {
 // order to extract debug/internal information about the SpdyFramer as it
 // operates.
 //
-// Most SPDY implementations need not bother with this interface at all.
+// Most HTTP2 implementations need not bother with this interface at all.
 class NET_EXPORT_PRIVATE SpdyFramerDebugVisitorInterface {
  public:
   virtual ~SpdyFramerDebugVisitorInterface() {}
@@ -317,9 +276,7 @@ class NET_EXPORT_PRIVATE SpdyFramerDebugVisitorInterface {
 
 class NET_EXPORT_PRIVATE SpdyFramer {
  public:
-  // SPDY states.
-  // TODO(mbelshe): Can we move these into the implementation
-  //                and avoid exposing through the header.  (Needed for test)
+  // HTTP2 states.
   enum SpdyState {
     SPDY_ERROR,
     SPDY_READY_FOR_FRAME,  // Framer is ready for reading the next frame.
@@ -370,9 +327,8 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   // Constant for invalid (or unknown) stream IDs.
   static const SpdyStreamId kInvalidStream;
 
-  // The maximum size of header data chunks delivered to the framer visitor
-  // through OnControlFrameHeaderData. (It is exposed here for unit test
-  // purposes.)
+  // The maximum size of header data decompressed/delivered at once to the
+  // header block parser. (Exposed here for unit test purposes.)
   static const size_t kHeaderDataChunkMaxSize;
 
   void SerializeHeaderBlockWithoutCompression(
@@ -380,18 +336,14 @@ class NET_EXPORT_PRIVATE SpdyFramer {
       const SpdyHeaderBlock& header_block) const;
 
   // Retrieve serialized length of SpdyHeaderBlock.
-  // TODO(hkhalil): Remove, or move to quic code.
-  static size_t GetSerializedLength(
-      const SpdyMajorVersion spdy_version,
-      const SpdyHeaderBlock* headers);
+  static size_t GetSerializedLength(const SpdyHeaderBlock* headers);
 
-  // Create a new Framer, provided a SPDY version.
-  explicit SpdyFramer(SpdyMajorVersion version);
+  SpdyFramer();
 
   // Used recursively from the above constructor in order to support
   // instantiating a SpdyFramerDecoderAdapter selected via flags or some other
   // means.
-  SpdyFramer(SpdyMajorVersion version, DecoderAdapterFactoryFn adapter_factory);
+  explicit SpdyFramer(DecoderAdapterFactoryFn adapter_factory);
 
   virtual ~SpdyFramer();
 
@@ -427,14 +379,40 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   SpdyState state() const;
   bool HasError() const { return state() == SPDY_ERROR; }
 
-  // Given a buffer containing a decompressed header block in SPDY
-  // serialized format, parse out a SpdyHeaderBlock, putting the results
-  // in the given header block.
+  // Given a buffer containing a serialized header block parse out a
+  // SpdyHeaderBlock, putting the results in the given header block.
   // Returns true if successfully parsed, false otherwise.
   bool ParseHeaderBlockInBuffer(const char* header_data,
                                 size_t header_length,
                                 SpdyHeaderBlock* block) const;
 
+  // Iteratively converts a SpdyHeadersIR (with a possibly huge SpdyHeaderBlock)
+  // into an appropriate sequence of SpdySerializedFrames.
+  class NET_EXPORT_PRIVATE SpdyHeaderFrameIterator {
+   public:
+    SpdyHeaderFrameIterator(SpdyFramer* framer,
+                            std::unique_ptr<SpdyHeadersIR> headers_ir);
+    ~SpdyHeaderFrameIterator();
+
+    // SpdyHeaderFrameIterator is neither copyable nor movable.
+    SpdyHeaderFrameIterator(const SpdyHeaderFrameIterator&) = delete;
+    SpdyHeaderFrameIterator& operator=(const SpdyHeaderFrameIterator&) = delete;
+
+    SpdySerializedFrame NextFrame();
+    bool HasNextFrame() const { return has_next_frame_; }
+
+   private:
+    std::unique_ptr<SpdyHeadersIR> headers_ir_;
+    std::unique_ptr<HpackEncoder::ProgressiveEncoder> encoder_;
+    SpdyFramer* framer_;
+
+    // Field for debug reporting.
+    size_t debug_total_size_;
+
+    bool is_first_frame_;
+    bool has_next_frame_;
+  };
+
   // Serialize a data frame.
   SpdySerializedFrame SerializeData(const SpdyDataIR& data) const;
   // Serializes the data frame header and optionally padding length fields,
@@ -442,12 +420,6 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   SpdySerializedFrame SerializeDataFrameHeaderWithPaddingLengthField(
       const SpdyDataIR& data) const;
 
-  // Serializes a SYN_STREAM frame.
-  SpdySerializedFrame SerializeSynStream(const SpdySynStreamIR& syn_stream);
-
-  // Serialize a SYN_REPLY frame.
-  SpdySerializedFrame SerializeSynReply(const SpdySynReplyIR& syn_reply);
-
   SpdySerializedFrame SerializeRstStream(
       const SpdyRstStreamIR& rst_stream) const;
 
@@ -466,11 +438,11 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   SpdySerializedFrame SerializeGoAway(const SpdyGoAwayIR& goaway) const;
 
   // Serializes a HEADERS frame. The HEADERS frame is used
-  // for sending additional headers outside of a SYN_STREAM/SYN_REPLY.
+  // for sending headers.
   SpdySerializedFrame SerializeHeaders(const SpdyHeadersIR& headers);
 
   // Serializes a WINDOW_UPDATE frame. The WINDOW_UPDATE
-  // frame is used to implement per stream flow control in SPDY.
+  // frame is used to implement per stream flow control.
   SpdySerializedFrame SerializeWindowUpdate(
       const SpdyWindowUpdateIR& window_update) const;
 
@@ -489,11 +461,8 @@ class NET_EXPORT_PRIVATE SpdyFramer {
 
   // Serializes a CONTINUATION frame. The CONTINUATION frame is used
   // to continue a sequence of header block fragments.
-  // TODO(jgraettinger): This implementation is incorrect. The continuation
-  // frame continues a previously-begun HPACK encoding; it doesn't begin a
-  // new one. Figure out whether it makes sense to keep SerializeContinuation().
   SpdySerializedFrame SerializeContinuation(
-      const SpdyContinuationIR& continuation);
+      const SpdyContinuationIR& continuation) const;
 
   // Serializes an ALTSVC frame. The ALTSVC frame advertises the
   // availability of an alternative service to the client.
@@ -506,18 +475,8 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   // Serialize a frame of unknown type.
   SpdySerializedFrame SerializeFrame(const SpdyFrameIR& frame);
 
-  // NOTES about frame compression.
-  // We want spdy to compress headers across the entire session.  As long as
-  // the session is over TCP, frames are sent serially.  The client & server
-  // can each compress frames in the same order and then compress them in that
-  // order, and the remote can do the reverse.  However, we ultimately want
-  // the creation of frames to be less sensitive to order so that they can be
-  // placed over a UDP based protocol and yet still benefit from some
-  // compression.  We don't know of any good compression protocol which does
-  // not build its state in a serial (stream based) manner....  For now, we're
-  // using zlib anyway.
-
   // For ease of testing and experimentation we can tweak compression on/off.
+  bool enable_compression() const { return enable_compression_; }
   void set_enable_compression(bool value) {
     enable_compression_ = value;
   }
@@ -526,31 +485,9 @@ class NET_EXPORT_PRIVATE SpdyFramer {
     GetHpackEncoder()->SetIndexingPolicy(std::move(policy));
   }
 
-  // Used only in log messages.
-  void set_display_protocol(const std::string& protocol) {
-    display_protocol_ = protocol;
-  }
-
-  void set_max_decode_buffer_size_bytes(size_t max_decode_buffer_size_bytes) {
-    GetHpackDecoder()->set_max_decode_buffer_size_bytes(
-        max_decode_buffer_size_bytes);
-  }
-
-  size_t send_frame_size_limit() const { return send_frame_size_limit_; }
-
-  void set_send_frame_size_limit(size_t send_frame_size_limit) {
-    send_frame_size_limit_ = send_frame_size_limit;
-  }
-
-  void set_recv_frame_size_limit(size_t recv_frame_size_limit) {
-    recv_frame_size_limit_ = recv_frame_size_limit;
-  }
-
   // Returns the (minimum) size of frames (sans variable-length portions).
   size_t GetDataFrameMinimumSize() const;
   size_t GetFrameHeaderSize() const;
-  size_t GetSynStreamMinimumSize() const;
-  size_t GetSynReplyMinimumSize() const;
   size_t GetRstStreamMinimumSize() const;
   size_t GetSettingsMinimumSize() const;
   size_t GetPingSize() const;
@@ -578,8 +515,6 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   static const char* StatusCodeToString(int status_code);
   static const char* FrameTypeToString(SpdyFrameType type);
 
-  SpdyMajorVersion protocol_version() const { return protocol_version_; }
-
   // Did the most recent frame header appear to be an HTTP/1.x (or earlier)
   // response (i.e. start with "HTTP/")?
   bool probable_http_response() const;
@@ -588,14 +523,6 @@ class NET_EXPORT_PRIVATE SpdyFramer {
 
   SpdyPriority GetHighestPriority() const { return kV3HighestPriority; }
 
-  // Deliver the given control frame's compressed headers block to the visitor
-  // in decompressed form, in chunks. Returns true if the visitor has
-  // accepted all of the chunks.
-  bool IncrementallyDecompressControlFrameHeaderData(
-      SpdyStreamId stream_id,
-      const char* data,
-      size_t len);
-
   // Updates the maximum size of the header encoder compression table.
   void UpdateHeaderEncoderTableSize(uint32_t value);
 
@@ -605,17 +532,27 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   // Returns the maximum size of the header encoder compression table.
   size_t header_encoder_table_size() const;
 
+  void set_max_decode_buffer_size_bytes(size_t max_decode_buffer_size_bytes) {
+    GetHpackDecoder()->set_max_decode_buffer_size_bytes(
+        max_decode_buffer_size_bytes);
+  }
+
+  size_t send_frame_size_limit() const { return send_frame_size_limit_; }
+  void set_send_frame_size_limit(size_t send_frame_size_limit) {
+    send_frame_size_limit_ = send_frame_size_limit;
+  }
+
+  size_t recv_frame_size_limit() const { return recv_frame_size_limit_; }
+  void set_recv_frame_size_limit(size_t recv_frame_size_limit) {
+    recv_frame_size_limit_ = recv_frame_size_limit;
+  }
+
   void SetDecoderHeaderTableDebugVisitor(
       std::unique_ptr<HpackHeaderTable::DebugVisitorInterface> visitor);
 
   void SetEncoderHeaderTableDebugVisitor(
       std::unique_ptr<HpackHeaderTable::DebugVisitorInterface> visitor);
 
-  // For testing support (i.e. for clients and backends),
-  // allow overriding the flag on a per framer basis.
-  void set_use_new_methods_for_test(bool v) { use_new_methods_ = v; }
-  bool use_new_methods_for_test() const { return use_new_methods_; }
-
  protected:
   friend class BufferedSpdyFramer;
   friend class HttpNetworkLayer;  // This is temporary for the server.
@@ -669,9 +606,7 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   // HPACK data is re-encoded as SPDY3 and re-entrantly delivered through
   // |ProcessControlFrameHeaderBlock()|. |is_hpack_header_block| controls
   // whether data is treated as HPACK- vs SPDY3-encoded.
-  size_t ProcessControlFrameHeaderBlock(const char* data,
-                                        size_t len,
-                                        bool is_hpack_header_block);
+  size_t ProcessControlFrameHeaderBlock(const char* data, size_t len);
   size_t ProcessDataFramePaddingLength(const char* data, size_t len);
   size_t ProcessFramePadding(const char* data, size_t len);
   size_t ProcessDataFramePayload(const char* data, size_t len);
@@ -685,7 +620,7 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   // Validates the frame header against the current protocol, e.g.
   // Frame type must be known, must specify a non-zero stream id.
   //
-  // is_control_frame    : the control bit for SPDY3
+  // is_control_frame    : the control bit
   // frame_type_field    : the unparsed frame type octet(s)
   // payload_length_field: the stated length in octets of the frame payload
   //
@@ -696,27 +631,11 @@ class NET_EXPORT_PRIVATE SpdyFramer {
                                     int frame_type_field,
                                     size_t payload_length_field);
 
-  // TODO(jgraettinger): To be removed with migration to
-  // SpdyHeadersHandlerInterface.  Serializes the last-processed
-  // header block of |hpack_decoder_| as a SPDY3 format block, and
-  // delivers it to the visitor via reentrant call to
-  // ProcessControlFrameHeaderBlock().  |compressed_len| is used for
-  // logging compression percentage.
-  void DeliverHpackBlockAsSpdy3Block(size_t compressed_len);
-
   // Helpers for above internal breakouts from ProcessInput.
   void ProcessControlFrameHeader(int control_frame_type_field);
   // Always passed exactly 1 setting's worth of data.
   bool ProcessSetting(const char* data);
 
-  // Retrieve serialized length of SpdyHeaderBlock. If compression is enabled, a
-  // maximum estimate is returned.
-  size_t GetSerializedLength(const SpdyHeaderBlock& headers);
-
-  // Get (and lazily initialize) the ZLib state.
-  z_stream* GetHeaderCompressor();
-  z_stream* GetHeaderDecompressor();
-
   // Get (and lazily initialize) the HPACK state.
   HpackEncoder* GetHpackEncoder();
   HpackDecoderInterface* GetHpackDecoder();
@@ -745,19 +664,25 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   size_t UpdateCurrentFrameBuffer(const char** data, size_t* len,
                                   size_t max_bytes);
 
-  void WriteHeaderBlockToZ(const SpdyHeaderBlock* headers,
-                           z_stream* out) const;
+  // Serializes a HEADERS frame from the given SpdyHeadersIR and encoded header
+  // block. Does not need or use the SpdyHeaderBlock inside SpdyHeadersIR.
+  SpdySerializedFrame SerializeHeadersGivenEncoding(
+      const SpdyHeadersIR& headers,
+      const std::string& encoding) const;
+
+  // Calculates the number of bytes required to serialize a SpdyHeadersIR, not
+  // including the bytes to be used for the encoded header set.
+  size_t GetHeaderFrameSizeSansBlock(const SpdyHeadersIR& header_ir) const;
 
-  // Compresses automatically according to enable_compression_.
-  void SerializeHeaderBlock(SpdyFrameBuilder* builder,
-                            const SpdyFrameWithHeaderBlockIR& frame);
+  // Serializes the flags octet for a given SpdyHeadersIR.
+  uint8_t SerializeHeaderFrameFlags(const SpdyHeadersIR& header_ir) const;
 
   // Set the error code and moves the framer into the error state.
   void set_error(SpdyError error);
 
   // The size of the control frame buffer.
   // Since this is only used for control frame headers, the maximum control
-  // frame header size (SYN_STREAM) is sufficient; all remaining control
+  // frame header size is sufficient; all remaining control
   // frame data is streamed to the visitor.
   static const size_t kControlFrameBufferSize;
 
@@ -819,10 +744,6 @@ class NET_EXPORT_PRIVATE SpdyFramer {
 
   std::unique_ptr<CharBuffer> altsvc_scratch_;
 
-  // SPDY header compressors.
-  std::unique_ptr<z_stream> header_compressor_;
-  std::unique_ptr<z_stream> header_decompressor_;
-
   std::unique_ptr<HpackEncoder> hpack_encoder_;
   std::unique_ptr<HpackDecoderInterface> hpack_decoder_;
 
@@ -832,33 +753,19 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   std::unique_ptr<SpdyHeadersBlockParser> header_parser_;
   SpdyHeadersHandlerInterface* header_handler_;
 
-  std::string display_protocol_;
-
   // Optional decoder to use instead of this instance.
   std::unique_ptr<SpdyFramerDecoderAdapter> decoder_adapter_;
 
-  // The protocol version to be spoken/understood by this framer.
-  const SpdyMajorVersion protocol_version_;
-
   // The flags field of the frame currently being read.
   uint8_t current_frame_flags_;
 
-  // Determines whether HPACK or gzip compression is used.
+  // Determines whether HPACK compression is used.
   bool enable_compression_;
 
-  // Tracks if we've ever gotten far enough in framing to see a control frame of
-  // type SYN_STREAM or SYN_REPLY.
-  //
-  // If we ever get something which looks like a data frame before we've had a
-  // SYN, we explicitly check to see if it looks like we got an HTTP response
-  // to a SPDY request.  This boolean lets us do that.
-  bool syn_frame_processed_;
-
-  // If we ever get a data frame before a SYN frame, we check to see if it
-  // starts with HTTP.  If it does, we likely have an HTTP response.   This
-  // isn't guaranteed though: we could have gotten a settings frame and then
-  // corrupt data that just looks like HTTP, but deterministic checking requires
-  // a lot more state.
+  // On the first read, we check to see if the data starts with HTTP.
+  // If it does, we likely have an HTTP response.   This isn't guaranteed
+  // though: we could have gotten a settings frame and then corrupt data that
+  // just looks like HTTP, but deterministic checking requires a lot more state.
   bool probable_http_response_;
 
   // If a HEADERS frame is followed by a CONTINUATION frame, the FIN/END_STREAM
@@ -870,9 +777,6 @@ class NET_EXPORT_PRIVATE SpdyFramer {
   // If true, then ProcessInput returns after processing a full frame,
   // rather than reading all available input.
   bool process_single_input_frame_ = false;
-
-  bool use_new_methods_ =
-      FLAGS_chromium_http2_flag_spdy_framer_use_new_methods4;
 };
 
 }  // namespace net
diff --git a/src/net/spdy/spdy_framer_decoder_adapter.cc b/src/net/spdy/spdy_framer_decoder_adapter.cc
index 949cbdf..83a479e 100644
--- a/src/net/spdy/spdy_framer_decoder_adapter.cc
+++ b/src/net/spdy/spdy_framer_decoder_adapter.cc
@@ -6,6 +6,7 @@
 
 #include <memory>
 #include <string>
+#include <utility>
 
 #include "base/format_macros.h"
 #include "base/logging.h"
@@ -47,6 +48,13 @@ void SpdyFramerVisitorAdapter::OnError(SpdyFramer* framer) {
   visitor_->OnError(framer_);
 }
 
+void SpdyFramerVisitorAdapter::OnCommonHeader(SpdyStreamId stream_id,
+                                              size_t length,
+                                              uint8_t type,
+                                              uint8_t flags) {
+  visitor_->OnCommonHeader(stream_id, length, type, flags);
+}
+
 void SpdyFramerVisitorAdapter::OnDataFrameHeader(SpdyStreamId stream_id,
                                                  size_t length,
                                                  bool fin) {
@@ -78,27 +86,6 @@ void SpdyFramerVisitorAdapter::OnHeaderFrameEnd(SpdyStreamId stream_id,
   visitor_->OnHeaderFrameEnd(stream_id, end_headers);
 }
 
-bool SpdyFramerVisitorAdapter::OnControlFrameHeaderData(
-    SpdyStreamId stream_id,
-    const char* header_data,
-    size_t header_data_len) {
-  return visitor_->OnControlFrameHeaderData(stream_id, header_data,
-                                            header_data_len);
-}
-
-void SpdyFramerVisitorAdapter::OnSynStream(SpdyStreamId stream_id,
-                                           SpdyStreamId associated_stream_id,
-                                           SpdyPriority priority,
-                                           bool fin,
-                                           bool unidirectional) {
-  visitor_->OnSynStream(stream_id, associated_stream_id, priority, fin,
-                        unidirectional);
-}
-
-void SpdyFramerVisitorAdapter::OnSynReply(SpdyStreamId stream_id, bool fin) {
-  visitor_->OnSynReply(stream_id, fin);
-}
-
 void SpdyFramerVisitorAdapter::OnRstStream(SpdyStreamId stream_id,
                                            SpdyRstStreamStatus status) {
   visitor_->OnRstStream(stream_id, status);
@@ -197,7 +184,7 @@ class NestedSpdyFramerDecoder : public SpdyFramerDecoderAdapter {
 
  public:
   explicit NestedSpdyFramerDecoder(SpdyFramer* outer)
-      : framer_(HTTP2, nullptr), outer_(outer) {
+      : framer_(nullptr), outer_(outer) {
     DVLOG(1) << PRETTY_THIS;
   }
   ~NestedSpdyFramerDecoder() override { DVLOG(1) << PRETTY_THIS; }
@@ -233,12 +220,6 @@ class NestedSpdyFramerDecoder : public SpdyFramerDecoderAdapter {
 
   size_t ProcessInput(const char* data, size_t len) override {
     DVLOG(2) << "ProcessInput(data, " << len << ")";
-    const bool use_new_methods = outer_->use_new_methods_for_test();
-    if (framer_.use_new_methods_for_test() != use_new_methods) {
-      DVLOG(1) << "Overriding use_new_methods_ in nested framer, setting="
-               << (use_new_methods ? "true" : "false");
-      framer_.set_use_new_methods_for_test(use_new_methods);
-    }
     size_t result = framer_.ProcessInput(data, len);
     DVLOG(2) << "ProcessInput(data, " << len << ")  returning " << result;
     return result;
diff --git a/src/net/spdy/spdy_framer_decoder_adapter.h b/src/net/spdy/spdy_framer_decoder_adapter.h
index c20bb8d..4c08c53 100644
--- a/src/net/spdy/spdy_framer_decoder_adapter.h
+++ b/src/net/spdy/spdy_framer_decoder_adapter.h
@@ -99,6 +99,10 @@ class SpdyFramerVisitorAdapter : public SpdyFramerVisitorInterface {
   // The visitor needs the original SpdyFramer, not the SpdyFramerDecoderAdapter
   // instance.
   void OnError(SpdyFramer* framer) override;
+  void OnCommonHeader(SpdyStreamId stream_id,
+                      size_t length,
+                      uint8_t type,
+                      uint8_t flags) override;
   void OnDataFrameHeader(SpdyStreamId stream_id,
                          size_t length,
                          bool fin) override;
@@ -110,15 +114,6 @@ class SpdyFramerVisitorAdapter : public SpdyFramerVisitorInterface {
   SpdyHeadersHandlerInterface* OnHeaderFrameStart(
       SpdyStreamId stream_id) override;
   void OnHeaderFrameEnd(SpdyStreamId stream_id, bool end_headers) override;
-  bool OnControlFrameHeaderData(SpdyStreamId stream_id,
-                                const char* header_data,
-                                size_t header_data_len) override;
-  void OnSynStream(SpdyStreamId stream_id,
-                   SpdyStreamId associated_stream_id,
-                   SpdyPriority priority,
-                   bool fin,
-                   bool unidirectional) override;
-  void OnSynReply(SpdyStreamId stream_id, bool fin) override;
   void OnRstStream(SpdyStreamId stream_id, SpdyRstStreamStatus status) override;
   void OnSetting(SpdySettingsIds id, uint8_t flags, uint32_t value) override;
   void OnPing(SpdyPingId unique_id, bool is_ack) override;
diff --git a/src/net/spdy/spdy_header_block.cc b/src/net/spdy/spdy_header_block.cc
index fa6379b..f56a527 100644
--- a/src/net/spdy/spdy_header_block.cc
+++ b/src/net/spdy/spdy_header_block.cc
@@ -14,6 +14,7 @@
 #include "base/values.h"
 #include "net/base/arena.h"
 #include "net/http/http_log_util.h"
+#include "net/log/net_log_capture_mode.h"
 
 using base::StringPiece;
 using std::dec;
@@ -79,7 +80,7 @@ class SpdyHeaderBlock::Storage {
   UnsafeArena arena_;
 };
 
-SpdyHeaderBlock::StringPieceProxy::StringPieceProxy(
+SpdyHeaderBlock::ValueProxy::ValueProxy(
     SpdyHeaderBlock::MapType* block,
     SpdyHeaderBlock::Storage* storage,
     SpdyHeaderBlock::MapType::iterator lookup_result,
@@ -88,9 +89,10 @@ SpdyHeaderBlock::StringPieceProxy::StringPieceProxy(
       storage_(storage),
       lookup_result_(lookup_result),
       key_(key),
-      valid_(true) {}
+      valid_(true) {
+}
 
-SpdyHeaderBlock::StringPieceProxy::StringPieceProxy(StringPieceProxy&& other)
+SpdyHeaderBlock::ValueProxy::ValueProxy(ValueProxy&& other)
     : block_(other.block_),
       storage_(other.storage_),
       lookup_result_(other.lookup_result_),
@@ -99,8 +101,8 @@ SpdyHeaderBlock::StringPieceProxy::StringPieceProxy(StringPieceProxy&& other)
   other.valid_ = false;
 }
 
-SpdyHeaderBlock::StringPieceProxy& SpdyHeaderBlock::StringPieceProxy::operator=(
-    SpdyHeaderBlock::StringPieceProxy&& other) {
+SpdyHeaderBlock::ValueProxy& SpdyHeaderBlock::ValueProxy::operator=(
+    SpdyHeaderBlock::ValueProxy&& other) {
   block_ = other.block_;
   storage_ = other.storage_;
   lookup_result_ = other.lookup_result_;
@@ -110,8 +112,8 @@ SpdyHeaderBlock::StringPieceProxy& SpdyHeaderBlock::StringPieceProxy::operator=(
   return *this;
 }
 
-SpdyHeaderBlock::StringPieceProxy::~StringPieceProxy() {
-  // If the StringPieceProxy is destroyed while lookup_result_ == block_->end(),
+SpdyHeaderBlock::ValueProxy::~ValueProxy() {
+  // If the ValueProxy is destroyed while lookup_result_ == block_->end(),
   // the assignment operator was never used, and the block's Storage can
   // reclaim the memory used by the key. This makes lookup-only access to
   // SpdyHeaderBlock through operator[] memory-neutral.
@@ -120,7 +122,7 @@ SpdyHeaderBlock::StringPieceProxy::~StringPieceProxy() {
   }
 }
 
-SpdyHeaderBlock::StringPieceProxy& SpdyHeaderBlock::StringPieceProxy::operator=(
+SpdyHeaderBlock::ValueProxy& SpdyHeaderBlock::ValueProxy::operator=(
     const StringPiece value) {
   if (lookup_result_ == block_->end()) {
     DVLOG(1) << "Inserting: (" << key_ << ", " << value << ")";
@@ -133,9 +135,12 @@ SpdyHeaderBlock::StringPieceProxy& SpdyHeaderBlock::StringPieceProxy::operator=(
   return *this;
 }
 
-SpdyHeaderBlock::StringPieceProxy::operator StringPiece() const {
-  return (lookup_result_ == block_->end()) ? StringPiece()
-                                           : lookup_result_->second;
+string SpdyHeaderBlock::ValueProxy::as_string() const {
+  if (lookup_result_ == block_->end()) {
+    return "";
+  } else {
+    return lookup_result_->second.as_string();
+  }
 }
 
 SpdyHeaderBlock::SpdyHeaderBlock() {}
@@ -189,16 +194,24 @@ void SpdyHeaderBlock::clear() {
 
 void SpdyHeaderBlock::insert(
     const SpdyHeaderBlock::MapType::value_type& value) {
-  ReplaceOrAppendHeader(value.first, value.second);
+  // TODO(birenroy): Write new value in place of old value, if it fits.
+  auto iter = block_.find(value.first);
+  if (iter == block_.end()) {
+    DVLOG(1) << "Inserting: (" << value.first << ", " << value.second << ")";
+    AppendHeader(value.first, value.second);
+  } else {
+    DVLOG(1) << "Updating key: " << iter->first
+             << " with value: " << value.second;
+    iter->second = GetStorage()->Write(value.second);
+  }
 }
 
-SpdyHeaderBlock::StringPieceProxy SpdyHeaderBlock::operator[](
-    const StringPiece key) {
+SpdyHeaderBlock::ValueProxy SpdyHeaderBlock::operator[](const StringPiece key) {
   DVLOG(2) << "Operator[] saw key: " << key;
   StringPiece out_key;
   auto iter = block_.find(key);
   if (iter == block_.end()) {
-    // We write the key first, to assure that the StringPieceProxy has a
+    // We write the key first, to assure that the ValueProxy has a
     // reference to a valid StringPiece in its operator=.
     out_key = GetStorage()->Write(key);
     DVLOG(2) << "Key written as: " << std::hex
@@ -207,25 +220,7 @@ SpdyHeaderBlock::StringPieceProxy SpdyHeaderBlock::operator[](
   } else {
     out_key = iter->first;
   }
-  return StringPieceProxy(&block_, GetStorage(), iter, out_key);
-}
-
-StringPiece SpdyHeaderBlock::GetHeader(const StringPiece key) const {
-  auto iter = block_.find(key);
-  return iter == block_.end() ? StringPiece() : iter->second;
-}
-
-void SpdyHeaderBlock::ReplaceOrAppendHeader(const StringPiece key,
-                                            const StringPiece value) {
-  // TODO(birenroy): Write new value in place of old value, if it fits.
-  auto iter = block_.find(key);
-  if (iter == block_.end()) {
-    DVLOG(1) << "Inserting: (" << key << ", " << value << ")";
-    AppendHeader(key, value);
-  } else {
-    DVLOG(1) << "Updating key: " << iter->first << " with value: " << value;
-    iter->second = GetStorage()->Write(value);
-  }
+  return ValueProxy(&block_, GetStorage(), iter, out_key);
 }
 
 void SpdyHeaderBlock::AppendValueOrAddHeader(const StringPiece key,
diff --git a/src/net/spdy/spdy_header_block.h b/src/net/spdy/spdy_header_block.h
index 6a24a44..fef27e8 100644
--- a/src/net/spdy/spdy_header_block.h
+++ b/src/net/spdy/spdy_header_block.h
@@ -18,13 +18,16 @@
 #include "net/base/net_export.h"
 #include "net/log/net_log.h"
 
+namespace base {
+class Value;
+}
+
 namespace net {
 
-// Allows arg-dependent lookup to work for logging's operator<<.
-using ::operator<<;
+class NetLogCaptureMode;
 
 namespace test {
-class StringPieceProxyPeer;
+class ValueProxyPeer;
 }
 
 // This class provides a key-value map that can be used to store SPDY header
@@ -32,7 +35,7 @@ class StringPieceProxyPeer;
 //
 // Under the hood, this data structure uses large, contiguous blocks of memory
 // to store names and values. Lookups may be performed with StringPiece keys,
-// and values are returned as StringPieces (via StringPieceProxy, below).
+// and values are returned as StringPieces (via ValueProxy, below).
 // Value StringPieces are valid as long as the SpdyHeaderBlock exists; allocated
 // memory is never freed until SpdyHeaderBlock's destruction.
 //
@@ -51,7 +54,7 @@ class NET_EXPORT SpdyHeaderBlock {
   using value_type = MapType::value_type;
   using reverse_iterator = MapType::reverse_iterator;
 
-  class StringPieceProxy;
+  class ValueProxy;
 
   SpdyHeaderBlock();
   SpdyHeaderBlock(const SpdyHeaderBlock& other) = delete;
@@ -90,11 +93,6 @@ class NET_EXPORT SpdyHeaderBlock {
   // adds a new header to the end of the block.
   void insert(const MapType::value_type& value);
 
-  // If key already exists in the block, replaces the value of that key. Else
-  // adds a new header to the end of the block.
-  void ReplaceOrAppendHeader(const base::StringPiece key,
-                             const base::StringPiece value);
-
   // If a header with the key is already present, then append the value to the
   // existing header value, NUL ("\0") separated unless the key is cookie, in
   // which case the separator is "; ".
@@ -103,47 +101,36 @@ class NET_EXPORT SpdyHeaderBlock {
                               const base::StringPiece value);
 
   // Allows either lookup or mutation of the value associated with a key.
-  StringPieceProxy operator[](const base::StringPiece key);
-
-  // Non-mutating lookup of header value. Returns empty StringPiece if key not
-  // present. To distinguish between absence of header and empty header value,
-  // use find().
-  base::StringPiece GetHeader(const base::StringPiece key) const;
+  ValueProxy operator[](const base::StringPiece key);
 
   // This object provides automatic conversions that allow SpdyHeaderBlock to be
   // nearly a drop-in replacement for linked_hash_map<string, string>. It reads
   // data from or writes data to a SpdyHeaderBlock::Storage.
-  class NET_EXPORT StringPieceProxy {
+  class NET_EXPORT ValueProxy {
    public:
-    ~StringPieceProxy();
+    ~ValueProxy();
 
     // Moves are allowed.
-    StringPieceProxy(StringPieceProxy&& other);
-    StringPieceProxy& operator=(StringPieceProxy&& other);
+    ValueProxy(ValueProxy&& other);
+    ValueProxy& operator=(ValueProxy&& other);
 
     // Copies are not.
-    StringPieceProxy(const StringPieceProxy& other) = delete;
-    StringPieceProxy& operator=(const StringPieceProxy& other) = delete;
+    ValueProxy(const ValueProxy& other) = delete;
+    ValueProxy& operator=(const ValueProxy& other) = delete;
 
     // Assignment modifies the underlying SpdyHeaderBlock.
-    StringPieceProxy& operator=(const base::StringPiece other);
-
-    // Allows a StringPieceProxy to be automatically converted to a StringPiece.
-    // This makes SpdyHeaderBlock::operator[] easy to use with StringPieces.
-    operator base::StringPiece() const;
+    ValueProxy& operator=(const base::StringPiece other);
 
-    std::string as_string() const {
-      return static_cast<base::StringPiece>(*this).as_string();
-    }
+    std::string as_string() const;
 
    private:
     friend class SpdyHeaderBlock;
-    friend class test::StringPieceProxyPeer;
+    friend class test::ValueProxyPeer;
 
-    StringPieceProxy(SpdyHeaderBlock::MapType* block,
-                     SpdyHeaderBlock::Storage* storage,
-                     SpdyHeaderBlock::MapType::iterator lookup_result,
-                     const base::StringPiece key);
+    ValueProxy(SpdyHeaderBlock::MapType* block,
+               SpdyHeaderBlock::Storage* storage,
+               SpdyHeaderBlock::MapType::iterator lookup_result,
+               const base::StringPiece key);
 
     SpdyHeaderBlock::MapType* block_;
     SpdyHeaderBlock::Storage* storage_;
@@ -153,7 +140,6 @@ class NET_EXPORT SpdyHeaderBlock {
   };
 
  private:
-  void Write(const base::StringPiece s);
   void AppendHeader(const base::StringPiece key, const base::StringPiece value);
   Storage* GetStorage();
 
diff --git a/src/net/spdy/spdy_headers_block_parser.cc b/src/net/spdy/spdy_headers_block_parser.cc
index d5f0341..5e6bc6f 100644
--- a/src/net/spdy/spdy_headers_block_parser.cc
+++ b/src/net/spdy/spdy_headers_block_parser.cc
@@ -6,6 +6,7 @@
 
 #include "base/sys_byteorder.h"
 #include "net/spdy/spdy_bug_tracker.h"
+#include "net/spdy/spdy_flags.h"
 
 namespace net {
 namespace {
@@ -22,7 +23,6 @@ const size_t kLengthFieldSize = sizeof(uint32_t);
 const size_t SpdyHeadersBlockParser::kMaximumFieldLength = 16 * 1024;
 
 SpdyHeadersBlockParser::SpdyHeadersBlockParser(
-    SpdyMajorVersion spdy_version,
     SpdyHeadersHandlerInterface* handler)
     : state_(READING_HEADER_BLOCK_LEN),
       max_headers_in_block_(MaxNumberOfHeaders()),
@@ -30,8 +30,7 @@ SpdyHeadersBlockParser::SpdyHeadersBlockParser(
       remaining_key_value_pairs_for_frame_(0),
       handler_(handler),
       stream_id_(kInvalidStreamId),
-      error_(NO_PARSER_ERROR),
-      spdy_version_(spdy_version) {
+      error_(NO_PARSER_ERROR) {
   // The handler that we set must not be NULL.
   DCHECK(handler_ != NULL);
 }
@@ -113,7 +112,16 @@ bool SpdyHeadersBlockParser::HandleControlFrameHeadersData(
           next_state = READING_KEY_LEN;
         } else {
           next_state = READING_HEADER_BLOCK_LEN;
-          handler_->OnHeaderBlockEnd(total_bytes_received_);
+          if (FLAGS_chromium_http2_flag_log_compressed_size) {
+            // We reach here in two cases: 1) Spdy3 or 2) HTTP/2 without hpack
+            // encoding. For the first case, we just log the uncompressed size
+            // since we are going to deprecate Spdy3 soon. For the second case,
+            // the compressed size is the same as the uncompressed size.
+            handler_->OnHeaderBlockEnd(total_bytes_received_,
+                                       total_bytes_received_);
+          } else {
+            handler_->OnHeaderBlockEnd(total_bytes_received_);
+          }
           stream_id_ = kInvalidStreamId;
           // Expect to have consumed all buffer.
           if (reader.Available() != 0) {
diff --git a/src/net/spdy/spdy_headers_block_parser.h b/src/net/spdy/spdy_headers_block_parser.h
index 8e2db8b..1ad7ddf 100644
--- a/src/net/spdy/spdy_headers_block_parser.h
+++ b/src/net/spdy/spdy_headers_block_parser.h
@@ -19,12 +19,6 @@
 
 namespace net {
 
-namespace test {
-
-class SpdyHeadersBlockParserPeer;
-
-}  // namespace test
-
 // This class handles SPDY headers block bytes and parses out key-value pairs
 // as they arrive. This class is not thread-safe, and assumes that all headers
 // block bytes are processed in a single thread.
@@ -35,8 +29,7 @@ class NET_EXPORT_PRIVATE SpdyHeadersBlockParser {
 
   // Constructor. The handler's OnHeader will be called for every key
   // value pair that we parsed from the headers block.
-  SpdyHeadersBlockParser(SpdyMajorVersion spdy_version,
-                         SpdyHeadersHandlerInterface* handler);
+  explicit SpdyHeadersBlockParser(SpdyHeadersHandlerInterface* handler);
 
   virtual ~SpdyHeadersBlockParser();
 
@@ -63,8 +56,6 @@ class NET_EXPORT_PRIVATE SpdyHeadersBlockParser {
   };
   ParserError get_error() const { return error_; }
 
-  SpdyMajorVersion spdy_version() const { return spdy_version_; }
-
   // Returns the maximal number of headers in a SPDY headers block.
   static size_t MaxNumberOfHeaders();
 
@@ -119,8 +110,6 @@ class NET_EXPORT_PRIVATE SpdyHeadersBlockParser {
   SpdyStreamId stream_id_;
 
   ParserError error_;
-
-  const SpdyMajorVersion spdy_version_;
 };
 
 }  // namespace net
diff --git a/src/net/spdy/spdy_headers_handler_interface.h b/src/net/spdy/spdy_headers_handler_interface.h
index 2c48abf..e4652dd 100644
--- a/src/net/spdy/spdy_headers_handler_interface.h
+++ b/src/net/spdy/spdy_headers_handler_interface.h
@@ -27,10 +27,18 @@ class NET_EXPORT_PRIVATE SpdyHeadersHandlerInterface {
   // values for a given key will be emitted as multiple calls to OnHeader.
   virtual void OnHeader(base::StringPiece key, base::StringPiece value) = 0;
 
+  // TODO(yasong): deprecate this method with
+  // --gfe2_reloadable_flag_log_compressed_size.
   // A callback method which notifies when the parser finishes handling a
   // header block (i.e. the containing frame has the END_HEADERS flag set).
   // Also indicates the total number of bytes in this block.
   virtual void OnHeaderBlockEnd(size_t uncompressed_header_bytes) = 0;
+
+  // A callback method which notifies when the parser finishes handling a
+  // header block (i.e. the containing frame has the END_HEADERS flag set).
+  // Also indicates the total number of bytes in this block.
+  virtual void OnHeaderBlockEnd(size_t uncompressed_header_bytes,
+                                size_t compressed_header_bytes) = 0;
 };
 
 }  // namespace net
diff --git a/src/net/spdy/spdy_protocol.cc b/src/net/spdy/spdy_protocol.cc
index 77304da..cd77339 100644
--- a/src/net/spdy/spdy_protocol.cc
+++ b/src/net/spdy/spdy_protocol.cc
@@ -45,174 +45,88 @@ SpdyPriority Http2WeightToSpdy3Priority(int weight) {
   return static_cast<SpdyPriority>(7.f - (weight - 1) / kSteps);
 }
 
-bool SpdyConstants::IsValidFrameType(SpdyMajorVersion version,
-                                     int frame_type_field) {
-  switch (version) {
-    case SPDY3:
-      // SYN_STREAM is the first valid frame.
-      if (frame_type_field < SerializeFrameType(version, SYN_STREAM)) {
-        return false;
-      }
-
-      // WINDOW_UPDATE is the last valid frame.
-      if (frame_type_field > SerializeFrameType(version, WINDOW_UPDATE)) {
-        return false;
-      }
-
-      return true;
-    case HTTP2:
-      // Check for recognized extensions.
-      if (frame_type_field == SerializeFrameType(version, ALTSVC) ||
-          frame_type_field == SerializeFrameType(version, BLOCKED)) {
-        return true;
-      }
-
-      // DATA is the first valid frame.
-      if (frame_type_field < SerializeFrameType(version, DATA)) {
-        return false;
-      }
-
-      // CONTINUATION is the last valid frame.
-      if (frame_type_field > SerializeFrameType(version, CONTINUATION)) {
-        return false;
-      }
-
-      return true;
+bool SpdyConstants::IsValidFrameType(int frame_type_field) {
+  // Check for recognized extensions.
+  if (frame_type_field == SerializeFrameType(ALTSVC) ||
+      frame_type_field == SerializeFrameType(BLOCKED)) {
+    return true;
   }
 
-  SPDY_BUG << "Unhandled SPDY version " << version;
-  return false;
-}
+  // DATA is the first valid frame.
+  if (frame_type_field < SerializeFrameType(DATA)) {
+    return false;
+  }
 
-SpdyFrameType SpdyConstants::ParseFrameType(SpdyMajorVersion version,
-                                            int frame_type_field) {
-  switch (version) {
-    case SPDY3:
-      switch (frame_type_field) {
-        case 1:
-          return SYN_STREAM;
-        case 2:
-          return SYN_REPLY;
-        case 3:
-          return RST_STREAM;
-        case 4:
-          return SETTINGS;
-        case 6:
-          return PING;
-        case 7:
-          return GOAWAY;
-        case 8:
-          return HEADERS;
-        case 9:
-          return WINDOW_UPDATE;
-      }
-      break;
-    case HTTP2:
-      switch (frame_type_field) {
-        case 0:
-          return DATA;
-        case 1:
-          return HEADERS;
-        case 2:
-          return PRIORITY;
-        case 3:
-          return RST_STREAM;
-        case 4:
-          return SETTINGS;
-        case 5:
-          return PUSH_PROMISE;
-        case 6:
-          return PING;
-        case 7:
-          return GOAWAY;
-        case 8:
-          return WINDOW_UPDATE;
-        case 9:
-          return CONTINUATION;
-        case 10:
-          return ALTSVC;
-        case 11:
-          return BLOCKED;
-      }
-      break;
+  // CONTINUATION is the last valid frame.
+  if (frame_type_field > SerializeFrameType(CONTINUATION)) {
+    return false;
   }
 
+  return true;
+}
+
+SpdyFrameType SpdyConstants::ParseFrameType(int frame_type_field) {
+  switch (frame_type_field) {
+    case 0:
+      return DATA;
+    case 1:
+      return HEADERS;
+    case 2:
+      return PRIORITY;
+    case 3:
+      return RST_STREAM;
+    case 4:
+      return SETTINGS;
+    case 5:
+      return PUSH_PROMISE;
+    case 6:
+      return PING;
+    case 7:
+      return GOAWAY;
+    case 8:
+      return WINDOW_UPDATE;
+    case 9:
+      return CONTINUATION;
+    case 10:
+      return ALTSVC;
+    case 11:
+      return BLOCKED;
+  }
   SPDY_BUG << "Unhandled frame type " << frame_type_field;
   return DATA;
 }
 
-int SpdyConstants::SerializeFrameType(SpdyMajorVersion version,
-                                      SpdyFrameType frame_type) {
-  switch (version) {
-    case SPDY3:
-      switch (frame_type) {
-        case SYN_STREAM:
-          return 1;
-        case SYN_REPLY:
-          return 2;
-        case RST_STREAM:
-          return 3;
-        case SETTINGS:
-          return 4;
-        case PING:
-          return 6;
-        case GOAWAY:
-          return 7;
-        case HEADERS:
-          return 8;
-        case WINDOW_UPDATE:
-          return 9;
-        default:
-          SPDY_BUG << "Serializing unhandled frame type " << frame_type;
-          return -1;
-      }
-    case HTTP2:
-      switch (frame_type) {
-        case DATA:
-          return 0;
-        case HEADERS:
-          return 1;
-        case PRIORITY:
-          return 2;
-        case RST_STREAM:
-          return 3;
-        case SETTINGS:
-          return 4;
-        case PUSH_PROMISE:
-          return 5;
-        case PING:
-          return 6;
-        case GOAWAY:
-          return 7;
-        case WINDOW_UPDATE:
-          return 8;
-        case CONTINUATION:
-          return 9;
-        // ALTSVC and BLOCKED are extensions.
-        case ALTSVC:
-          return 10;
-        case BLOCKED:
-          return 11;
-        default:
-          SPDY_BUG << "Serializing unhandled frame type " << frame_type;
-          return -1;
-      }
-  }
-
-  SPDY_BUG << "Unhandled SPDY version " << version;
-  return -1;
-}
-
-int SpdyConstants::DataFrameType(SpdyMajorVersion version) {
-  switch (version) {
-    case SPDY3:
-      return 0;
-    case HTTP2:
-      return SerializeFrameType(version, DATA);
+int SpdyConstants::SerializeFrameType(SpdyFrameType frame_type) {
+  switch (frame_type) {
+    case DATA:
+      return kDataFrameType;
+    case HEADERS:
+      return 1;
+    case PRIORITY:
+      return 2;
+    case RST_STREAM:
+      return 3;
+    case SETTINGS:
+      return 4;
+    case PUSH_PROMISE:
+      return 5;
+    case PING:
+      return 6;
+    case GOAWAY:
+      return 7;
+    case WINDOW_UPDATE:
+      return 8;
+    case CONTINUATION:
+      return 9;
+    // ALTSVC and BLOCKED are extensions.
+    case ALTSVC:
+      return 10;
+    case BLOCKED:
+      return 11;
+    default:
+      SPDY_BUG << "Serializing unhandled frame type " << frame_type;
+      return -1;
   }
-
-  SPDY_BUG << "Unhandled SPDY version " << version;
-  return 0;
 }
 
 bool SpdyConstants::IsValidHTTP2FrameStreamId(
@@ -244,233 +158,102 @@ bool SpdyConstants::IsValidHTTP2FrameStreamId(
   }
 }
 
-bool SpdyConstants::IsValidSettingId(SpdyMajorVersion version,
-                                     int setting_id_field) {
-  switch (version) {
-    case SPDY3:
-      // UPLOAD_BANDWIDTH is the first valid setting id.
-      if (setting_id_field <
-          SerializeSettingId(version, SETTINGS_UPLOAD_BANDWIDTH)) {
-        return false;
-      }
-
-      // INITIAL_WINDOW_SIZE is the last valid setting id.
-      if (setting_id_field >
-          SerializeSettingId(version, SETTINGS_INITIAL_WINDOW_SIZE)) {
-        return false;
-      }
+bool SpdyConstants::ParseSettingsId(int wire_setting_id,
+                                    SpdySettingsIds* setting_id) {
+  // HEADER_TABLE_SIZE is the first defined setting id.
+  if (wire_setting_id < SETTINGS_MIN) {
+    return false;
+  }
 
-      return true;
-    case HTTP2:
-      // HEADER_TABLE_SIZE is the first valid setting id.
-      if (setting_id_field <
-          SerializeSettingId(version, SETTINGS_HEADER_TABLE_SIZE)) {
-        return false;
-      }
+  // MAX_HEADER_LIST_SIZE is the last defined setting id.
+  if (wire_setting_id > SETTINGS_MAX) {
+    return false;
+  }
 
-      // MAX_HEADER_LIST_SIZE is the last valid setting id.
-      if (setting_id_field >
-          SerializeSettingId(version, SETTINGS_MAX_HEADER_LIST_SIZE)) {
-        return false;
-      }
+  *setting_id = static_cast<SpdySettingsIds>(wire_setting_id);
+  return true;
+}
 
+bool SpdyConstants::SettingsIdToString(SpdySettingsIds id,
+                                       const char** settings_id_string) {
+  switch (id) {
+    case SETTINGS_HEADER_TABLE_SIZE:
+      *settings_id_string = "SETTINGS_HEADER_TABLE_SIZE";
+      return true;
+    case SETTINGS_ENABLE_PUSH:
+      *settings_id_string = "SETTINGS_ENABLE_PUSH";
+      return true;
+    case SETTINGS_MAX_CONCURRENT_STREAMS:
+      *settings_id_string = "SETTINGS_MAX_CONCURRENT_STREAMS";
+      return true;
+    case SETTINGS_INITIAL_WINDOW_SIZE:
+      *settings_id_string = "SETTINGS_INITIAL_WINDOW_SIZE";
+      return true;
+    case SETTINGS_MAX_FRAME_SIZE:
+      *settings_id_string = "SETTINGS_MAX_FRAME_SIZE";
+      return true;
+    case SETTINGS_MAX_HEADER_LIST_SIZE:
+      *settings_id_string = "SETTINGS_MAX_HEADER_LIST_SIZE";
       return true;
   }
 
-  SPDY_BUG << "Unhandled SPDY version " << version;
+  *settings_id_string = "SETTINGS_UNKNOWN";
   return false;
 }
 
-SpdySettingsIds SpdyConstants::ParseSettingId(SpdyMajorVersion version,
-                                              int setting_id_field) {
-  switch (version) {
-    case SPDY3:
-      switch (setting_id_field) {
-        case 1:
-          return SETTINGS_UPLOAD_BANDWIDTH;
-        case 2:
-          return SETTINGS_DOWNLOAD_BANDWIDTH;
-        case 3:
-          return SETTINGS_ROUND_TRIP_TIME;
-        case 4:
-          return SETTINGS_MAX_CONCURRENT_STREAMS;
-        case 5:
-          return SETTINGS_CURRENT_CWND;
-        case 6:
-          return SETTINGS_DOWNLOAD_RETRANS_RATE;
-        case 7:
-          return SETTINGS_INITIAL_WINDOW_SIZE;
-      }
-      break;
-    case HTTP2:
-      switch (setting_id_field) {
-        case 1:
-          return SETTINGS_HEADER_TABLE_SIZE;
-        case 2:
-          return SETTINGS_ENABLE_PUSH;
-        case 3:
-          return SETTINGS_MAX_CONCURRENT_STREAMS;
-        case 4:
-          return SETTINGS_INITIAL_WINDOW_SIZE;
-        case 5:
-          return SETTINGS_MAX_FRAME_SIZE;
-        case 6:
-          return SETTINGS_MAX_HEADER_LIST_SIZE;
-      }
-      break;
+bool SpdyConstants::IsValidRstStreamStatus(int rst_stream_status_field) {
+  // NO_ERROR is the first valid status code.
+  if (rst_stream_status_field < SerializeRstStreamStatus(RST_STREAM_NO_ERROR)) {
+    return false;
   }
 
-  SPDY_BUG << "Unhandled setting ID " << setting_id_field;
-  return SETTINGS_UPLOAD_BANDWIDTH;
-}
-
-int SpdyConstants::SerializeSettingId(SpdyMajorVersion version,
-                                       SpdySettingsIds id) {
-  switch (version) {
-    case SPDY3:
-      switch (id) {
-        case SETTINGS_UPLOAD_BANDWIDTH:
-          return 1;
-        case SETTINGS_DOWNLOAD_BANDWIDTH:
-          return 2;
-        case SETTINGS_ROUND_TRIP_TIME:
-          return 3;
-        case SETTINGS_MAX_CONCURRENT_STREAMS:
-          return 4;
-        case SETTINGS_CURRENT_CWND:
-          return 5;
-        case SETTINGS_DOWNLOAD_RETRANS_RATE:
-          return 6;
-        case SETTINGS_INITIAL_WINDOW_SIZE:
-          return 7;
-        default:
-          SPDY_BUG << "Serializing unhandled setting id " << id;
-          return -1;
-      }
-    case HTTP2:
-      switch (id) {
-        case SETTINGS_HEADER_TABLE_SIZE:
-          return 1;
-        case SETTINGS_ENABLE_PUSH:
-          return 2;
-        case SETTINGS_MAX_CONCURRENT_STREAMS:
-          return 3;
-        case SETTINGS_INITIAL_WINDOW_SIZE:
-          return 4;
-        case SETTINGS_MAX_FRAME_SIZE:
-          return 5;
-        case SETTINGS_MAX_HEADER_LIST_SIZE:
-          return 6;
-        default:
-          SPDY_BUG << "Serializing unhandled setting id " << id;
-          return -1;
-      }
+  // TODO(hkhalil): Omit COMPRESSION_ERROR and SETTINGS_TIMEOUT
+  /*
+  // This works because GOAWAY and RST_STREAM share a namespace.
+  if (rst_stream_status_field ==
+  SerializeGoAwayStatus(version, GOAWAY_COMPRESSION_ERROR) ||
+  rst_stream_status_field ==
+  SerializeGoAwayStatus(version, GOAWAY_SETTINGS_TIMEOUT)) {
+  return false;
   }
-  SPDY_BUG << "Unhandled SPDY version " << version;
-  return -1;
-}
-
-bool SpdyConstants::IsValidRstStreamStatus(SpdyMajorVersion version,
-                                           int rst_stream_status_field) {
-  switch (version) {
-    case SPDY3:
-      // PROTOCOL_ERROR is the valid first status code.
-      if (rst_stream_status_field <
-          SerializeRstStreamStatus(version, RST_STREAM_PROTOCOL_ERROR)) {
-        return false;
-      }
-
-      // FRAME_TOO_LARGE is the valid last status code.
-      if (rst_stream_status_field >
-          SerializeRstStreamStatus(version, RST_STREAM_FRAME_TOO_LARGE)) {
-        return false;
-      }
-
-      return true;
-    case HTTP2:
-      // NO_ERROR is the first valid status code.
-      if (rst_stream_status_field <
-          SerializeRstStreamStatus(version, RST_STREAM_PROTOCOL_ERROR)) {
-        return false;
-      }
-
-      // TODO(hkhalil): Omit COMPRESSION_ERROR and SETTINGS_TIMEOUT
-      /*
-      // This works because GOAWAY and RST_STREAM share a namespace.
-      if (rst_stream_status_field ==
-          SerializeGoAwayStatus(version, GOAWAY_COMPRESSION_ERROR) ||
-          rst_stream_status_field ==
-          SerializeGoAwayStatus(version, GOAWAY_SETTINGS_TIMEOUT)) {
-        return false;
-      }
-      */
+  */
 
-      // HTTP_1_1_REQUIRED is the last valid status code.
-      if (rst_stream_status_field >
-          SerializeRstStreamStatus(version, RST_STREAM_HTTP_1_1_REQUIRED)) {
-        return false;
-      }
-
-      return true;
+  // HTTP_1_1_REQUIRED is the last valid status code.
+  if (rst_stream_status_field >
+      SerializeRstStreamStatus(RST_STREAM_HTTP_1_1_REQUIRED)) {
+    return false;
   }
-  SPDY_BUG << "Unhandled SPDY version " << version;
-  return false;
+
+  return true;
 }
 
 SpdyRstStreamStatus SpdyConstants::ParseRstStreamStatus(
-    SpdyMajorVersion version,
     int rst_stream_status_field) {
-  switch (version) {
-    case SPDY3:
-      switch (rst_stream_status_field) {
-        case 1:
-          return RST_STREAM_PROTOCOL_ERROR;
-        case 2:
-          return RST_STREAM_INVALID_STREAM;
-        case 3:
-          return RST_STREAM_REFUSED_STREAM;
-        case 4:
-          return RST_STREAM_UNSUPPORTED_VERSION;
-        case 5:
-          return RST_STREAM_CANCEL;
-        case 6:
-          return RST_STREAM_INTERNAL_ERROR;
-        case 7:
-          return RST_STREAM_FLOW_CONTROL_ERROR;
-        case 8:
-          return RST_STREAM_STREAM_IN_USE;
-        case 9:
-          return RST_STREAM_STREAM_ALREADY_CLOSED;
-        case 11:
-          return RST_STREAM_FRAME_TOO_LARGE;
-      }
-      break;
-    case HTTP2:
-      switch (rst_stream_status_field) {
-        case 1:
-          return RST_STREAM_PROTOCOL_ERROR;
-        case 2:
-          return RST_STREAM_INTERNAL_ERROR;
-        case 3:
-          return RST_STREAM_FLOW_CONTROL_ERROR;
-        case 5:
-          return RST_STREAM_STREAM_CLOSED;
-        case 6:
-          return RST_STREAM_FRAME_SIZE_ERROR;
-        case 7:
-          return RST_STREAM_REFUSED_STREAM;
-        case 8:
-          return RST_STREAM_CANCEL;
-        case 10:
-          return RST_STREAM_CONNECT_ERROR;
-        case 11:
-          return RST_STREAM_ENHANCE_YOUR_CALM;
-        case 12:
-          return RST_STREAM_INADEQUATE_SECURITY;
-        case 13:
-          return RST_STREAM_HTTP_1_1_REQUIRED;
-      }
-      break;
+  switch (rst_stream_status_field) {
+    case 0:
+      return RST_STREAM_NO_ERROR;
+    case 1:
+      return RST_STREAM_PROTOCOL_ERROR;
+    case 2:
+      return RST_STREAM_INTERNAL_ERROR;
+    case 3:
+      return RST_STREAM_FLOW_CONTROL_ERROR;
+    case 5:
+      return RST_STREAM_STREAM_CLOSED;
+    case 6:
+      return RST_STREAM_FRAME_SIZE_ERROR;
+    case 7:
+      return RST_STREAM_REFUSED_STREAM;
+    case 8:
+      return RST_STREAM_CANCEL;
+    case 10:
+      return RST_STREAM_CONNECT_ERROR;
+    case 11:
+      return RST_STREAM_ENHANCE_YOUR_CALM;
+    case 12:
+      return RST_STREAM_INADEQUATE_SECURITY;
+    case 13:
+      return RST_STREAM_HTTP_1_1_REQUIRED;
   }
 
   SPDY_BUG << "Invalid RST_STREAM status " << rst_stream_status_field;
@@ -478,269 +261,142 @@ SpdyRstStreamStatus SpdyConstants::ParseRstStreamStatus(
 }
 
 int SpdyConstants::SerializeRstStreamStatus(
-    SpdyMajorVersion version,
     SpdyRstStreamStatus rst_stream_status) {
-  switch (version) {
-    case SPDY3:
-      switch (rst_stream_status) {
-        case RST_STREAM_PROTOCOL_ERROR:
-          return 1;
-        case RST_STREAM_INVALID_STREAM:
-          return 2;
-        case RST_STREAM_REFUSED_STREAM:
-          return 3;
-        case RST_STREAM_UNSUPPORTED_VERSION:
-          return 4;
-        case RST_STREAM_CANCEL:
-          return 5;
-        case RST_STREAM_INTERNAL_ERROR:
-          return 6;
-        case RST_STREAM_FLOW_CONTROL_ERROR:
-          return 7;
-        case RST_STREAM_STREAM_IN_USE:
-          return 8;
-        case RST_STREAM_STREAM_ALREADY_CLOSED:
-          return 9;
-        case RST_STREAM_FRAME_TOO_LARGE:
-          return 11;
-        default:
-          SPDY_BUG << "Unhandled RST_STREAM status " << rst_stream_status;
-          return -1;
-      }
-    case HTTP2:
-      switch (rst_stream_status) {
-        case RST_STREAM_PROTOCOL_ERROR:
-          return 1;
-        case RST_STREAM_INTERNAL_ERROR:
-          return 2;
-        case RST_STREAM_FLOW_CONTROL_ERROR:
-          return 3;
-        case RST_STREAM_STREAM_CLOSED:
-          return 5;
-        case RST_STREAM_FRAME_SIZE_ERROR:
-          return 6;
-        case RST_STREAM_REFUSED_STREAM:
-          return 7;
-        case RST_STREAM_CANCEL:
-          return 8;
-        case RST_STREAM_CONNECT_ERROR:
-          return 10;
-        case RST_STREAM_ENHANCE_YOUR_CALM:
-          return 11;
-        case RST_STREAM_INADEQUATE_SECURITY:
-          return 12;
-        case RST_STREAM_HTTP_1_1_REQUIRED:
-          return 13;
-        default:
-          SPDY_BUG << "Unhandled RST_STREAM status " << rst_stream_status;
-          return -1;
-      }
+  switch (rst_stream_status) {
+    case RST_STREAM_NO_ERROR:
+      return 0;
+    case RST_STREAM_PROTOCOL_ERROR:
+      return 1;
+    case RST_STREAM_INTERNAL_ERROR:
+      return 2;
+    case RST_STREAM_FLOW_CONTROL_ERROR:
+      return 3;
+    case RST_STREAM_STREAM_CLOSED:
+      return 5;
+    case RST_STREAM_FRAME_SIZE_ERROR:
+      return 6;
+    case RST_STREAM_REFUSED_STREAM:
+      return 7;
+    case RST_STREAM_CANCEL:
+      return 8;
+    case RST_STREAM_CONNECT_ERROR:
+      return 10;
+    case RST_STREAM_ENHANCE_YOUR_CALM:
+      return 11;
+    case RST_STREAM_INADEQUATE_SECURITY:
+      return 12;
+    case RST_STREAM_HTTP_1_1_REQUIRED:
+      return 13;
+    default:
+      SPDY_BUG << "Unhandled RST_STREAM status " << rst_stream_status;
+      return -1;
   }
-  SPDY_BUG << "Unhandled SPDY version " << version;
-  return -1;
 }
 
-bool SpdyConstants::IsValidGoAwayStatus(SpdyMajorVersion version,
-                                        int goaway_status_field) {
-  switch (version) {
-    case SPDY3:
-      // GOAWAY_OK is the first valid status.
-      if (goaway_status_field < SerializeGoAwayStatus(version, GOAWAY_OK)) {
-        return false;
-      }
-
-      // GOAWAY_INTERNAL_ERROR is the last valid status.
-      if (goaway_status_field > SerializeGoAwayStatus(version,
-                                                      GOAWAY_INTERNAL_ERROR)) {
-        return false;
-      }
-
-      return true;
-    case HTTP2:
-      // GOAWAY_NO_ERROR is the first valid status.
-      if (goaway_status_field < SerializeGoAwayStatus(version,
-                                                      GOAWAY_NO_ERROR)) {
-        return false;
-      }
-
-      // GOAWAY_HTTP_1_1_REQUIRED is the last valid status.
-      if (goaway_status_field >
-          SerializeGoAwayStatus(version, GOAWAY_HTTP_1_1_REQUIRED)) {
-        return false;
-      }
+bool SpdyConstants::IsValidGoAwayStatus(int goaway_status_field) {
+  // GOAWAY_NO_ERROR is the first valid status.
+  if (goaway_status_field < SerializeGoAwayStatus(GOAWAY_NO_ERROR)) {
+    return false;
+  }
 
-      return true;
+  // GOAWAY_HTTP_1_1_REQUIRED is the last valid status.
+  if (goaway_status_field > SerializeGoAwayStatus(GOAWAY_HTTP_1_1_REQUIRED)) {
+    return false;
   }
-  SPDY_BUG << "Unknown SpdyMajorVersion " << version;
-  return false;
-}
 
-SpdyGoAwayStatus SpdyConstants::ParseGoAwayStatus(SpdyMajorVersion version,
-                                                  int goaway_status_field) {
-  switch (version) {
-    case SPDY3:
-      switch (goaway_status_field) {
-        case 0:
-          return GOAWAY_OK;
-        case 1:
-          return GOAWAY_PROTOCOL_ERROR;
-        case 2:
-          return GOAWAY_INTERNAL_ERROR;
-      }
-      break;
-    case HTTP2:
-      switch (goaway_status_field) {
-        case 0:
-          return GOAWAY_NO_ERROR;
-        case 1:
-          return GOAWAY_PROTOCOL_ERROR;
-        case 2:
-          return GOAWAY_INTERNAL_ERROR;
-        case 3:
-          return GOAWAY_FLOW_CONTROL_ERROR;
-        case 4:
-          return GOAWAY_SETTINGS_TIMEOUT;
-        case 5:
-          return GOAWAY_STREAM_CLOSED;
-        case 6:
-          return GOAWAY_FRAME_SIZE_ERROR;
-        case 7:
-          return GOAWAY_REFUSED_STREAM;
-        case 8:
-          return GOAWAY_CANCEL;
-        case 9:
-          return GOAWAY_COMPRESSION_ERROR;
-        case 10:
-          return GOAWAY_CONNECT_ERROR;
-        case 11:
-          return GOAWAY_ENHANCE_YOUR_CALM;
-        case 12:
-          return GOAWAY_INADEQUATE_SECURITY;
-        case 13:
-          return GOAWAY_HTTP_1_1_REQUIRED;
-      }
-      break;
+  return true;
+}
+
+SpdyGoAwayStatus SpdyConstants::ParseGoAwayStatus(int goaway_status_field) {
+  switch (goaway_status_field) {
+    case 0:
+      return GOAWAY_NO_ERROR;
+    case 1:
+      return GOAWAY_PROTOCOL_ERROR;
+    case 2:
+      return GOAWAY_INTERNAL_ERROR;
+    case 3:
+      return GOAWAY_FLOW_CONTROL_ERROR;
+    case 4:
+      return GOAWAY_SETTINGS_TIMEOUT;
+    case 5:
+      return GOAWAY_STREAM_CLOSED;
+    case 6:
+      return GOAWAY_FRAME_SIZE_ERROR;
+    case 7:
+      return GOAWAY_REFUSED_STREAM;
+    case 8:
+      return GOAWAY_CANCEL;
+    case 9:
+      return GOAWAY_COMPRESSION_ERROR;
+    case 10:
+      return GOAWAY_CONNECT_ERROR;
+    case 11:
+      return GOAWAY_ENHANCE_YOUR_CALM;
+    case 12:
+      return GOAWAY_INADEQUATE_SECURITY;
+    case 13:
+      return GOAWAY_HTTP_1_1_REQUIRED;
   }
 
   SPDY_BUG << "Unhandled GOAWAY status " << goaway_status_field;
   return GOAWAY_PROTOCOL_ERROR;
 }
 
-int SpdyConstants::SerializeGoAwayStatus(SpdyMajorVersion version,
-                                         SpdyGoAwayStatus status) {
-  switch (version) {
-    case SPDY3:
-      // TODO(jgraettinger): Merge this back to server-side.
-      switch (status) {
-        case GOAWAY_NO_ERROR:
-          return 0;
-        case GOAWAY_PROTOCOL_ERROR:
-        case GOAWAY_INTERNAL_ERROR:
-        case GOAWAY_FLOW_CONTROL_ERROR:
-        case GOAWAY_SETTINGS_TIMEOUT:
-        case GOAWAY_STREAM_CLOSED:
-        case GOAWAY_FRAME_SIZE_ERROR:
-        case GOAWAY_REFUSED_STREAM:
-        case GOAWAY_CANCEL:
-        case GOAWAY_COMPRESSION_ERROR:
-        case GOAWAY_CONNECT_ERROR:
-        case GOAWAY_ENHANCE_YOUR_CALM:
-        case GOAWAY_INADEQUATE_SECURITY:
-        case GOAWAY_HTTP_1_1_REQUIRED:
-          return 1;  // PROTOCOL_ERROR.
-        default:
-          SPDY_BUG << "Serializing unhandled GOAWAY status " << status;
-          return -1;
-      }
-    case HTTP2:
-      switch (status) {
-        case GOAWAY_NO_ERROR:
-          return 0;
-        case GOAWAY_PROTOCOL_ERROR:
-          return 1;
-        case GOAWAY_INTERNAL_ERROR:
-          return 2;
-        case GOAWAY_FLOW_CONTROL_ERROR:
-          return 3;
-        case GOAWAY_SETTINGS_TIMEOUT:
-          return 4;
-        case GOAWAY_STREAM_CLOSED:
-          return 5;
-        case GOAWAY_FRAME_SIZE_ERROR:
-          return 6;
-        case GOAWAY_REFUSED_STREAM:
-          return 7;
-        case GOAWAY_CANCEL:
-          return 8;
-        case GOAWAY_COMPRESSION_ERROR:
-          return 9;
-        case GOAWAY_CONNECT_ERROR:
-          return 10;
-        case GOAWAY_ENHANCE_YOUR_CALM:
-          return 11;
-        case GOAWAY_INADEQUATE_SECURITY:
-          return 12;
-        case GOAWAY_HTTP_1_1_REQUIRED:
-          return 13;
-        default:
-          SPDY_BUG << "Serializing unhandled GOAWAY status " << status;
-          return -1;
-      }
-  }
-  SPDY_BUG << "Unknown SpdyMajorVersion " << version;
-  return -1;
-}
-
-size_t SpdyConstants::GetFrameHeaderSize(SpdyMajorVersion version) {
-  switch (version) {
-    case SPDY3:
+int SpdyConstants::SerializeGoAwayStatus(SpdyGoAwayStatus status) {
+  switch (status) {
+    case GOAWAY_NO_ERROR:
+      return 0;
+    case GOAWAY_PROTOCOL_ERROR:
+      return 1;
+    case GOAWAY_INTERNAL_ERROR:
+      return 2;
+    case GOAWAY_FLOW_CONTROL_ERROR:
+      return 3;
+    case GOAWAY_SETTINGS_TIMEOUT:
+      return 4;
+    case GOAWAY_STREAM_CLOSED:
+      return 5;
+    case GOAWAY_FRAME_SIZE_ERROR:
+      return 6;
+    case GOAWAY_REFUSED_STREAM:
+      return 7;
+    case GOAWAY_CANCEL:
       return 8;
-    case HTTP2:
+    case GOAWAY_COMPRESSION_ERROR:
       return 9;
+    case GOAWAY_CONNECT_ERROR:
+      return 10;
+    case GOAWAY_ENHANCE_YOUR_CALM:
+      return 11;
+    case GOAWAY_INADEQUATE_SECURITY:
+      return 12;
+    case GOAWAY_HTTP_1_1_REQUIRED:
+      return 13;
+    default:
+      SPDY_BUG << "Serializing unhandled GOAWAY status " << status;
+      return -1;
   }
-  SPDY_BUG << "Unhandled SPDY version: " << version;
-  return 0;
 }
 
-size_t SpdyConstants::GetDataFrameMinimumSize(SpdyMajorVersion version) {
-  return GetFrameHeaderSize(version);
-}
+const int SpdyConstants::kDataFrameType = 0;
 
-size_t SpdyConstants::GetMaxFrameSizeLimit(SpdyMajorVersion version) {
-  return kSpdyMaxFrameSizeLimit + GetFrameHeaderSize(version);
-}
+const size_t SpdyConstants::kFrameHeaderSize = 9;
 
-size_t SpdyConstants::GetSizeOfSizeField() {
-  return sizeof(uint32_t);
-}
+const size_t SpdyConstants::kDataFrameMinimumSize = kFrameHeaderSize;
 
-size_t SpdyConstants::GetPerHeaderOverhead(SpdyMajorVersion version) {
-  return (version == net::HTTP2) ? 32 : 0;
-}
+const size_t SpdyConstants::kMaxFrameSizeLimit =
+    kSpdyMaxFrameSizeLimit + kFrameHeaderSize;
 
-size_t SpdyConstants::GetSettingSize(SpdyMajorVersion version) {
-  return version == SPDY3 ? 8 : 6;
-}
+const size_t SpdyConstants::kSizeOfSizeField = sizeof(uint32_t);
 
-int32_t SpdyConstants::GetInitialStreamWindowSize(SpdyMajorVersion version) {
-  return (version == SPDY3) ? (64 * 1024) : (64 * 1024 - 1);
-}
+const size_t SpdyConstants::kPerHeaderOverhead = 32;
 
-int32_t SpdyConstants::GetInitialSessionWindowSize(SpdyMajorVersion version) {
-  return (version == SPDY3) ? (64 * 1024) : (64 * 1024 - 1);
-}
+const int32_t SpdyConstants::kInitialStreamWindowSize = 64 * 1024 - 1;
 
-std::string SpdyConstants::GetVersionString(SpdyMajorVersion version) {
-  switch (version) {
-    case SPDY3:
-      return "spdy/3.1";
-    case HTTP2:
-      return "h2";
-    default:
-      SPDY_BUG << "Unsupported SPDY major version: " << version;
-      return "spdy/3.1";
-  }
-}
+const int32_t SpdyConstants::kInitialSessionWindowSize = 64 * 1024 - 1;
+
+const char SpdyConstants::kHttp2Npn[] = "h2";
 
 SpdyFrameWithHeaderBlockIR::SpdyFrameWithHeaderBlockIR(
     SpdyStreamId stream_id,
@@ -750,7 +406,11 @@ SpdyFrameWithHeaderBlockIR::SpdyFrameWithHeaderBlockIR(
 SpdyFrameWithHeaderBlockIR::~SpdyFrameWithHeaderBlockIR() {}
 
 SpdyDataIR::SpdyDataIR(SpdyStreamId stream_id, base::StringPiece data)
-    : SpdyFrameWithFinIR(stream_id), padded_(false), padding_payload_len_(0) {
+    : SpdyFrameWithFinIR(stream_id),
+      data_(nullptr),
+      data_len_(0),
+      padded_(false),
+      padding_payload_len_(0) {
   SetDataDeep(data);
 }
 
@@ -760,12 +420,17 @@ SpdyDataIR::SpdyDataIR(SpdyStreamId stream_id, const char* data)
 SpdyDataIR::SpdyDataIR(SpdyStreamId stream_id, std::string data)
     : SpdyFrameWithFinIR(stream_id),
       data_store_(base::MakeUnique<std::string>(std::move(data))),
-      data_(*data_store_),
+      data_(data_store_->data()),
+      data_len_(data_store_->size()),
       padded_(false),
       padding_payload_len_(0) {}
 
 SpdyDataIR::SpdyDataIR(SpdyStreamId stream_id)
-    : SpdyFrameWithFinIR(stream_id), padded_(false), padding_payload_len_(0) {}
+    : SpdyFrameWithFinIR(stream_id),
+      data_(nullptr),
+      data_len_(0),
+      padded_(false),
+      padding_payload_len_(0) {}
 
 SpdyDataIR::~SpdyDataIR() {}
 
@@ -773,14 +438,6 @@ void SpdyDataIR::Visit(SpdyFrameVisitor* visitor) const {
   return visitor->VisitData(*this);
 }
 
-void SpdySynStreamIR::Visit(SpdyFrameVisitor* visitor) const {
-  return visitor->VisitSynStream(*this);
-}
-
-void SpdySynReplyIR::Visit(SpdyFrameVisitor* visitor) const {
-  return visitor->VisitSynReply(*this);
-}
-
 SpdyRstStreamIR::SpdyRstStreamIR(SpdyStreamId stream_id,
                                  SpdyRstStreamStatus status)
     : SpdyFrameWithStreamIdIR(stream_id) {
@@ -833,6 +490,13 @@ SpdyGoAwayIR::SpdyGoAwayIR(SpdyStreamId last_good_stream_id,
 
 SpdyGoAwayIR::~SpdyGoAwayIR() {}
 
+SpdyContinuationIR::SpdyContinuationIR(SpdyStreamId stream_id)
+    : SpdyFrameWithStreamIdIR(stream_id), end_headers_(false) {
+  encoding_ = base::MakeUnique<std::string>();
+}
+
+SpdyContinuationIR::~SpdyContinuationIR() {}
+
 void SpdyGoAwayIR::Visit(SpdyFrameVisitor* visitor) const {
   return visitor->VisitGoAway(*this);
 }
diff --git a/src/net/spdy/spdy_protocol.h b/src/net/spdy/spdy_protocol.h
index 072d9ac..f71d6b2 100644
--- a/src/net/spdy/spdy_protocol.h
+++ b/src/net/spdy/spdy_protocol.h
@@ -31,19 +31,7 @@
 
 namespace net {
 
-// The major versions of SPDY. Major version differences indicate
-// framer-layer incompatibility, as opposed to minor version numbers
-// which indicate application-layer incompatibility. It is NOT guaranteed
-// that the enum value SPDYn maps to the integer n.
-enum SpdyMajorVersion {
-  SPDY3 = 1,
-  HTTP2,
-};
-
-// 15 bit version field for SPDY/3 frames.
-const uint16_t kSpdy3Version = 3;
-
-// A SPDY stream id is a 31 bit entity.
+// A stream id is a 31 bit entity.
 typedef uint32_t SpdyStreamId;
 
 // Specifies the stream ID used to denote the current session (for
@@ -67,189 +55,6 @@ const int32_t kSpdyMaximumWindowSize = 0x7FFFFFFF;  // Max signed 32bit int
 // Maximum padding size in octets for one DATA or HEADERS or PUSH_PROMISE frame.
 const int32_t kPaddingSizePerFrame = 256;
 
-// SPDY 3 dictionary.
-const char kV3Dictionary[] = {
-  0x00, 0x00, 0x00, 0x07, 0x6f, 0x70, 0x74, 0x69,  // ....opti
-  0x6f, 0x6e, 0x73, 0x00, 0x00, 0x00, 0x04, 0x68,  // ons....h
-  0x65, 0x61, 0x64, 0x00, 0x00, 0x00, 0x04, 0x70,  // ead....p
-  0x6f, 0x73, 0x74, 0x00, 0x00, 0x00, 0x03, 0x70,  // ost....p
-  0x75, 0x74, 0x00, 0x00, 0x00, 0x06, 0x64, 0x65,  // ut....de
-  0x6c, 0x65, 0x74, 0x65, 0x00, 0x00, 0x00, 0x05,  // lete....
-  0x74, 0x72, 0x61, 0x63, 0x65, 0x00, 0x00, 0x00,  // trace...
-  0x06, 0x61, 0x63, 0x63, 0x65, 0x70, 0x74, 0x00,  // .accept.
-  0x00, 0x00, 0x0e, 0x61, 0x63, 0x63, 0x65, 0x70,  // ...accep
-  0x74, 0x2d, 0x63, 0x68, 0x61, 0x72, 0x73, 0x65,  // t-charse
-  0x74, 0x00, 0x00, 0x00, 0x0f, 0x61, 0x63, 0x63,  // t....acc
-  0x65, 0x70, 0x74, 0x2d, 0x65, 0x6e, 0x63, 0x6f,  // ept-enco
-  0x64, 0x69, 0x6e, 0x67, 0x00, 0x00, 0x00, 0x0f,  // ding....
-  0x61, 0x63, 0x63, 0x65, 0x70, 0x74, 0x2d, 0x6c,  // accept-l
-  0x61, 0x6e, 0x67, 0x75, 0x61, 0x67, 0x65, 0x00,  // anguage.
-  0x00, 0x00, 0x0d, 0x61, 0x63, 0x63, 0x65, 0x70,  // ...accep
-  0x74, 0x2d, 0x72, 0x61, 0x6e, 0x67, 0x65, 0x73,  // t-ranges
-  0x00, 0x00, 0x00, 0x03, 0x61, 0x67, 0x65, 0x00,  // ....age.
-  0x00, 0x00, 0x05, 0x61, 0x6c, 0x6c, 0x6f, 0x77,  // ...allow
-  0x00, 0x00, 0x00, 0x0d, 0x61, 0x75, 0x74, 0x68,  // ....auth
-  0x6f, 0x72, 0x69, 0x7a, 0x61, 0x74, 0x69, 0x6f,  // orizatio
-  0x6e, 0x00, 0x00, 0x00, 0x0d, 0x63, 0x61, 0x63,  // n....cac
-  0x68, 0x65, 0x2d, 0x63, 0x6f, 0x6e, 0x74, 0x72,  // he-contr
-  0x6f, 0x6c, 0x00, 0x00, 0x00, 0x0a, 0x63, 0x6f,  // ol....co
-  0x6e, 0x6e, 0x65, 0x63, 0x74, 0x69, 0x6f, 0x6e,  // nnection
-  0x00, 0x00, 0x00, 0x0c, 0x63, 0x6f, 0x6e, 0x74,  // ....cont
-  0x65, 0x6e, 0x74, 0x2d, 0x62, 0x61, 0x73, 0x65,  // ent-base
-  0x00, 0x00, 0x00, 0x10, 0x63, 0x6f, 0x6e, 0x74,  // ....cont
-  0x65, 0x6e, 0x74, 0x2d, 0x65, 0x6e, 0x63, 0x6f,  // ent-enco
-  0x64, 0x69, 0x6e, 0x67, 0x00, 0x00, 0x00, 0x10,  // ding....
-  0x63, 0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74, 0x2d,  // content-
-  0x6c, 0x61, 0x6e, 0x67, 0x75, 0x61, 0x67, 0x65,  // language
-  0x00, 0x00, 0x00, 0x0e, 0x63, 0x6f, 0x6e, 0x74,  // ....cont
-  0x65, 0x6e, 0x74, 0x2d, 0x6c, 0x65, 0x6e, 0x67,  // ent-leng
-  0x74, 0x68, 0x00, 0x00, 0x00, 0x10, 0x63, 0x6f,  // th....co
-  0x6e, 0x74, 0x65, 0x6e, 0x74, 0x2d, 0x6c, 0x6f,  // ntent-lo
-  0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x00, 0x00,  // cation..
-  0x00, 0x0b, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x6e,  // ..conten
-  0x74, 0x2d, 0x6d, 0x64, 0x35, 0x00, 0x00, 0x00,  // t-md5...
-  0x0d, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74,  // .content
-  0x2d, 0x72, 0x61, 0x6e, 0x67, 0x65, 0x00, 0x00,  // -range..
-  0x00, 0x0c, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x6e,  // ..conten
-  0x74, 0x2d, 0x74, 0x79, 0x70, 0x65, 0x00, 0x00,  // t-type..
-  0x00, 0x04, 0x64, 0x61, 0x74, 0x65, 0x00, 0x00,  // ..date..
-  0x00, 0x04, 0x65, 0x74, 0x61, 0x67, 0x00, 0x00,  // ..etag..
-  0x00, 0x06, 0x65, 0x78, 0x70, 0x65, 0x63, 0x74,  // ..expect
-  0x00, 0x00, 0x00, 0x07, 0x65, 0x78, 0x70, 0x69,  // ....expi
-  0x72, 0x65, 0x73, 0x00, 0x00, 0x00, 0x04, 0x66,  // res....f
-  0x72, 0x6f, 0x6d, 0x00, 0x00, 0x00, 0x04, 0x68,  // rom....h
-  0x6f, 0x73, 0x74, 0x00, 0x00, 0x00, 0x08, 0x69,  // ost....i
-  0x66, 0x2d, 0x6d, 0x61, 0x74, 0x63, 0x68, 0x00,  // f-match.
-  0x00, 0x00, 0x11, 0x69, 0x66, 0x2d, 0x6d, 0x6f,  // ...if-mo
-  0x64, 0x69, 0x66, 0x69, 0x65, 0x64, 0x2d, 0x73,  // dified-s
-  0x69, 0x6e, 0x63, 0x65, 0x00, 0x00, 0x00, 0x0d,  // ince....
-  0x69, 0x66, 0x2d, 0x6e, 0x6f, 0x6e, 0x65, 0x2d,  // if-none-
-  0x6d, 0x61, 0x74, 0x63, 0x68, 0x00, 0x00, 0x00,  // match...
-  0x08, 0x69, 0x66, 0x2d, 0x72, 0x61, 0x6e, 0x67,  // .if-rang
-  0x65, 0x00, 0x00, 0x00, 0x13, 0x69, 0x66, 0x2d,  // e....if-
-  0x75, 0x6e, 0x6d, 0x6f, 0x64, 0x69, 0x66, 0x69,  // unmodifi
-  0x65, 0x64, 0x2d, 0x73, 0x69, 0x6e, 0x63, 0x65,  // ed-since
-  0x00, 0x00, 0x00, 0x0d, 0x6c, 0x61, 0x73, 0x74,  // ....last
-  0x2d, 0x6d, 0x6f, 0x64, 0x69, 0x66, 0x69, 0x65,  // -modifie
-  0x64, 0x00, 0x00, 0x00, 0x08, 0x6c, 0x6f, 0x63,  // d....loc
-  0x61, 0x74, 0x69, 0x6f, 0x6e, 0x00, 0x00, 0x00,  // ation...
-  0x0c, 0x6d, 0x61, 0x78, 0x2d, 0x66, 0x6f, 0x72,  // .max-for
-  0x77, 0x61, 0x72, 0x64, 0x73, 0x00, 0x00, 0x00,  // wards...
-  0x06, 0x70, 0x72, 0x61, 0x67, 0x6d, 0x61, 0x00,  // .pragma.
-  0x00, 0x00, 0x12, 0x70, 0x72, 0x6f, 0x78, 0x79,  // ...proxy
-  0x2d, 0x61, 0x75, 0x74, 0x68, 0x65, 0x6e, 0x74,  // -authent
-  0x69, 0x63, 0x61, 0x74, 0x65, 0x00, 0x00, 0x00,  // icate...
-  0x13, 0x70, 0x72, 0x6f, 0x78, 0x79, 0x2d, 0x61,  // .proxy-a
-  0x75, 0x74, 0x68, 0x6f, 0x72, 0x69, 0x7a, 0x61,  // uthoriza
-  0x74, 0x69, 0x6f, 0x6e, 0x00, 0x00, 0x00, 0x05,  // tion....
-  0x72, 0x61, 0x6e, 0x67, 0x65, 0x00, 0x00, 0x00,  // range...
-  0x07, 0x72, 0x65, 0x66, 0x65, 0x72, 0x65, 0x72,  // .referer
-  0x00, 0x00, 0x00, 0x0b, 0x72, 0x65, 0x74, 0x72,  // ....retr
-  0x79, 0x2d, 0x61, 0x66, 0x74, 0x65, 0x72, 0x00,  // y-after.
-  0x00, 0x00, 0x06, 0x73, 0x65, 0x72, 0x76, 0x65,  // ...serve
-  0x72, 0x00, 0x00, 0x00, 0x02, 0x74, 0x65, 0x00,  // r....te.
-  0x00, 0x00, 0x07, 0x74, 0x72, 0x61, 0x69, 0x6c,  // ...trail
-  0x65, 0x72, 0x00, 0x00, 0x00, 0x11, 0x74, 0x72,  // er....tr
-  0x61, 0x6e, 0x73, 0x66, 0x65, 0x72, 0x2d, 0x65,  // ansfer-e
-  0x6e, 0x63, 0x6f, 0x64, 0x69, 0x6e, 0x67, 0x00,  // ncoding.
-  0x00, 0x00, 0x07, 0x75, 0x70, 0x67, 0x72, 0x61,  // ...upgra
-  0x64, 0x65, 0x00, 0x00, 0x00, 0x0a, 0x75, 0x73,  // de....us
-  0x65, 0x72, 0x2d, 0x61, 0x67, 0x65, 0x6e, 0x74,  // er-agent
-  0x00, 0x00, 0x00, 0x04, 0x76, 0x61, 0x72, 0x79,  // ....vary
-  0x00, 0x00, 0x00, 0x03, 0x76, 0x69, 0x61, 0x00,  // ....via.
-  0x00, 0x00, 0x07, 0x77, 0x61, 0x72, 0x6e, 0x69,  // ...warni
-  0x6e, 0x67, 0x00, 0x00, 0x00, 0x10, 0x77, 0x77,  // ng....ww
-  0x77, 0x2d, 0x61, 0x75, 0x74, 0x68, 0x65, 0x6e,  // w-authen
-  0x74, 0x69, 0x63, 0x61, 0x74, 0x65, 0x00, 0x00,  // ticate..
-  0x00, 0x06, 0x6d, 0x65, 0x74, 0x68, 0x6f, 0x64,  // ..method
-  0x00, 0x00, 0x00, 0x03, 0x67, 0x65, 0x74, 0x00,  // ....get.
-  0x00, 0x00, 0x06, 0x73, 0x74, 0x61, 0x74, 0x75,  // ...statu
-  0x73, 0x00, 0x00, 0x00, 0x06, 0x32, 0x30, 0x30,  // s....200
-  0x20, 0x4f, 0x4b, 0x00, 0x00, 0x00, 0x07, 0x76,  // .OK....v
-  0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00, 0x00,  // ersion..
-  0x00, 0x08, 0x48, 0x54, 0x54, 0x50, 0x2f, 0x31,  // ..HTTP.1
-  0x2e, 0x31, 0x00, 0x00, 0x00, 0x03, 0x75, 0x72,  // .1....ur
-  0x6c, 0x00, 0x00, 0x00, 0x06, 0x70, 0x75, 0x62,  // l....pub
-  0x6c, 0x69, 0x63, 0x00, 0x00, 0x00, 0x0a, 0x73,  // lic....s
-  0x65, 0x74, 0x2d, 0x63, 0x6f, 0x6f, 0x6b, 0x69,  // et-cooki
-  0x65, 0x00, 0x00, 0x00, 0x0a, 0x6b, 0x65, 0x65,  // e....kee
-  0x70, 0x2d, 0x61, 0x6c, 0x69, 0x76, 0x65, 0x00,  // p-alive.
-  0x00, 0x00, 0x06, 0x6f, 0x72, 0x69, 0x67, 0x69,  // ...origi
-  0x6e, 0x31, 0x30, 0x30, 0x31, 0x30, 0x31, 0x32,  // n1001012
-  0x30, 0x31, 0x32, 0x30, 0x32, 0x32, 0x30, 0x35,  // 01202205
-  0x32, 0x30, 0x36, 0x33, 0x30, 0x30, 0x33, 0x30,  // 20630030
-  0x32, 0x33, 0x30, 0x33, 0x33, 0x30, 0x34, 0x33,  // 23033043
-  0x30, 0x35, 0x33, 0x30, 0x36, 0x33, 0x30, 0x37,  // 05306307
-  0x34, 0x30, 0x32, 0x34, 0x30, 0x35, 0x34, 0x30,  // 40240540
-  0x36, 0x34, 0x30, 0x37, 0x34, 0x30, 0x38, 0x34,  // 64074084
-  0x30, 0x39, 0x34, 0x31, 0x30, 0x34, 0x31, 0x31,  // 09410411
-  0x34, 0x31, 0x32, 0x34, 0x31, 0x33, 0x34, 0x31,  // 41241341
-  0x34, 0x34, 0x31, 0x35, 0x34, 0x31, 0x36, 0x34,  // 44154164
-  0x31, 0x37, 0x35, 0x30, 0x32, 0x35, 0x30, 0x34,  // 17502504
-  0x35, 0x30, 0x35, 0x32, 0x30, 0x33, 0x20, 0x4e,  // 505203.N
-  0x6f, 0x6e, 0x2d, 0x41, 0x75, 0x74, 0x68, 0x6f,  // on-Autho
-  0x72, 0x69, 0x74, 0x61, 0x74, 0x69, 0x76, 0x65,  // ritative
-  0x20, 0x49, 0x6e, 0x66, 0x6f, 0x72, 0x6d, 0x61,  // .Informa
-  0x74, 0x69, 0x6f, 0x6e, 0x32, 0x30, 0x34, 0x20,  // tion204.
-  0x4e, 0x6f, 0x20, 0x43, 0x6f, 0x6e, 0x74, 0x65,  // No.Conte
-  0x6e, 0x74, 0x33, 0x30, 0x31, 0x20, 0x4d, 0x6f,  // nt301.Mo
-  0x76, 0x65, 0x64, 0x20, 0x50, 0x65, 0x72, 0x6d,  // ved.Perm
-  0x61, 0x6e, 0x65, 0x6e, 0x74, 0x6c, 0x79, 0x34,  // anently4
-  0x30, 0x30, 0x20, 0x42, 0x61, 0x64, 0x20, 0x52,  // 00.Bad.R
-  0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x34, 0x30,  // equest40
-  0x31, 0x20, 0x55, 0x6e, 0x61, 0x75, 0x74, 0x68,  // 1.Unauth
-  0x6f, 0x72, 0x69, 0x7a, 0x65, 0x64, 0x34, 0x30,  // orized40
-  0x33, 0x20, 0x46, 0x6f, 0x72, 0x62, 0x69, 0x64,  // 3.Forbid
-  0x64, 0x65, 0x6e, 0x34, 0x30, 0x34, 0x20, 0x4e,  // den404.N
-  0x6f, 0x74, 0x20, 0x46, 0x6f, 0x75, 0x6e, 0x64,  // ot.Found
-  0x35, 0x30, 0x30, 0x20, 0x49, 0x6e, 0x74, 0x65,  // 500.Inte
-  0x72, 0x6e, 0x61, 0x6c, 0x20, 0x53, 0x65, 0x72,  // rnal.Ser
-  0x76, 0x65, 0x72, 0x20, 0x45, 0x72, 0x72, 0x6f,  // ver.Erro
-  0x72, 0x35, 0x30, 0x31, 0x20, 0x4e, 0x6f, 0x74,  // r501.Not
-  0x20, 0x49, 0x6d, 0x70, 0x6c, 0x65, 0x6d, 0x65,  // .Impleme
-  0x6e, 0x74, 0x65, 0x64, 0x35, 0x30, 0x33, 0x20,  // nted503.
-  0x53, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65, 0x20,  // Service.
-  0x55, 0x6e, 0x61, 0x76, 0x61, 0x69, 0x6c, 0x61,  // Unavaila
-  0x62, 0x6c, 0x65, 0x4a, 0x61, 0x6e, 0x20, 0x46,  // bleJan.F
-  0x65, 0x62, 0x20, 0x4d, 0x61, 0x72, 0x20, 0x41,  // eb.Mar.A
-  0x70, 0x72, 0x20, 0x4d, 0x61, 0x79, 0x20, 0x4a,  // pr.May.J
-  0x75, 0x6e, 0x20, 0x4a, 0x75, 0x6c, 0x20, 0x41,  // un.Jul.A
-  0x75, 0x67, 0x20, 0x53, 0x65, 0x70, 0x74, 0x20,  // ug.Sept.
-  0x4f, 0x63, 0x74, 0x20, 0x4e, 0x6f, 0x76, 0x20,  // Oct.Nov.
-  0x44, 0x65, 0x63, 0x20, 0x30, 0x30, 0x3a, 0x30,  // Dec.00.0
-  0x30, 0x3a, 0x30, 0x30, 0x20, 0x4d, 0x6f, 0x6e,  // 0.00.Mon
-  0x2c, 0x20, 0x54, 0x75, 0x65, 0x2c, 0x20, 0x57,  // ..Tue..W
-  0x65, 0x64, 0x2c, 0x20, 0x54, 0x68, 0x75, 0x2c,  // ed..Thu.
-  0x20, 0x46, 0x72, 0x69, 0x2c, 0x20, 0x53, 0x61,  // .Fri..Sa
-  0x74, 0x2c, 0x20, 0x53, 0x75, 0x6e, 0x2c, 0x20,  // t..Sun..
-  0x47, 0x4d, 0x54, 0x63, 0x68, 0x75, 0x6e, 0x6b,  // GMTchunk
-  0x65, 0x64, 0x2c, 0x74, 0x65, 0x78, 0x74, 0x2f,  // ed.text.
-  0x68, 0x74, 0x6d, 0x6c, 0x2c, 0x69, 0x6d, 0x61,  // html.ima
-  0x67, 0x65, 0x2f, 0x70, 0x6e, 0x67, 0x2c, 0x69,  // ge.png.i
-  0x6d, 0x61, 0x67, 0x65, 0x2f, 0x6a, 0x70, 0x67,  // mage.jpg
-  0x2c, 0x69, 0x6d, 0x61, 0x67, 0x65, 0x2f, 0x67,  // .image.g
-  0x69, 0x66, 0x2c, 0x61, 0x70, 0x70, 0x6c, 0x69,  // if.appli
-  0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x78,  // cation.x
-  0x6d, 0x6c, 0x2c, 0x61, 0x70, 0x70, 0x6c, 0x69,  // ml.appli
-  0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x78,  // cation.x
-  0x68, 0x74, 0x6d, 0x6c, 0x2b, 0x78, 0x6d, 0x6c,  // html.xml
-  0x2c, 0x74, 0x65, 0x78, 0x74, 0x2f, 0x70, 0x6c,  // .text.pl
-  0x61, 0x69, 0x6e, 0x2c, 0x74, 0x65, 0x78, 0x74,  // ain.text
-  0x2f, 0x6a, 0x61, 0x76, 0x61, 0x73, 0x63, 0x72,  // .javascr
-  0x69, 0x70, 0x74, 0x2c, 0x70, 0x75, 0x62, 0x6c,  // ipt.publ
-  0x69, 0x63, 0x70, 0x72, 0x69, 0x76, 0x61, 0x74,  // icprivat
-  0x65, 0x6d, 0x61, 0x78, 0x2d, 0x61, 0x67, 0x65,  // emax-age
-  0x3d, 0x67, 0x7a, 0x69, 0x70, 0x2c, 0x64, 0x65,  // .gzip.de
-  0x66, 0x6c, 0x61, 0x74, 0x65, 0x2c, 0x73, 0x64,  // flate.sd
-  0x63, 0x68, 0x63, 0x68, 0x61, 0x72, 0x73, 0x65,  // chcharse
-  0x74, 0x3d, 0x75, 0x74, 0x66, 0x2d, 0x38, 0x63,  // t.utf-8c
-  0x68, 0x61, 0x72, 0x73, 0x65, 0x74, 0x3d, 0x69,  // harset.i
-  0x73, 0x6f, 0x2d, 0x38, 0x38, 0x35, 0x39, 0x2d,  // so-8859-
-  0x31, 0x2c, 0x75, 0x74, 0x66, 0x2d, 0x2c, 0x2a,  // 1.utf-..
-  0x2c, 0x65, 0x6e, 0x71, 0x3d, 0x30, 0x2e         // .enq.0.
-};
-const int kV3DictionarySize = arraysize(kV3Dictionary);
-
 // The HTTP/2 connection header prefix, which must be the first bytes
 // sent by the client upon starting an HTTP/2 connection, and which
 // must be followed by a SETTINGS frame.
@@ -266,11 +71,9 @@ const int kHttp2ConnectionHeaderPrefixSize =
 
 const char kHttp2VersionString[] = "HTTP/1.1";
 
-// Types of SPDY frames.
+// Types of HTTP2 frames.
 enum SpdyFrameType {
   DATA,
-  SYN_STREAM,
-  SYN_REPLY,
   RST_STREAM,
   SETTINGS,
   PING,
@@ -331,34 +134,26 @@ enum SpdySettingsFlags {
   SETTINGS_FLAG_PERSISTED = 0x02,
 };
 
-// List of known settings. Avoid changing these enum values, as persisted
-// settings are keyed on them, and they are also exposed in net-internals.
 enum SpdySettingsIds {
-  SETTINGS_UPLOAD_BANDWIDTH = 0x1,
-  SETTINGS_DOWNLOAD_BANDWIDTH = 0x2,
-  // Network round trip time in milliseconds.
-  SETTINGS_ROUND_TRIP_TIME = 0x3,
-  // The maximum number of simultaneous live streams in each direction.
-  SETTINGS_MAX_CONCURRENT_STREAMS = 0x4,
-  // TCP congestion window in packets.
-  SETTINGS_CURRENT_CWND = 0x5,
-  // Downstream byte retransmission rate in percentage.
-  SETTINGS_DOWNLOAD_RETRANS_RATE = 0x6,
-  // Initial window size in bytes
-  SETTINGS_INITIAL_WINDOW_SIZE = 0x7,
   // HPACK header table maximum size.
-  SETTINGS_HEADER_TABLE_SIZE = 0x8,
+  SETTINGS_HEADER_TABLE_SIZE = 0x1,
+  SETTINGS_MIN = SETTINGS_HEADER_TABLE_SIZE,
   // Whether or not server push (PUSH_PROMISE) is enabled.
-  SETTINGS_ENABLE_PUSH = 0x9,
+  SETTINGS_ENABLE_PUSH = 0x2,
+  // The maximum number of simultaneous live streams in each direction.
+  SETTINGS_MAX_CONCURRENT_STREAMS = 0x3,
+  // Initial window size in bytes
+  SETTINGS_INITIAL_WINDOW_SIZE = 0x4,
   // The size of the largest frame payload that a receiver is willing to accept.
-  SETTINGS_MAX_FRAME_SIZE = 0xa,
+  SETTINGS_MAX_FRAME_SIZE = 0x5,
   // The maximum size of header list that the sender is prepared to accept.
-  SETTINGS_MAX_HEADER_LIST_SIZE = 0xb,
+  SETTINGS_MAX_HEADER_LIST_SIZE = 0x6,
+  SETTINGS_MAX = SETTINGS_MAX_HEADER_LIST_SIZE
 };
 
 // Status codes for RST_STREAM frames.
 enum SpdyRstStreamStatus {
-  RST_STREAM_INVALID = 0,
+  RST_STREAM_NO_ERROR = 0,
   RST_STREAM_PROTOCOL_ERROR = 1,
   RST_STREAM_INVALID_STREAM = 2,
   RST_STREAM_STREAM_CLOSED = 2,  // Equivalent to INVALID_STREAM
@@ -448,24 +243,16 @@ class NET_EXPORT_PRIVATE SpdyConstants {
  public:
   // Returns true if a given on-the-wire enumeration of a frame type is valid
   // for a given protocol version, false otherwise.
-  static bool IsValidFrameType(SpdyMajorVersion version, int frame_type_field);
+  static bool IsValidFrameType(int frame_type_field);
 
-  // Parses a frame type from an on-the-wire enumeration of a given protocol
-  // version.
+  // Parses a frame type from an on-the-wire enumeration.
   // Behavior is undefined for invalid frame type fields; consumers should first
   // use IsValidFrameType() to verify validity of frame type fields.
-  static SpdyFrameType ParseFrameType(SpdyMajorVersion version,
-                                      int frame_type_field);
-
-  // Serializes a given frame type to the on-the-wire enumeration value for the
-  // given protocol version.
-  // Returns -1 on failure (I.E. Invalid frame type for the given version).
-  static int SerializeFrameType(SpdyMajorVersion version,
-                                SpdyFrameType frame_type);
+  static SpdyFrameType ParseFrameType(int frame_type_field);
 
-  // Returns the frame type for non-control (i.e. data) frames
-  // in the given SPDY version.
-  static int DataFrameType(SpdyMajorVersion version);
+  // Serializes a given frame type to the on-the-wire enumeration value.
+  // Returns -1 on failure (I.E. Invalid frame type).
+  static int SerializeFrameType(SpdyFrameType frame_type);
 
   // (HTTP/2) All standard frame types except WINDOW_UPDATE are
   // (stream-specific xor connection-level). Returns false iff we know
@@ -473,87 +260,62 @@ class NET_EXPORT_PRIVATE SpdyConstants {
   static bool IsValidHTTP2FrameStreamId(SpdyStreamId current_frame_stream_id,
                                         SpdyFrameType frame_type_field);
 
-  // Returns true if a given on-the-wire enumeration of a setting id is valid
-  // for a given protocol version, false otherwise.
-  static bool IsValidSettingId(SpdyMajorVersion version, int setting_id_field);
-
-  // Parses a setting id from an on-the-wire enumeration of a given protocol
-  // version.
-  // Behavior is undefined for invalid setting id fields; consumers should first
-  // use IsValidSettingId() to verify validity of setting id fields.
-  static SpdySettingsIds ParseSettingId(SpdyMajorVersion version,
-                                        int setting_id_field);
+  // If |wire_setting_id| is the on-the-wire representation of a defined
+  // SETTINGS parameter, parse it to |*setting_id| and return true.
+  static bool ParseSettingsId(int wire_setting_id, SpdySettingsIds* setting_id);
 
-  // Serializes a given setting id to the on-the-wire enumeration value for the
-  // given protocol version.
-  // Returns -1 on failure (I.E. Invalid setting id for the given version).
-  static int SerializeSettingId(SpdyMajorVersion version, SpdySettingsIds id);
+  // Return if |id| corresponds to a defined setting; stringify |id| to
+  // |*settings_id_string| regardless.
+  static bool SettingsIdToString(SpdySettingsIds id,
+                                 const char** settings_id_string);
 
   // Returns true if a given on-the-wire enumeration of a RST_STREAM status code
-  // is valid for a given protocol version, false otherwise.
-  static bool IsValidRstStreamStatus(SpdyMajorVersion version,
-                                     int rst_stream_status_field);
+  // is valid, false otherwise.
+  static bool IsValidRstStreamStatus(int rst_stream_status_field);
 
-  // Parses a RST_STREAM status code from an on-the-wire enumeration of a given
-  // protocol version.
+  // Parses a RST_STREAM status code from an on-the-wire enumeration.
   // Behavior is undefined for invalid RST_STREAM status code fields; consumers
   // should first use IsValidRstStreamStatus() to verify validity of RST_STREAM
   // status code fields..
-  static SpdyRstStreamStatus ParseRstStreamStatus(SpdyMajorVersion version,
-                                                  int rst_stream_status_field);
+  static SpdyRstStreamStatus ParseRstStreamStatus(int rst_stream_status_field);
 
   // Serializes a given RST_STREAM status code to the on-the-wire enumeration
-  // value for the given protocol version.
+  // value.
   // Returns -1 on failure (I.E. Invalid RST_STREAM status code for the given
   // version).
-  static int SerializeRstStreamStatus(SpdyMajorVersion version,
-                                      SpdyRstStreamStatus rst_stream_status);
+  static int SerializeRstStreamStatus(SpdyRstStreamStatus rst_stream_status);
 
   // Returns true if a given on-the-wire enumeration of a GOAWAY status code is
-  // valid for the given protocol version, false otherwise.
-  static bool IsValidGoAwayStatus(SpdyMajorVersion version,
-                                  int goaway_status_field);
+  // valid, false otherwise.
+  static bool IsValidGoAwayStatus(int goaway_status_field);
 
-  // Parses a GOAWAY status from an on-the-wire enumeration of a given protocol
-  // version.
+  // Parses a GOAWAY status from an on-the-wire enumeration.
   // Behavior is undefined for invalid GOAWAY status fields; consumers should
   // first use IsValidGoAwayStatus() to verify validity of GOAWAY status fields.
-  static SpdyGoAwayStatus ParseGoAwayStatus(SpdyMajorVersion version,
-                                            int goaway_status_field);
+  static SpdyGoAwayStatus ParseGoAwayStatus(int goaway_status_field);
 
-  // Serializes a given GOAWAY status to the on-the-wire enumeration value for
-  // the given protocol version.
+  // Serializes a given GOAWAY status to the on-the-wire enumeration value.
   // Returns -1 on failure (I.E. Invalid GOAWAY status for the given version).
-  static int SerializeGoAwayStatus(SpdyMajorVersion version,
-                                   SpdyGoAwayStatus status);
-
-  // Size, in bytes, of the data frame header. Future versions of SPDY
-  // will likely vary this, so we allow for the flexibility of a function call
-  // for this value as opposed to a constant.
-  static size_t GetDataFrameMinimumSize(SpdyMajorVersion version);
+  static int SerializeGoAwayStatus(SpdyGoAwayStatus status);
 
+  // Frame type for non-control (i.e. data) frames.
+  static const int kDataFrameType;
+  // Size, in bytes, of the data frame header.
+  static const size_t kDataFrameMinimumSize;
   // Number of octets in the frame header.
-  static size_t GetFrameHeaderSize(SpdyMajorVersion version);
-
+  static const size_t kFrameHeaderSize;
   // Maximum possible configurable size of a frame in octets.
-  static size_t GetMaxFrameSizeLimit(SpdyMajorVersion version);
-
-  // Returns the size of a header block size field. Valid only for SPDY 3.
-  static size_t GetSizeOfSizeField();
-
-  // Returns the per-header overhead for block size accounting in bytes.
-  static size_t GetPerHeaderOverhead(SpdyMajorVersion version);
-
-  // Returns the size (in bytes) of a wire setting ID and value.
-  static size_t GetSettingSize(SpdyMajorVersion version);
-
+  static const size_t kMaxFrameSizeLimit;
+  // Size of a header block size field. Valid only for SPDY 3.
+  static const size_t kSizeOfSizeField;
+  // Per-header overhead for block size accounting in bytes.
+  static const size_t kPerHeaderOverhead;
   // Initial window size for a stream in bytes.
-  static int32_t GetInitialStreamWindowSize(SpdyMajorVersion version);
-
+  static const int32_t kInitialStreamWindowSize;
   // Initial window size for a session in bytes.
-  static int32_t GetInitialSessionWindowSize(SpdyMajorVersion version);
-
-  static std::string GetVersionString(SpdyMajorVersion version);
+  static const int32_t kInitialSessionWindowSize;
+  // The NPN string for HTTP2, "h2".
+  static const char kHttp2Npn[];
 };
 
 // Variant type (i.e. tagged union) that is either a SPDY 3.x priority value,
@@ -654,7 +416,7 @@ typedef StreamPrecedence<SpdyStreamId> SpdyStreamPrecedence;
 
 class SpdyFrameVisitor;
 
-// Intermediate representation for SPDY frames.
+// Intermediate representation for HTTP2 frames.
 class NET_EXPORT_PRIVATE SpdyFrameIR {
  public:
   virtual ~SpdyFrameIR() {}
@@ -752,7 +514,8 @@ class NET_EXPORT_PRIVATE SpdyDataIR
 
   ~SpdyDataIR() override;
 
-  base::StringPiece data() const { return data_; }
+  const char* data() const { return data_; }
+  size_t data_len() const { return data_len_; }
 
   bool padded() const { return padded_; }
 
@@ -768,14 +531,24 @@ class NET_EXPORT_PRIVATE SpdyDataIR
 
   // Deep-copy of data (keep private copy).
   void SetDataDeep(base::StringPiece data) {
-    data_store_.reset(new std::string(data.data(), data.length()));
-    data_ = *(data_store_.get());
+    data_store_.reset(new std::string(data.data(), data.size()));
+    data_ = data_store_->data();
+    data_len_ = data.size();
   }
 
   // Shallow-copy of data (do not keep private copy).
   void SetDataShallow(base::StringPiece data) {
     data_store_.reset();
-    data_ = data;
+    data_ = data.data();
+    data_len_ = data.size();
+  }
+
+  // Use this method if we don't have a contiguous buffer and only
+  // need a length.
+  void SetDataShallow(size_t len) {
+    data_store_.reset();
+    data_ = nullptr;
+    data_len_ = len;
   }
 
   void Visit(SpdyFrameVisitor* visitor) const override;
@@ -783,7 +556,8 @@ class NET_EXPORT_PRIVATE SpdyDataIR
  private:
   // Used to store data that this SpdyDataIR should own.
   std::unique_ptr<std::string> data_store_;
-  base::StringPiece data_;
+  const char* data_;
+  size_t data_len_;
 
   bool padded_;
   // padding_payload_len_ = desired padding length - len(padding length field).
@@ -792,51 +566,6 @@ class NET_EXPORT_PRIVATE SpdyDataIR
   DISALLOW_COPY_AND_ASSIGN(SpdyDataIR);
 };
 
-class NET_EXPORT_PRIVATE SpdySynStreamIR : public SpdyFrameWithHeaderBlockIR {
- public:
-  explicit SpdySynStreamIR(SpdyStreamId stream_id)
-      : SpdySynStreamIR(stream_id, SpdyHeaderBlock()) {}
-  SpdySynStreamIR(SpdyStreamId stream_id, SpdyHeaderBlock header_block)
-      : SpdyFrameWithHeaderBlockIR(stream_id, std::move(header_block)),
-        associated_to_stream_id_(0),
-        priority_(0),
-        unidirectional_(false) {}
-  SpdyStreamId associated_to_stream_id() const {
-    return associated_to_stream_id_;
-  }
-  void set_associated_to_stream_id(SpdyStreamId stream_id) {
-    associated_to_stream_id_ = stream_id;
-  }
-  SpdyPriority priority() const { return priority_; }
-  void set_priority(SpdyPriority priority) { priority_ = priority; }
-  bool unidirectional() const { return unidirectional_; }
-  void set_unidirectional(bool unidirectional) {
-    unidirectional_ = unidirectional;
-  }
-
-  void Visit(SpdyFrameVisitor* visitor) const override;
-
- private:
-  SpdyStreamId associated_to_stream_id_;
-  SpdyPriority priority_;
-  bool unidirectional_;
-
-  DISALLOW_COPY_AND_ASSIGN(SpdySynStreamIR);
-};
-
-class NET_EXPORT_PRIVATE SpdySynReplyIR : public SpdyFrameWithHeaderBlockIR {
- public:
-  explicit SpdySynReplyIR(SpdyStreamId stream_id)
-      : SpdySynReplyIR(stream_id, SpdyHeaderBlock()) {}
-  SpdySynReplyIR(SpdyStreamId stream_id, SpdyHeaderBlock header_block)
-      : SpdyFrameWithHeaderBlockIR(stream_id, std::move(header_block)) {}
-
-  void Visit(SpdyFrameVisitor* visitor) const override;
-
- private:
-  DISALLOW_COPY_AND_ASSIGN(SpdySynReplyIR);
-};
-
 class NET_EXPORT_PRIVATE SpdyRstStreamIR : public SpdyFrameWithStreamIdIR {
  public:
   SpdyRstStreamIR(SpdyStreamId stream_id, SpdyRstStreamStatus status);
@@ -907,7 +636,6 @@ class NET_EXPORT_PRIVATE SpdyPingIR : public SpdyFrameIR {
   explicit SpdyPingIR(SpdyPingId id) : id_(id), is_ack_(false) {}
   SpdyPingId id() const { return id_; }
 
-  // ACK logic is valid only for SPDY versions 4 and above.
   bool is_ack() const { return is_ack_; }
   void set_is_ack(bool is_ack) { is_ack_ = is_ack; }
 
@@ -992,6 +720,8 @@ class NET_EXPORT_PRIVATE SpdyHeadersIR : public SpdyFrameWithHeaderBlockIR {
     // The pad field takes one octet on the wire.
     padding_payload_len_ = padding_len - 1;
   }
+  bool end_headers() const { return end_headers_; }
+  void set_end_headers(bool end_headers) { end_headers_ = end_headers; }
 
  private:
   bool has_priority_ = false;
@@ -1000,6 +730,7 @@ class NET_EXPORT_PRIVATE SpdyHeadersIR : public SpdyFrameWithHeaderBlockIR {
   bool exclusive_ = false;
   bool padded_ = false;
   int padding_payload_len_ = 0;
+  bool end_headers_ = false;
 
   DISALLOW_COPY_AND_ASSIGN(SpdyHeadersIR);
 };
@@ -1071,23 +802,22 @@ class NET_EXPORT_PRIVATE SpdyPushPromiseIR : public SpdyFrameWithHeaderBlockIR {
   DISALLOW_COPY_AND_ASSIGN(SpdyPushPromiseIR);
 };
 
-// TODO(jgraettinger): This representation needs review. SpdyContinuationIR
-// needs to frame a portion of a single, arbitrarily-broken encoded buffer.
-class NET_EXPORT_PRIVATE SpdyContinuationIR
-    : public SpdyFrameWithHeaderBlockIR {
+class NET_EXPORT_PRIVATE SpdyContinuationIR : public SpdyFrameWithStreamIdIR {
  public:
-  explicit SpdyContinuationIR(SpdyStreamId stream_id)
-      : SpdyContinuationIR(stream_id, SpdyHeaderBlock()) {}
-  SpdyContinuationIR(SpdyStreamId stream_id, SpdyHeaderBlock header_block)
-      : SpdyFrameWithHeaderBlockIR(stream_id, std::move(header_block)),
-        end_headers_(false) {}
+  explicit SpdyContinuationIR(SpdyStreamId stream_id);
+  ~SpdyContinuationIR() override;
 
   void Visit(SpdyFrameVisitor* visitor) const override;
 
   bool end_headers() const { return end_headers_; }
   void set_end_headers(bool end_headers) {end_headers_ = end_headers;}
+  const std::string& encoding() const { return *encoding_; }
+  void take_encoding(std::unique_ptr<std::string> encoding) {
+    encoding_ = std::move(encoding);
+  }
 
  private:
+  std::unique_ptr<std::string> encoding_;
   bool end_headers_;
   DISALLOW_COPY_AND_ASSIGN(SpdyContinuationIR);
 };
@@ -1195,6 +925,23 @@ class SpdySerializedFrame {
   // Returns the actual size of the underlying buffer.
   size_t size() const { return size_; }
 
+  // Returns a buffer containing the contents of the frame, of which the caller
+  // takes ownership, and clears this SpdySerializedFrame.
+  char* ReleaseBuffer() {
+    char* buffer;
+    if (owns_buffer_) {
+      // If the buffer is owned, relinquish ownership to the caller.
+      buffer = frame_;
+      owns_buffer_ = false;
+    } else {
+      // Otherwise, we need to make a copy to give to the caller.
+      buffer = new char[size_];
+      memcpy(buffer, frame_, size_);
+    }
+    *this = SpdySerializedFrame();
+    return buffer;
+  }
+
  protected:
   char* frame_;
 
@@ -1210,8 +957,6 @@ class SpdySerializedFrame {
 // method of this class will be called.
 class SpdyFrameVisitor {
  public:
-  virtual void VisitSynStream(const SpdySynStreamIR& syn_stream) = 0;
-  virtual void VisitSynReply(const SpdySynReplyIR& syn_reply) = 0;
   virtual void VisitRstStream(const SpdyRstStreamIR& rst_stream) = 0;
   virtual void VisitSettings(const SpdySettingsIR& settings) = 0;
   virtual void VisitPing(const SpdyPingIR& ping) = 0;
diff --git a/src/net/spdy/write_scheduler.h b/src/net/spdy/write_scheduler.h
index ebcefc2..3d24335 100644
--- a/src/net/spdy/write_scheduler.h
+++ b/src/net/spdy/write_scheduler.h
@@ -8,6 +8,7 @@
 #include <tuple>
 #include <vector>
 
+#include "net/base/net_export.h"
 #include "net/spdy/spdy_protocol.h"
 
 namespace net {
diff --git a/src/third_party/ashmem/ashmem.h b/src/third_party/ashmem/ashmem.h
deleted file mode 100644
index 7d411cc..0000000
--- a/src/third_party/ashmem/ashmem.h
+++ /dev/null
@@ -1,46 +0,0 @@
-/* third_party/ashmem/ashmem.h
- **
- ** Copyright 2008 The Android Open Source Project
- **
- ** This file is dual licensed.  It may be redistributed and/or modified
- ** under the terms of the Apache 2.0 License OR version 2 of the GNU
- ** General Public License.
- */
-
-#ifndef _THIRD_PARTY_ASHMEM_H
-#define _THIRD_PARTY_ASHMEM_H
-
-#include <stddef.h>
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-int ashmem_create_region(const char *name, size_t size);
-int ashmem_set_prot_region(int fd, int prot);
-int ashmem_pin_region(int fd, size_t offset, size_t len);
-int ashmem_unpin_region(int fd, size_t offset, size_t len);
-int ashmem_get_size_region(int fd);
-int ashmem_purge_all(void);
-
-#ifdef __cplusplus
-}
-#endif
-
-#ifndef __ASHMEMIOC	/* in case someone included <linux/ashmem.h> too */
-
-#define ASHMEM_NAME_LEN		256
-
-#define ASHMEM_NAME_DEF		"dev/ashmem"
-
-/* Return values from ASHMEM_PIN: Was the mapping purged while unpinned? */
-#define ASHMEM_NOT_PURGED	0
-#define ASHMEM_WAS_PURGED	1
-
-/* Return values from ASHMEM_UNPIN: Is the mapping now pinned or unpinned? */
-#define ASHMEM_IS_UNPINNED	0
-#define ASHMEM_IS_PINNED	1
-
-#endif	/* ! __ASHMEMIOC */
-
-#endif	/* _THIRD_PARTY_ASHMEM_H */
diff --git a/src/third_party/protobuf/proto_library.gni b/src/third_party/protobuf/proto_library.gni
index 0a77705..7c74e4e 100644
--- a/src/third_party/protobuf/proto_library.gni
+++ b/src/third_party/protobuf/proto_library.gni
@@ -43,8 +43,15 @@
 #       GN label for plugin executable which generates custom cc stubs.
 #       Don't specify a toolchain, host toolchain is assumed.
 #
-#   generator_plugin_suffix (required if |generator_plugin_label| set)
-#       Suffix (before extension) for generated .cc and .h files.
+#   generator_plugin_script (optional)
+#       Path to plugin script. Mutually exclusive with |generator_plugin_label|.
+#
+#   generator_plugin_script_deps (optional)
+#       List of additional files required for generator plugin script.
+#
+#   generator_plugin_suffix[es] (required if using a plugin)
+#       Suffix (before extension) for generated .cc and .h files
+#       or list of suffixes for all files (with extensions).
 #
 #   generator_plugin_options (optional)
 #       Extra flags passed to the plugin. See cc_generator_options.
@@ -52,6 +59,10 @@
 #   deps (optional)
 #       Additional dependencies.
 #
+#   use_protobuf_full (optional)
+#       If adding protobuf library would be required, adds protobuf_full to deps
+#       instead of protobuf_lite.
+#
 # Parameters for compiling the generated code:
 #
 #   component_build_force_source_set (Default=false)
@@ -86,6 +97,12 @@ template("proto_library") {
   # this template shouldn't re-apply the filter.
   set_sources_assignment_filter([])
 
+  if (host_os == "win") {
+    host_executable_suffix = ".exe"
+  } else {
+    host_executable_suffix = ""
+  }
+
   if (defined(invoker.generate_cc)) {
     generate_cc = invoker.generate_cc
   } else {
@@ -99,43 +116,31 @@ template("proto_library") {
   }
 
   if (defined(invoker.generator_plugin_label)) {
-    generator_plugin_label = invoker.generator_plugin_label
-    generator_plugin_suffix = invoker.generator_plugin_suffix
-    generate_with_plugin = true
-
     # Straightforward way to get the name of executable doesn't work because
     # |root_out_dir| and |root_build_dir| may differ in cross-compilation and
     # also Windows executables have .exe at the end.
 
-    plugin_host_label = generator_plugin_label + "($host_toolchain)"
-    plugin_path = get_label_info(plugin_host_label, "root_out_dir") + "/" +
-                  get_label_info(plugin_host_label, "name")
-    if (host_os == "win") {
-      plugin_path += ".exe"
-    }
-    plugin_path = rebase_path(plugin_path, root_build_dir)
+    plugin_host_label = invoker.generator_plugin_label + "($host_toolchain)"
+    plugin_path =
+        get_label_info(plugin_host_label, "root_out_dir") + "/" +
+        get_label_info(plugin_host_label, "name") + host_executable_suffix
+    generate_with_plugin = true
+  } else if (defined(invoker.generator_plugin_script)) {
+    plugin_path = invoker.generator_plugin_script
+    generate_with_plugin = true
   } else {
     generate_with_plugin = false
   }
 
-  # TODO(kraynov): Remove (in the next CL) merge conflict temporary workaround.
-  # This option along with |inputs| would be replaced by the following pattern:
-  # source_set("some_python_plugin") {
-  #   sources = [
-  #     "bar.py",
-  #     ...
-  #   ]
-  # }
-  # proto_library("some_proto_lib") {
-  #   generator_plugin_label = ":some_python_plugin"
-  #   generator_plugin_suffix = ".pb.foo"
-  #   generator_plugin_script = "bar.py"
-  # }
-  if (defined(invoker.json_converter)) {
-    generator_plugin_suffix = "_json_converter"
-    plugin_path = rebase_path(invoker.json_converter)
-    invoker.generator_plugin_options = "output_dir=:"
-    generate_with_plugin = true
+  if (generate_with_plugin) {
+    if (defined(invoker.generator_plugin_suffix)) {
+      generator_plugin_suffixes = [
+        "${invoker.generator_plugin_suffix}.h",
+        "${invoker.generator_plugin_suffix}.cc",
+      ]
+    } else {
+      generator_plugin_suffixes = invoker.generator_plugin_suffixes
+    }
   }
 
   if (defined(invoker.proto_in_dir)) {
@@ -201,14 +206,8 @@ template("proto_library") {
       protogens += [ "$py_out_dir/${proto_path}_pb2.py" ]
     }
     if (generate_with_plugin) {
-      # TODO(kraynov): Remove merge conflict temporary workaround.
-      if (defined(invoker.json_converter)) {
-        protogens += [ "$cc_out_dir/${proto_path}$generator_plugin_suffix.h" ]
-      } else {
-        protogens += [
-          "$cc_out_dir/${proto_path}$generator_plugin_suffix.h",
-          "$cc_out_dir/${proto_path}$generator_plugin_suffix.cc",
-        ]
+      foreach(suffix, generator_plugin_suffixes) {
+        protogens += [ "$cc_out_dir/${proto_path}${suffix}" ]
       }
     }
   }
@@ -224,18 +223,15 @@ template("proto_library") {
     outputs = get_path_info(protogens, "abspath")
     args = protos
 
-    if (defined(invoker.inputs)) {
-      inputs = invoker.inputs
-    }
-
     protoc_label = "//third_party/protobuf:protoc($host_toolchain)"
-    protoc_out_dir = get_label_info(protoc_label, "root_out_dir")
+    protoc_path = get_label_info(protoc_label, "root_out_dir") + "/protoc" +
+                  host_executable_suffix
     args += [
       # Wrapper should never pick a system protoc.
       # Path should be rebased because |root_build_dir| for current toolchain
       # may be different from |root_out_dir| of protoc built on host toolchain.
       "--protoc",
-      "./" + rebase_path(protoc_out_dir, root_build_dir) + "/protoc",
+      "./" + rebase_path(protoc_path, root_build_dir),
       "--proto-in-dir",
       rebase_path(proto_in_dir, root_build_dir),
     ]
@@ -269,7 +265,7 @@ template("proto_library") {
     if (generate_with_plugin) {
       args += [
         "--plugin",
-        plugin_path,
+        rebase_path(plugin_path, root_build_dir),
         "--plugin-out-dir",
         rel_cc_out_dir,
       ]
@@ -281,14 +277,26 @@ template("proto_library") {
       }
     }
 
+    # System protoc is not used so it's necessary to build a chromium one.
+    inputs = [
+      protoc_path,
+    ]
     deps = [
-      # System protoc is not used so it's necessary to build a chromium one.
       protoc_label,
     ]
-    if (defined(plugin_host_label)) {
-      # Action depends on generator plugin but for host toolchain only.
-      deps += [ plugin_host_label ]
+
+    if (generate_with_plugin) {
+      inputs += [ plugin_path ]
+      if (defined(invoker.generator_plugin_script_deps)) {
+        # Additional scripts for plugin.
+        inputs += invoker.generator_plugin_script_deps
+      }
+      if (defined(plugin_host_label)) {
+        # Action depends on native generator plugin but for host toolchain only.
+        deps += [ plugin_host_label ]
+      }
     }
+
     if (defined(invoker.deps)) {
       # The deps may have steps that have to run before running protoc.
       deps += invoker.deps
@@ -297,8 +305,7 @@ template("proto_library") {
 
   # Option to disable building a library in component build.
   if (defined(invoker.component_build_force_source_set) &&
-      invoker.component_build_force_source_set &&
-      is_component_build) {
+      invoker.component_build_force_source_set && is_component_build) {
     link_target_type = "source_set"
   } else {
     link_target_type = "static_library"
@@ -344,9 +351,16 @@ template("proto_library") {
       # within protobuf_lite. Hence, dependencies require those headers too.
       # If using generator plugin, extra deps should be resolved by the invoker.
       if (generate_cc) {
-        public_deps = [
-          "//third_party/protobuf:protobuf_lite",
-        ]
+        if (defined(invoker.use_protobuf_full) &&
+            invoker.use_protobuf_full == true) {
+          public_deps = [
+            "//third_party/protobuf:protobuf_full",
+          ]
+        } else {
+          public_deps = [
+            "//third_party/protobuf:protobuf_lite",
+          ]
+        }
       }
     }
 
diff --git a/src/url/gurl.cc b/src/url/gurl.cc
index 8b5c892..bdd3522 100644
--- a/src/url/gurl.cc
+++ b/src/url/gurl.cc
@@ -180,14 +180,6 @@ const std::string& GURL::spec() const {
   return EmptyStringForGURL();
 }
 
-bool GURL::operator==(const GURL& other) const {
-  return spec_ == other.spec_;
-}
-
-bool GURL::operator!=(const GURL& other) const {
-  return spec_ != other.spec_;
-}
-
 bool GURL::operator<(const GURL& other) const {
   return spec_ < other.spec_;
 }
@@ -510,3 +502,20 @@ void GURL::Swap(GURL* other) {
 std::ostream& operator<<(std::ostream& out, const GURL& url) {
   return out << url.possibly_invalid_spec();
 }
+
+bool operator==(const GURL& x, const GURL& y) {
+  return x.possibly_invalid_spec() == y.possibly_invalid_spec();
+}
+
+bool operator!=(const GURL& x, const GURL& y) {
+  return !(x == y);
+}
+
+bool operator==(const GURL& x, const base::StringPiece& spec) {
+  DCHECK_EQ(GURL(spec).possibly_invalid_spec(), spec);
+  return x.possibly_invalid_spec() == spec;
+}
+
+bool operator!=(const GURL& x, const base::StringPiece& spec) {
+  return !(x == spec);
+}
diff --git a/src/url/gurl.h b/src/url/gurl.h
index c9111d3..5753230 100644
--- a/src/url/gurl.h
+++ b/src/url/gurl.h
@@ -132,10 +132,6 @@ class URL_EXPORT GURL {
     return parsed_;
   }
 
-  // Defiant equality operator!
-  bool operator==(const GURL& other) const;
-  bool operator!=(const GURL& other) const;
-
   // Allows GURL to used as a key in STL (for example, a std::set or std::map).
   bool operator<(const GURL& other) const;
   bool operator>(const GURL& other) const;
@@ -240,7 +236,8 @@ class URL_EXPORT GURL {
   // higher-level and more complete semantics. See that function's documentation
   // for more detail.
   bool SchemeIsCryptographic() const {
-    return SchemeIs(url::kHttpsScheme) || SchemeIs(url::kWssScheme);
+    return SchemeIs(url::kHttpsScheme) || SchemeIs(url::kWssScheme) ||
+           SchemeIs(url::kHttpsSuboriginScheme);
   }
 
   // Returns true if the scheme is "blob".
@@ -248,6 +245,12 @@ class URL_EXPORT GURL {
     return SchemeIs(url::kBlobScheme);
   }
 
+  // Returns true if the scheme indicates a serialized suborigin.
+  bool SchemeIsSuborigin() const {
+    return SchemeIs(url::kHttpSuboriginScheme) ||
+           SchemeIs(url::kHttpsSuboriginScheme);
+  }
+
   // The "content" of the URL is everything after the scheme (skipping the
   // scheme delimiting colon). It is an error to get the content of an invalid
   // URL: the result will be an empty string.
@@ -447,4 +450,13 @@ class URL_EXPORT GURL {
 // Stream operator so GURL can be used in assertion statements.
 URL_EXPORT std::ostream& operator<<(std::ostream& out, const GURL& url);
 
+URL_EXPORT bool operator==(const GURL& x, const GURL& y);
+URL_EXPORT bool operator!=(const GURL& x, const GURL& y);
+
+// Equality operator for comparing raw spec_. This should be used in place of
+// url == GURL(spec) where |spec| is known (i.e. constants). This is to prevent
+// needlessly re-parsing |spec| into a temporary GURL.
+URL_EXPORT bool operator==(const GURL& x, const base::StringPiece& spec);
+URL_EXPORT bool operator!=(const GURL& x, const base::StringPiece& spec);
+
 #endif  // URL_GURL_H_
diff --git a/src/url/third_party/mozilla/url_parse.cc b/src/url/third_party/mozilla/url_parse.cc
index ba842b8..60aeb05 100644
--- a/src/url/third_party/mozilla/url_parse.cc
+++ b/src/url/third_party/mozilla/url_parse.cc
@@ -175,6 +175,31 @@ void DoParseAuthority(const CHAR* spec,
   }
 }
 
+template <typename CHAR>
+inline void FindQueryAndRefParts(const CHAR* spec,
+                          const Component& path,
+                          int* query_separator,
+                          int* ref_separator) {
+  int path_end = path.begin + path.len;
+  for (int i = path.begin; i < path_end; i++) {
+    switch (spec[i]) {
+      case '?':
+        // Only match the query string if it precedes the reference fragment
+        // and when we haven't found one already.
+        if (*query_separator < 0)
+          *query_separator = i;
+        break;
+      case '#':
+        // Record the first # sign only.
+        if (*ref_separator < 0) {
+          *ref_separator = i;
+          return;
+        }
+        break;
+    }
+  }
+}
+
 template<typename CHAR>
 void ParsePath(const CHAR* spec,
                const Component& path,
@@ -193,25 +218,9 @@ void ParsePath(const CHAR* spec,
   DCHECK(path.len > 0) << "We should never have 0 length paths";
 
   // Search for first occurrence of either ? or #.
-  int path_end = path.begin + path.len;
-
   int query_separator = -1;  // Index of the '?'
   int ref_separator = -1;    // Index of the '#'
-  for (int i = path.begin; i < path_end; i++) {
-    switch (spec[i]) {
-      case '?':
-        // Only match the query string if it precedes the reference fragment
-        // and when we haven't found one already.
-        if (ref_separator < 0 && query_separator < 0)
-          query_separator = i;
-        break;
-      case '#':
-        // Record the first # sign only.
-        if (ref_separator < 0)
-          ref_separator = i;
-        break;
-    }
-  }
+  FindQueryAndRefParts(spec, path, &query_separator, &ref_separator);
 
   // Markers pointing to the character after each of these corresponding
   // components. The code below words from the end back to the beginning,
@@ -219,6 +228,7 @@ void ParsePath(const CHAR* spec,
   int file_end, query_end;
 
   // Ref fragment: from the # to the end of the path.
+  int path_end = path.begin + path.len;
   if (ref_separator >= 0) {
     file_end = query_end = ref_separator;
     *ref = MakeRange(ref_separator + 1, path_end);
diff --git a/src/url/url_canon.h b/src/url/url_canon.h
index 95d5345..c4852e4 100644
--- a/src/url/url_canon.h
+++ b/src/url/url_canon.h
@@ -379,6 +379,33 @@ URL_EXPORT void CanonicalizeHostVerbose(const base::char16* spec,
                                         CanonOutput* output,
                                         CanonHostInfo* host_info);
 
+// Canonicalizes a string according to the host canonicalization rules. Unlike
+// CanonicalizeHost, this will not check for IP addresses which can change the
+// meaning (and canonicalization) of the components. This means it is possible
+// to call this for sub-components of a host name without corruption.
+//
+// As an example, "01.02.03.04.com" is a canonical hostname. If you called
+// CanonicalizeHost on the substring "01.02.03.04" it will get "fixed" to
+// "1.2.3.4" which will produce an invalid host name when reassembled. This
+// can happen more than one might think because all numbers by themselves are
+// considered IP addresses; so "5" canonicalizes to "0.0.0.5".
+//
+// Be careful: Because Punycode works on each dot-separated substring as a
+// unit, you should only pass this function substrings that represent complete
+// dot-separated subcomponents of the original host. Even if you have ASCII
+// input, percent-escaped characters will have different meanings if split in
+// the middle.
+//
+// Returns true if the host was valid. This function will treat a 0-length
+// host as valid (because it's designed to be used for substrings) while the
+// full version above will mark empty hosts as broken.
+URL_EXPORT bool CanonicalizeHostSubstring(const char* spec,
+                                          const Component& host,
+                                          CanonOutput* output);
+URL_EXPORT bool CanonicalizeHostSubstring(const base::char16* spec,
+                                          const Component& host,
+                                          CanonOutput* output);
+
 // IP addresses.
 //
 // Tries to interpret the given host name as an IPv4 or IPv6 address. If it is
diff --git a/src/url/url_canon_etc.cc b/src/url/url_canon_etc.cc
index e9da94c..9dd40da 100644
--- a/src/url/url_canon_etc.cc
+++ b/src/url/url_canon_etc.cc
@@ -89,7 +89,7 @@ bool DoScheme(const CHAR* spec,
     // Scheme is unspecified or empty, convert to empty by appending a colon.
     *out_scheme = Component(output->length(), 0);
     output->push_back(':');
-    return true;
+    return false;
   }
 
   // The output scheme starts from the current position.
diff --git a/src/url/url_canon_host.cc b/src/url/url_canon_host.cc
index d7959c7..67bee7b 100644
--- a/src/url/url_canon_host.cc
+++ b/src/url/url_canon_host.cc
@@ -312,7 +312,25 @@ bool DoComplexHost(const base::char16* host, int host_len,
   return DoIDNHost(host, host_len, output);
 }
 
-template<typename CHAR, typename UCHAR>
+template <typename CHAR, typename UCHAR>
+bool DoHostSubstring(const CHAR* spec,
+                     const Component& host,
+                     CanonOutput* output) {
+  bool has_non_ascii, has_escaped;
+  ScanHostname<CHAR, UCHAR>(spec, host, &has_non_ascii, &has_escaped);
+
+  if (has_non_ascii || has_escaped) {
+    return DoComplexHost(&spec[host.begin], host.len, has_non_ascii,
+                         has_escaped, output);
+  }
+
+  const bool success =
+      DoSimpleHost(&spec[host.begin], host.len, output, &has_non_ascii);
+  DCHECK(!has_non_ascii);
+  return success;
+}
+
+template <typename CHAR, typename UCHAR>
 void DoHost(const CHAR* spec,
             const Component& host,
             CanonOutput* output,
@@ -324,26 +342,10 @@ void DoHost(const CHAR* spec,
     return;
   }
 
-  bool has_non_ascii, has_escaped;
-  ScanHostname<CHAR, UCHAR>(spec, host, &has_non_ascii, &has_escaped);
-
   // Keep track of output's initial length, so we can rewind later.
   const int output_begin = output->length();
 
-  bool success;
-  if (!has_non_ascii && !has_escaped) {
-    success = DoSimpleHost(&spec[host.begin], host.len,
-                           output, &has_non_ascii);
-    DCHECK(!has_non_ascii);
-  } else {
-    success = DoComplexHost(&spec[host.begin], host.len,
-                            has_non_ascii, has_escaped, output);
-  }
-
-  if (!success) {
-    // Canonicalization failed. Set BROKEN to notify the caller.
-    host_info->family = CanonHostInfo::BROKEN;
-  } else {
+  if (DoHostSubstring<CHAR, UCHAR>(spec, host, output)) {
     // After all the other canonicalization, check if we ended up with an IP
     // address. IP addresses are small, so writing into this temporary buffer
     // should not cause an allocation.
@@ -359,6 +361,9 @@ void DoHost(const CHAR* spec,
       output->set_length(output_begin);
       output->Append(canon_ip.data(), canon_ip.length());
     }
+  } else {
+    // Canonicalization failed. Set BROKEN to notify the caller.
+    host_info->family = CanonHostInfo::BROKEN;
   }
 
   host_info->out_host = MakeRange(output_begin, output->length());
@@ -400,4 +405,16 @@ void CanonicalizeHostVerbose(const base::char16* spec,
   DoHost<base::char16, base::char16>(spec, host, output, host_info);
 }
 
+bool CanonicalizeHostSubstring(const char* spec,
+                               const Component& host,
+                               CanonOutput* output) {
+  return DoHostSubstring<char, unsigned char>(spec, host, output);
+}
+
+bool CanonicalizeHostSubstring(const base::char16* spec,
+                               const Component& host,
+                               CanonOutput* output) {
+  return DoHostSubstring<base::char16, base::char16>(spec, host, output);
+}
+
 }  // namespace url
diff --git a/src/url/url_canon_icu_unittest.cc b/src/url/url_canon_icu_unittest.cc
index 13601f0..af320f9 100644
--- a/src/url/url_canon_icu_unittest.cc
+++ b/src/url/url_canon_icu_unittest.cc
@@ -14,8 +14,6 @@
 
 namespace url {
 
-using test_utils::WStringToUTF16;
-
 namespace {
 
 // Wrapper around a UConverter object that managers creation and destruction.
@@ -64,7 +62,8 @@ TEST(URLCanonIcuTest, ICUCharsetConverter) {
     std::string str;
     StdStringCanonOutput output(&str);
 
-    base::string16 input_str(WStringToUTF16(icu_cases[i].input));
+    base::string16 input_str(
+        test_utils::TruncateWStringToUTF16(icu_cases[i].input));
     int input_len = static_cast<int>(input_str.length());
     converter.ConvertFromUTF16(input_str.c_str(), input_len, &output);
     output.Complete();
@@ -134,7 +133,8 @@ TEST(URLCanonIcuTest, QueryWithConverter) {
     }
 
     if (query_cases[i].input16) {
-      base::string16 input16(WStringToUTF16(query_cases[i].input16));
+      base::string16 input16(
+          test_utils::TruncateWStringToUTF16(query_cases[i].input16));
       int len = static_cast<int>(input16.length());
       Component in_comp(0, len);
       std::string out_str;
diff --git a/src/url/url_canon_stdurl.cc b/src/url/url_canon_stdurl.cc
index 7d1758b..e0bca9d 100644
--- a/src/url/url_canon_stdurl.cc
+++ b/src/url/url_canon_stdurl.cc
@@ -120,6 +120,14 @@ int DefaultPortForScheme(const char* scheme, int scheme_len) {
       if (!strncmp(scheme, kWsScheme, scheme_len))
         default_port = 80;
       break;
+    case 7:
+      if (!strncmp(scheme, kHttpSuboriginScheme, scheme_len))
+        default_port = 80;
+      break;
+    case 8:
+      if (!strncmp(scheme, kHttpsSuboriginScheme, scheme_len))
+        default_port = 443;
+      break;
   }
   return default_port;
 }
diff --git a/src/url/url_canon_unittest.cc b/src/url/url_canon_unittest.cc
index f5fedfc..8ac73bc 100644
--- a/src/url/url_canon_unittest.cc
+++ b/src/url/url_canon_unittest.cc
@@ -6,6 +6,7 @@
 #include <stddef.h>
 
 #include "base/macros.h"
+#include "base/strings/utf_string_conversions.h"
 #include "testing/gtest/include/gtest/gtest.h"
 #include "url/third_party/mozilla/url_parse.h"
 #include "url/url_canon.h"
@@ -15,10 +16,6 @@
 
 namespace url {
 
-using test_utils::WStringToUTF16;
-using test_utils::ConvertUTF8ToUTF16;
-using test_utils::ConvertUTF16ToUTF8;
-
 namespace {
 
 struct ComponentCase {
@@ -195,7 +192,8 @@ TEST(URLCanonTest, UTF) {
       out_str.clear();
       StdStringCanonOutput output(&out_str);
 
-      base::string16 input_str(WStringToUTF16(utf_cases[i].input16));
+      base::string16 input_str(
+          test_utils::TruncateWStringToUTF16(utf_cases[i].input16));
       int input_len = static_cast<int>(input_str.length());
       bool success = true;
       for (int ch = 0; ch < input_len; ch++) {
@@ -213,11 +211,12 @@ TEST(URLCanonTest, UTF) {
 
       // UTF-16 -> UTF-8
       std::string input8_str(utf_cases[i].input8);
-      base::string16 input16_str(WStringToUTF16(utf_cases[i].input16));
-      EXPECT_EQ(input8_str, ConvertUTF16ToUTF8(input16_str));
+      base::string16 input16_str(
+          test_utils::TruncateWStringToUTF16(utf_cases[i].input16));
+      EXPECT_EQ(input8_str, base::UTF16ToUTF8(input16_str));
 
       // UTF-8 -> UTF-16
-      EXPECT_EQ(input16_str, ConvertUTF8ToUTF16(input8_str));
+      EXPECT_EQ(input16_str, base::UTF8ToUTF16(input8_str));
     }
   }
 }
@@ -240,6 +239,7 @@ TEST(URLCanonTest, Scheme) {
       // Don't re-escape something already escaped. Note that it will
       // "canonicalize" the 'A' to 'a', but that's OK.
     {"ht%3Atp", "ht%3atp:", Component(0, 7), false},
+    {"", ":", Component(0, 0), false},
   };
 
   std::string out_str;
@@ -264,7 +264,7 @@ TEST(URLCanonTest, Scheme) {
     out_str.clear();
     StdStringCanonOutput output2(&out_str);
 
-    base::string16 wide_input(ConvertUTF8ToUTF16(scheme_cases[i].input));
+    base::string16 wide_input(base::UTF8ToUTF16(scheme_cases[i].input));
     in_comp.len = static_cast<int>(wide_input.length());
     success = CanonicalizeScheme(wide_input.c_str(), in_comp, &output2,
                                  &out_comp);
@@ -282,7 +282,7 @@ TEST(URLCanonTest, Scheme) {
   out_str.clear();
   StdStringCanonOutput output(&out_str);
 
-  EXPECT_TRUE(CanonicalizeScheme("", Component(0, -1), &output, &out_comp));
+  EXPECT_FALSE(CanonicalizeScheme("", Component(0, -1), &output, &out_comp));
   output.Complete();
 
   EXPECT_EQ(std::string(":"), out_str);
@@ -529,7 +529,8 @@ TEST(URLCanonTest, Host) {
 
     // Wide version.
     if (host_cases[i].input16) {
-      base::string16 input16(WStringToUTF16(host_cases[i].input16));
+      base::string16 input16(
+          test_utils::TruncateWStringToUTF16(host_cases[i].input16));
       int host_len = static_cast<int>(input16.length());
       Component in_comp(0, host_len);
       Component out_comp;
@@ -579,7 +580,8 @@ TEST(URLCanonTest, Host) {
 
     // Wide version.
     if (host_cases[i].input16) {
-      base::string16 input16(WStringToUTF16(host_cases[i].input16));
+      base::string16 input16(
+          test_utils::TruncateWStringToUTF16(host_cases[i].input16));
       int host_len = static_cast<int>(input16.length());
       Component in_comp(0, host_len);
 
@@ -701,7 +703,8 @@ TEST(URLCanonTest, IPv4) {
     }
 
     // 16-bit version.
-    base::string16 input16(WStringToUTF16(cases[i].input16));
+    base::string16 input16(
+        test_utils::TruncateWStringToUTF16(cases[i].input16));
     component = Component(0, static_cast<int>(input16.length()));
 
     std::string out_str2;
@@ -853,7 +856,8 @@ TEST(URLCanonTest, IPv6) {
     }
 
     // 16-bit version.
-    base::string16 input16(WStringToUTF16(cases[i].input16));
+    base::string16 input16(
+        test_utils::TruncateWStringToUTF16(cases[i].input16));
     component = Component(0, static_cast<int>(input16.length()));
 
     std::string out_str2;
@@ -886,6 +890,51 @@ TEST(URLCanonTest, IPEmpty) {
   EXPECT_FALSE(host_info.IsIPAddress());
 }
 
+// Verifies that CanonicalizeHostSubstring produces the expected output and
+// does not "fix" IP addresses. Because this code is a subset of
+// CanonicalizeHost, the shared functionality is not tested.
+TEST(URLCanonTest, CanonicalizeHostSubstring) {
+  // Basic sanity check.
+  {
+    std::string out_str;
+    StdStringCanonOutput output(&out_str);
+    EXPECT_TRUE(CanonicalizeHostSubstring("M\xc3\x9cNCHEN.com",
+                                          Component(0, 12), &output));
+    output.Complete();
+    EXPECT_EQ("xn--mnchen-3ya.com", out_str);
+  }
+
+  // Failure case.
+  {
+    std::string out_str;
+    StdStringCanonOutput output(&out_str);
+    EXPECT_FALSE(CanonicalizeHostSubstring(
+        test_utils::TruncateWStringToUTF16(L"\xfdd0zyx.com").c_str(),
+        Component(0, 8), &output));
+    output.Complete();
+    EXPECT_EQ("%EF%BF%BDzyx.com", out_str);
+  }
+
+  // Should return true for empty input strings.
+  {
+    std::string out_str;
+    StdStringCanonOutput output(&out_str);
+    EXPECT_TRUE(CanonicalizeHostSubstring("", Component(0, 0), &output));
+    output.Complete();
+    EXPECT_EQ(std::string(), out_str);
+  }
+
+  // Numbers that look like IP addresses should not be changed.
+  {
+    std::string out_str;
+    StdStringCanonOutput output(&out_str);
+    EXPECT_TRUE(
+        CanonicalizeHostSubstring("01.02.03.04", Component(0, 11), &output));
+    output.Complete();
+    EXPECT_EQ("01.02.03.04", out_str);
+  }
+}
+
 TEST(URLCanonTest, UserInfo) {
   // Note that the canonicalizer should escape and treat empty components as
   // not being there.
@@ -939,7 +988,7 @@ TEST(URLCanonTest, UserInfo) {
     // Now try the wide version
     out_str.clear();
     StdStringCanonOutput output2(&out_str);
-    base::string16 wide_input(ConvertUTF8ToUTF16(user_info_cases[i].input));
+    base::string16 wide_input(base::UTF8ToUTF16(user_info_cases[i].input));
     success = CanonicalizeUserInfo(wide_input.c_str(),
                                    parsed.username,
                                    wide_input.c_str(),
@@ -1002,7 +1051,7 @@ TEST(URLCanonTest, Port) {
     // Now try the wide version
     out_str.clear();
     StdStringCanonOutput output2(&out_str);
-    base::string16 wide_input(ConvertUTF8ToUTF16(port_cases[i].input));
+    base::string16 wide_input(base::UTF8ToUTF16(port_cases[i].input));
     success = CanonicalizePort(wide_input.c_str(),
                                in_comp,
                                port_cases[i].default_port,
@@ -1122,7 +1171,8 @@ TEST(URLCanonTest, Path) {
     }
 
     if (path_cases[i].input16) {
-      base::string16 input16(WStringToUTF16(path_cases[i].input16));
+      base::string16 input16(
+          test_utils::TruncateWStringToUTF16(path_cases[i].input16));
       int len = static_cast<int>(input16.length());
       Component in_comp(0, len);
       Component out_comp;
@@ -1197,7 +1247,8 @@ TEST(URLCanonTest, Query) {
     }
 
     if (query_cases[i].input16) {
-      base::string16 input16(WStringToUTF16(query_cases[i].input16));
+      base::string16 input16(
+          test_utils::TruncateWStringToUTF16(query_cases[i].input16));
       int len = static_cast<int>(input16.length());
       Component in_comp(0, len);
       std::string out_str;
@@ -1259,7 +1310,8 @@ TEST(URLCanonTest, Ref) {
 
     // 16-bit input
     if (ref_cases[i].input16) {
-      base::string16 input16(WStringToUTF16(ref_cases[i].input16));
+      base::string16 input16(
+          test_utils::TruncateWStringToUTF16(ref_cases[i].input16));
       int len = static_cast<int>(input16.length());
       Component in_comp(0, len);
       Component out_comp;
@@ -1303,7 +1355,7 @@ TEST(URLCanonTest, CanonicalizeStandardURL) {
     {"http://[www.google.com]/", "http://[www.google.com]/", false},
     {"ht\ttp:@www.google.com:80/;p?#", "ht%09tp://www.google.com:80/;p?#", false},
     {"http:////////user:@google.com:99?foo", "http://user@google.com:99/?foo", true},
-    {"www.google.com", ":www.google.com/", true},
+    {"www.google.com", ":www.google.com/", false},
     {"http://192.0x00A80001", "http://192.168.0.1/", true},
     {"http://www/foo%2Ehtml", "http://www/foo.html", true},
     {"http://user:pass@/", "http://user:pass@/", false},
@@ -1758,7 +1810,7 @@ TEST(URLCanonTest, CanonicalizePathURL) {
   } path_cases[] = {
     {"javascript:", "javascript:"},
     {"JavaScript:Foo", "javascript:Foo"},
-    {":\":This /is interesting;?#", ":\":This /is interesting;?#"},
+    {"Foo:\":This /is interesting;?#", "foo:\":This /is interesting;?#"},
   };
 
   for (size_t i = 0; i < arraysize(path_cases); i++) {
@@ -1895,12 +1947,12 @@ TEST(URLCanonTest, _itow_s) {
   const base::char16 fill_char = 0xffff;
   memset(buf, fill_mem, sizeof(buf));
   EXPECT_EQ(0, _itow_s(12, buf, sizeof(buf) / 2 - 1, 10));
-  EXPECT_EQ(WStringToUTF16(L"12"), base::string16(buf));
+  EXPECT_EQ(base::UTF8ToUTF16("12"), base::string16(buf));
   EXPECT_EQ(fill_char, buf[3]);
 
   // Test the edge cases - exactly the buffer size and one over
   EXPECT_EQ(0, _itow_s(1234, buf, sizeof(buf) / 2 - 1, 10));
-  EXPECT_EQ(WStringToUTF16(L"1234"), base::string16(buf));
+  EXPECT_EQ(base::UTF8ToUTF16("1234"), base::string16(buf));
   EXPECT_EQ(fill_char, buf[5]);
 
   memset(buf, fill_mem, sizeof(buf));
@@ -1910,12 +1962,13 @@ TEST(URLCanonTest, _itow_s) {
   // Test the template overload (note that this will see the full buffer)
   memset(buf, fill_mem, sizeof(buf));
   EXPECT_EQ(0, _itow_s(12, buf, 10));
-  EXPECT_EQ(WStringToUTF16(L"12"), base::string16(buf));
+  EXPECT_EQ(base::UTF8ToUTF16("12"),
+            base::string16(buf));
   EXPECT_EQ(fill_char, buf[3]);
 
   memset(buf, fill_mem, sizeof(buf));
   EXPECT_EQ(0, _itow_s(12345, buf, 10));
-  EXPECT_EQ(WStringToUTF16(L"12345"), base::string16(buf));
+  EXPECT_EQ(base::UTF8ToUTF16("12345"), base::string16(buf));
 
   EXPECT_EQ(EINVAL, _itow_s(123456, buf, 10));
 }
@@ -2151,7 +2204,7 @@ TEST(URLCanonTest, ReplacementOverflow) {
   for (int i = 0; i < 4800; i++)
     new_query.push_back('a');
 
-  base::string16 new_path(WStringToUTF16(L"/foo"));
+  base::string16 new_path(test_utils::TruncateWStringToUTF16(L"/foo"));
   repl.SetPath(new_path.c_str(), Component(0, 4));
   repl.SetQuery(new_query.c_str(),
                 Component(0, static_cast<int>(new_query.length())));
@@ -2172,4 +2225,35 @@ TEST(URLCanonTest, ReplacementOverflow) {
   EXPECT_TRUE(expected == repl_str);
 }
 
+TEST(URLCanonTest, DefaultPortForScheme) {
+  struct TestCases {
+    const char* scheme;
+    const int expected_port;
+  } cases[]{
+      {"http", 80},
+      {"https", 443},
+      {"ftp", 21},
+      {"ws", 80},
+      {"wss", 443},
+      {"gopher", 70},
+      {"http-so", 80},
+      {"https-so", 443},
+      {"fake-scheme", PORT_UNSPECIFIED},
+      {"HTTP", PORT_UNSPECIFIED},
+      {"HTTPS", PORT_UNSPECIFIED},
+      {"FTP", PORT_UNSPECIFIED},
+      {"WS", PORT_UNSPECIFIED},
+      {"WSS", PORT_UNSPECIFIED},
+      {"GOPHER", PORT_UNSPECIFIED},
+      {"HTTP-SO", PORT_UNSPECIFIED},
+      {"HTTPS-SO", PORT_UNSPECIFIED},
+  };
+
+  for (auto& test_case : cases) {
+    SCOPED_TRACE(test_case.scheme);
+    EXPECT_EQ(test_case.expected_port,
+              DefaultPortForScheme(test_case.scheme, strlen(test_case.scheme)));
+  }
+}
+
 }  // namespace url
diff --git a/src/url/url_constants.cc b/src/url/url_constants.cc
index 549819e..73c9a76 100644
--- a/src/url/url_constants.cc
+++ b/src/url/url_constants.cc
@@ -24,6 +24,9 @@ const char kMailToScheme[] = "mailto";
 const char kWsScheme[] = "ws";
 const char kWssScheme[] = "wss";
 
+const char kHttpSuboriginScheme[] = "http-so";
+const char kHttpsSuboriginScheme[] = "https-so";
+
 const char kStandardSchemeSeparator[] = "://";
 
 const size_t kMaxURLChars = 2 * 1024 * 1024;
diff --git a/src/url/url_constants.h b/src/url/url_constants.h
index 3a423d2..c110589 100644
--- a/src/url/url_constants.h
+++ b/src/url/url_constants.h
@@ -30,6 +30,11 @@ URL_EXPORT extern const char kMailToScheme[];
 URL_EXPORT extern const char kWsScheme[];
 URL_EXPORT extern const char kWssScheme[];
 
+// Special HTTP and HTTPS schemes for serialization of suborigins. See
+// https://w3c.github.io/webappsec-suborigins/.
+URL_EXPORT extern const char kHttpSuboriginScheme[];
+URL_EXPORT extern const char kHttpsSuboriginScheme[];
+
 // Used to separate a standard scheme and the hostname: "://".
 URL_EXPORT extern const char kStandardSchemeSeparator[];
 
diff --git a/src/url/url_util.cc b/src/url/url_util.cc
index 7a0a1f8..0b3044d 100644
--- a/src/url/url_util.cc
+++ b/src/url/url_util.cc
@@ -19,25 +19,36 @@ namespace url {
 
 namespace {
 
-const int kNumStandardURLSchemes = 8;
+// Pass this enum through for methods which would like to know if whitespace
+// removal is necessary.
+enum WhitespaceRemovalPolicy {
+  REMOVE_WHITESPACE,
+  DO_NOT_REMOVE_WHITESPACE,
+};
+
+const int kNumStandardURLSchemes = 10;
 const SchemeWithType kStandardURLSchemes[kNumStandardURLSchemes] = {
-  {kHttpScheme, SCHEME_WITH_PORT},
-  {kHttpsScheme, SCHEME_WITH_PORT},
-  // Yes, file URLs can have a hostname, so file URLs should be handled as
-  // "standard". File URLs never have a port as specified by the SchemeType
-  // field.
-  {kFileScheme, SCHEME_WITHOUT_PORT},
-  {kFtpScheme, SCHEME_WITH_PORT},
-  {kGopherScheme, SCHEME_WITH_PORT},
-  {kWsScheme, SCHEME_WITH_PORT},    // WebSocket.
-  {kWssScheme, SCHEME_WITH_PORT},   // WebSocket secure.
-  {kFileSystemScheme, SCHEME_WITHOUT_AUTHORITY},
+    {kHttpScheme, SCHEME_WITH_PORT},
+    {kHttpsScheme, SCHEME_WITH_PORT},
+    // Yes, file URLs can have a hostname, so file URLs should be handled as
+    // "standard". File URLs never have a port as specified by the SchemeType
+    // field.
+    {kFileScheme, SCHEME_WITHOUT_PORT},
+    {kFtpScheme, SCHEME_WITH_PORT},
+    {kGopherScheme, SCHEME_WITH_PORT},
+    {kWsScheme, SCHEME_WITH_PORT},   // WebSocket.
+    {kWssScheme, SCHEME_WITH_PORT},  // WebSocket secure.
+    {kFileSystemScheme, SCHEME_WITHOUT_AUTHORITY},
+    {kHttpSuboriginScheme, SCHEME_WITH_PORT},
+    {kHttpsSuboriginScheme, SCHEME_WITH_PORT},
 };
 
-const int kNumReferrerURLSchemes = 2;
+const int kNumReferrerURLSchemes = 4;
 const SchemeWithType kReferrerURLSchemes[kNumReferrerURLSchemes] = {
-  {kHttpScheme, SCHEME_WITH_PORT},
-  {kHttpsScheme, SCHEME_WITH_PORT},
+    {kHttpScheme, SCHEME_WITH_PORT},
+    {kHttpsScheme, SCHEME_WITH_PORT},
+    {kHttpSuboriginScheme, SCHEME_WITH_PORT},
+    {kHttpsSuboriginScheme, SCHEME_WITH_PORT},
 };
 
 // Lists of the currently installed standard and referrer schemes. These lists
@@ -150,19 +161,19 @@ bool DoFindAndCompareScheme(const CHAR* str,
   return DoCompareSchemeComponent(spec, our_scheme, compare);
 }
 
-template<typename CHAR>
-bool DoCanonicalize(const CHAR* in_spec,
-                    int in_spec_len,
+template <typename CHAR>
+bool DoCanonicalize(const CHAR* spec,
+                    int spec_len,
                     bool trim_path_end,
+                    WhitespaceRemovalPolicy whitespace_policy,
                     CharsetConverter* charset_converter,
                     CanonOutput* output,
                     Parsed* output_parsed) {
-  // Remove any whitespace from the middle of the relative URL, possibly
-  // copying to the new buffer.
+  // Remove any whitespace from the middle of the relative URL if necessary.
+  // Possibly this will result in copying to the new buffer.
   RawCanonOutputT<CHAR> whitespace_buffer;
-  int spec_len;
-  const CHAR* spec = RemoveURLWhitespace(in_spec, in_spec_len,
-                                         &whitespace_buffer, &spec_len);
+  if (whitespace_policy == REMOVE_WHITESPACE)
+    spec = RemoveURLWhitespace(spec, spec_len, &whitespace_buffer, &spec_len);
 
   Parsed parsed_input;
 #ifdef WIN32
@@ -283,7 +294,8 @@ bool DoResolveRelative(const char* base_spec,
       // based on base_parsed_authority instead of base_parsed) and needs to be
       // re-created.
       DoCanonicalize(temporary_output.data(), temporary_output.length(), true,
-                     charset_converter, output, output_parsed);
+                     REMOVE_WHITESPACE, charset_converter, output,
+                     output_parsed);
       return did_resolve_succeed;
     }
   } else if (is_relative) {
@@ -296,8 +308,9 @@ bool DoResolveRelative(const char* base_spec,
   }
 
   // Not relative, canonicalize the input.
-  return DoCanonicalize(relative, relative_length, true, charset_converter,
-                        output, output_parsed);
+  return DoCanonicalize(relative, relative_length, true,
+                        DO_NOT_REMOVE_WHITESPACE, charset_converter, output,
+                        output_parsed);
 }
 
 template<typename CHAR>
@@ -344,8 +357,8 @@ bool DoReplaceComponents(const char* spec,
     RawCanonOutput<128> recanonicalized;
     Parsed recanonicalized_parsed;
     DoCanonicalize(scheme_replaced.data(), scheme_replaced.length(), true,
-                   charset_converter,
-                   &recanonicalized, &recanonicalized_parsed);
+                   REMOVE_WHITESPACE, charset_converter, &recanonicalized,
+                   &recanonicalized_parsed);
 
     // Recurse using the version with the scheme already replaced. This will now
     // use the replacement rules for the new scheme.
@@ -531,8 +544,8 @@ bool Canonicalize(const char* spec,
                   CharsetConverter* charset_converter,
                   CanonOutput* output,
                   Parsed* output_parsed) {
-  return DoCanonicalize(spec, spec_len, trim_path_end, charset_converter,
-                        output, output_parsed);
+  return DoCanonicalize(spec, spec_len, trim_path_end, REMOVE_WHITESPACE,
+                        charset_converter, output, output_parsed);
 }
 
 bool Canonicalize(const base::char16* spec,
@@ -541,8 +554,8 @@ bool Canonicalize(const base::char16* spec,
                   CharsetConverter* charset_converter,
                   CanonOutput* output,
                   Parsed* output_parsed) {
-  return DoCanonicalize(spec, spec_len, trim_path_end, charset_converter,
-                        output, output_parsed);
+  return DoCanonicalize(spec, spec_len, trim_path_end, REMOVE_WHITESPACE,
+                        charset_converter, output, output_parsed);
 }
 
 bool ResolveRelative(const char* base_spec,
